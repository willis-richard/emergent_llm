"""
Strategy descriptions for public_goods_prompt.

Generated with:
- Provider: OpenAI
- Model: gpt-5-mini
"""


description_COLLECTIVE_1 = '''
Strategy name: Thresholded Reciprocal with Individual Reputation and Forgiveness (TRIF)

Principles (collective mindset)
- Aim to sustain high group contributions by rewarding rounds with substantial cooperation and withholding cooperation when many players free-ride.
- Be lenient to one-off mistakes but punish persistent defectors enough to make cooperation attractive in repeated interaction.
- Use only observed history and game parameters (n, r, k); do not assume coordination or shared norms.

Parameters (derived from game parameters; fixed at start)
- Lookback window L = min(5, r). (Use up to five recent rounds to estimate behavior; smaller if game is short.)
- Majority threshold M = ceil(n/2). (Treat a majority cooperating as evidence of a cooperative norm.)
- Tolerated slip D_allow = max(1, floor(n/8)). (Small number of simultaneous defectors tolerated without group punishment.)
- Punishment length P = 2 (defect for P rounds in response to observed breakdowns).
- Forgiveness requirement S = 2 (require S consecutive rounds meeting cooperation criteria to return to full trust).
- Endgame caution window E = min(2, r) (apply special rules in the last E rounds).

State I maintain
- For each player j (including myself), a running cooperation score s_j initialized at 1.0. After each round, update s_j by exponential smoothing: s_j <- 0.6*s_j + 0.4*a_j where a_j is 1 if j cooperated this round, 0 if defected. (This gives more weight to recent behavior while keeping memory.)
- A local punishment counter punish_count (initially 0) indicating how many rounds I will defect as punishment before reconsidering.
- A consecutive-good-rounds counter good_streak (initially 0).

Action rules (played each round t from 1..r)
1. First round:
   - Cooperate. (Begin by signaling willingness to cooperate.)

2. After each observed round (update s_j and history):
   - Compute C_prev = number of players who cooperated in the immediately preceding round.
   - Compute avg_other_score = (sum_{j != me} s_j) / (n-1).
   - Identify persistent defectors: any j with s_j < 0.25 is treated as low-reputation.

3. Punishment handling:
   - If punish_count > 0: play D this round and decrement punish_count by 1. (Carry out the punishment phase.)

4. Otherwise (not currently punishing), decide whether to C or D this round:
   A. Endgame special-case (round t in last E rounds):
      - If t == r (final round): play D. (Default safe choice in a finite endgame where backward induction can unravel cooperation.)
      - If t == r-1 and E >= 2: play C only if both (i) C_prev == n (everyone cooperated last round) OR (ii) avg_other_score >= 0.9 and no persistent defectors; otherwise play D. (Be cautious near the end but allow a final cooperative payoff if strong evidence of mutual cooperation exists.)
   B. Normal rounds (not in punishment, not final cautious moments):
      - If C_prev >= n - D_allow:
          - Many cooperated last round (at most D_allow defectors): play C. Rationale: tolerate a small number of slips to avoid collapse from noise or isolated free-riders.
      - Else if C_prev >= M:
          - A majority cooperated last round: play C. (Support and stabilize majority cooperation.)
      - Else:
          - Play D this round, and set punish_count = P. Also reset good_streak = 0. (Respond to clear breakdowns by a brief, collective withholding of cooperation to signal cost of defection.)

5. Forgiveness and recovery:
   - After each round where I played C and the criteria in step 4 would have produced C (i.e., group shows enough cooperation), increment good_streak by 1. If good_streak >= S, reset punish_count = 0 and gradually restore trust (smoothing continues).
   - If a persistent defector (s_j < 0.25) returns to cooperation over L recent rounds (s_j rises above 0.4), treat them as rehabilitated; allow cooperation under the normal rules.

6. Handling single/double defects during otherwise cooperative groups:
   - If exactly one (or up to D_allow) player defected while C_prev >= n - D_allow, do NOT trigger punishment phase against the whole group; instead decrease my trust score for that individual (via the smoothing update) but continue cooperating. If that individual defects repeatedly (s_j falls under 0.25), normal punishment logic will be triggered as group cooperation falls.

Why this is adaptive and robust
- Starts cooperative to give mutual cooperation a chance.
- Uses simple, observable statistics (round cooperators and per-player reputation) so it adapts to many strategy types (unconditional cooperators, unconditional defectors, conditional cooperators, noisy players).
- Tolerates occasional slips and noise (prevents cascade collapse from single errors) but applies short, clear punishments for persistent breakdowns so that sustained free-riding is costly.
- Forgives after evidence of recovery so cooperative equilibria can re-emerge.
- Uses cautious behavior in the last rounds to limit exploitation when future punishment is impossible, while still allowing final cooperation if strong evidence of mutual cooperation exists.
- All rules depend only on n, r, k (via parameter choices above) and observed history; no communication or coordination is assumed.

Summary pseudocode (informal)
- Initialize s_j = 1 for all j, punish_count = 0, good_streak = 0.
- Round 1: play C.
- For each subsequent round:
  - Update s_j = 0.6*s_j + 0.4*a_j for each j after observing last round.
  - If punish_count > 0: play D; punish_count--.
  - Else apply endgame special-case if in last E rounds (see step 4.A).
  - Else compute C_prev, avg_other_score:
    - If C_prev >= n - D_allow or C_prev >= M: play C and increment good_streak (reset punish_count if good_streak >= S).
    - Else: play D; set punish_count = P; good_streak = 0.
- Continuously rehabilitate low s_j when they show recent cooperation.

This keeps the focus on maximizing collective welfare by supporting cooperative majorities, punishing persistent free-riding, and forgiving when cooperation returns.
'''

description_COLLECTIVE_2 = '''
Adaptive Collective Win‑Stay / Lose‑Shift (AC‑WSLS)

Goal: sustain high group cooperation while avoiding long runs of exploitation. The rule set uses only the game parameters (n, r, k) and observed history (every player’s past actions and payoffs). It is deterministic, easy to compute, forgiving, and biased slightly toward cooperation to support collective welfare.

Definitions used by the rule:
- In round t, denote my action last round by a_last ∈ {C,D} and my realized payoff last round by π_last.
- Let S_last = total contributions by all players in the previous round (an integer between 0 and n).
- Compute the one‑shot counterfactual payoff I would have received last round had I played the opposite action while everyone else’s actions remained the same. (This is directly computable from S_last and a_last.)
- “Win” means π_last ≥ counterfactual payoff (I did at least as well as I would have by switching); “Lose” means π_last < counterfactual payoff.

Core decision rule (applied each round except the last round; last round is handled below):
1. First round: cooperate (play C). This signals willingness to support the public good.
2. For rounds t = 2 .. r−1:
   - If Win (I did at least as well as by switching): repeat my previous action (win‑stay).
   - If Lose (I would have been better off switching): switch my action this round (lose‑shift).
   - Tie‑break: when π_last equals the counterfactual exactly, choose C (a small cooperative bias to support collective welfare).
3. Forgiveness and recovery are automatic in the WSLS rule: after a punishment-defection that yields a poor payoff, the rule switches back to cooperation; after cooperation that yields a good payoff, it continues. This produces short, targeted punishment instead of permanent collapse.

Additional collective safeguards (still depends only on observed history):
- If in the previous round S_last = n (everybody cooperated), always play C this round (reward full cooperation).
- If my own history shows I have been defecting for many rounds because I repeatedly lost when cooperating, the WSLS dynamics will attempt cooperation again when payoff conditions indicate it could help; no extra special-case needed.

Last round and endgame handling:
- In the final round t = r: defect (play D). Because there is no future to enforce reciprocity, defect is the safe one‑shot best response. (Do not exploit earlier rounds by defecting early because WSLS sustains cooperation until exploitation occurs; only the final round is an unavoidable endgame defection.)
- If you prefer a slightly more optimistic endgame in small r settings, an alternative safe variant is: if a unanimous cooperative streak (S_last = n) continued through round r−1, you may play C in round r; otherwise play D. (Either variant depends only on observed history; the default is to defect in round r.)

Why this is collective and robust:
- WSLS preserves cooperation when it is mutually profitable: if cooperating last round led to as-good-or-better payoff than defecting, it continues cooperating — this stabilizes mutually beneficial cooperation among many cooperators.
- It punishes exploitation quickly but briefly: when cooperating is exploited (you would have done better by defecting), you switch and thereby discourage persistent free‑riding without causing permanent collapse.
- It is forgiving: a short switch back to cooperation is automatic when the payoff environment improves, so occasional mistakes or noise from others do not lock you into permanent defection.
- The tie‑break bias toward cooperation supports group gains when the data are ambiguous.
- The final‑round defection avoids being systematically exploited in the terminal period.

Implementation notes (all computable from parameters and history):
- Counterfactual payoff calculation: from S_last and a_last, compute the payoff you would have obtained had your last action been flipped, holding others fixed (simple arithmetic using the payoff formula provided).
- No external coordination or communication is required. The rule uses only observed actions and payoffs.
- This strategy is fully specified for every round by the history and game length r; there are no hidden parameters or randomization (except the optional optimistic final‑round variant above).

Summary (short): Start by cooperating. In each nonfinal round, compare your actual payoff last round to the payoff you would have obtained by switching your last action; if you did at least as well, repeat the same action (win‑stay); if you would have done better by switching, switch now (lose‑shift). Tie → cooperate. In the final round, defect. This rule promotes stable collective cooperation, punishes exploitation briefly, and forgives to recover cooperation.
'''

description_COLLECTIVE_3 = '''
Name: Collective Conditional Cooperator with Proportional Retaliation and Forgiveness (CCCPR-F)

Goal: maximize long-run group payoff by sustaining cooperation when others are willing, while avoiding long or costly retaliation when exploited. The rule set is deterministic, uses only game parameters (n, r, k) and observed history (each player’s past C/D), and is adaptive to a wide range of opponent behaviors.

Derived constants (computed once at start):
- Memory window W = min(10, max(1, floor(r/5))) — use recent history but lengthen for longer games.
- Cooperation threshold τ:
  - if k/n >= 0.75 then τ = 0.45 (be more lenient when group benefit is large)
  - else if k/n >= 0.5 then τ = 0.50
  - else τ = 0.60 (be stricter when collective benefit is smaller)
- Small-noise tolerance ε = 0.20 (forgive occasional single-round slips)
- Base punishment length P_base = 2 rounds; maximum punishment P_max = min(4, max(1, floor(r/10)+1)).

State maintained (update each round from observed history):
- For every other player j, S_j = fraction of rounds (over the most recent min(W, t-1) rounds) in which j contributed.
- G = average of S_j over all j ≠ me (group cooperation rate among others in the memory window).
- last-round defect fraction f_last = (# of other players who chose D in previous round) / (n-1).
- A (possibly empty) set PunishTargets with an associated integer PunishUntilRound for the current active group punishment (if any). PunishTargets are identified when deliberate, repeated defection is detected (see below).

Decision rule for round t:

1. Final-round rule
   - If t == r (the last round), play D. (Backward induction: last-round defection is dominant.)

2. First-round rule
   - If t == 1, play C (start nice to give cooperation a chance).

3. If currently inside an active group punishment (current round ≤ PunishUntilRound):
   - Play D (continue the calibrated punishment).
   - After playing, re-evaluate S_j and G. If G has recovered above τ (others collectively resumed cooperation), clear PunishTargets and stop punishment immediately; return to cooperative evaluation next round.

4. Otherwise (normal evaluation, t in 2..r-1 and not in punishment):
   - Compute S_j and G as above and f_last.
   - If G ≥ τ: play C (group is sufficiently cooperative).
   - Else (G < τ):
     a. If f_last == 0: play C (no recent defections — allow recovery).
     b. Else if 0 < f_last ≤ ε: play C (forgive small slips/noise).
     c. Else (f_last > ε): trigger a calibrated, limited punishment:
        - Let m = number of other players with S_j ≤ 0.30 (chronic defectors in memory window).
        - Set punishment length P = min(P_max, P_base + floor(m/2)). (Longer if there are multiple persistent defectors, but capped.)
        - Set PunishTargets = {all players who defected in the most recent round or who have S_j ≤ 0.30}.
        - Set PunishUntilRound = current round + P - 1.
        - Play D this round (initiate punishment).
   - After playing, continue to next round and re-evaluate (punishment may be stopped early if collective cooperation returns to ≥ τ).

Additional notes for robustness and collective orientation:
- Punishment is short and proportional: we punish long enough to deter repeated exploitation but never indefinitely. This limits cost to the group and encourages return to cooperation.
- Punishment targets are identified by recent, repeated defection (low S_j) and recent defections; the rule avoids permanent ostracism for a single slip.
- The strategy is forgiving: small or isolated defections are tolerated to accommodate strategic experimentation or occasional errors; the strategy resumes cooperation as soon as others’ cooperative behavior recovers (G ≥ τ).
- The strategy is collective: it prioritizes restoring and maintaining high group cooperation (cooperating whenever the group is sufficiently cooperative), and when necessary imposes limited, proportionate costs on defectors rather than continuous mutual defection.
- Endgame behavior: because the one-shot incentive is to defect in the last round, CCCPR-F defects in round r. This preserves robustness to pure defectors in the final move while still attempting to sustain cooperation earlier.

Summary of intuitive behavior:
- Start cooperative to signal willingness.
- Cooperate whenever the recent average cooperation of others is at or above a threshold tuned by k and n.
- Forgive occasional or rare defections.
- If defections are nontrivial, retaliate by defecting for a short, proportional number of rounds targeted at the recent/persistent defectors.
- Stop punishing as soon as group cooperation is restored.
- Defect in the last round.

This procedure is transparent, parameterized only by (n, r, k) and observable actions, encourages collective welfare, and is robust: it resists exploitation by persistent defectors while minimizing unnecessary costs from long punishments and tolerating occasional deviations.
'''

description_COLLECTIVE_4 = '''
Strategy name: Adaptive Collective Conditional Cooperation (ACCC)

High-level aim
- Promote and maintain high group contributions whenever others are cooperating, while defending the group against sustained free-riding with short, predictable punishments and prompt forgiveness. The strategy is collective in intent: it sacrifices short-term private payoff occasionally to sustain long-run group gains, but it avoids being a permanent sucker by responding to persistent defection.

State and obvious variables used
- n, r, k (game parameters).
- t = current round number (1..r).
- History: for each past round s < t we observe each player’s contribution (0/1).
- W = min(4, max(1, r-1)): look-back window in rounds used for short-term statistics.
- Remaining rounds left = R = r − t + 1 (including current decision for round t).
- A cooperative state flag (either “Cooperate-mode” or “Punish-mode”).
- A Punishment counter when in Punish-mode.

Initialization and edge cases
1. If r = 1 (single-shot): defect (D). No future to sustain cooperation.
2. Otherwise (r ≥ 2): start in Cooperate-mode and play C in round 1 (signal willingness to cooperate).
3. Final round: always defect (D) in round r (no future to enforce cooperation). If r is 2, follow this rule (cooperate round 1, defect round 2).

Core decision rules (for rounds t with 1 <= t < r)
I. Compute recent cooperation statistics from history:
   - For each of the last up to W rounds (s = max(1,t−W) … t−1), compute fraction of players who contributed in that round (fraction includes all players except that this is just observed past data).
   - Let RecentFraction = average of those fractions. If there is no past round (t=1) treat RecentFraction as 1.0 (encouraging first-round cooperation).

II. Cooperate-mode behavior
   - Default action while in Cooperate-mode: contribute (C).
   - But if RecentFraction falls below a tolerance threshold T_low, switch to Punish-mode and begin punishment (see below).
   - T_low = 0.5 (i.e., if on average fewer than half the group has been contributing recently, the collective is failing enough to justify punishment).
   - Small dip tolerance: to avoid overreacting to one noisy round, require RecentFraction < T_low (averaged over up to W rounds) before punishing.

III. Punish-mode behavior
   - Upon entering Punish-mode at the start of round t:
     - Set PunishmentLength P = min(3, max(1, floor(R/4))). (Short, finite punishment scaled down if few rounds remain.)
     - Defect (D) for the next P rounds (including the current round).
   - After a punishment block completes, do not immediately return to unconditional cooperation. Instead require rehabilitation:
     - Observe the next H consecutive rounds (H = min(2, max(1, floor(W/2)))).
     - If, during those H rounds, the average fraction of contributors in the group (RecentFraction over those rounds) is >= T_high, then switch back to Cooperate-mode and resume contributing.
     - Otherwise, re-enter Punish-mode for another P' rounds, where P' = min(P+1, R_remaining/2 rounded down) — i.e., escalate modestly but bounded by remaining rounds.
   - T_high = 0.8 (high bar for forgiveness: the group must show clear return to cooperation).

IV. Ongoing adaptation and proportionality
   - Punishment length and escalation are deliberately short and bounded to be credible but not ruinous. Punishments are group-level (we withhold contribution) rather than trying to single out players, because only group-level withholding is available as credible leverage.
   - If the group returns to consistent cooperation (RecentFraction >= T_high for H consecutive rounds), stop punishing and resume contribution to rebuild group welfare.
   - If defection is only occasional or noisy (one or two defectors in a window), the averaging and thresholds avoid triggering punishment. This gives forgiveness for mistakes and robustness to noisy opponents.

V. Last-round and endgame adaptation
   - Round r: always defect (D).
   - If only a very small number of rounds remain (R <= 2), reduce punishment lengths to avoid wasting the last rounds on mutual mutual harm: set P = 1 in such cases and require H = 1 for rehabilitation.
   - If most opponents are known to be unconditional cooperators (they contributed in every observed round so far), remain in Cooperate-mode even late in the game until r−1, but still defect in round r.

Additional practical points (collective mindset)
- The strategy sacrifices one token occasionally to rebuild long-term cooperation, but it never pays out perpetual tolerance: repeated group-level defection triggers predictable short punishments that deter exploitation.
- The strategy is forgiving and noise-tolerant: it reacts to sustained patterns, not single mistakes.
- It is transparent in spirit: contributions signal willingness to cooperate; sustained coordinated defection by others is met by short, bounded group-level withholding, then a clear rule for rehabilitation so cooperation can resume.
- Against pure defectors it will stop being exploited: after detecting persistent low RecentFraction it will withhold contribution enough to reduce exploiter gains.
- Against cooperative strategies it achieves near-full cooperation except for the final-round defection.

Summary in one paragraph
Start by cooperating to signal collectiveness. Measure the recent average fraction of contributors over a short window. Cooperate as long as that recent average stays above 50%. If the recent average falls below 50%, switch to a short, bounded punishment phase of defection (typically 1–3 rounds, shorter near the end of the game). After punishment require a clear rebound (high recent contribution rate, e.g. ≥ 80% for a short rehabilitation window) before returning to cooperation. Always defect in the final round. Use short, proportionate punishments and prompt forgiveness so the group can quickly return to mutually beneficial cooperation while avoiding long-term exploitation.
'''

description_COLLECTIVE_5 = '''
Collective conditional-cooperation with graduated punishment and forgiveness

Principles (collective mindset)
- Prefer mutual contributions whenever doing so is plausible — that maximizes group welfare and tends to produce higher long-run payoffs for everyone.
- Be reciprocal: reward rounds that look cooperative, punish rounds that show exploitation, but avoid permanent collapse by forgiving and probing for recovery.
- Be cautious in the final round(s) where future punishments are not possible.

Setup (computed from known parameters n, k, r)
- Majority threshold M = ceil(n / 2). Use a simple majority as the signal that the group is broadly cooperating.
- Short punishment cap P_max = min(4, max(1, floor(r / 10))). (Punishments are short and proportional to game length.)
- Resignation window W = min(r, 6). Resignation threshold R_th = 0.30 (if cooperation has been very low recently, stop trying to restore cooperation except for occasional probes).
- Probe interval L = max(4, floor(r / 6)). When “resigned”, perform a cooperation probe every L rounds to test whether the group has begun cooperating again.

State variables (maintain in memory)
- mode ∈ {cooperative, punishing, resigned}
- punishment_timer (integer ≥ 0)
- last_punish_round (round index when punishment started; used only for bookkeeping)

Decision rules (applied each round t = 1..r)
1) First round (t = 1)
- Cooperate (contribute 1). Start in mode = cooperative, punishment_timer = 0.

2) Final round (t = r)
- Defect (contribute 0). There is no future to enforce cooperation reliably; defecting is individually dominant in the last stage.

3) Otherwise (1 < t < r):
A. If mode == resigned:
  - If this round is a probe round (i.e., (t mod L) == 0): cooperate this round to test whether others will respond.
  - Otherwise defect.
  - After each round while resigned, check the cooperation rate over the last W rounds; if that rate ≥ M/n (i.e., majority in the recent window), switch mode → cooperative, reset punishment_timer = 0.

B. If punishment_timer > 0 (we are in an ongoing punishment phase):
  - Defect this round.
  - Decrement punishment_timer by 1.
  - After decrementing, if punishment_timer == 0 then: examine cooperation in the most recent two rounds (the last round before the end of punishment and the round just ended). If majority cooperation appears (≥ M) in that small post-punishment window, switch mode → cooperative. If not, set punishment_timer = min(P_max, 1 + number_of_defectors_in_most_recent_round) to continue a short, proportionate punishment (this implements graduated escalation with a cap).
  - Additionally, if over the last W rounds the fraction of cooperators (count of cooperators per round averaged) is < R_th, switch to mode = resigned.

C. If mode == cooperative and punishment_timer == 0:
  - Look at the previous round (t-1). Let c_last = number of players who cooperated in t-1 (0..n).
  - If c_last == n (unanimous cooperation in the last round): cooperate.
  - Else if c_last ≥ M (a majority cooperated in the last round): cooperate (be lenient — reward near-cooperation to help restore full cooperation).
  - Else (strict minority cooperated; evidence of exploitation):
    - Enter punishment: set mode → punishing and set punishment_timer = min(P_max, 1 + (n - c_last)). Immediately defect this round (start the punishment).
    - If after entering punishment you observe that the recent cooperation rate over the last W rounds < R_th, switch to mode → resigned (see above).

4) Forgiveness and recovery (general)
- Punishments are short and proportional to the observed level of defection; they are intended to deter free-riding but not to destroy cooperation forever.
- After a punishment phase ends, the strategy returns to cooperation as soon as there is clear evidence (majority) that others are cooperating again. This prevents long vendettas and encourages re-establishment of public-good contributions.
- If the group remains largely uncooperative for a sustained short window (W rounds), go into resigned mode (stop trying to re-establish cooperation except for occasional probes). This prevents repeated costly punishments against persistent defectors and preserves our own payoff when the group clearly will not cooperate.

Design rationale and robustness
- Starting cooperatively signals willingness to form a collective outcome and benefits unconditional cooperators and conditional cooperators.
- Using a majority threshold M makes the rule robust to noise and small deviations and avoids overreacting to one-off mistakes or random behavior by a single player.
- Graduated punishment proportional to how many defected avoids overpunishing and makes retaliation interpretable by others (they can infer why we punished and how long).
- Forgiveness (short punishments, immediate return on evidence of majority cooperation) prevents collapse and supports recovery of cooperation.
- Resigned mode avoids wasting payoff on repeated punishments in hopeless groups but still probes occasionally to capture opportunities if the group changes behavior.
- Last-round defection prevents exploitation in the final stage; the short punishments and probing balance exploitation risk vs. chance to restore cooperation earlier.

Edge cases
- If n = 2 (pairwise PGG reduces to a symmetrical two-player dilemma): majority threshold equals 1 — the rules still work (cooperate after mutual cooperation, punish when partner defects).
- If k is small (close to 1) so cooperation yields little group benefit: the strategy still favors cooperation early but will quickly switch to resigned if others do not reciprocate, limiting losses.
- If many players are unconditional cooperators: the strategy benefits them and sustains cooperation.
- If many players are unconditional defectors or noisy defectors: the strategy quickly (but not permanently) punishes, then gives up after a short window and probes occasionally.
- If opponents punish harshly and incoherently: short, proportionate punishments and forgiveness reduce likelihood of mutual escalation.

Summary (one-line rule)
- Start by cooperating; cooperate whenever a majority cooperated recently; when a minority defects, punish briefly in proportion to the size of defection (capped), then forgive quickly if cooperation returns; if cooperation remains low for a short window, resign to defection but probe occasionally; always defect in the final round.
'''

description_COLLECTIVE_6 = '''
Collective Conditional-Cooperation (CCC) — a simple, adaptive, forgiving strategy that maximizes collective welfare while avoiding long-term exploitation.

Principles
- Start by trying to establish group cooperation quickly.
- Cooperate when enough other players are cooperating recently.
- Withhold contribution (punish) when the group shows clear signs of free-riding.
- Punish in a limited, proportional, and forgiving way so cooperation can be re-established.
- Be conservative in the final rounds to avoid being exploited by endgame defectors.

Parameters (computed from game inputs r, n, k)
- Memory window W = min(5, max(1, round(sqrt(r)))) — how many recent rounds to judge behavior.
- Forgiveness window R = 2 — number of consecutive “good” rounds required to resume cooperation after punishment.
- Punishment length cap P_max = max(1, round(0.2 * r)) — longest punishment phase for persistent defection.
- Cooperation threshold theta (fraction of other players cooperating, evaluated over the last round or last W rounds):
  - If k/n >= 0.6, theta = 0.40 (public good is strong → be more lenient).
  - If k/n <= 0.4, theta = 0.60 (public good is weak → be stricter).
  - Otherwise theta = 0.50.
(These thresholds adapt to how valuable the public good is: stronger goods justify more trust.)

State variables tracked from history
- For each player j ≠ me: f_j = fraction of rounds (last W) in which j cooperated.
- Group recent cooperation F_last = fraction of players (excluding me) who cooperated in the immediately previous round.
- Group recent average F_avg = average_j f_j (average cooperation rate among others over last W).
- Punishment timer t_punish (0 when not punishing).

Decision rules (round t)
1. First round (t = 1): Cooperate. Signal willingness to form a cooperative norm.

2. If t == r (final round): Defect. (Avoid being exploited in the last, one-shot incentive.)

3. Otherwise evaluate recent behavior:
   - Compute F_last and F_avg as above.
   - Detect a defection event:
     - A “bad round” is when F_last < theta (i.e., fewer than the threshold fraction of others cooperated last round).
     - Detect persistent defectors if any player j has f_j < 0.25 and has defected in the last round.

4. Punishment entry:
   - If not currently punishing (t_punish == 0) and a bad round occurred, start a punishment phase:
     - Set t_punish = min(P_max, 1 + number_of_players_with_f_j < 0.5).
     - Immediately defect this round (withhold contribution).
     - Rationale: withhold contribution to reduce the payoff advantage of free-riders and signal costs of defection.

5. Punishment continuation and proportionality:
   - While t_punish > 0:
     - Defect this round.
     - After the round, decrement t_punish by 1 if the group shows improvement (F_last >= theta or F_avg rises compared to the round before punishment); otherwise keep punishing up to the cap.
     - If punish was aimed at specific persistent defectors and they have increased their f_j above 0.5, reduce t_punish faster.

6. Forgiveness and resumption of cooperation:
   - After punishment ends, require R consecutive “good” rounds before resuming unconditional cooperation:
     - During these R rounds, cooperate if F_last >= theta; otherwise re-enter punishment.
   - Once R consecutive good rounds are observed, resume normal cooperative policy (see rule 7).

7. Normal cooperative policy (when not in punishment or cooldown):
   - If F_last >= theta OR F_avg >= theta, Cooperate.
   - Otherwise, Defect (and if the bad condition is serious, enter punishment as in rule 4).

8. Targeted adjustment for persistent defectors:
   - If a small number of players persistently defect (f_j < 0.25 over W) while the rest cooperate:
     - Use proportional punishment: defect until the fraction of cooperating players among others (excluding those persistently defecting) recovers above theta, and require persistent defectors to show at least one cooperating round in W before forgiving fully.
     - This keeps punishment concentrated and avoids punishing well-behaved cooperators indefinitely.

9. Robustness notes
   - The approach is memory-limited (W small) so it adapts quickly to changing opponent behavior and does not lock into permanent retaliation.
   - Punishment is limited in duration (P_max) and conditional on observed improvement, preventing long-term mutual losses.
   - Starting with cooperation creates opportunities to reach high-payoff equilibria; the adaptive threshold theta uses k and n to tune trust.
   - Final-round defection prevents being exploited by strategies that take advantage of cooperative endgame signals.

Summary intuition
- Try to cooperate early and when most others do.
- Withhold cooperation briefly and proportionally when the group shows free-riding, but forgive quickly when cooperation returns.
- Use short memory and bounded punishment so the group can re-coordinate on high-welfare play.
- Adjust tolerance for occasional defections according to how strong the public good (k/n) is, and always avoid exploitation in the final round.
'''

description_COLLECTIVE_7 = '''
Name: Adaptive Collective Conditional Cooperation (ACCC)

Goal: Maximize collective payoff by sustaining mutual cooperation when others reciprocate, while limiting exploitation by defectors. The rule set is deterministic, uses only game parameters (n, r, k) and observed history, and is deliberately forgiving so cooperation can be re-established.

Parameters computed from game size (fixed, known at start)
- Memory window m = max(1, floor(r/5)). (Uses a window of recent rounds; short games use small m.)
- Individual cooperation threshold T_indiv = 0.5.
- Group cooperation high threshold T_high = 0.75.
- Group cooperation low threshold T_low = 0.40.
- Minimal punishment length base p_base = 1 (punishment lengths are small and proportional to observed defection).

Definitions (computed each decision round t)
- For each player j (including myself) compute coop_rate_j = fraction of rounds in the last m rounds in which j contributed (use fewer rounds if t<m).
- Group_recent_rate = average of coop_rate_j across all other players (exclude self).
- Most_recent_round_contributions = number of players who contributed in last round.

Decision rules (rounds 1..r)
1. First round (t = 1)
   - Play C (contribute 1). Start by signaling willingness to cooperate.

2. Non-final rounds (1 < t < r)
   A. If all other players have coop_rate_j = 1 over the last m rounds (unanimous recent cooperation), play C.
   B. Else if Group_recent_rate >= T_high, play C (the group is largely cooperative; reward and sustain cooperation).
   C. Else if Group_recent_rate <= T_low, play D (the group is mostly defecting; avoid giving free benefits).
   D. Else (intermediate region):
      - Identify clear defectors: set Defectors = { j : coop_rate_j < T_indiv }.
      - If Defectors is empty:
         - Use reciprocity by matching recent group behavior: if I cooperated in the last round and a majority of other players cooperated in the last round (Most_recent_round_contributions > n/2), play C; otherwise play D.
      - If Defectors non-empty:
         - Enter targeted, proportional punishment against those defectors:
           * Punishment rule: defect (play D) until the punished player's coop_rate_j over the most recent m rounds rises to at least T_indiv. For proportionality, after each round of punishment reduce remaining punishment length by 1 if the punished player contributed in that round; otherwise continue.
           * While punishing, still monitor group behavior: if overall Group_recent_rate rises above T_high during punishment, stop punishment early and resume cooperation with the whole group.
         - If more than half of players are clear defectors (|Defectors| > n/2), switch to collective safety mode: play D until Group_recent_rate recovers above T_high.

   Notes on punishment and forgiveness:
   - Punishments are short and explicitly conditional: they end as soon as the punished player's recent behavior indicates reform.
   - This prevents long cycles of mutual defection and makes cooperation attractive to return to.
   - Punish individuals (by defecting) rather than indiscriminately punishing the whole group when possible, to keep cooperation incentives for bystanders.

3. Final round (t = r)
   - Default: play D (no future to enforce cooperation).
   - Exception (collective last-round cooperation): if the last m rounds show stable unanimous cooperation among all players (every player’s coop_rate_j = 1 over that window), then play C to secure the higher collective payoff in the final round. This is only done when cooperation is already fully established and credible from history.

Additional operational rules and edge cases
- Short games (r small): m will be small; all calculations use the available history (do not pad).
- Noisy or rare one-off defections: a single defection by one player in an otherwise cooperative history triggers only short, targeted punishment (often a single-round D) before resuming cooperation. This protects against isolated opportunism while being forgiving.
- Widespread collapse: if cooperation collapses (Group_recent_rate stays below T_low for multiple successive windows), stay defecting until you observe a clear majority re-adopt cooperation (Group_recent_rate >= T_high) or unanimous behavior in the window.
- Determinism: all choices are fully determined by the computed coop_rate values and thresholds—no randomization or off-book coordination.

Collective mindset explanation (how this promotes group welfare)
- Start cooperative to signal willingness to build a cooperative equilibrium.
- Reward and sustain groups that show high recent cooperation (T_high), restoring and preserving the socially optimal all-C path.
- Use small, targeted punishments that are proportional and forgivable to deter persistent free-riders without destroying cooperation among mostly-cooperative players.
- Avoid being exploited by defecting when the group has collapsed or when many players are persistent defectors.
- Prefer full-group cooperation in the last round only when cooperation is already proven and unanimous, preserving collective payoff when it is safe and credible.

Behavior summary
- Open with cooperation.
- Cooperate while most others cooperate.
- Target and proportionally punish clear defectors, but forgive quickly when they reform.
- Revert to defection if cooperation collapses; return to cooperation when the group re-establishes cooperative behavior.
- Defect in final round unless cooperation has been perfectly stable and unanimous in recent history.

This strategy is simple, adaptive to a wide variety of opponent behaviors, aims to sustain collective cooperation when feasible, guards against exploitation, and uses forgiving, proportional punishment to restore cooperation rather than forcing permanent breakdown.
'''

description_COLLECTIVE_8 = '''
Collective Adaptive Pavlov (CAP) — a simple, forgiving, group-aware rule that starts cooperative, rewards cooperation, punishes defections briefly, and forgives to restore collective welfare.

Parameters (computed from game parameters or fixed small constants)
- n, k, r: given game parameters.
- theta_coop = max(0.5, k / n). (Group cooperation threshold: require at least this fraction of players to have cooperated in the previous round to treat the group as “cooperating.”)
- P = 2. (punishment length in full rounds)
- epsilon = 0.05. (small exploration / forgiveness probability)
- delta = 0 (tie-breaking: treat equal payoffs as “no exploitation”)

State kept from history
- last_round_contributions (how many players contributed last round).
- my_last_action and my_last_round_payoff.
- punishment_counter (how many more rounds we will defect as punishment; 0 means not punishing).

Decision rules (run each round t = 1..r)
1. First round (t = 1)
   - Play C (cooperate). This signals a collective mindset and tests whether others will reciprocate.

2. Final round (t = r)
   - Play D (defect). The one-shot dominant action; avoid being exploited in a final-stage-only interaction.

3. Penalty window (if punishment_counter > 0 and t < r)
   - Play D, decrement punishment_counter by 1 after the round.
   - Exception (forgiveness test): with probability epsilon, play C instead of D to probe whether cooperation has returned early.

4. Normal adaptive step (t > 1 and t < r and punishment_counter = 0)
   - Compute what your payoff last round actually was: pi_actual = (1 - my_last_action) + (k / n) * last_round_contributions.
   - Compute the payoff you would have gotten last round if you had defected instead (holding others’ contributions fixed): pi_if_defect = 0 + (k / n) * (last_round_contributions - my_last_action).
   - If pi_if_defect > pi_actual + delta (i.e., you would have been strictly better off by defecting last round):
       - Treat this as exploitation. Enter punishment: set punishment_counter = P and play D this round.
       - Rationale: a short firm reply discourages unilateral exploitation without ending cooperation forever.
   - Else (you were not exploited last round):
       - Use a group-oriented test to decide between C and D:
         a) If last_round_contributions / n >= theta_coop:
            - The group is cooperating enough — play C.
         b) Otherwise:
            - The group has been insufficiently cooperative — play D.
       - In either branch, with small probability epsilon flip to C (forgiveness/exploration) even if you would play D; this allows recovery from mutual defection and prevents deadlocks.

5. Extra rule to avoid needless escalation
   - If many players (e.g., > 1) defected in the last round but your own last-round payoff was still high (pi_actual >= pi_if_defect), do not punish — prefer rejoining cooperation when group signals are mixed. Punishment is only triggered by personal exploitation, not by distant group noise.

Rationale and properties
- Collective mindset: starts cooperative and prefers cooperation when the observed group cooperation rate meets a reasonable threshold (theta_coop). The threshold scales with k/n: when the public good is relatively more productive, we require at least a modest majority to continue cooperating.
- Personal-adaptive Pavlovic reaction: we punish only when we were personally better off defecting last round — that signals we were exploited. This ties retaliation to direct experience rather than noisy hypotheses about motives.
- Short, limited punishment (P rounds) prevents permanent mutual defection (avoids "grim" outcomes) but still provides deterrence. Small-probability forgiveness (epsilon) allows recovery from noise or mistaken punishment.
- Endgame safety: defect in the last round to avoid final-stage exploitation. (If you prefer to risk cooperating with obviously naive opponents in final round for extra group payoff, you can set the last-round rule to use the same adaptive test instead of forced D; the safe default is D.)
- Robustness: uses only observable history and game parameters, tolerates noise, punishes exploiters, forgives, and favors collective outcomes when the group shows sufficient cooperation.

Summary pseudo-flow (plain language)
- Round 1: cooperate.
- Each later round until the last:
  - If currently serving a punishment period: defect (but occasionally probe with cooperation).
  - Else, if you would have gained by defecting last round (given what others did): begin a short punishment and defect.
  - Otherwise, cooperate if a sufficient fraction of players cooperated last round (threshold = max(0.5, k/n)); otherwise defect. Occasionally cooperate anyway with small probability to restore cooperation.
- Last round: defect.

This strategy is simple, relies only on parameters and observed history, promotes group welfare when others reciprocate, is robust to exploitation, and is forgiving enough to recover cooperation after mistakes.
'''

description_COLLECTIVE_9 = '''
Collective-Conditional-Cooperator with Graduated Punishment and Forgiveness (CCC-GPF)

Goal: maximize collective welfare by sustaining high contribution levels, while being robust to free-riders and mistakes. The strategy uses only game parameters (n, r, k) and observed history (who contributed each round and payoffs).

Parameter setup (computed once at start)
- If r = 1: special-case (see “Edge cases”).
- Memory window m = max(3, min(10, ceil(r/10))). (Longer games use slightly longer memory; m is at least 3 to filter noise.)
- Coop-sensitivity threshold qc = 0.5 + 0.2 * (1 - k/n). (If the public-good multiplier gives less private return (k/n small), require stronger evidence of cooperation before continuing cooperation; if k/n is large, be a bit more permissive.)
- Base punishment length p_base = 1 round. Maximum punishment length p_max = min(3, r - 1). (Keep punishments short so cooperation can recover.)
- Probation length after punishment: 1 test cooperation round.

State and bookkeeping
- cooperative_state: boolean, initially true.
- If cooperative_state = true, I intend to contribute, subject to the checks below.
- Track the last m rounds of observed total contributions (fraction of players contributing each round) and each individual player’s recent contribution record (for diagnosing whether deviation is isolated).

Decision rules (each round t, 1-indexed)
1. Edge-case checks:
   - If r = 1: defect (D). No future to enforce cooperation.
   - If t = r (the final round): defect (D). (No future punishments; defecting prevents exploitation in endgame.)
   - If remaining rounds rem = r - t are less than 1, obey final-round rule above.

2. Normal rounds (1 < = t < r or t = 1 with r > 1):
   - Round 1: cooperate (C). Start by signaling willingness to sustain cooperation.
   - For t > 1 compute:
     a. recent_group_fraction = average over the last min(m, t-1) rounds of (total contributors / n).
     b. last_round_fraction = (contributors in round t-1) / n.
     c. recent_individual_defectors = list of players who contributed less than expected in the last min(m, t-1) rounds (used for diagnosis).

   - If cooperative_state = true:
     - If recent_group_fraction >= qc: continue cooperating (C). The group shows sufficient cooperative behavior to justify maintaining cooperation.
     - If recent_group_fraction < qc:
       * Switch cooperative_state to false (enter punishment phase).
       * Set punishment_length p = min(p_max, p_base + ceil((qc - recent_group_fraction) * n)). (Punishment length grows modestly with the shortfall to make responses proportional.)
       * Defect this round (D) and begin counting down p (do not defect in the final round; reduce p if close to end).
       * Record whether the shortfall appears to be isolated (e.g., only 1 player consistently defecting) or widespread.

   - If cooperative_state = false (punishment or probation):
     - If currently in punishment countdown (> 0): defect (D) and decrement countdown. If punishment would extend into final round, truncate so final-round rule still leads to a defection in the last round.
     - After punishment countdown reaches 0: enter probation:
       * Probation round: cooperate (C) as a test.
       * Observe next round’s group behavior:
         - If, during probation or immediately thereafter, recent_group_fraction (computed over the most recent min(m, t) rounds) recovers to >= qc: set cooperative_state = true and resume cooperation.
         - If recovery fails (recent_group_fraction < qc): repeat punishment: set p = min(p_max, p_base + ceil((qc - recent_group_fraction) * n)) and defect for p rounds. (Punishment cycles are short and followed by an explicit attempt to restore cooperation.)

Targeted response to isolated defectors
- If the shortfall is clearly caused by a small number s of repeat defectors (identified by their individual records over the last m rounds), punish proportionally but briefly: set p = min(p_max, max(1, ceil(s/2))). This penalizes repeated individual free-riders but avoids collapsing group cooperation for one or two mistakes.

Forgiveness and error tolerance
- All punishments are short and followed by a probationary cooperative test. This design tolerates mistakes and noisy behavior while still deterring persistent exploitation.
- If the group rapidly returns to cooperative behavior after probation, immediately resume cooperative_state.

Additional robustness notes
- The strategy always begins by cooperating to invite collective welfare and uses public information (everyone’s past actions) to decide.
- The coop-sensitivity qc adapts to k and n so the strategy is more demanding when per-token private return is small and more forgiving when k/n is larger.
- Punishments are graduated and capped, preventing long destructive spirals while remaining credible enough to discourage sustained free-riding.
- Final-round defection prevents exploitation at the endgame; short punishments and probation reduce perverse incentives to defect earlier solely to avoid late retaliation.

Intended behavior summary
- Signal cooperation immediately, sustain cooperation while a clear majority (adjusted for k/n) is cooperating, respond promptly and proportionally when cooperation drops, and forgive quickly with a one-round test that allows re-establishment of cooperation. Defect in the final round. The policy favors collective outcomes but protects against exploitation and noise.
'''

description_COLLECTIVE_10 = '''
Name: Collective-First Conditional Cooperator (CFCC)

Goal: Sustain high group contribution when a substantial fraction of the group reciprocates, punish briefly and restore cooperation quickly when exploitation appears, and avoid being a pure sucker in the endgame. The rule set depends only on n, k, r and the observed history of contributions.

Parameters (computed from game parameters)
- Memory window w = min(5, r). (Use up to the last 5 rounds to smooth noise.)
- T_frac = clamp(1 - (k - 1) / (n - 1), lower = 0.5, upper = 0.9).
  - Intuition: when k is close to 1 cooperation yields small public benefit so require a high observed cooperation rate to justify contributing; when k is large be more tolerant.
- Threshold S = ceil(T_frac * n) (number of contributors in a round equivalent to the fraction threshold).

State
- punishment_counter (initially 0). When >0 the strategy defects; it counts down each round.
- history of observed contributions (all players, all past rounds).

Decision rules (each round t = 1..r)
1. Last-round rule
   - If t == r (the final round): play D (defect). No future to reward.

2. Early-round initialization
   - If t == 1: play C (cooperate) to try to seed cooperation.

3. Punishment handling
   - If punishment_counter > 0:
     - Play D this round.
     - Decrement punishment_counter by 1 afterwards.
     - After playing, re-evaluate history next round for possible forgiveness (see below).
     - (Punishment phases are short — see how they are triggered in step 5.)

4. Compute recent cooperation rate
   - Let m = min(w, t - 1) (number of past rounds available).
   - If m == 0 (only possible at t==1) treat recent cooperation rate R = 1.
   - Else let total_contribs = total number of contributions (by all players) in the last m rounds.
   - Let R = total_contribs / (n * m). (This is the average fraction of players who contributed per recent round.)

5. Main cooperation rule and punishment trigger
   - If R >= T_frac: play C.
     - If we had been in a punishment phase but the recent cooperation rate recovered to >= T_frac, reset punishment_counter to 0 and resume cooperating immediately (forgiveness).
   - If R < T_frac: the group is not cooperating enough.
     - Play D this round (protect against exploitation).
     - Trigger punishment: set punishment_counter = 1 (defect for one extra round beyond this one). The one-round punishment is short and proportional so as not to collapse cooperation with long vendettas; repeated low R will re-trigger repeated short punishments.

Additional refinements / notes (collective mindset)
- Collective aim: CFCC prefers mutual cooperation and tries to sustain it by cooperating early and whenever a substantial fraction of the group is reciprocating. The threshold T_frac is chosen from n and k so the strategy tolerates some free-riding when the public good is especially productive (large k) and demands stricter reciprocity when the public return is small.
- Forgiveness: punishments are brief (single-round) to avoid long mutual retaliation and to allow reestablishment of cooperation after shocks or a stray defection.
- Robustness: the rule uses a short memory window to smooth noisy behavior but react quickly to systematic defection; it punishes to deter exploiters but keeps punishment short to avoid exploitation via long grudges.
- Endgame: last-round defection prevents being exploited in a round with no future; because of this, CFCC may not fully sustain cooperation to the very last round when opponents are purely selfish, but it nevertheless preserves group welfare through most of the repeated interaction if enough players reciprocate.

Summary (operational)
- Round 1: C.
- Each non-final round: compute recent cooperation rate R over up to the last 5 rounds. If R >= T_frac → C. If R < T_frac → D and set a 1-round punishment (defect next round too unless cooperation recovers). Last round: D.
'''

description_COLLECTIVE_11 = '''
Name: Collective-Forgiving Majority (CFM)

Summary (one line)
- Start by offering cooperation, sustain cooperation when the group shows it, punish defections briefly and proportionally, forgive quickly to restore group gains; defect in the known final round.

Parameters computed from game parameters (only using n, k, r)
- threshold_fraction = max(0.5, min(0.8, k / n))
  - Rationale: require at least a majority (≥50%) to signal group momentum; raise the bar when the multiplier k makes collective returns especially large (so preserving cooperation is more valuable), but cap to avoid being unattainable.
- max_punish = min(3, max(1, floor(r / 10)))
  - Rationale: short, bounded punishments (long enough to deter but short enough to restore cooperation).
- history_window = min(10, r)
  - Rationale: use the recent window to detect persistent defectors.

State we maintain (derived from observed history only)
- For each player j: defect_count_j = number of rounds j defected in the last history_window rounds.
- global last_round_cooperators = number of players who contributed in the immediately preceding round.
- punish_timer (integer ≥ 0): remaining rounds of collective punishment we are currently carrying out; initialized 0.

Decision rules (per round t, using only parameters and full history)
1. Special-case terminal rounds:
   - If r = 1 (single-round game): defect (no future to sustain cooperation).
   - If t = r (final round): defect (no future benefit from cooperation).

2. First move (t = 1, and r > 1):
   - Cooperate. This signals willingness to build cooperation.

3. If punish_timer > 0:
   - Defect this round.
   - Decrement punish_timer by 1 at the end of the round.
   - (We punish collectively for a short, precommitted number of rounds, then stop.)

4. Otherwise (normal operation, not in punishment):
   - Compute f_prev = last_round_cooperators / n (fraction who cooperated last round).
   - Compute persistent_defectors = { j | defect_count_j ≥ ceil(history_window/2) }.
   - If f_prev ≥ threshold_fraction:
       - Cooperate. (Group shows sufficient cooperation; respond with cooperation.)
   - Else if f_prev == 0:
       - Defect. (Nobody cooperated last round; avoid being a lone cooperator.)
       - Set punish_timer := min(max_punish, 1 + |persistent_defectors|).
         (Start a short punishment proportional to number of persistent defectors.)
   - Else (0 < f_prev < threshold_fraction):
       - Use proportional, forgiving response:
         - With probability p = f_prev, Cooperate. With probability 1 − p, Defect.
         - If actual number of defectors last round exceeded (1 − threshold_fraction) * n (i.e., large shock), set punish_timer := min(max_punish, 1 + |persistent_defectors|).
       - Rationale: respond probabilistically so a small drop in cooperation does not trigger permanent mutual defection; the probability ties our willingness to cooperate to observed willingness from others.

5. After each round update:
   - Update defect_count_j for every player using the latest history_window rounds.
   - If a player's defect_count_j becomes very large relative to history_window (persistent defector), they increase punish_timer on the next triggering punishment, but do not cause permanent exclusion — punishment remains bounded and forgives.

Behavioral summary and rationale
- Collective mindset: We begin by offering cooperation, try to sustain collective welfare when the group demonstrates cooperation, and avoid continual mutual retaliation by forgiving quickly. Punishments are short and proportional to the observed degree and persistence of defection so as to deter exploitation but not collapse the group’s long-run welfare.
- Robustness:
  - Works against unconditional defectors (we stop cooperating when cooperation collapses and punish briefly).
  - Works against conditional cooperators (we reward visible cooperation immediately).
  - Avoids catastrophic permanent retaliation by bounding punishments and using probabilistic forgiveness, which helps recover cooperation even when noise or occasional mistakes occur.
  - Last-round behavior is backward-looking (defect) to avoid being exploited in the known terminal period while preserving cooperation until then.
- Minimal information use: decisions use only n, k, r and observed past actions/payoffs (no communication, no external coordination).

Edge cases
- r = 1: defect (no future).
- Very short games (r small): max_punish is small; punishments will be very short or zero to avoid useless endgame punishments.
- If everyone else cooperates every round we will always cooperate (except final round), maximizing group payoff.
- If the group shows noisy or oscillating cooperation, the probabilistic reaction avoids locking into mutual defection and helps re-establish cooperation.

Implementation notes (how to execute in tournament)
- Track last_round_cooperators each round and compute f_prev.
- Maintain per-player defect counts over the fixed history window.
- Maintain the punish_timer state and follow rules above deterministically except where a probability p = f_prev is used to decide cooperation when cooperation has weakened.
- All parameters are fixed functions of n, k, r as stated (no ad-hoc external tuning).
'''

description_COLLECTIVE_12 = '''
Strategy name: Conditional Collective Cooperator with Proportional Punishment (CCCPP)

Principles (collective mindset)
- Prefer and try to sustain high group cooperation because group payoff grows with contributions.
- Avoid being steadily exploited: punish defections proportionally so defectors learn cooperation is costly, but punishments are short and forgivable so cooperation can recover.
- Tolerate a small, stable minority of defectors rather than triggering perpetual breakdown.
- Be cautious in the final rounds to avoid being trivially exploited by endgame defections.

Parameters derived from game and history (all numeric choices below depend only on n, r and observed history)
- Window length L = min(10, r - 1) for measuring recent behavior.
- Small-defector tolerance T_small = 0.20 (20% of players). This is the fraction of defectors the strategy tolerates without triggering harsh punishment.
- Punishment cap P_max = 3 rounds (punishment is short).
- Forgiveness window F = 2 rounds (require a short cooperative streak to return to full cooperation).
- Trend window m = min(3, L) to detect short-term improvement or decline in cooperation.
- Final-round unanimity threshold U = 0.95 (used only to allow cooperation in the last round when near-unanimous cooperation has been observed).

State variables (maintained from history)
- punishment_timer (integer, initially 0): number of remaining rounds the strategy will defect to punish.
- recover_counter (integer, initially 0): counts consecutive recovery rounds with high cooperation after punishment.

Decision rules (what I play each round t)
1. First round (t = 1)
   - Play C. Start by cooperating to signal willingness to support collective welfare.

2. If punishment_timer > 0
   - Play D this round (enacting calibrated punishment).
   - Decrease punishment_timer by 1.
   - Do not update recover_counter while punishing.

3. Otherwise (punishment_timer = 0) for rounds t = 2..r
   A. Compute recent statistics using the last L rounds (or all previous rounds if fewer):
      - For each round s in the window, observe total contributions S_s (0..n).
      - Let coop_frac_s = S_s / n (fraction of players who cooperated in round s).
      - Let recent_coop = average of coop_frac_s across the window.
      - Let last_coop = coop_frac_(t-1) (fraction who cooperated in the immediately previous round).
      - Let trend = last_coop - average of coop_frac over the m most recent rounds prior to t-1 (if available). Positive trend means cooperation rising.
      - Let defectors_last = n - S_(t-1).
      - Let tolerated_defectors = ceil(n * T_small).

   B. Last round exceptions (endgame):
      - If t = r (final round):
         - If in each of the min(3, t-1) previous rounds coop_frac_s >= U (i.e., near-unanimous cooperation repeatedly), play C as a cooperative gesture.
         - Otherwise play D (protect against profitable final-round defection).

   C. Main decision (middle rounds):
      - If recent_coop >= 1 - T_small (i.e., almost everyone has been cooperating recently):
         - Play C (reward and sustain widespread cooperation).
      - Else if recent_coop <= T_small (i.e., the group is mostly defecting):
         - Play D (do not subsidize persistent collapse).
      - Else (mixed regime):
         - If trend >= 0 (cooperation stable or improving) then play C to support recovery.
         - If trend < 0 (cooperation falling) then play D to avoid being exploited until recovery signs appear.

   D. Punishment trigger (when to start a short, proportional punishment)
      - If punishment_timer = 0 and last_coop < 1 - T_small (i.e., more than tolerated_defectors defected last round) and last_coop decreased noticeably compared to the window average (last_coop < recent_coop - 0.05):
         - Set excess_defectors = max(0, defectors_last - tolerated_defectors).
         - Set punishment_length = min(P_max, max(1, excess_defectors)). (Punish proportionally to how many defected above tolerance, but cap punishment length.)
         - Set punishment_timer = min(punishment_length, remaining rounds r - t + 1). Start punishing next round (or immediately if still in this round’s decision).
         - Immediately play D this round (begin the punishment).
      - If punishment was just applied and later rounds show recovery (recent_coop >= 1 - T_small for F consecutive rounds), reset punishment_timer to 0 and set recover_counter = 0.

   E. Forgiveness and recovery
      - After punishment_timer finishes, require F consecutive rounds in which recent_coop >= 1 - T_small (i.e., group mostly cooperates) before resuming unconditional cooperation; until then use the mixed-regime rules above.
      - This avoids oscillations and gives the group a short, clear path back to cooperation.

4. Persistent minority defectors
   - If a small set of players repeatedly defect but the majority cooperates (recent_coop remains >= 1 - T_small), tolerate them and continue cooperating rather than triggering punishment targeted at an entire group.

5. Avoiding runaway or end-of-game punishment
   - Never start a punishment that would extend past the last round (punishment length is truncated to remaining rounds).
   - If there are only a few rounds left (e.g., remaining rounds <= P_max), be conservative about triggering new punishments; require a clearer drop in cooperation (last_coop < recent_coop - 0.10) to initiate punishment.

Rationale and robustness
- Starting with cooperation establishes a cooperating baseline and tests whether others reciprocate.
- The small-defector tolerance avoids reacting to occasional or isolated defections (noise or selfish single-step deviations) and prevents collapse from tiny shocks.
- Punishment is proportional, short, and capped so that it signals costliness of defection but does not destroy future cooperation forever.
- Forgiveness restores cooperation quickly when others respond, so the strategy works well against conditional cooperators and avoids getting stuck in mutual defection against forgiving opponents.
- Trend detection (short-term slope) allows recovery when cooperation is improving and defection when it is declining.
- Final-round protection avoids being strictly dominated in the last round unless near-unanimous cooperation has been reliably demonstrated.
- The rules rely only on observable history and parameters (n, r, k implicitly through choice of conservative thresholds); they do not require communication or shared norms.

Summary one-line policy
- Start by cooperating; keep cooperating while the group is mostly cooperating or trending up; tolerate a small minority of defectors; when defections exceed tolerance and cooperation clearly falls, enact a short, proportional group punishment (defect for a few rounds) and then quickly forgive if the group recovers; defect in the last round unless near-unanimous cooperation has been consistently observed.
'''

description_COLLECTIVE_13 = '''
Collective Conditional Cooperator with Forgiveness (CCCF)

Goal: sustain high collective contributions by signalling cooperation, reciprocating group-level behavior, punishing defections briefly and proportionally, forgiving quickly to re-establish cooperation, and protecting against end‑game exploitation. The decision rules use only (n, k, r) and the observed action history.

Parameters (computed from game parameters)
- m = k / n (m in (0,1)): marginal public-good return per contribution.
- Window W = min(5, max(1, floor(r / 10))) — how many past rounds to average (short-run smoothing).
- Cooperation threshold θ_coop = clamp(0.40, 0.60 - 0.40*(k-1)/(n-1), 0.60). (Lower θ_coop when k is larger so we are more willing to cooperate when public-good returns are higher.)
- Punishment threshold θ_punish = θ_coop - 0.20 (never less than 0.10).
- Punishment length P = min(3, max(1, round(2 * (1 - m)))) — 1–3 rounds of temporary defection when punishment is triggered.
- Endgame cutoff L_end = min(3, r) — in the last L_end rounds we switch to defensive play to avoid guaranteed exploitation.

High-level rule (applied each round t, with rem = r - t + 1 rounds remaining)
1. First round: Cooperate (C). This sends a clear pro‑collective signal.

2. Endgame safety: If rem <= L_end, play Defect (D). (In very short remaining horizon mutual cooperation is fragile; defend against exploitation.)

3. Compute recent group cooperation:
   - For each round in the last W rounds (or fewer if not available), record the fraction of the other players (exclude yourself) who contributed. Let avg_others be the average of these fractions.
   - Also note last_round_frac = fraction of other players who cooperated in the most recent round.

4. Baseline cooperative decision:
   - If avg_others >= θ_coop, play C (we reciprocate a clear cooperative environment).
   - Else if avg_others <= θ_punish, trigger punishment: play D for the next P rounds (countdown) to impose a cost on systematic defectors and deter further free-riding.
   - Else (ambiguous zone): follow the last-round majority of others — if last_round_frac >= 0.5 play C, else play D. This makes responses timely while smoothing noise.

5. Punishment mechanics and contrition:
   - When punishment is triggered, start a punishment countdown of length P during which play D regardless of small fluctuations (but still observe others).
   - If, during punishment, the group returns to cooperation such that avg_others (recomputed over W) rises above θ_coop, immediately abandon the remaining punishment rounds and return to C next round (forgiveness and contrition).
   - If you yourself defected in the previous round (because you were punishing) and the group shows renewed cooperation, you take the first cooperating move unilaterally (contrite cooperation) to help re‑establish cooperation.

6. Rapid reward for sudden cooperation:
   - If you observe a sudden spike where last_round_frac >= 0.80 (many players attempting to re‑coordinate), cooperate immediately to reinforce the recovery.

7. Robustness to noise and exploitation:
   - Using W smooths accidental defections; punishment is short and proportional (P ≤ 3) to avoid long vendettas.
   - Thresholds adapt to k: higher k reduces θ_coop so the strategy is more tolerant when collective returns are high.
   - The strategy never uses permanent (grim) punishment except implicitly in the very last rounds when we defect defensively.

Rationale and collective mindset
- Start cooperative to invite mutually beneficial play.
- Reciprocity is at the group level: we condition on the observed fraction of cooperators (not on any assumed norms or private promises).
- Punishments are temporary, proportional, and forgiving to avoid cascading collapse from noise or mistakes and to allow a return to high welfare when others reciprocate.
- The endgame cutoff guards against exploitation when there is little future to incentivize reciprocation.
- Parameters are explicitly derived from (n, k, r) and from observed history only; no external coordination is assumed or required.

Behavioral summary (quick reference)
- Round 1: C.
- If few rounds left (rem ≤ L_end): D.
- If recent cooperation ≥ θ_coop: C.
- If recent cooperation ≤ θ_punish: D for P rounds (but abandon punishment early if others resume cooperating).
- Otherwise follow the majority in the last round (C if ≥50% of others cooperated, else D).
- If many others (≥80%) suddenly cooperate, cooperate immediately to reinforce the comeback.

This strategy aims to achieve broad collective cooperation with measured, reversible deterrence against free-riders, while protecting itself near the end of the game.
'''

description_COLLECTIVE_14 = '''
Name: Collective Conditional Cooperation with Proportional Punishment and Stochastic Forgiveness (CCPPSF)

Goal: Promote and sustain high group contributions while avoiding long-term exploitation. Start by signalling willingness to cooperate, respond to defections in proportion to their severity, and allow controlled, probabilistic forgiveness so cooperation can be recovered. Always treat every player symmetrically and base decisions only on game parameters (n, r, k) and the observable history of actions and payoffs.

Summary of parameters (computed from n, r, k):
- Window W for “recent history”: W = min(5, max(1, floor(r/5))). (Short games use a short window; longer games use up to 5 rounds.)
- Cooperation threshold α = 0.6 (fraction of other players who must have cooperated recently to view the group as largely cooperative).
- Punishment intensity factor β = 0.5 (punishment length scales with fraction of defectors × β × remaining rounds).
- Forgiveness probe probability ε = 0.05 (small chance to cooperate during punishment to test recovery).
- Endgame safety: last round always defects; in the final G rounds be conservative, where G = min(3, floor(r/10)).

Decision rules (round t, 1 ≤ t ≤ r):
1. Endgame override
   - If t = r (last round): defect. (In a known-finite horizon, last-round defection avoids guaranteed unilateral loss.)
   - If t > r − G (the final G rounds, excluding the very last): only cooperate if the recent history indicates near-unanimous cooperation (see rule 3). Otherwise defect.

2. First round
   - If r = 1: defect (last-round rule).
   - Otherwise (r > 1 and t = 1): cooperate. Use first-round cooperation to signal willingness to build a collective equilibrium.

3. Compute recent-group-cooperation score
   - Let f_w be the fraction of other players who contributed in the last W rounds, averaged over rounds (i.e., for each of the last W rounds, count other players’ cooperations, average over rounds and normalize by (n−1)).
   - If there is less than W rounds of history, average over the available rounds.

4. Cooperative mode vs. punishment mode
   - Normal cooperative decision:
     - If f_w ≥ α (≥ 60% of other players have cooperated recently) then contribute this round (cooperate).
     - If f_w < α then enter/continue a punishment phase (defect) as below.
   - Punishment phase:
     - Let p = 1 − f_w be the recent fraction of other players who defected.
     - Set punishment length L = min( remaining rounds − 1, max(1, ceil(β × p × r)) ). (Punishment cannot extend into the final round.) Implement L as a countdown; while L > 0 defect each round.
     - During punishment, with small probability ε cooperate on any given round (a “probe” cooperation) to test whether others have returned to cooperation; if a probe finds that subsequent rounds show restored cooperation (f_w rises back ≥ α), end punishment early.
   - Notes:
     - Punishment severity grows with how many others defected recently (p) and with available horizon (r). Small, isolated defection triggers only short punishment; widespread or persistent defection triggers longer punishment.

5. Handling ambiguity and own recent defection
   - If my own last action was D because I was punishing: I follow the same rules (do not treat myself as “excused” unless the group restores cooperation).
   - If I defected unintentionally (e.g., probe or noise), forgiveness probing and the EMA-driven f_w will typically restore cooperation quickly; I do not escalate punishment solely because my own previous action was D.

6. Recovery / forgiveness
   - After a punishment phase ends, return to cooperative mode if f_w ≥ α.
   - If cooperation is restored only partly (α not yet reached) continue with short, proportional punishments: use short L values (as computed) rather than permanent “grim” trigger.
   - The probe cooperation probability ε helps unblock cycles: it can re-start cooperation when many strategies reciprocate.

Edge cases and clarifications
- Small r (very short games): W and G adjust automatically. If r = 1 the strategy defects (last-round dominant). If r = 2 or 3 the strategy is cautious in the final rounds and only cooperates initially when the group is likely to reciprocate.
- No history yet (t = 1): cooperate unless the round is the last round.
- Unusual opponent behavior (e.g., alternating defect/cooperate, targeted punishment): proportional punishment and stochastic probing prevent getting locked into endless retaliation loops and allow quick recovery when others respond.
- Symmetry and fairness: all players are treated identically based only on observed actions; punishment and forgiveness scale with observed group behavior (not with identity).
- Robustness: the strategy is cooperative-seeking but does not allow permanent exploitation because punishment length increases with severity of defection; it also avoids permanent collapse to defection by using limited punishments plus probabilistic probes to restore cooperation.

Rationale (brief)
- Begin cooperatively to signal willingness and try to attain the socially efficient outcome.
- Use a threshold over recent rounds (α) to detect whether the group is sufficiently cooperative to justify contributing despite a single-round temptation to defect.
- Punish defections proportionally and temporarily to make defection unattractive in expectation while avoiding ruinous long punishments that lose opportunities for future gains.
- Use small-probability probes to re-establish cooperation when others are willing, avoiding endless mutual punishment.
- Always defect on the very last round to avoid being exploited when no future reciprocal benefit exists.

By following these rules the strategy favors high collective payoffs when others are willing to reciprocate, responds robustly to selfish or arbitrary opponents, and limits losses in the presence of exploitation — all while depending only on the game parameters and the observable history.
'''

description_COLLECTIVE_15 = '''
Name: Proportional Reciprocity with Forgiveness (PRF)

Goal: Sustain near-universal cooperation when others respond to reciprocity, punish defectors proportionally (to avoid exploitation), forgive and return to cooperation when the group improves, and avoid being permanently exploited near the end of the game.

Definitions (computed from parameters and history):
- n = number of players, r = total rounds, t = current round (1-indexed), remaining = r - t + 1.
- Window W = min(4, t) — use up to the last 4 rounds of history (or fewer early on).
- For each other player j, coop_j = proportion of rounds they cooperated in the last W rounds (0..1).
- group_coop_rate = average of coop_j over all other players (equivalently: average proportion of other players who cooperated per round over the last W rounds).
- Persistent defector threshold: if coop_j <= 0.2 over the last min(6, t) rounds and t >= 6, mark j as persistent defector.
- Punishment counter P_count: number of rounds still left in a current punishment stage (initially 0). This counter is determined from history (see rules below).

Policy (what I play this round):
1) First round (t = 1):
   - Cooperate (C). This signals a cooperative intent and gives cooperation a chance to emerge.

2) Endgame rule (when remaining rounds are small):
   - If remaining <= 2:
     - If in every of the last min(2,t-1) rounds every player cooperated (full cooperation recently), play C to preserve a recently established cooperative norm.
     - Otherwise play D (defect). Rationale: when few rounds remain, the future leverage of reciprocity is small, so avoid being exploited unless cooperation is recently unanimous.

3) Persistent-defector defense:
   - If at least half of the other players are marked as persistent defectors, switch to permanent defection (play D every remaining round). Rationale: when a majority are stubborn free-riders, continuing to cooperate is futile and would be systematically exploited.

4) Normal rounds (remaining > 2 and not in permanent-defect mode):
   - Compute group_coop_rate over W rounds.
   - If P_count > 0 (we are currently in a punishment period):
     - If group_coop_rate has recovered to >= 0.6 during the last W rounds, cancel punishment immediately (set P_count = 0) and play C this round.
     - Otherwise decrement P_count by 1 and play D this round (continuing proportional punishment).
   - If not in a punishment period (P_count = 0):
     - If group_coop_rate >= 0.6: play C (reward cooperation).
     - If 0.3 <= group_coop_rate < 0.6: play C (choose cooperation) — withhold harsh punishment for small lapses; this encourages recovery rather than escalation.
     - If group_coop_rate < 0.3: enter a proportional punishment and play D. Set P_count = 1 + ceil((0.6 - group_coop_rate) * 3). That is, the punishment lasts 1 plus up to 3 additional rounds proportional to how low cooperation is. Then play D this round.
   - Notes on thresholds:
     - 0.6 is the “cooperation accepted” threshold: it tolerates some unilateral lapses but demands a clear majority of cooperative behavior to keep cooperating.
     - 0.3 is a concession zone: if cooperation falls into this bucket, give the group a chance to recover without immediate escalation; if it falls below 0.3, respond more firmly.

5) Forgiveness and return to cooperation:
   - Punishment is temporary and proportional. If the group_coop_rate improves to >= 0.6 at any time, immediately stop punishing and resume cooperation.
   - If a single or a few isolated defections occur but the average response by others remains high (group_coop_rate remains >= 0.6), never punish—keep cooperating.

6) Miscellaneous practical points:
   - All computations use only the public history of actions (who cooperated each round) and r, n, t. No communication, no private signals are required.
   - The strategy is deterministic except in that the punishment duration is derived from group_coop_rate; no randomization is necessary to achieve robustness.
   - The parameters (W=4, thresholds 0.6 and 0.3, punishment scaling factor 3, persistent-defector cutoff 0.2) are chosen to be simple, forgiving, and robust across a wide variety of opponent types. They can be interpreted as "moderately demanding but generous": we reward clear majority cooperation, tolerate occasional lapses, punish proportionally when cooperation collapses, and forgive quickly when the group corrects.

Why this is collective-minded and robust:
- It starts and prefers cooperation, so it helps establish high collective payoffs when others reciprocate.
- It punishes only proportionally and temporarily, which avoids cascading mutual punishment from small mistakes and allows recovery.
- It defends against persistent exploitation by switching to permanent defection only when a majority are persistently noncooperative (a pragmatic concession to avoid being exploited).
- It accounts for the finite horizon: when reciprocity cannot be enforced (endgame), it avoids needless exploitation unless cooperation is already unanimous.
- The rules rely only on observable past behavior and game parameters, and adapt automatically to a wide range of opponent behaviors (cooperators, conditional cooperators, random players, stubborn defectors).
'''

description_COLLECTIVE_16 = '''
Collective-First Conditional Cooperation (CFCC)

Summary goal
- Try to sustain near-universal contributions early and in the middle of the game by signaling cooperation and using short, graded, forgiving punishments when group cooperation falls. Protect yourself from sustained exploitation and from the unavoidable last-round defection by switching to defection in the final round. All decisions use only n, k, r and the observed history of every player’s past actions and payoffs.

Parameters (computed from game parameters)
- w = min(5, max(1, floor(r/10))). (Memory window used to judge recent group behavior.)
- T = 0.60 (cooperation threshold: roughly 60% of players cooperating is treated as good collective behavior).
- base_punish = max(1, ceil(r/10)) (base punishment length).
- max_punish = max(1, r - current_round - 1) (never punish through the final round).
- A “severity” measure = 1 − recent_coop_fraction (so severe when many defect).

State overview
- NORMAL: default, try to cooperate to build/maintain cooperation.
- PUNISH(L): actively defect for L rounds as a calibrated collective punishment.
- TEST: after a punishment period, cooperate for one round to test restoration; go back to NORMAL if test succeeds, otherwise re-enter PUNISH with increased severity.

Decision rules (per round t, 1..r)
1. Final-round rule
   - If t == r (last round), play D (defect). The last round cannot be credibly punished, so defect to avoid being exploited.

2. Initialization
   - If t == 1 and r > 1, start in NORMAL and play C (cooperate) to signal willingness to sustain collective cooperation.

3. If in PUNISH(L)
   - Play D this round.
   - Decrease L by 1. If L becomes 0 after this round, switch to TEST for the next round.

4. If in TEST
   - Play C this round (one restoration test).
   - At the end of the test round observe others’ contributions during that test round.
     - If fraction of players (including the tester) who contributed ≥ T, set state = NORMAL.
     - Else compute new_punish_length = min(max_punish, max(1, ceil(base_punish * severity * 1.5))) where severity = 1 − recent_coop_fraction measured over the same memory window (see “recent cooperation” below). Set state = PUNISH(new_punish_length).

5. If in NORMAL
   - Compute recent_coop_fraction: the fraction of all possible contributions that were C in the past w rounds (equivalently, average across players and rounds in the window). If fewer than w past rounds exist, use all available rounds.
   - If recent_coop_fraction ≥ T → play C (cooperate). Goal: reward and maintain cooperation.
   - If recent_coop_fraction < T:
     - Require that this low-cooperation condition holds on at least two of the last min(w, t−1) rounds (i.e., avoid punishing for a single blip). If this sustained low cooperation condition is not met, play C (remain lenient).
     - If sustained low cooperation is detected:
       - Compute punish_length = min(max_punish, max(1, ceil(base_punish * (1 − recent_coop_fraction)))).
       - Set state = PUNISH(punish_length) and play D this round (start calibrated collective punishment).

Graded and calibrated punishment logic
- Punishments scale with how bad recent cooperation has been (more defectors → longer punishment) but have an upper limit so they do not recklessly consume all remaining rounds and destroy potential recovery.
- Punishments are group-level: they are applied to the whole group (we defect) rather than attempting to single out individuals in a one-shot stage; this creates a clear, observable cost to defecting that other conditional strategies can read and respond to.
- Punishment lengths grow if tests fail (doubling / scaling by 1.5 of base severity), but are capped by max_punish.

Forgiveness and recovery
- After any punishment block we always run exactly one cooperative TEST round. If the test shows cooperation restored (≥ T), we return to NORMAL cooperation. This avoids endless cycles of retaliation for accidental or one-off defections.
- The two-round minimum detection before punishing prevents overreaction to single stray defection(s).

Short-game adjustments
- If r is small so w = 1 (very short games), behave slightly more cautious: still cooperate in round 1 (if r>1), but require only one low-coop observation to trigger the short base_punish. The same final-round defection rule applies.

Collective mindset justification
- Default is cooperative: prefer group welfare and signal it early and often.
- Punishments are collective, calibrated, and temporary: they are designed to impose a visible cost on defectors to restore cooperation rather than to destroy long-run value.
- Forgiveness is built in so the strategy returns to collective play when others reciprocate.
- Final-round defection is an individual safeguard against last-round exploitation; it’s the minimal strategic concession to finite-horizon logic while preserving strong cooperative incentives for most of the game.

Behavioral summary (quick)
- Round 1 (if r>1): cooperate.
- While NORMAL: cooperate when recent group cooperation ≥ 60%; otherwise, after a short confirmation of sustained drop, start a temporary, calibrated collective punishment (defect L rounds).
- After punishment: test with one cooperative round; if cooperation returns, resume; if not, punish again with larger L (capped).
- Last round: defect.

This strategy is simple to implement from history, robust to many opponent types (lenient to transient noise, punitive to persistent free-riders, forgiving to restored cooperation), and explicitly collective in motive and mechanism while protecting myself against exploitation, especially near the end of the game.
'''

description_COLLECTIVE_17 = '''
Adaptive Collective Cooperator (ACC)

Purpose: build and sustain high group contributions when others reciprocate, punish clear exploitation to protect the group, and forgive so cooperation can recover. Uses only game parameters (n, k, r) and publicly observed history of contributions/payoffs.

Parameters (determined from n, k, r; fixed during play)
- window w = min(5, r-1)  // use up to last 5 rounds of history (fewer near start)
- high_multiplier = (k / n) >= 0.6
- cooperation_threshold q_req = 0.5 if high_multiplier else 0.7
  // if the public-good multiplier is high, be easier to cooperate; otherwise require stronger evidence
- tolerance tol = 0.15  // allow occasional one-off defections without triggering long punishment
- base_punish_length L0 = 2  // minimum punishment length
- max_punish_length Lmax = min(5, r)  // never punish longer than a short window

State variables (maintained from history)
- punishment_counter P (initially 0)
- recent_fraction p_recent = fraction of other players' contributions averaged over last w rounds (computed each round)
- last_round_fraction q_last = fraction of other players who contributed in the immediately previous round

Decision rules (what I do each round)
1. Terminal-round rule
   - If this is the final round (round r): defect (D). (Rationale: last-round defection is individually dominant; avoid being exploited near the literal end.)

2. Initialization
   - If this is the first round (round 1) and r > 1: cooperate (C). (Signal cooperative intent; enables reciprocal cooperation if partners are conditional cooperators.)
   - If r == 1: defect (D) (single-shot).

3. Compute summary statistics
   - Compute q_last = (# of other players who contributed in previous round) / (n - 1).
   - Compute p_recent = average of q_last over up to the last w rounds.

4. If currently in punishment mode (P > 0)
   - Play D (defect) this round and decrement P by 1.
   - After decrementing, continue to step 6 (for bookkeeping/forgiveness check next round).

5. Normal mode (P == 0): decide whether to cooperate or defect
   - If p_recent >= q_req:
       - Play C (cooperate). (Group has been cooperating enough recently; reciprocate to maximize collective payoff.)
   - Else:
       - Play D (defect). (Not enough recent cooperation to justify risking exploitation.)

6. Triggering punishment (only checked after observing the previous round)
   - After observing the outcome of a round (and before the next action), check whether a punitive response should be scheduled:
     - Let d = (n - 1) * q_last  // number of other players who cooperated last round
     - Actually compute number of defectors among others last round: defectors = (n - 1) - round((n - 1) * q_last)
     - Condition to punish: previous round showed a clear, nontrivial defection episode:
         - If q_last <= (q_req - tol) and (p_recent < q_req) AND (defectors >= 1)
           (That is: the last round was worse than what we tolerate and recent history is below threshold.)
       - Then set punishment length P = min(Lmax, L0 + floor(defectors / max(1, round((n-1)/4))))
         (Punish for a short number of rounds scaled modestly with the number of defectors.)
     - If we enter punishment mode we will defect for P subsequent rounds (collective punishment) and then return to normal mode.
   - Note: do not punish for one-off slippage if overall recent cooperation is strong (p_recent >= q_req) — that is handled by tolerance.

7. Forgiveness and recovery
   - After punishment ends, resume normal mode and re-evaluate p_recent. If p_recent >= q_req, cooperate; otherwise defect until cooperation is restored.
   - If multiple players respond to punishment by returning to cooperation, ACC will resume cooperation quickly (one round after seeing sufficient recovery).

Design rationales (concise)
- Start-cooperate signal: gives reciprocal strategies a chance to coordinate on high contributions.
- Threshold q_req references observed group behavior, and is tuned by k/n: when the multiplier is generous, be more willing to cooperate.
- Punish briefly and proportionally: collective punishment deters free riding but is bounded so one opportunistic or noisy defection cannot collapse cooperation permanently.
- Forgive quickly when cooperation resumes: prevents endless cycles of retaliation and allows the group to return to high-payoff outcomes.
- Last-round defection avoids being exploited by backward-inducing defectors and prevents being the sucker in the final move.

Edge cases
- Small r: when r is 1 we defect; when r is 2 we cooperate round 1, defect round 2 (still allow a single cooperative signal).
- Heavy sustained defection: ACC will defect until p_recent rises above q_req; it does not attempt to outlast persistent noncooperators with long punishments.
- Noise / accidental defects: small deviations tolerated (tol), so accidental single defections do not trigger long punishments.
- Varying group size / multiplier: q_req depends on k/n so behavior scales with game incentives.

Collective mindset summary
- ACC always aims to maximize collective payoff when group behavior shows reciprocity: it cooperates when a clear majority or sustained fraction of others cooperate.
- It protects the collective by imposing short, proportional punishments when exploitation becomes visible.
- It is forgiving enough to restore cooperation quickly so the group can get back to mutually beneficial contributions.
'''

description_COLLECTIVE_18 = '''
Strategy name: Forgiving Group‑Conditional Cooperation (FGCC)

Summary goal
- Maintain and restore collective cooperation whenever possible, punish defections briefly and proportionally to discourage free‑riding, and avoid permanent collapse from single mistakes. Defect in the final round (no future to reward cooperation).

Common parameters derived from the game
- n, r, k are given.
- Window W = min(5, max(1, r // 5)) — use up to five most recent rounds (fewer if r is small).
- Group threshold θ = 0.6 (require a clear majority of other players cooperating recently to judge the group cooperative).
- Punishment length P = 2 rounds (short, to be proportional and forgiving).
- Final‑round horizon H = 1 (always defect in final round). If r ≤ 2, follow the simplified edge rules below.

State (maintained from history only)
- inPunish: true/false (whether currently executing a punishment period).
- punishLeft: integer rounds remaining in the punishment period.

Initial state
- inPunish = false, punishLeft = 0.

Decision rule (applied each round t = 1..r)
1. Last round rule
   - If t = r (final round): choose D (defect). End.

2. Very short games (edge cases)
   - If r = 1: choose D (single round — defect is dominant).
   - If r = 2:
     - Round 1: choose C (try to seed cooperation).
     - Round 2: choose D (final round).

3. If inPunish is true
   - Play D this round.
   - Decrement punishLeft. If punishLeft becomes 0, set inPunish = false.
   - Continue to next round.

4. Otherwise (not in punishment)
   - Compute recent group cooperation p:
     - For up to the last W rounds (exclude the current decision), compute the average fraction of other players who contributed each round. If there is no prior round (t = 1), treat p = 1 by default (start optimistic).
     - Concretely, for each of the last up to W rounds count how many players (excluding me) contributed; divide by (n−1) and average across those rounds → p in [0,1].
   - If p ≥ θ:
     - Play C (cooperate) to support continued group cooperation.
   - If p < θ:
     - Enter a short punishment: set inPunish = true and punishLeft = min(P, r − t) (do not schedule punishment beyond remaining rounds).
     - Play D this round (start the punishment).

Forgiveness and recovery
- Punishments are temporary (max P rounds) and non‑targeted: they are collective responses to low group cooperation, not permanent exclusions of specific players.
- After punishLeft reaches zero, the strategy resumes observing p over the next rounds; it returns to cooperation as soon as the recent cooperation fraction p meets or exceeds θ.

Rationale and properties
- Collective orientation: the decision rule focuses on the observed behavior of the group (fraction cooperating), not on exploiting individuals or trying to single out players. This encourages and sustains group cooperation when a clear majority cooperates.
- Reciprocity and adaption: the strategy rewards groups that keep cooperating (cooperates whenever recent group cooperation is strong) and imposes short, predictable punishments when the group is performing poorly, which deters sustained free‑riding.
- Robustness to mistakes: short punishment length P and averaging over a window W avoid permanent breakdown from isolated or accidental defections.
- Final‑round safety: defecting in the final round avoids being exploited when future punishments are impossible.
- Parameter choices (W, θ, P) are modest and work across many n, r, k; they are explicit and may be tuned (the strategy only uses game parameters and observed history).

Examples (intuitive)
- If most players cooperated in recent rounds, FGCC cooperates to keep the productive equilibrium.
- If cooperation suddenly drops (many defect), FGCC defects for a short punishment period; if the group restores cooperation thereafter, FGCC forgives and returns to cooperating.
- If one player repeatedly defects and the group does not recover, FGCC will keep punishing in short bursts whenever the recent cooperation fraction falls below θ, discouraging persistent free‑riding without committing to infinite retaliation.
'''

description_COLLECTIVE_19 = '''
Name: Collective Conditional Cooperator with Lenient Reciprocity and Probing

Goal (collective mindset)
- Preserve and restore high group cooperation whenever possible, while avoiding prolonged exploitation. Accept short, limited personal cost to sustain cooperation if a clear majority is cooperating; respond to persistent or broad defection with short, proportional punishment; use occasional probes to re-start cooperation.

Parameters (computed from game info and history)
- W (window length for recent behavior): W = min(10, t-1) (use all past rounds if t-1 < 10).
- Cooperation score per other player j: r_j = fraction of the last W rounds in which j contributed.
- Group cooperation level: r_bar = average_j r_j (average over the n-1 other players).
- Base willingness threshold: tau_base = 0.60.
- Multiplier adjustment: adj = 0.15 * (k-1)/(n-1). (Larger k => more willing to cooperate.)
- Cooperation threshold: tau = clamp(tau_base - adj, 0.35, 0.75).
- Lenient lower bound: tau_low = max(0.10, tau - 0.25).
- Punishment length if triggered: P = clamp(2 + floor(3*(1 - r_bar)), 1, 6) rounds.
- Probe interval: S = 4 rounds (once every S rounds try a cooperative probe when otherwise defecting).
- Endgame window: K = min(3, max(1, floor(r/10))). Final round is handled specially.

State variables (carried in history)
- punishment_remaining: rounds left in an active punishment phase (initially 0).
- rounds_since_my_last_coop (for probing logic).

Decision rules (what I do each round)
1. If t = 1 (first round): cooperate. Rationale: honest cooperative signal to enable collective outcomes.

2. If t = r (final round): defect. Rationale: no future to enforce cooperation (avoid being exploited in last move).

3. If t > r - K (last K rounds, approaching endgame) but t < r:
   - Cooperate only if r_bar >= 0.90 AND no single other player has defected in the last 2 rounds. Otherwise defect. Rationale: avoid being a sucker as end approaches, but preserve cooperation if the group shows near-unanimous commitment.

4. If punishment_remaining > 0:
   - Defect this round. Decrement punishment_remaining by 1. Rationale: proportional, temporary punishment.

5. Otherwise (normal operation):
   a. Compute r_bar and examine distribution of r_j.
   b. If r_bar >= tau:
      - Cooperate. Rationale: a clear majority is cooperating; accept short-term cost to sustain high group welfare.
   c. Else if r_bar <= tau_low:
      - Defect and begin a punishment phase: set punishment_remaining = P - 1 (we defect this round plus P-1 future rounds). Rationale: many partners are not cooperating; withhold cooperation and signal displeasure.
   d. Else (ambiguous middle zone tau_low < r_bar < tau):
      - Lenient rule: cooperate now as a generous move. Then observe immediate responses in the next W' = min(3, t-1) rounds:
         - If a significant fraction (more than 40% of players) fail to respond by cooperating in those next W' rounds, start a punishment as in 5.c.
      - This gives a short chance for recovery rather than immediately punishing small or noisy drops.

6. Probing when stuck in defection:
   - If I have been defecting for >= S consecutive rounds (and not in the last K rounds) and there is no active punishment countdown, perform a one-off cooperative probe (cooperate this round). If a number of others respond by returning to cooperation in the following two rounds, resume normal cooperative checks; otherwise resume defection and consider a punishment phase. Rationale: allow a path back to cooperation after long mutual defection.

Additional checks and safeguards
- When deciding punishment, use broad signals (group averages and counts) rather than targeting single players; punishment is collective (I defect) intended to shift global incentives, not to permanently ostracize individuals.
- Avoid permanent grim triggers. Punishments are short and scale with how bad recent cooperation is (via P). After punishment ends, revert to the normal decision rules so cooperation can be restored.
- Treat occasional isolated defections leniently (ambiguous zone handling) to tolerate errors/noise and preserve cooperation rather than collapse quickly.
- All decisions use only the public history (past actions of everyone, payoffs are not required for the rule) and game parameters n, r, k.

Rationale summary
- The rule starts cooperatively to enable mutuality, favors cooperation when there is clear majority support (to maximize collective welfare over repeated interaction), punishes proportionally and temporarily when cooperation collapses, and includes explicit probing and forgiveness to restore cooperation after breakdowns. The threshold tau is adjusted by k so the strategy is more willing to sustain cooperation when the public-good multiplier is stronger. The endgame is treated conservatively to avoid being exploited when backward reasoning dominates, but still allows cooperation in late rounds if the group shows almost unanimous commitment. This strategy is collective in intent (prioritizes group welfare where sustainable) while robust to exploiters and noise.
'''

description_COLLECTIVE_20 = '''
Collective-First Conditional-Cooperator (CFCC)

Goal (collective mindset)
- Maximize group payoff by sustaining mutual contributions when others do; deter persistent free-riding with temporary, proportionate punishments; be forgiving so cooperation can recover. Do not assume others share norms or can coordinate — use only observed histories.

Parameters (computed from game parameters; no external info)
- n, k, r are given by the game.
- Window W = min(3, r-1) — use up to the last 3 rounds to judge recent behavior.
- Threshold θ = 0.60 — require a clear majority of others to have contributed in the window to count as cooperative behavior.
- Punishment length L = max(1, ceil(0.15 * r)) — a finite, noticeable punishment phase (≈15% of horizon) to deter defects.
- Recovery length R = min(2, max(1, r-2)) — after punishment, try short, explicit recovery cooperation.
- Endgame rule: always defect in the final round (t = r). If only a very small number of rounds remain (≤ L), be conservative about entering new punishments (see rules below).

State variables (maintained from history)
- Mode ∈ {Cooperate, Punish, Recover}
- PunishCounter (if in Punish mode)
- RecoverCounter (if in Recover mode)

Initialization
- Mode = Cooperate
- Play C (contribute) in round 1.

Per-round decision rules (for round t, 1 ≤ t ≤ r)
1. Endgame override
   - If t = r (last round): choose D (defect). Reason: single-shot incentive dominates in last round.

2. If Mode = Cooperate:
   - Compute for each of the last W rounds (or all past rounds if fewer exist) the fraction f_t of the other (n-1) players who contributed in that round; average these to get f_recent.
   - If f_recent ≥ θ, play C (contribute) this round and remain in Cooperate.
   - If f_recent < θ:
     - Enter Punish: Mode := Punish; PunishCounter := L (but if remaining rounds before the last round < L, set PunishCounter := max(1, remaining_rounds_before_last)); play D this round.

3. If Mode = Punish:
   - Play D this round.
   - Decrement PunishCounter by 1.
   - If PunishCounter > 0: remain in Punish.
   - If PunishCounter reaches 0: enter Recover: Mode := Recover; RecoverCounter := R.

   (Exception for endgame proximity: if remaining rounds before the last round are fewer than R, set RecoverCounter := min(R, remaining_rounds_before_last). If remaining rounds ≦ 1, switch directly to Cooperate only if the last observed round before last showed near-unanimous cooperation (f_recent ≥ 0.95); otherwise remain in Punish until last round override.)

4. If Mode = Recover:
   - Play C this round (give a short, explicit restoration of trust).
   - Decrement RecoverCounter by 1.
   - Observe the contribution rate of others this recover round (the fraction f_now among others who played C).
   - If f_now ≥ θ: success — switch Mode := Cooperate immediately and continue cooperating next round.
   - If f_now < θ:
     - Treat as failure to reciprocate — re-enter Punish: Mode := Punish; PunishCounter := L (or remaining rounds before last, as above) and play D next round.

Additional adaptive details and rationales
- Windowing (W) and averaging make the strategy robust to occasional single-shot noise or one-off mistakes by others: a single defector does not immediately collapse cooperation if the recent majority cooperated.
- Finite punishment length (L) rather than permanent revenge: punishments must be costly enough to deter defection but finite so cooperation can be restored. L scales with r so it matters in longer games but does not doom future cooperation.
- Recovery phase is explicit and brief (R): we offer a clear, low-cost chance to return to mutual cooperation. If others respond by cooperating, we resume full cooperation; if not, we punish again.
- Endgame caution: always defect in last round. Because cooperation cannot be enforced once the game ends, conserve your private endowment then. If only a few rounds remain, avoid initiating long punishments that cannot be completed and would simply throw away group payoff.
- Collective bias: in ties or uncertainty we favor cooperating (except the last round), because the strategy prioritizes group payoff and aims to sustain cooperation where possible. However, it will robustly punish repeated, unreciprocated free-riding.

Edge cases
- First round: we cooperate to signal intent and try to start cooperation.
- Very short games (r small): W, L, R automatically scale down (window ≤ rounds−1, L at least 1, R ≤ remaining rounds−1), so punishments and recoveries fit the horizon.
- If many players defect simultaneously repeatedly (persistent mass defection), CFCC will enter and remain in Punish until either others start cooperating in recovery rounds or the endgame forces defection. This avoids being exploited indefinitely.
- If almost everyone cooperates except a small fraction of persistent free-riders, CFCC’s punish-then-recover cycles make defection unprofitable for the persistent free-riders because their temporary one-shot gains are offset by multiround loss of cooperative returns.

Why this is robust and adaptive
- Uses only observed actions and payoffs history (no communication or external coordination).
- Balances deterrence and forgiveness: finite punishments pressure defectors but allow re-establishment of cooperation.
- Parameter scaling with r ensures behavior is meaningful for short and long tournaments.
- Conservative in the endgame so it avoids wasting contributions when enforcement is impossible.

Summary (short)
- Start by cooperating. Cooperate as long as a strong recent majority (≥60%) of others contributes. If cooperation drops, defect for a fixed punishment length (≈15% of the horizon), then attempt a short cooperative recovery. If recovery succeeds, return to cooperation; if not, punish again. Always defect in the final round. This keeps a collective focus, punishes repeated free-riding, and forgives to rebuild cooperation.
'''

description_COLLECTIVE_21 = '''
Name: Collective Conditional Cooperate with Forgiving Punishment (C3FP)

Principles (collective mindset)
- My objective is to sustain high group payoffs across the repeated game. I will start by offering cooperation, reward clear cooperative groups, and impose short, predictable punishments when the group’s cooperation falls, but I will forgive quickly so cooperation can recover. I avoid permanent retaliation (which destroys group value) and avoid blind unconditional cooperation (which gets exploited).

Parameters (computed from game parameters n, k, r)
- window w = min(5, r). I use the most recent up-to-w rounds to judge group behavior.
- punishment length L = min(5, max(1, ceil(r/10))). This makes punishments longer in longer games but bounded to avoid permanent loss.
- cooperation threshold θ = max(0.5, 1 - (k - 1) / (n - 1)).
  - Intuition: when the multiplier k is large (close to n) cooperation is easier to sustain so I accept a lower threshold (≥50%); when k is small I require a higher visible cooperation fraction before I keep cooperating.

Definitions used each round t (t = 1..r)
- For rounds past the first, let contributions_by_others_in_round(s) be the number of players other than me who contributed in round s.
- recent_fraction = average over the last min(w, t-1) rounds of [contributions_by_others_in_round(s) / (n - 1)]. (If t = 1 no history exists.)
- persistent_defectors(j) = fraction of rounds in the last w rounds in which player j defected (used only for optional fine-grained target punishment below).

Decision rules (pseudocode-style description)

Round 1:
- Cooperate.

For any round t where 1 < t <= r:
1. Endgame rule:
   - If t == r (last round): Defect. (No future to punish or be punished.)
2. If I am currently in an active punishment episode (I am counting down remaining_punish > 0):
   - Action = Defect.
   - After playing, if in the just-completed round the observed fraction of others who cooperated ≥ θ, end the punishment immediately (set remaining_punish = 0) and resume cooperation next round. Otherwise decrement remaining_punish by 1 and continue punishment as scheduled.
   - Rationale: punish briefly but stop as soon as group returns to sufficient cooperation.
3. If not in punishment:
   - Compute recent_fraction using up to the last w rounds (if none, treat recent_fraction = 1 for round 2 after starting with cooperation).
   - If recent_fraction ≥ θ:
       - Action = Cooperate. (Reward and sustain cooperation.)
   - Else (recent_fraction < θ):
       - Enter a punishment episode: set remaining_punish = L and Action = Defect this round.
       - Rationale: signal displeasure and impose a short, predictable cost to defectors so cooperation becomes attractive again.

Optional targeted adjustment (keeps strategy still non-coordinating and uses only public history):
- If recent_fraction is low but I detect one or a few persistent defectors (some players j with persistent_defectors(j) ≥ 0.9 over the last w rounds), I keep defecting only while those same players are persistently defecting, but if a majority of the group returns to cooperating I resume cooperation immediately. This avoids overly punishing mostly-cooperative groups because of a tiny set of exploiters.

Notes and rationale
- Start-by-cooperating establishes willingness to build group value.
- The threshold θ depends on k and n so the strategy scales: when the public good multiplier makes cooperation more socially valuable (k large) the strategy is more willing to maintain cooperation even if not everyone cooperates; when k is small the strategy requires stronger evidence of cooperative behavior before contributing.
- Punishments are short and forgiving (finite L with early exit on recovery). This prevents permanent collapse of cooperation from accidental or isolated defections and reduces incentives for long runs of mutual defection that harm group payoff.
- Last-round defection prevents being exploited when no future punishment is possible (standard endgame adjustment). Because punishments are finite and predictable, cooperation in earlier rounds can still be supported.
- The strategy uses only observed histories (every player’s contributions each round) and the game parameters n, k, r. No communication or coordination beyond public history is assumed.
- Robustness: the design cooperates with conditional cooperators and rewards high group cooperation; it punishes persistent defectors sufficiently to make exploitation costly; forgiveness allows recovery. It avoids extreme rules (grim trigger), so it is resilient to noise/occasional defections and to strategies that try to provoke permanent retaliations.

Summary (one-line)
- Cooperate initially; in each non-final round, cooperate whenever the recent fraction of other players’ contributions ≥ θ (threshold computed from k and n); if the recent fraction falls below θ, defect for a short, fixed punishment length L but end punishment early if the group’s cooperation quickly returns; always defect in the final round.
'''

description_COLLECTIVE_22 = '''
Adaptive Collective Conditional Contributor (AC3)

Goal: maximize collective welfare by sustaining mutual contributions where possible, while protecting myself from persistent exploiters. The strategy uses simple, interpretable statistics from the observed history, is forgiving of noise, and scales back cooperation toward the end of a finite game.

Parameters derived from game inputs (set once at start)
- n, r, k are given by the game.
- L (lookback window size) = max(3, floor(r/10)) — use recent behavior for reputation.
- Theta_high = 0.60 (threshold for “group is cooperative”).
- Theta_low = 0.30 (threshold for “group is largely non-cooperative”).
- Probe_prob = 0.10 (chance to probe/cooperate during punishment to test recovery).
- Final_rounds = min(3, floor(r/4)) — number of rounds near the end to enter “endgame” caution.

State maintained from history
- For each player j ≠ me, compute p_j = (# of times j contributed in the last L rounds) / L.
- Group cooperation level P = average of p_j across j ≠ me (or across all players if preferred).
- S_last = total contributions observed in the immediately previous round.
- Remaining rounds R = r - t + 1 (if t is current round number).

Decision rules (what I do each round)
1. First round (t = 1)
   - Cooperate (C). This signals willingness to form a cooperative convention.

2. If R ≤ 1 (the final round)
   - Defect (D). In a one-shot last round, contribution cannot be reciprocated later; defect to avoid being exploited.

3. Endgame precaution (2 ≤ R ≤ Final_rounds)
   - Only cooperate if recent evidence of cooperation is very strong:
     - If S_last = n (everyone contributed last round) AND P ≥ 0.9, then cooperate.
     - Otherwise defect, but with a small Probe_prob chance cooperate to check whether cooperation can be reestablished.

4. Normal play (R > Final_rounds)
   - Compute P (group recent cooperation rate).
   - Case A: P ≥ Theta_high (group is largely cooperative)
     - Cooperate. Reward and sustain cooperative convention.
   - Case B: Theta_low < P < Theta_high (mixed / uncertain environment)
     - Reciprocity with caution:
       - If S_last ≥ round_up(n/2) (a majority contributed last round), cooperate.
       - Else cooperate with probability equal to P (i.e., more likely to cooperate when others cooperated recently); otherwise defect.
   - Case C: P ≤ Theta_low (group largely non-cooperative)
     - Enter a proportional punishment phase:
       - Defect for a punishment length L_punish = min(R - 1, 1 + ceil((Theta_high - P)/0.1)).
         (Punishment length increases the worse the recent cooperation; never punishing beyond remaining rounds needed.)
       - During the punishment phase, occasionally (with probability Probe_prob each round) cooperate to test for recovery.
       - After L_punish rounds, re-evaluate P and follow the normal rules (A–C), allowing forgiveness if cooperation rebounds.

5. Handling single or occasional defections (noise tolerance)
   - If a single player drops contribution once but group P remains ≥ Theta_high, treat it as noise: continue cooperating.
   - If many players show isolated lapses but the group trend stays cooperative, do not punish immediately; punish only when the moving-average P crosses thresholds.

6. Adaptive targeting and proportionality
   - Punishment is collective (I choose D), not discriminatory (I cannot target specific players with a single binary action). The punishment length and severity are proportional to the measured decline in P so that small mistakes do not provoke permanent collapse and large exploitation is countered decisively.

7. Probing and recovery
   - When I defect (punishment), I still probe with small probability (Probe_prob) to allow recovery and to detect if opponents are shifting back to cooperation; once P rebounds to ≥ Theta_high, immediately resume cooperation.

8. Special short-game tweak
   - If r ≤ 5 (very short game), be more conservative:
     - Cooperate in round 1 to signal, but otherwise require S_last = n (unanimous last-round cooperation) and P ≥ 0.9 to continue cooperating; otherwise defect except occasional probes.

Collective mindset (what this does for the group)
- I begin by signaling cooperation and reward others’ cooperation promptly (case A).
- I punish defections proportionally rather than forever, which discourages exploitation but does not destroy cooperation for small mistakes.
- I forgive when others restore cooperative behavior, and I use low-probability probes to help re-establish cooperation after a breakdown.
- Near the end of the finite horizon I become cautious to avoid being the last-round sucker, but only when clear evidence of continuing cooperation is lacking.

Implementation notes (interpretation, not external inputs)
- All thresholds (Theta_high, Theta_low, Probe_prob, L) are fixed functions of r (and constants above) and of observed history only.
- The strategy is deterministic except for controlled small-probability probes and probabilistic cooperation in mixed environments; these random elements allow escape from deadlocks and make exploitation harder.
- The strategy balances collective welfare (favor cooperation when others cooperate) with robustness (proportional punishment, forgiveness, and endgame caution).
'''

description_COLLECTIVE_23 = '''
Collective-Conditional Cooperator with Proportional Punishment and Forgiveness (CCP)

Goal: maximize group welfare by sustaining high, stable contributions when others reciprocate; avoid being a long-term sucker; punish sustained free-riding but forgive quickly so cooperation can resume.

Parameters (derived from game parameters r, n):
- Memory window w = min(5, r). We evaluate recent behavior over the last w rounds.
- Cooperation threshold gamma = 0.50 (majority). If a clear majority of players have been cooperating recently, treat the group as “cooperative.”
- Punishment length base P = min(3, max(1, floor(r/10))) rounds. Punishments are short and proportional to the offense.
- Endgame safety window L = min(3, max(1, floor(r/10))). In the final L rounds we avoid long-term exploitation by switching to safe play.

State variables:
- mode ∈ {COOPERATIVE, PUNISHING}
- punish_counter (integer, how many more rounds to punish)

Initialization:
- mode = COOPERATIVE
- punish_counter = 0

Decision rules (round t):
1. First round (t = 1): Cooperate (contribute 1). This signals cooperative intent.

2. Endgame (t > r − L): Defect (contribute 0) in the final L rounds. Rationale: finite-horizon backward-induction pressure is concentrated at the end; we protect ourselves from endgame exploitation while having attempted to build cooperation earlier.

3. Otherwise (normal round):
   a. Compute recent group cooperation rate among the other players over the last w rounds:
      - For the last w rounds (or fewer when t ≤ w), sum all contributions of the other n−1 players and divide by w*(n−1). Call this avg_others (a number in [0,1]).
   b. If mode == COOPERATIVE:
      - If avg_others ≥ gamma: Cooperate (contribute 1). Continue signaling that we support collective provision.
      - If avg_others < gamma: Enter PUNISHING mode. Set punish_counter = max(1, round( P * (gamma − avg_others) / gamma )) (so short punishments are proportional to how far behavior has fallen). Defect this round.
   c. If mode == PUNISHING:
      - If punish_counter > 0: Defect this round and decrement punish_counter by 1.
      - If punish_counter == 0: Re-evaluate avg_others over the most recent w rounds.
         • If avg_others ≥ gamma: Exit PUNISHING, set mode = COOPERATIVE, and Cooperate this round.
         • If avg_others < gamma: Start one more short punishment (punish_counter = 1) and Defect this round.

Forgiveness and stability rules:
- Rapid recovery rule: if after exiting PUNISHING we observe avg_others ≥ gamma for two consecutive decision points, remain in COOPERATIVE and reset any punishment memory. This avoids oscillation between punishment and cooperation.
- Proportionality: punishments are short and scaled by the severity of recent non-cooperation; this reduces the risk that punishment collapses mutual cooperation forever.
- No perpetual retaliation: only short, proportional punishments are used; we never maintain an indefinite grim-trigger.

Tie-breaking and edge cases:
- Exactly at threshold (avg_others == gamma): treat as cooperative (Cooperate).
- Very small games or very short r: memory and punishment adapt because w, P, L are min’d by r; when r is 1 we cooperate in round 1 (but it is also the last round — see endgame rule precedence: if r==1 the "first round" rule and endgame coincide; choose Defect only if t > r−L; with L≥1 this makes final round defective — to preserve signal in tiny games change preference: if r==1, defect in the single round to avoid being exploited).
- If observations are incomplete because fewer than w past rounds exist, use all available past rounds to compute avg_others.

Why this is collective:
- Starts by signaling cooperation and sustains contributions whenever a clear majority reciprocates, focusing on maximizing group payoff.
- Detects and discourages persistent freeriding via brief, proportional punishments that make repeated defection costly for others while minimizing long mutual defection.
- Built-in forgiveness allows cooperation to resume quickly when others respond, preventing destructive punishment cycles and letting the group capture the collective gains of cooperation.
- Endgame safety preserves payoff near the horizon without undermining earlier cooperation.

Summary (compact policy):
- Round 1: cooperate to signal intent.
- In non-final rounds: cooperate whenever recent majority cooperation by others (avg_others ≥ 0.5); if not, apply a short proportional punishment (a few rounds of defection), then re-evaluate and forgive if others improve.
- In final L rounds (small, parameterized by r), defect to avoid endgame exploitation.
- Always use short, proportional punishments with prompt forgiveness to stabilize high group contributions over the repeated play.
'''

description_COLLECTIVE_24 = '''
Collective Conditional Cooperation with Graduated Punishment (C3GP)

Goal (collective mindset)
- Aim to sustain high group contributions whenever a clear cooperative norm exists among the other players.
- Deter and punish sustained or heavy free‑riding in a way that is proportional and forgiving so the group can return to cooperation.

Parameters computed from game inputs (only n, k, r and observed history)
- Lookback window L = min(5, t−1) (use up to the last 5 rounds of history; shorter early on).
- Recent average cooperation among others avg_recent = (sum of other players’ contributions over the last L rounds) / ((n−1) * L). If t=1, avg_recent is undefined — handled below.
- Cooperate threshold H:
  - If k >= n/2 (multiplier large relative to group) set H = 0.60 (be more forgiving).
  - Otherwise set H = 0.70 (be stricter when cooperation is harder to sustain).
- Punishment counter P (internal state): initially P = 0. When P > 0 the strategy is in a punishment phase and counts down each round.

Decision rules (what I play each round)
1. First round (t = 1)
   - Play C (cooperate). Signal cooperative intent to establish a norm.

2. Last round (t = r)
   - Play D (defect). In a finitely repeated setting the last round is not enforceable; defect to avoid being exploited.

3. Otherwise (1 < t < r)
   - Update avg_recent (use L as above). If L = 0 because t=1 we are already handled.
   - If P > 0 (I am punishing)
     - If avg_recent >= H (others have restored cooperation in the recent window), immediately cancel punishment: set P = 0 and play C this round.
     - Else: play D this round, then decrement P by 1.
   - If P = 0 (not currently punishing)
     - If avg_recent >= H: play C (reward cooperative group behavior).
     - If avg_recent < H: enter a proportional punishment:
       - Compute defection_severity = H − avg_recent (how far below the cooperation threshold the group is).
       - Set punishment length
         P = min(r − t, 1 + ceil( defection_severity * 5 * (n / max(1,k)) )).
         (Intuition: larger shortfalls and larger groups trigger longer punishments; scaling by n/k makes the punishment longer when individual return from the public good is smaller relative to group size.)
       - Immediately play D this round (punishment starts now). If P was set >0 then it will be decremented each subsequent round until either it reaches 0 or others restore cooperation (avg_recent >= H), which cancels punishment early.

Additional practical rules / tie breakers
- If avg_recent is near the threshold (within ±0.03), prefer cooperation (bias toward re-establishing cooperation rather than punishing marginal noise).
- When computing avg_recent early in the game with small L, give more weight to the most recent round: treat last round’s contributions as a tiebreaker (if last round had many cooperators, lean to C).
- If the tournament environment is extremely short (r ≤ 2), play D in round r and in round r−1 treat as above but be cautious: a one‑round history is noisy so punish only when last round had clear multi-player defection.

Why this is collective and robust
- Signals cooperation by starting with C and rewards groups that cooperate (so mutualists obtain higher joint payoff).
- Punishment is graduated and proportional: a single small mistake triggers a short punishment; sustained or large-scale free‑riding triggers longer punishments. This reduces vulnerability to exploitation but avoids harsh permanent retaliation (no infinite GRIM).
- Punishments are forgivable and immediately cancelled when others resume cooperative behavior, allowing recovery to mutually beneficial cooperation.
- The rules use only observed histories and game parameters n, k, r; no communication or outside coordination is required.
- Last round defection avoids end‑game exploitation while earlier rounds still support maintaining cooperation if the group reciprocates.

Summary (short pseudocode)
- t=1: C
- t=r: D
- else:
  - compute avg_recent over L = min(5,t−1)
  - if P>0:
      if avg_recent >= H: P=0, play C
      else: play D, P = P−1
    else (P=0):
      if avg_recent >= H: play C
      else: set P = min(r−t, 1 + ceil((H−avg_recent)*5*(n/max(1,k)))), play D

This strategy is designed to maximize collective welfare where possible by sustaining cooperation, to deter free‑riding with proportional, temporary punishment, and to forgive promptly so cooperation can resume.
'''

description_COLLECTIVE_25 = '''
Strategy name: Proportional Reciprocal Collective (PRC)

Summary goal
- Sustain high collective contributions while avoiding long-term exploitation.
- Start by giving the group the benefit of the doubt, punish defections in proportion to how many defect, and forgive gradually so cooperation can be re-established.
- Use only game parameters (n, r, k) and observed history of contributions; no communication or external signals.

Fixed internal parameters (derived from r)
- Window W = max(1, floor(r / 5)) — how many recent rounds we use to judge behaviour.
- Endgame horizon H = min(3, max(1, floor(r / 10))) — small final stretch where we guard modestly against unraveling.
- Cooperation threshold tau = 0.60 — require roughly majority/cooperative tendency to keep cooperating.
- Strong-cooperation threshold tau_high = 0.85 — used to permit cooperation even in end/last round.
(These constants are chosen to be responsive but forgiving; they depend only on r.)

State maintained from history
- For each player j (including self) compute s_j = fraction of rounds they cooperated in the most recent W rounds (or all past rounds if fewer than W).
- Let S_others = average of s_j over other players (exclude self).
- Let f_last = fraction of other players who defected in the immediately preceding round (if t=1, f_last = 0).

Decision rule for round t (1 ≤ t ≤ r)
1. First-round and general-initiation rule
   - Round 1: cooperate. (Start by trying to establish cooperation.)

2. Endgame safety (last H rounds)
   - If t > r - H (we are inside the final H rounds):
     - If r = 1: defect (no future to enforce reciprocity).
     - If S_others ≥ tau_high (≥ 0.85): cooperate (group has been reliably cooperative).
     - Else: defect. (Guard against being exploited when punishment opportunity is minimal.)

3. Normal-round rule (not in final H rounds)
   - If S_others ≥ tau (≥ 0.60): cooperate. (The group is sufficiently cooperative recently; sustain it.)
   - If S_others < tau: begin a proportional punishment and recovery procedure:
     a. Trigger punishment length P = 1 + ceil(f_last * W).
        - Interpretation: punish short and proportional to how many defected last round; if many defected, punish longer.
     b. Maintain a local counter punish_remaining; when we enter a punishment phase set punish_remaining = P.
     c. While punish_remaining > 0:
        - Defect this round.
        - After the round, recompute s_j and f_last, decrement punish_remaining by 1.
        - If during punishment S_others rises back above tau before punish_remaining reaches 0, immediately cancel remaining punishment and resume cooperating from next round.
     d. After punishment ends and group shows at least tau again, resume cooperating.

4. Tie-breakers and small-sample smoothing
   - If S_others equals tau exactly, prefer to cooperate (give the group the benefit of doubt).
   - When there are fewer than W past rounds, compute s_j over available rounds; behavior otherwise identical.

5. Forgiveness and re-entry
   - Forgiveness is automatic: cooperation resumes once recent average behaviour crosses the tau threshold.
   - Punishments are limited (proportional and short) so temporary mistakes or experiments do not lead to permanent collapse.

6. Last-round special-case (t = r)
   - If S_others ≥ tau_high: cooperate.
   - Else: defect. (No future rounds remain to deter exploitation unless past behaviour justifies trust.)

Rationale and properties
- Collectivity: The strategy prefers cooperation whenever the group as a whole has shown a sustained cooperative tendency (S_others ≥ tau). It aims to maximize collective payoff rather than narrow short-run individual gain.
- Proportionality: Punishments are proportional to recent observed defections (f_last) and limited in length (P ≤ 1 + W), avoiding overreaction that destroys cooperation.
- Forgiveness: Because punishments expire and are canceled early if the group recovers, the strategy re-establishes cooperation quickly after noise or limited opportunism.
- Endgame safety: In the very final rounds the strategy requires very strong past cooperation to keep cooperating, preventing easy exploitation by endgame defectors.
- Parameter dependence: All thresholds and windows are defined only from r (and fixed constants); they do not rely on assumptions about opponents’ psychology or coordination.

Edge cases handled
- r = 1: defect (no future to enforce cooperation).
- Very short games (r small): W and H shrink; the rules naturally become more conservative.
- Single persistent defector(s): the strategy punishes enough to make defection unattractive while not destroying cooperation with moderate punishment length.
- Occasional mistakes by others: short, proportional punishment plus forgiveness allows rapid return to cooperation.

Behavioural summary (quick)
- Round 1: cooperate.
- While the recent average cooperation of others ≥ 60%: cooperate.
- If that average falls below 60%: defect for a short, proportional number of rounds (longer if many players defected last round), then resume cooperation once the group’s recent behaviour recovers.
- In the last few rounds, require very strong past cooperation (≥ 85%) to keep cooperating; otherwise defect.

This strategy balances collective goals (sustaining cooperation) with robustness (limited proportional punishment and endgame caution) and uses only the allowed information (observed contributions and payoffs via the implied history).
'''

description_COLLECTIVE_26 = '''
Collective-minded adaptive strategy (natural-language pseudocode)

Principles
- Aim to sustain high group contributions when a substantial fraction of others are cooperating.
- Avoid being exploited by persistent defectors through proportionate, temporary punishment.
- Use forgiving recovery and periodic probes to restore cooperation after breakdowns.
- Defect in the final round (no future to reward cooperation).

Initialize (before round 1)
- Let r = total rounds, n = number of players, k = multiplier (1<k<n).
- Set memory window m = min(10, max(3, floor(r/4))).  (Use the most recent m rounds to judge behavior.)
- Set cooperation threshold tau = 0.6. (Require a clear majority of past cooperation to trust collective cooperation.)
- Set individual forgiveness threshold tau_ind = 0.5. (Individual considered “cooperative” if their recent cooperation ≥ tau_ind.)
- Set punishment_length_base p0 = 2. (Base number of rounds to punish a clear defection.)
- Set probe_interval = max(6, ceil(r/6)). (Occasional test cooperation while in defensive mode.)
- Maintain for each other player i: recent_coop_count_i (initialized 0), punishment_timer_i (initialized 0), last_probe_round = 0.
- Round counter t starts at 1.

Every round (before choosing action)
1. If t == r (final round): choose D (defect). End of decision. Rationale: there is no future to encourage cooperation.

2. Update recent histories using the observed actions from round t-1 (if t>1):
   - For each other player i, update recent_coop_count_i = number of times i chose C in last m rounds (sliding window).
   - For each i with punishment_timer_i > 0 decrement punishment_timer_i by 1.

3. Compute group statistics (excluding self):
   - For each i, recent_coop_rate_i = recent_coop_count_i / m.
   - group_coop_rate = average over i of (recent_coop_rate_i).  (This is the average recent cooperation rate among others.)
   - last_round_cooperators = number of other players who chose C in round t-1 (if t>1).

4. Immediate punishment rule (targeted and proportional):
   - For any player i whose recent_coop_rate_i fell below tau_ind AND whose defection in the very recent round(s) represents a clear deviation (e.g., changed from cooperating to defecting in the last 1–2 rounds), set punishment_timer_i = max(punishment_timer_i, p0 + ceil((tau_ind - recent_coop_rate_i) * m)).  
   - (Interpretation: persistent or abrupt low cooperation triggers a short proportional punishment window.)

5. Decide action for round t (priority order)
   A. If any punishment_timer_i > 0 and that player i’s recent defection pattern justifies punishment:
      - Defect (D) this round to impose a short, targeted sanction. (Do not punish forever; punishment timers count down and are re-evaluated.)
      - Rationale: targeted punishment deters persistent free-riding while limiting harm to the group.

   B. Else if group_coop_rate ≥ tau:
      - Cooperate (C). Rationale: enough of the group has been cooperating recently; contribute to sustain collective gains.

   C. Else (group_coop_rate < tau):
      - Defensive but exploratory behavior:
        i. If currently in a defensive phase (group_coop_rate has been below tau for multiple recent rounds), normally Defect to avoid exploitation.
       ii. But once every probe_interval rounds (i.e., if t - last_probe_round ≥ probe_interval), do a single Probe: Cooperate this round and set last_probe_round = t. If others reciprocate in the following rounds (their recent rates rise), return to cooperative mode. Rationale: probes let us discover if others are willing to reform cooperation.
      - Implementation: if no probe due, choose D; if probe due, choose C (a single-round offer to restart cooperation).

6. Tie-breakers / small adjustments
   - If group_coop_rate is very near tau (within ±0.05), bias toward cooperation once the recent trend of last 2 rounds is improving (more cooperators last round than previous). Bias toward defection if trend is worsening.
   - If almost all others (≥ n-2) have historically cooperated (recent_coop_rate_i ≥ 0.9 for most i), be slightly more generous: lower tau to 0.55 to maintain cooperation.

7. Recovery and contrition
   - Do not use permanent, indiscriminate punishment. When punished players begin cooperating enough that their recent_coop_rate_i ≥ tau_ind, cancel their punishment_timer_i (set to 0).
   - If this strategy itself was punished (others defected in response), recover by cooperating when indicators show a high fraction of others cooperating (group_coop_rate ≥ tau) or in a scheduled probe.

Edge cases
- First round (t=1): Cooperate (C). Rationale: give cooperation a chance to form. This is combined with readiness to punish if others exploit thereafter.
- Very short games (r ≤ 2): If r==1, follow final-round rule and Defect. If r==2, Defect on round 2 (final); on round 1 choose C only if n is small and k very close to n (but simpler default: cooperate on round 1 to test cooperation).
- If all players defect persistently: this strategy will converge to mutual defection with occasional probes to test for reform—minimizing loss.
- If a small minority persistently defects while most cooperate: punishment_timer_i targets those defectors, protecting the cooperative majority while minimizing overall welfare loss.

Why this is collective-minded and robust
- Collective: we cooperate whenever a clear majority of others have shown recent cooperation, thereby sustaining high-group-payoff equilibria when possible.
- Proportionate punishment: targeted, temporary punishments deter persistent defectors without destroying group cooperation (avoids permanent grim-trigger damage).
- Forgiving and adaptive: scheduled probes and short punishment windows allow recovery after mistakes or after opponents change strategy.
- Endgame-aware: we defect in the final round (no future incentive), preventing exploitation in the true last period while still promoting cooperation earlier.
- Parameter choices scale with r and use a short memory to adapt rapidly to changing opponent behavior; they do not rely on coordination or shared conventions.

Summary decision rule (one-sentence)
- Cooperate by default to sustain cooperation when the recent average cooperation of others is above a threshold; impose short, proportional, targeted punishments on persistent defectors; probe periodically during defensive phases to restore cooperation; and defect in the final round.
'''

description_COLLECTIVE_27 = '''
Name: Collective-Graded Reciprocity (CGR)

Goal: Sustain near-universal contribution (collective welfare) while avoiding prolonged exploitation by defectors. The rule set is deterministic, uses only n, k, r and the public history, and balances firm, proportionate punishment with fast forgiveness.

Definitions and parameters (computed from game parameters before play):
- Memory window W = min(10, r-1) (use up to the last 10 rounds or fewer if early).
- Weight for group tolerance adjusted by multiplier:
  high_coop_threshold = clamp(0.65 + 0.25 * (k - 1) / max(1, n - 1), 0.5, 0.95)
  low_coop_threshold  = clamp(0.45 + 0.20 * (k - 1) / max(1, n - 1), 0.2, high_coop_threshold)
  (Clamp means keep values inside [0,1]; these thresholds bias toward cooperation more when k is larger.)
- Targeted forgiveness requirement: an offender must cooperate for G = 2 consecutive rounds to be considered “rehabilitated.”
- Maximum group punishment length Pmax = min(4, r) (punishment should be short and proportional).

State tracked from history:
- For each player j (including self) compute recent cooperation rate PR_j = fraction of rounds they contributed within the last W rounds (if W = 0, define PR_j = 1 for initialization).
- Group recent cooperation rate RC = average_j PR_j (average over all n players).
- last_round_defectors = list of players who defected in the most recent completed round.
- For each player j, maintain a flag punished_j and number of punishment rounds remaining punish_rem_j (initialized to 0). These are derived from history deterministically as described below (no hidden variables required).

Decision rules (round t; rounds numbered 1..r):

1) First and last rounds
- If t = 1: Cooperate. (Signal willingness to build cooperation.)
- If t = r (final round): Defect. (No future to incentivize reciprocation; cooperating is purely altruistic with no return.)

2) Rehabilitation and targeted punishment (priority over group punishment)
- For each opponent j ≠ self:
  - If PR_j (computed over last W rounds) ≤ 0.4 and j has defected in at least one of the last two rounds, begin targeted punishment of j:
    - Set punish_rem_j = min( Pmax, 1 + number_of_times_j_defected_in_last_W_rounds ).
    - While punish_rem_j > 0: defect this round (to punish the group-level presence of that persistent defector), decrement punish_rem_j each round.
  - If a previously punished opponent j has cooperated for G consecutive rounds, clear punish_rem_j = 0 and resume cooperating with respect to j.
- If any punish_rem_j > 0 this round: defect. (Targeted punishment takes precedence; it is collective but aimed at persistent defectors rather than punishing a whole group forever.)

3) Group assessment and graded response (applies when no active targeted punishment)
- Compute RC (recent group cooperation rate).
- If RC ≥ high_coop_threshold: Cooperate. (Trust is high; support full cooperation.)
- If RC ≤ low_coop_threshold: Defect. (Group has eroded; withhold contribution to avoid being exploited.)
- If low_coop_threshold < RC < high_coop_threshold: use a graded short punishment if the most recent round showed a meaningful drop:
  - Let d_last = number of defectors in the most recent completed round.
  - If d_last = 0: Cooperate.
  - If d_last = 1: Cooperate (treat one-off mistakes leniently).
  - If 2 ≤ d_last ≤ ceil(0.25 * n): Defect for P = 1 round (mild group-level shock to remind others).
  - If d_last > ceil(0.25 * n): Defect for P = min(Pmax, 1 + floor(d_last / 2)) rounds (stronger short punishment proportional to scale of the collapse).
  - After the prescribed P rounds of group punishment, re-evaluate RC and targeted punishments; resume cooperation only if RC has recovered to ≥ high_coop_threshold or if defectors show rehabilitation (see step 2).

4) Forgiveness and recovery
- Punishments are always short and proportional. After any punishment epoch (targeted or group), resume cooperation as soon as either:
  - RC ≥ high_coop_threshold, or
  - All punished individuals have shown G consecutive cooperative rounds.
- Never lock into permanent full defection. The strategy’s social aim is to return to near-universal contribution quickly if others respond.

5) Ties and deterministic tie-breaking
- Where thresholds or counts leave ambiguity, break ties in favor of cooperation unless doing so would repeatedly allow the same player to exploit you (tracked by targeted punishment rules).

Rationale and properties
- Collective mindset: This strategy prefers collective welfare — it starts cooperative, aims for full contribution, and resumes cooperation quickly once others behave cooperatively.
- Robustness: Persistent defectors trigger targeted punishment so the whole group is not permanently harmed by a few exploiters. Group punishments are short and scaled to the severity of recent collapse, preventing run-away retaliation cycles and avoiding giving defectors long-term spoils.
- Adaptivity: Uses recent behavior (window W) and k,n to tune tolerance and punishment severity. It is lenient to one-off deviations but firm against repeated exploitation.
- Endgame safety: Defects in the final round to avoid certain exploitation when no future reward is available.

This strategy uses only observed contributions and the known game parameters, is deterministic, and balances the collective objective (maximize group payoff via cooperation) with protection against exploitation and quick forgiveness to re-establish cooperation.
'''

description_COLLECTIVE_28 = '''
Name: Collective Conditional Cooperator with Graduated Punishment and Forgiveness (C3-GPF)

Intuition (one sentence): Start by signalling a cooperative intention; keep cooperating as long as a clear majority of the group is cooperating; when free‑riding becomes persistent, apply a short, proportional group punishment to restore norms; always forgive reasonably quickly so cooperation can resume; defect in the final round (no future enforcement).

Parameters computed from the game (deterministic, based only on n, r, k):
- m = min(3, r) — smoothing window (use up to the last 3 rounds to reduce noise).
- target = clamp(0.5 + 0.2 * (k - 1) / (n - 1), 0.5, 0.9). (A threshold fraction of players cooperating that signals a healthy cooperative norm. It increases slowly with k.)
- P_max = max(1, ceil(r / 6)) — the maximum punishment length (never extremely long relative to the game length).
- forgiveness_required = 2 — number of consecutive “good” rounds needed to cancel an ongoing punishment early.
- endgame_defect_round = r (always defect in the last round).
- endgame_soften = ceil(r * 0.1) — in the final ~10% rounds, avoid starting long punishments; punishments are limited to at most 1 round if initiated there.

State you maintain:
- punish_counter (integer, initially 0) — rounds remaining of active punishment.
- last_m_rounds_coop_rate (computed each round from history): average fraction of players who contributed across the last m completed rounds (exclude the current pending decision).

Decision rules (pseudocode-like description):

At the start of round t (1 ≤ t ≤ r), observe full history of actions up to round t-1 and any internal punish_counter.

1. Final round safety
   - If t == endgame_defect_round: choose D. (No credible punishment afterward.)

2. Compute recent cooperation
   - If t == 1: recent_rate = 1 (interpret as “no evidence of defection” so we open cooperatively).
   - Else: let recent_rate = average over last m completed rounds of (number of players who chose C in that round / n).

3. If punish_counter > 0 (we are currently punishing):
   - Action: choose D this round.
   - Decrement punish_counter by 1.
   - Observation after the round: if after finishing the punishment there were at least forgiveness_required consecutive completed rounds (ending with this round) in which the fraction cooperating ≥ target, set punish_counter = 0 and resume normal cooperation behavior next round (i.e., forgive early if the group restores the norm).

4. If not currently punishing (punish_counter = 0):
   - a) If recent_rate ≥ target:
       - Action: choose C (cooperate). (Reward continued cooperation.)
   - b) If recent_rate < target:
       - Start a proportional, limited punishment:
         - deficit = target - recent_rate (a number in (0, target]).
         - planned_length = min(P_max, max(1, ceil(deficit * r)))  // punishment length proportional to how large the shortfall is, at least 1, capped by P_max
         - If t > r - endgame_soften: // near the end, don't start long punishments
             planned_length = min(planned_length, 1)
         - Set punish_counter = planned_length.
         - Action (this round): choose D (begin the group punishment).
       - Rationale: a short, proportional groupwide withholding of contributions signals costs for free‑riding and gives incentive to return to cooperating in order to end punishment.

5. Ties and individual idiosyncrasies
   - If recent_rate is exactly equal to target, treat as “good” (cooperate).
   - If the group quickly restores cooperation (recent_rate ≥ target for forgiveness_required consecutive rounds), immediately stop punishment and resume cooperating.
   - If a single defection occurs in an otherwise cooperative group (isolated blip), the moving average over m rounds reduces overreaction; a single blip will usually not drop recent_rate below target, so the strategy tolerates occasional mistakes/noise.

Edge cases, explained:
- First round: cooperate. This signals collective intent and gives cooperation a chance to emerge without preemptive defection.
- Last round: defect. There is no future to enforce cooperation, so contribution is not credible; this prevents being exploited in the final round.
- Near the end of the game: punishments are shortened (to at most 1 round in the final ~10% of rounds) because long punishments are not credible when few rounds remain.
- Noise tolerance: using a short moving average (m up to 3) and forgiveness_required = 2 prevents endless retaliation from single mistakes.
- Proportionality: punishment length scales with how far the group deviated from the cooperative target, so the response is neither negligible nor excessively harsh.
- No coordination/labels assumed: the strategy conditions only on observable group cooperation rates and its own punishment state; it does not rely on private signals or communication.

Collective mindset and incentives:
- Defaulting to cooperation and forgiving reasonable lapses maximizes expected group welfare if enough players are conditional cooperators.
- Graduated, temporary group punishment makes defection costly to defectors by reducing everyone’s payoff during the punishment but limits damage by keeping punishments short and proportional; this creates clear incentives for others to return to cooperation without spawning endless vendettas.
- By calibrating target to the game parameters (k,n) and keeping punishments bounded by r, the strategy is adaptive to both short and long games and to the size/multiplier of the public good.

Summary rule-of-thumb (one-line operational): Start cooperating; cooperate as long as the recent fraction of cooperators ≥ target; if the group’s recent cooperation falls below target, withhold contributions (defect) for a short, proportional number of rounds to signal and deter free‑riding; forgive quickly when the group restores cooperation; always defect in the last round.
'''

description_COLLECTIVE_29 = '''
Strategy name: Threshold-Grace Reciprocity (TGR)

Intuition (collective mindset)
- I want to sustain high group payoffs by cooperating when a clear core of players reciprocates, and to punish reliably when cooperation breaks down so defection is not profitable. I balance firmness (to deter exploitation) with forgiveness (to restore cooperation after mistakes or exploration). I never rely on communication or identity-based promises — only on observed contribution counts and payoffs.

Setup (computed from game parameters)
- n = number of players, r = total rounds, k = multiplier.
- Cooperation threshold T = max(2, ceil(n/2)). (I treat a simple majority as the sign that a cooperative norm is active.)
- Small testing probability epsilon = 0.10 (used only during punishment to probe restoration).
- Last-round rule: in the final round (round r) I always defect (no credible punishment afterward).

State variables (derived from history each round)
- last_cooperators = number of players who contributed in the previous round (0..n).
- offense_streak = number of consecutive prior rounds in which last_cooperators < T (treat as 0 if no such recent failures).
- remaining_rounds = r - (current_round - 1).

Decision rules (what I play this round)
1. First round:
   - Play C (cooperate). I open by signaling willingness to build cooperation.

2. Final round:
   - If this is round r (final round), play D.

3. Normal rounds (not first or final):
   - Update offense_streak:
     - If last_cooperators >= T then set offense_streak = max(0, offense_streak - 1) (forgiveness for a good round).
     - Else set offense_streak = offense_streak + 1 (escalate when cooperation is lacking).
   - If offense_streak == 0:
     - Play C (I trust the cooperative norm is in force).
   - If offense_streak > 0:
     - Punish by playing D, except:
       - With small probability epsilon I will play C as a probe (testing whether others are returning to cooperation). This probe is rare and only to allow coordinated restoration.
     - Continue punishing D until I observe a full recovery signal (see Recovery rule below).

Recovery rule (how cooperation resumes)
- I interpret recovery as observing at least one round (while I'm not locked in a permanent endgame) with last_cooperators >= T.
- After observing such a recovery round:
  - I take one “probation” cooperation round: I play C the next round to confirm the recovery.
  - If the probation round is followed by last_cooperators >= T again, I set offense_streak = 0 and resume cooperative mode (play C while threshold is met).
  - If probation fails (another round with last_cooperators < T), I resume punishment (set offense_streak >= 1 and defect).

Escalation and limits
- The longer the consecutive failures (higher offense_streak), the longer I will continue defecting, because I require a clear multi-round signal of recovery before trusting others again.
- Punishment is proportionate and finite: it can be ended by a clear recovery signal; it is not an unbounded grim trigger unless other players never meet the recovery threshold.
- If I find myself the only cooperator for multiple rounds (I see last_cooperators = 1 repeatedly), I switch to persistent defection until I see the recovery signal — this avoids being exploited as a lone contributor.

Endgame caution
- I always defect in the final round. In the penultimate rounds my behavior still follows the above rules with the awareness that remaining_rounds is small; I avoid long punishments that cannot be sustained or recovered in time — i.e., if only one round remains after punishment would start, I prefer to conserve tokens (defect) rather than attempt a costly punishment that cannot be enforced.

Summary of properties
- Collective: starts cooperative, cooperates when a clear majority reciprocates, and uses group-level signals (how many cooperated) rather than individual targeting to cultivate public good.
- Adaptive: escalates punishment when cooperation drops, but forgives after observed recovery; probes occasionally to escape deadlocks.
- Robust: avoids being repeatedly exploited (switches to defection when isolated cooperator), deters short-term free-riding by credible, proportionate retaliation, and is resilient to a wide range of opponent behaviours because it reacts to aggregate cooperation levels rather than depending on identities or promises.
'''

description_COLLECTIVE_30 = '''
Name: Reciprocal Collective with Graded Forgiveness (RC-GF)

Goal (collective mindset)
- Preserve and restore high group contributions whenever feasible; avoid being endlessly exploited; punish defections just long enough to deter them and allow repentant players back into cooperation. Use public history only.

Parameters computed from game data
- n, r, k are given by the game.
- Memory window L = min(5, r) (recent rounds to judge behavior).
- Single-defection leniency: S = 1 (single-round punishment for isolated defections).
- Maximum short punishment Pmax = min(3, r) (caps punishment length).
- Strong punishment multiplier M = 2 (extra punishment for mass/serial defection).
- Endgame vigilance window E = min(2, r) (final rounds where we are careful).

Overview of decision style
- Start optimistic (cooperate).
- Reward widespread cooperation.
- Punish defections in proportion to severity (number and persistence).
- Forgive after a limited punishment if cooperation resumes.
- In the final rounds be cautious but still preserve cooperation if the group has been reliably cooperative.

Detailed decision rules (what I do each round t)
1. First round (t = 1)
   - Contribute (C). This signals cooperative intent.

2. At the start of each subsequent round t (2 ≤ t ≤ r), compute from history:
   - For each player j and each past round s, c_j(s) ∈ {0,1} is their contribution.
   - recent_rounds = rounds max(1, t-L) ... t-1.
   - group_coop_rate_recent = (sum over j and s∈recent_rounds of c_j(s)) / (n * number_of_recent_rounds).
   - last_round_defectors = number of players j with c_j(t-1) = 0.
   - For each player j compute their personal_coop_rate over recent_rounds.
   - persistent_defectors = players with personal_coop_rate ≤ 0.2 (very low recent cooperation).

3. Main cooperation/defection logic
   - If currently in a Punish mode with remaining punishment rounds > 0:
     - Defect (D). Decrease remaining punishment rounds by 1. (Punish mode is set only by triggers below.)
   - Otherwise (not currently punishing):
     - Case A — Strongly cooperative recent history:
       - If group_coop_rate_recent ≥ 0.9:
         - Cooperate (C). Reward near-universal cooperation.
     - Case B — Mostly cooperative but not perfect:
       - If 0.6 ≤ group_coop_rate_recent < 0.9:
         - If last_round_defectors = 0:
           - Cooperate (C).
         - Else if last_round_defectors = 1:
           - Enter a lenient punishment: set remaining punishment rounds = S (1). Then Defect this round (D).
         - Else (last_round_defectors ≥ 2):
           - Enter a proportional punishment: set remaining punishment rounds = min(Pmax, M * (last_round_defectors - 0)) and Defect now.
     - Case C — Weak recent cooperation:
       - If group_coop_rate_recent < 0.6:
         - Treat as breakdown: set remaining punishment rounds = min(Pmax, M * ceil((1 - group_coop_rate_recent) * n))
           (practical effect: defect for 1–Pmax rounds scaled with severity). Defect now.
     - Reintegration rule:
       - After punishment completes, if group_coop_rate_recent (recomputed then) has risen to ≥ 0.6, immediately resume cooperation.

4. Handling persistent defectors
   - If one or more persistent_defectors exist (personal_coop_rate ≤ 0.2 over recent window):
     - Bias decisions toward defecting unless the cooperation rate excluding those persistent defectors is high:
       - compute coop_rate_excluding_persistent = (sum contributions in recent_rounds by all players not in persistent_defectors) / ((n - number_persistent) * number_of_recent_rounds).
       - If coop_rate_excluding_persistent ≥ 0.75 then Cooperate; else Defect.
     - This prevents repeatedly subsidizing a small group of serial free-riders while still cooperating with a cooperative majority.

5. Last rounds / endgame handling
   - If t is within the final E rounds (t > r - E):
     - Be cautious: do not automatically cooperate based on stale history.
     - Cooperate in a final-round only if the immediately previous round (t-1) had all players cooperating (sum_j c_j(t-1) = n) and we are not currently punishing. Otherwise Defect.
     - Rationale: protect against endgame exploitation but preserve cooperation if the group has clearly sustained it up to the end.

6. Tie-breaking and small randomization (optional but recommended)
   - If a rule leaves me indifferent (e.g., exactly at thresholds), prefer Cooperate to bias toward collective welfare.
   - Optionally, to avoid being exploited by deterministic cycles, occasionally (very small probability, e.g., 1%) cooperate when about to punish a single isolated defection; but randomness is not required.

Properties / rationale
- Starts cooperative to encourage mutual contributions.
- Uses recent group behavior (L rounds) rather than single incidents, so it is robust to occasional mistakes and to strategies that alternate.
- Punishments are graded and capped, avoiding permanent grudges that lock the group into low production.
- Single isolated defections get only brief, lenient punishment (keeps cooperation stable under noise or error).
- Wider or repeated defections get proportionally stronger punishment to deter exploitation.
- Persistent free-riders are not endlessly funded: the strategy declines to cooperate if they dominate recent behavior, but still can cooperate with the rest.
- Endgame vigilance prevents easy exploitation in final rounds but does not unconditionally sabotage cooperative endings.
- All decisions use only n, r, k (to set time windows) and observable history; no communication or coordination assumed.

Implementation notes (how to apply in the tournament)
- Maintain a small state: PunishCounter, recent history window L, list of persistent defectors.
- Update group_coop_rate_recent each round; set or decrement PunishCounter per the rules above.
- Always allow re-entry to cooperation once recent behavior shows improvement.

This strategy aims to maximize long-run group payoff where possible while remaining robust to defectors and avoiding escalatory or permanent retaliation.
'''

description_COLLECTIVE_31 = '''
Name: Proportional Forgiving Trigger (PFT) — a collective, reciprocity-based strategy

High-level idea
- Aim to sustain wide cooperation whenever other players are cooperating, but avoid being exploited by defectors. Punish defections in proportion to their size, then forgive so cooperation can recover. Start cooperatively to signal willingness to cooperate; defect in the final round because no future punishment is possible.

Definitions (used below)
- n: group size (given).
- r: total rounds (given).
- t: current round (1..r).
- coop_count(t-1): number of players who contributed (C) in round t-1 (includes your action in t-1).
- defect_count(t-1) = n − coop_count(t-1).
- majority_threshold = ceil(n/2) (strict majority). Treat fraction threshold = majority_threshold / n.
- punishment_timer: integer countdown of remaining punishment rounds (initially 0).
- recovery_check: after a punishment phase we require evidence (recent rounds) that cooperation has resumed before returning to open cooperation.

Decision rules (pseudocode-style)
- Initialization:
  - punishment_timer = 0
  - In round 1: play C (cooperate).

- For each round t = 1..r:
  - If t == r (final round): play D (defect). (No future to enforce cooperation; avoid being exploited.)
  - Else if punishment_timer > 0:
      - Play D.
      - Decrement punishment_timer by 1 after the round.
  - Else (punishment_timer == 0):
      - If t == 1: play C (handled above).
      - Else compute coop_count(t-1).
        - If coop_count(t-1) >= majority_threshold:
            - Play C (support and maintain cooperation).
        - Else (fewer than a majority cooperated last round):
            - Enter proportionate punishment:
              - Set punishment_timer := min(r - t, defect_count(t-1)).
                - (That is: punish for a number of rounds equal to the number of defectors in the last round, but never past the final round.)
              - Play D this round (start the punishment).

- Recovery / forgiveness rule (implicit in the above):
  - After the punishment_timer expires, the strategy resumes the “if last round had majority cooperators then C, else punish” rule. Because punishment lengths are short and proportional, a single or small defection leads to quick, limited punishment and then an opportunity to recover to cooperation if others respond by cooperating in subsequent rounds.

Notes on parameter choices and rationale
- Start cooperatively to signal a willingness to sustain group gains; cooperation is mutually beneficial if others reciprocate.
- Majority threshold (ceil(n/2)) is simple, easy to observe, and aligns with a collective mindset: if more than half of the group cooperated last round, the group is broadly supporting the public good and it is worth contributing to sustain it.
- Proportional punishment_length = number of defectors in the previous round:
  - If many players defected, the punishment is longer — this sends a stronger deterrent against large-scale free-riding.
  - If only one or a few players defected, punishment is short — this avoids overreacting to isolated lapses and increases robustness against transient deviations or strategic exploration by others.
- Forgiveness is automatic after the punishment timer expires and cooperation returns (as detected by the majority rule). This prevents permanent collapse of cooperation and invites restoration of mutually beneficial behavior.
- Final-round defection prevents being exploited when there is no ability to enforce future cooperation.

Edge cases and extra details
- If every player defects in round 1, this strategy will punish (defect) for defect_count(1) = n rounds bounded by the remaining horizon, which quickly ends because punishment cannot extend past r. The strategy will still attempt to restore cooperation if others start cooperating once punishment expires.
- If the group contains persistent defectors who repeatedly avoid cooperating, this strategy will continually punish when defect counts are high, reducing their gains while remaining ready to cooperate if the group majority shifts back.
- If the population sometimes mixes cooperative and exploitative strategies, PFT is forgiving enough to sustain cooperation with conditional cooperators and punitive enough to deter persistent free-riders.
- Deterministic: no randomization necessary; all decisions are derived from n, r and the observed history.

Collective mindset statement
- The protocol actively supports group welfare: it cooperates when a clear majority cooperates, it punishes in proportion to the harm done by defectors (deterring free-riding), and it forgives so cooperative norms can be restored. It therefore balances solidarity with accountability, maximizing the chance of sustained, high collective payoffs across diverse opponents.
'''

description_COLLECTIVE_32 = '''
Adaptive Proportional Reciprocity with Forgiveness (APRF)

Goal: maximize sustained group contributions while avoiding exploitation. Cooperate when the group shows recent, substantial cooperation; punish proportionally and briefly when cooperation falls; use controlled forgiveness (a single test cooperation) to recover cooperation. Always defect in the final round (no future to influence).

Parameters derived from game inputs:
- n = number of players (including you)
- r = total rounds
- k = multiplier
- w = window size for recent history = min(5, r) (short-term signal)
- W = longer window for trend detection = min(15, r)
- target fraction T = 0.60 (require a clear, but not extreme, majority of other players to be cooperating recently). If k is very large relative to n (contributions produce strong per-player returns), be slightly more forgiving: set T = 0.50 if k/(n) >= 0.7.
- Max punishment cap: P_max = max(1, min(r-1, 1 + floor(W/3)))

State variables (maintained from round to round):
- mode ∈ {COOP, PUNISH, TEST}; initially COOP
- punish_remaining (integer), initially 0
- last_punish_length (integer), initially 0

Definitions from observed history (after each completed round t):
- For each past round, observe each player's contribution c_j ∈ {0,1}.
- For a window of rounds, cooperation rate among others = average over the window of (sum_{j≠i} c_j) / (n-1).
- Recent_rate = cooperation rate among others over the last w rounds.
- Trend_rate = cooperation rate among others over the last W rounds.

Decision rules (what to play this round), evaluated at the start of each round before choosing action:

1. Final-round rule
- If this is the last round (round index = r): choose D (defect). (No future to influence.)

2. Very short games
- If r = 1: defect (same as above).
- If r = 2: cooperate round 1 only if no prior information (start with COOP); but if opponents have shown uncooperative tendencies in the first round, switch to defect in the second.

3. General rule for rounds 1 .. r-1
- Round 1: start with C (cooperate) unless r = 1.
- For t ≥ 2, compute Recent_rate and Trend_rate from observed history (exclude the current round since not yet played).

Mode COOP (default cooperative posture)
- If Recent_rate ≥ T, play C and remain in COOP.
- If Recent_rate < T, interpret this as a harmful drop in group cooperation:
  - Compute short deficiency d = T - Recent_rate (a number in (0,1]).
  - Set punish_length = min(P_max, 1 + ceil( d * (n-1) )) — proportional to how far cooperation fell.
  - Set last_punish_length = punish_length; set punish_remaining = punish_length; set mode = PUNISH.
  - Play D this round (immediate proportional retaliation).

Grace for single slips: if Trend_rate ≥ 0.90 (very strong long-term cooperation) and Recent_rate is only slightly below T (d ≤ 0.10), treat as accidental slip: play C this round and do not enter PUNISH. This avoids collapsing cooperation over a single deviator.

Mode PUNISH (punish the group proportionally)
- While punish_remaining > 0:
  - Play D (defect).
  - Decrement punish_remaining by 1 each round.
- When punish_remaining reaches 0, transition to TEST mode on the next round.

Mode TEST (forgiveness probe)
- On the single TEST round: play C (one cooperative test).
- After observing contributions in the TEST round, measure Recent_rate (including that test round in the w-window).
  - If Recent_rate ≥ T, conclude cooperation is restored: set mode = COOP.
  - If Recent_rate < T, cooperation not restored:
    - Increase last_punish_length: last_punish_length = min(P_max, max(1, last_punish_length * 2)) (escalate but cap).
    - Set punish_remaining = last_punish_length, set mode = PUNISH, and play D next rounds while punishing.

Additional details and rationale
- Proportional punishment: punish_length scales with how badly group cooperation fell; this avoids overreacting to one or two defectors but ensures stronger response when many defect.
- Forgiveness via TEST: one cooperative test gives others a chance to re-establish cooperation; successful tests return us to cooperation quickly, preventing permanent cycles of retaliation.
- Escalation on repeated failures: if tests fail repeatedly, punishments lengthen (doubling) to make cooperation restoration more attractive to others, but punishments are capped (P_max) and never permanent.
- Trend-based leniency: if the long-run Trend_rate is very high, tolerate small, isolated drops to resist accidental collapses.
- Last-round defection: standard backward-induction safety — no future benefit from cooperating in the final round, so defect there to avoid being exploited.

Collective mindset summary
- Start cooperatively and prefer sustained mutual cooperation.
- Only defect to signal and deter persistent under-contribution; punish proportionally and temporarily, then offer a clear, low-cost path back to cooperation (single test round).
- Use short and longer windows to distinguish accidents from genuine breakdowns.
- Never punish in the last round (instead defect) so punishments are future-directed and credible.

This strategy is adaptive (windowed statistics, proportional punishments, escalation), robust (forgives slips, resists exploitation, caps punishment), simple to implement from public history, and explicitly oriented to maximize collective contributions whenever the group is willing to reciprocate.
'''

description_COLLECTIVE_33 = '''
Adaptive Collective Conditional Cooperator (ACCC)

Summary / intent
- Aim to sustain high group payoffs by conditional, proportionate reciprocity: reward rounds with strong group cooperation by cooperating; punish rounds with significant defection by withholding cooperation for a short, calibrated punishment phase; always forgive and return to cooperation if group behavior recovers. Use small randomized probes to detect changes in opponents’ strategies. In the final rounds act cautiously to avoid being exploited by endgame unraveling.

Notation / internal variables
- n, r, k: game parameters (players, rounds, multiplier), known to strategy.
- t: current round index (1..r).
- history: full observed sequence of all players’ actions and payoffs up to round t−1.
- coop_i(s): whether player i cooperated in round s (1 if C, 0 if D).
- For any round s, group_coop_fraction(s) = (sum_j coop_j(s)) / n (includes me’s action in s when s < t; when evaluating others use fraction among others if needed).
- window w = min(6, r) — recent rounds to summarize behavior.
- epsilon (exploration) = 0.03 (3%): small probability to probe the group by deviating.
- punishment_counter: integer ≥ 0; when >0 we are in punishment mode and will defect until it reaches zero.
- Determine thresholds once at start:
  - low_threshold = 0.35 (if recent group cooperation is below this, treat behavior as largely defecting)
  - high_threshold = clamp(0.60 + 0.30 * (1 − k/n), 0.60, 0.90)
    (higher k/n → easier to sustain cooperation, so threshold is lower; lower k/n → require stronger demonstrated cooperation)

Behavioral rules (step-by-step for each round t)

1) Endgame handling
- If t == r (last round): defect (D). No future rounds to enforce reciprocity; avoid being exploited.
- If t == r − 1 (second-to-last round): be cautious.
  - Cooperate only if the recent window (last w rounds) shows very stable, near-unanimous cooperation: average group_coop_fraction over last w rounds ≥ max(0.95, high_threshold). Otherwise defect. The aim is to avoid being exploited in the final two rounds where enforcement is weak.

2) Immediate punishment mode
- If punishment_counter > 0:
  - With probability (1 − epsilon) defect (D).
  - With probability epsilon cooperate (C) as a probe.
  - Decrement punishment_counter by 1 at the end of the round.
  - Rationale: short targeted punishment to signal cost for defection, while allowing probes to detect recovery.

3) First round
- If t == 1 and r > 3: cooperate (C). Signal willingness to reach efficient collective outcome.
- If r ≤ 3: be cautious; if r == 1 defect (no future), if r == 2 cooperate first round only if you expect reciprocal behavior (use same window logic but there is no history) — default: cooperate in round 1 for r==2 to allow a single cooperation exchange, but treat r small conservatively.

4) Regular rounds (1 < t < r − 1 and not in punishment)
- Compute recent behavior measures:
  - p_last = group_coop_fraction(t − 1) (fraction of players who cooperated last round).
  - p_window = average of group_coop_fraction(s) over the last w rounds (s = max(1,t − w) .. t − 1).
  - frac_defectors_last = 1 − p_last.
  - For each player j, compute personal_coop_rate_j over the last w rounds (to detect persistent defectors).
- Decision rules:
  A) If p_window ≥ high_threshold: cooperate (C) with probability (1 − epsilon) (small probes allowed); this rewards stable collective cooperation.
  B) If p_last between low_threshold and high_threshold:
     - Cooperate with probability p_last + 0.05 (i.e., roughly mirror the last-round group cooperation, slightly generous), subject to exploration epsilon (so actual cooperation prob = (1−epsilon)*(p_last+0.05) + epsilon*random).
     - If p_last is trending up relative to p_window, bias toward cooperating to help stabilize.
  C) If p_last < low_threshold:
     - Defect (D) (group is mostly defecting; stop being exploited).
     - Additionally, if frac_defectors_last ≥ 0.30 (i.e., substantial fraction defected last round), initiate a punishment phase:
         set punishment_counter = 1 + round( 4 * frac_defectors_last ).
       (Punishment length is proportional to severity but capped by r via natural ceiling.)
     - When defecting because of low cooperation, still allow with probability epsilon a cooperative probe to test for recovery.

5) Targeted consideration of persistent individual defectors
- Compute personal_coop_rate_j for each player j over last w rounds.
- If a subset of players (≥1) have personal_coop_rate_j ≤ 0.2 while the rest cooperate frequently, consider this as evidence of persistent free-riders. In that case:
  - Reduce your cooperation probability so that it is roughly equal to the fraction of players whose personal_coop_rate_j exceed 0.5 (i.e., cooperate mainly when a majority of players are not persistent defectors). This punishes defectors collectively while preserving cooperation with reciprocators.
  - Continue to probe occasionally (epsilon) in case those players’ behavior changes.

6) Forgiveness and recovery
- After any punishment phase or period of defection, if p_window over the most recent w rounds rises above high_threshold, end punishment early (set punishment_counter = 0) and resume cooperating with high probability. Forgiveness is immediate when group behavior improves — the strategy prioritizes restoring efficient outcomes.

7) Random probing (always)
- In all non-final rounds, apply epsilon exploration:
  - With probability epsilon, take the opposite action from the deterministic rule (a small chance to cooperate during punishment or to defect when otherwise cooperating); this detects changes in the opponent population and prevents being trapped.

Design rationale and robustness
- Collective mindset: ACCC privileges high group payoff by rewarding strong, stable cooperation, but it protects itself from persistent exploitation by temporary, proportional punishments rather than infinite grim triggers. This promotes rapid return to cooperation when opponents respond while avoiding open-ended vendettas that lower group welfare.
- Proportionality: Punishment length scales with how many players defected, so single mistakes are punished lightly, mass defections are punished more strongly.
- Forgiveness: Immediate return to cooperation when the group shows recovery prevents long punishment spirals and is well-suited to noisy environments or strategies that occasionally err.
- Endgame caution: Last-round defection and cautious second-to-last behavior avoid being exploited by backward-inducing defectors in a finite-horizon game.
- Exploration: Small randomized probes detect shifts in opponent behavior and prevent exploitation by extremely unforgiving opponents.
- Parameter dependence: high_threshold is lowered as k/n increases (cooperation is easier to sustain when the multiplier is large), so the strategy becomes more willing to cooperate when cooperation is more valuable.

Edge cases summary
- Round 1: generally cooperate to signal intent (unless r is 1, when defect).
- Last round: always defect.
- Second-to-last round: cooperate only under very strong prior evidence of unanimous cooperation.
- Short games (r small): be more cautious; do not commit to long punishment phases impossible to enforce.
- Single occasional defections: punished lightly (brief punishment_counter), with forgiveness quickly if group returns to cooperation.
- Widespread defection: respond with defection and a punishment phase proportional to severity.

Behavioral pseudocode (concise)
- Initialize punishment_counter = 0; compute w, thresholds, epsilon.
- For each round t:
  - If t == r: play D.
  - Else if punishment_counter > 0: with prob 1−epsilon play D, with prob epsilon play C; punishment_counter -= 1.
  - Else if t == 1 and r > 3: play C.
  - Else if t == r−1: if avg(group_coop over last w) ≥ max(0.95, high_threshold) play C else play D.
  - Else:
      compute p_last, p_window, frac_defectors_last, personal rates.
      if p_window ≥ high_threshold: play C (with prob 1−epsilon; epsilon probes).
      else if p_last ∈ [low_threshold, high_threshold): play C with prob approx (p_last + 0.05) (subject to epsilon).
      else (p_last < low_threshold): play D; if frac_defectors_last ≥ 0.30 set punishment_counter = 1 + round(4 * frac_defectors_last).
      adjust cooperation probability downward if a notable minority are persistent defectors (personal_coop_rate_j ≤ 0.2).
  - Apply epsilon exploration in every decision.

This strategy is simple to compute from observed history and game parameters, explicitly collective (seeking high group welfare), adaptive (responds to levels and trends of cooperation), robust (limited proportional punishment prevents exploitation without precipitating long vendettas), and conservative in the endgame to avoid unavoidable exploitation.
'''

description_COLLECTIVE_34 = '''
Strategy name: Collective-Conditional with Limited Punishment and Forgiveness (CC-LPF)

Goal: Sustain as much group cooperation as possible while avoiding long exploitation. Start by cooperating, reward groups that reciprocate, apply short proportionate punishments when many defect, and forgive quickly so cooperation can recover. Use only n, r, k and the observed history.

Parameters (computed from game parameters)
- Memory window w = min(4, r-1). (How many past rounds to inspect; if t=1 there is no history.)
- Cooperation threshold T = 0.60. (If a strong majority of others have been cooperating recently, treat the group as cooperative.)
- Low threshold T_low = 0.30. (If cooperation has collapsed, treat as defection wave.)
- Max punishment length P_max = min(4, max(1, floor(r/10)+1)). (Punishment is brief and scales mildly with total rounds.)
- Last-round safety: on round r (the final round) defect (no risk of future reciprocity).

State maintained
- pun_remaining (initially 0): number of rounds left in an active punishment phase.

Decision rule for round t (1..r)
1. Endgame rule
   - If r = 1: defect.
   - If t = r (final round): defect.

2. If pun_remaining > 0:
   - Defect this round.
   - Decrement pun_remaining by 1.
   - (After the punishment phase completes, resume the normal rule the next round.)

3. Compute recent cooperation rate among OTHER players:
   - If t = 1 (no history): treat recent cooperation rate p_recent = 1.0 (start optimistic).
   - Otherwise consider the last w rounds (or all past rounds if fewer than w exist). For each considered round compute the fraction of the other n-1 players who contributed; average those fractions to get p_recent ∈ [0,1].

4. Main conditional decision
   - If p_recent ≥ T:
     - Cooperate (reward the cooperative environment).
   - Else if p_recent < T_low:
     - Start a punishment phase: set pun_remaining = min(P_max, 1 + round((T - p_recent)/T * P_max)).
       (This scales punishment length with how badly cooperation collapsed, capped at P_max.)
     - Defect this round (the first punishment round).
   - Else (T_low ≤ p_recent < T):
     - Probe to rebuild cooperation: cooperate with probability 0.5 and defect with probability 0.5.
       (This stochastically tests whether others will return to cooperation without long cycles of retaliation.)

Additional notes / rationale
- Collective orientation: the rule prefers cooperation whenever a stable majority of others have been cooperating, encouraging and sustaining collective welfare rather than greedily defecting.
- Proportionate, limited punishment: punishments are short and scale with the observed breakdown in cooperation. This creates a deterrent to persistent free-riding but avoids locked-in mutual defection (which is costly to everyone).
- Forgiveness and probing: after punishment the strategy quickly tests returning to cooperation instead of escalating, allowing groups to reestablish high-payoff cooperative equilibria.
- Last round safety: defect in the final round where future reciprocity is impossible.
- Robustness: the method uses a short memory w and simple thresholds so it adapts to both steady cooperators and mixed/noisy opponents; probabilistic probing prevents brittle, endless punishment cycles.
- Parameter dependence: all numeric choices (w, P_max, T, T_low) are set using only n and r (and implicitly k through the collective orientation); they can be tuned but the scheme itself requires only game parameters and observed history.

Summary (short pseudocode style)
- Round 1: cooperate.
- For each round t:
  - If r=1 or t=r: defect.
  - If pun_remaining>0: defect; pun_remaining--.
  - Else compute p_recent from last w rounds.
    - If p_recent ≥ 0.60: cooperate.
    - If p_recent < 0.30: set pun_remaining per formula (≤ P_max); defect.
    - Else (0.30 ≤ p_recent < 0.60): cooperate with prob 0.5, else defect.

This strategy aims to maximize collective payoff by sustaining cooperation when others do, deterring freeloaders briefly and proportionally, and forgiving quickly so cooperative norms can return.
'''

description_COLLECTIVE_35 = '''
Collective Conditional-Cooperation with Forgiving Punishment (CCC-F)

Goal statement (collective mindset)
- My primary objective is to sustain high group contribution over the repeated interaction, while avoiding long-term exploitation. I default to cooperation to build group welfare, punish only enough to discourage free-riding, and restore cooperation quickly when others improve.

Parameters I use (derived from game parameters and horizon)
- n, k, r are known. I also use a few fixed internal tuning values that depend only on r (not opponent identities):
  - Recent window W = min(5, max(1, floor(r/10)) ) — lookback size for short-term behavior.
  - Forgiveness window F = W (same window for checking recovery).
  - Base punishment length P0 = min(2, r) (rounds of deliberate defection when punishment triggered).
  - Endgame window L = min(3, max(1, floor(0.1 * r))) — last rounds where I become cautious.
  - High-trust threshold Th_high = 0.90 (fraction of players contributing).
  - Medium-trust threshold Th_med = 0.60.
  - Generosity parameter g = 0.8 (probability of cooperating under medium trust).
  - Forgiveness probability p_forgive = 0.35 (used when attempting to restore cooperation after punishment).

Observables from history
- For any past round t: contributions_j(t) ∈ {0,1} for each player j.
- I compute recent_fraction = average over the last W rounds of (number of contributors in that round)/n. If fewer than W rounds exist, average over all past rounds.
- I also track long-run_fraction = average fraction of contributors over all completed rounds.

Decision rules (per round)
1. First round
   - Cooperate (contribute = 1). Starting cooperative signals collective intent and gives others chance to reciprocate.

2. General rule when not in a punishment episode (normal mode)
   - If remaining rounds ≤ L (in endgame window), switch to endgame rule (see below).
   - Compute recent_fraction.
   - If recent_fraction ≥ Th_high:
       - Cooperate. (Group is trustworthy; reward it with full cooperation.)
   - Else if Th_med ≤ recent_fraction < Th_high:
       - Cooperate with probability g (high generosity); otherwise defect this round.
       - Rationale: tolerate moderate lapses while remaining mostly cooperative.
   - Else (recent_fraction < Th_med):
       - Initiate a punishment episode: defect for P rounds where
         P = min( r_remaining, P0 + ceil((Th_med - recent_fraction)/0.10) ).
         (Punishment length increases modestly with how far recent_fraction is below Th_med.)
       - During punishment rounds I defect (contribute = 0). I publicly record the start and length (via my actions observed by others).

3. Punishment episode mechanics
   - While in a punishment episode I defect every round for the planned P rounds.
   - At the end of P rounds, enter a recovery check:
       - Measure recent_fraction over the last F rounds (now including some punishment rounds).
       - If recent_fraction has risen to ≥ Th_med (evidence others responded), I exit punishment and resume normal mode, starting with a cooperative round with probability p_forgive (to avoid immediate exploitation).
       - If recent_fraction remains < Th_med, repeat a short punishment (P' = min(r_remaining, max(1, floor(P/2))) ) and then re-check. This prevents indefinite escalation while keeping pressure.

4. Endgame rule (when remaining rounds ≤ L)
   - The backward-induction problem makes last-round cooperation fragile. To preserve group welfare when it is realistic:
     - If long-run_fraction ≥ Th_high (the group has been reliably cooperative across most of the game), continue to cooperate in endgame rounds.
     - Otherwise (group has not been reliably cooperative), be cautious and defect in endgame rounds—unless the immediate previous round showed full cooperation by all players, in which case cooperate this round (one-step trust).
   - This gives a bias toward preserving long-standing cooperation but prevents being repeatedly exploited in the final few rounds.

5. Single-round (r = 1)
   - Cooperate on round 1 (consistent with collective mindset). This risks exploitation but is consistent with favoring group welfare in the absence of reputation benefits.

Handling noise, mistaken moves, and mixed opponents
- Forgiveness and stochastic cooperation (g, p_forgive) prevent lock-in from single mistakes or occasional selfish actions.
- Punishment is proportional and temporary, designed to deter sustained free-riding while minimizing collateral damage to cooperators.
- Against unconditional cooperators: I keep cooperating (maximize group welfare).
- Against unconditional defectors: I quickly defect and stop wasting resources; punishment will be short-lived because others do not respond.
- Against conditional/strategic opponents: the visible pattern (cooperate-first, calibrated punishment, and forgiveness) encourages reciprocators to stabilize at high cooperation.

Targeting and fairness
- I do not single out individuals for permanent exclusion; punishments are applied as group-level responses because contributions are public goods. That is fair (no private sanctions) and clear to all players.
- Punishments are only as long as needed to elicit a recovery in group cooperation.

Summary (concise pseudocode-style)
- Round 1: contribute.
- Each round:
  - If in punishment episode: defect until P rounds are used; then evaluate recovery as above.
  - Else compute recent_fraction over W rounds.
    - If recent_fraction ≥ 0.90: cooperate.
    - Else if ≥ 0.60: cooperate with probability 0.8; otherwise defect.
    - Else: start punishment = defect for P = P0 + scaling; after P reassess and forgive probabilistically if cooperation recovers.
  - If in final L rounds: cooperate only if long-run_fraction ≥ 0.90 or last round was unanimous cooperation; otherwise defect.

Why this strategy is robust and collective
- It starts and rewards cooperation, which maximizes group payoffs when reciprocated.
- It punishes defection quickly but proportionally, discouraging exploitation without destroying future cooperation possibilities.
- It is forgiving and stochastic to recover from errors and to invite reciprocators back.
- It becomes cautious in the unavoidable endgame while preferring to preserve well-established cooperation.
- It depends only on parameters (n, k, r) and observed history (actions/payoffs), requires no communication or coordination, and balances collective welfare with self-protection in a tournament of unknown opponents.
'''

description_COLLECTIVE_36 = '''
Name: Reciprocal Collective (for finite repeated PGG)

Goal: Sustain high collective contribution whenever others reciprocate, while avoiding repeated exploitation. Be forgiving to recover from mistakes, but punish clear and persistent free-riding. Use only game parameters (n, r, k) and the observed history of actions and payoffs.

Fixed internal settings (deterministic functions of r):
- Window W = min(5, max(1, floor(r/5) * 1 + 2)) — in plain terms: evaluate the last up to 5 rounds (use fewer if r is small).
- Punishment length cap Pmax = min(3, r-1).
- Forgiveness probability F = 0.05 (small chance to forgive a single lapse and test restoration of cooperation).
- Strong-cooperation threshold TH_high = 0.80 (80% of players contributing in the window).
- Weak-cooperation threshold TH_low = 0.50 (50%).
- Last-round strictness: in round r (final round) require near-perfect recent cooperation to cooperate.

Decision rules (applied each round t = 1..r):

1) First-round rule:
- If r = 1 (one-shot), defect (D).
- If r > 1, start by cooperating (C). This opens opportunities for mutual cooperation.

2) At the start of any round t > 1 compute from history:
- For the most recent W rounds (or all past rounds if fewer exist), compute the average contribution rate among the other players:
  avg = (sum over those rounds of contributions by players other than me) / (W * (n-1)).
- Also record whether the most recent round was unanimous cooperation (everyone contributed).

3) Collective/majority encouragement:
- If avg >= TH_high: assume group is reliably cooperative — cooperate (C).
  Rationale: when most others are contributing, joining maximizes collective return and signals solidity.

4) Cautious cooperation / probabilistic testing:
- If TH_low <= avg < TH_high: cooperate with high probability (0.8) to maintain cooperation, but occasionally (1 - 0.8 = 0.2) defect to test whether cooperation is robust. If you defect in that random test, observe responses and resume evaluation next round.

5) Punishment against persistent free-riding:
- If avg < TH_low: presume group is not reliably cooperative.
  - Switch to punishment: defect (D) for up to P rounds, where P = min(Pmax, 1 + number_of_consecutive_rounds_with_avg_below_TH_low). The punishment length increases if low cooperation persists.
  - During punishment, keep monitoring avg; if avg returns above TH_low before P expires, end punishment and go to step 3/4.
  Rationale: proportional, finite punishment discourages exploitation but avoids permanent collapse.

6) Handling single lapses / errors (forgiveness):
- If there is exactly one round in the window with a single player defecting and otherwise the group is cooperative (avg >= TH_high except for that one lapse), treat it as noise: cooperate (C) with probability 1 - F; with small probability F, defect to test whether lapse is strategic. This prevents endless cycles of retaliation over mistakes.

7) Detecting targeted exploitation:
- If a single identifiable player (same player id) defects repeatedly while the rest cooperate, stop trying unilateral restoration: defect until that player’s behavior changes. This protects you against being repeatedly exploited by a pure defector.

8) Last-round handling (round t = r):
- Cooperate in the final round only if the immediately previous round was unanimous cooperation (every player contributed) and there have been no defections in the last min(3, r-1) rounds. Otherwise defect in the final round.
  Rationale: require strong recent evidence of full cooperation to risk cooperating in the endgame. This balances collective mindset (cooperate if group has been perfect) with exploitation avoidance.

9) Exceptional: short games and early endgame:
- If t is within the last 2 rounds (t >= r-1) be more conservative: raise TH_high to 0.95 and be more likely to defect unless near-perfect cooperation has been sustained. This reduces end-game unraveling while still allowing cooperation if the group has shown exceptional consistency.

Behavior summary (how it acts in practice):
- Open by cooperating (except one-shot), encouraging mutual cooperation.
- If the group largely reciprocates (>= 80% of others contributing recently), keep cooperating.
- If the group is mixed (50–80%), cooperate mostly but test and adjust stochastically so you neither surrender to defectors nor destroy fragile cooperation.
- If the group is weak (< 50%), punish for a short, proportional number of rounds, then re-evaluate (not permanent grim trigger).
- Forgive single lapses and noise with small probability to restore cooperation.
- Refuse to be repeatedly exploited by a persistent defector (identify and isolate them by withholding cooperation).
- In the final round (and final two rounds), require near-perfect prior cooperation to cooperate; otherwise defect.

Why this is collective and robust:
- Collective: the baseline choice is to cooperate and to sustain cooperation when others reciprocate; actions are geared toward maximizing collective payoff if reciprocity holds.
- Robust: the strategy defends itself against persistent free-riding through finite, proportional punishment and targeted isolation; it tolerates noise and includes forgiveness to recover cooperation; stochastic testing prevents being stuck when facing mixed strategies.
- Parameter choices depend only on r (through W and Pmax) and observed history; no external coordination or shared norms are assumed.

Implementation notes (for any tournament agent):
- Keep concise summary statistics each round (recent contributions by each player and totals).
- Use deterministic thresholds for most decisions, but include the small probabilistic elements for testing and forgiveness to avoid exploitable determinism.
- All thresholds and lengths above can be tuned slightly by the tournament entrant, but keep the qualitative structure: start cooperative, reciprocate majority cooperation, punish proportionally, forgive noise, and be cautious in the endgame.
'''

description_COLLECTIVE_37 = '''
Collective Conditional-Cooperator with Forgiving, Proportional Punishment

Goal (collective mindset)
- Promote and sustain group cooperation whenever other players are willing, while avoiding long-term exploitation by persistent defectors. Be clear and predictable: start cooperative, punish proportionally and temporarily when defections occur, and forgive if cooperation resumes.

Parameters (derived from game parameters n, k, r)
- Window length W = max(3, min(10, ⌈r/10⌉)). (Used to estimate recent behavior.)
- Punishment cap P_max = max(1, min(5, ⌈r/10⌉)). (Maximum rounds to punish after a clear group defection.)
- Forgiveness threshold for recent group cooperation C_thresh = 0.5 + 0.2 * (k - 1)/(n - 1). (Higher k → slightly higher tolerance for cooperation because group returns are larger.)
- Persistent-defector cutoff D_thresh = 0.2. (Players with long-run cooperation rate ≤ D_thresh are treated as persistent defectors.)
- Final-round safety: always defect in the last round. (Known finite horizon makes last-round cooperation exploitable.)
- If r = 1, defect (single-shot dominant action).

State to maintain from history
- For each other player j: total_coop_rate_j = fraction of rounds up to last round in which j cooperated.
- Recent_group_coop_rate = fraction of players who cooperated in the previous W rounds (averaged per round or equivalently the mean of per-round proportions).
- PunishRemaining (initially 0): number of remaining rounds to continue a punishment phase.
- PunishTriggerers: set of players whose recent defection triggered the current punishment (for bookkeeping/diagnosis).

Decision rules (what I play each round)
1. First-round rule:
   - Cooperate (start by showing willingness to build cooperation), unless r = 1 (see above).

2. Last-round rule:
   - If this is round r (final round), defect.

3. Before deciding, update statistics from history:
   - Compute each player's total_coop_rate_j and Recent_group_coop_rate over last W rounds.
   - Identify recent_defectors = set of players who defected in the previous round.
   - Identify persistent_defectors = players with total_coop_rate_j ≤ D_thresh.

4. If PunishRemaining > 0:
   - Defect this round and decrement PunishRemaining by 1.
   - If PunishRemaining becomes 0, clear PunishTriggerers and allow re-evaluation on next round (i.e., be ready to cooperate again if conditions are met).

5. If any persistent_defectors exist and their number is more than half of the group (excluding me):
   - Stop trying to maintain group cooperation: defect every round until the last round. (Protects against heavy exploitation when cooperation is hopeless.)

6. Normal decision (not in punishment, not dominated by persistent defectors):
   - If Recent_group_coop_rate ≥ C_thresh OR (everyone cooperated last round):
       - Cooperate. Rationale: the group is cooperating enough; reciprocate to sustain cooperation.
   - Else (recent group cooperation is low):
       - Initiate proportional punishment:
           - Let d = number of players who defected in the previous round (d = |recent_defectors|). If d = 0 but Recent_group_coop_rate < C_thresh, set d = 1 (punish a general decline).
           - Set PunishRemaining = min(P_max, 1 + d). Add recent_defectors to PunishTriggerers.
           - Defect this round (first round of punishment).

7. Targeting and proportionality notes:
   - Punishment is symmetric (I defect) rather than attempting impossible targeted actions; the length of punishment scales with how many defected recently so punishment is proportionate.
   - If the defection looks like a one-off (a single player defected but that player has a high total_coop_rate_j > 0.6), be lenient: set PunishRemaining = 1 (short punishment) to allow fast recovery from mistakes.

8. Re-entry to cooperation:
   - After PunishRemaining expires, resume cooperating if Recent_group_coop_rate ≥ C_thresh or if everyone cooperated in the most recent round; otherwise, continue punishing or defect by the rules above.
   - If PunishTriggerers (the players who caused punishment) resume cooperating consistently over W rounds (their recent rates rise above C_thresh individually), treat them as rehabilitated and stop holding their past against them.

Edge cases and robustness
- Very short games: if r ≤ 3, be conservative — cooperate in round 1, defect in final round, and if r = 2 cooperate round 1 then defect round 2.
- Noisy / single accidental defection: the lenient forgiveness (short punishments for lone or rare defections) prevents endless cycles caused by mistakes.
- Exploiters (unconditional defectors): low long-run cooperation rates trigger permanent defection if they are the dominant type, protecting my payoff.
- Mixed populations: this strategy rewards groups that can maintain cooperation (I cooperate when the group shows high cooperation), punishes proportionally when cooperation collapses, and is forgiving enough to re-establish cooperation when others reciprocate.

Why this is collective and robust
- Collective: decisions are driven by group-level statistics (recent_group_coop_rate and counts of recent defectors), not by trying to coordinate on arbitrary labels. The strategy signals willingness to cooperate early and repeatedly, and uses visible punishment only to restore collective cooperation.
- Robust: it avoids being naively exploited (detects and isolates persistent defectors), is forgiving so cooperation can recover from noise, and uses proportional punishments so it is neither too weak nor brutally unforgiving. It also respects the final-round incentive to defect so it does not get exploited at the end.

Summary (short pseudocode-style)
- If r = 1: defect.
- Else if round 1: cooperate.
- Else if round = r: defect.
- Else update cooperation statistics over window W and long-run rates.
  - If PunishRemaining > 0: defect and decrement PunishRemaining.
  - Else if persistent_defectors are majority: defect every round.
  - Else if recent_group_coop_rate ≥ C_thresh or everyone cooperated last round: cooperate.
  - Else initiate proportional punishment: set PunishRemaining = min(P_max, 1 + number_recent_defectors) (shorter if lone/rare defection by otherwise-cooperative player) and defect.
- After punishment, forgive and resume cooperation when group-level cooperation recovers.

This strategy therefore: open cooperatively, reciprocates cooperation, punishes in a proportional and temporary way to restore group welfare, forgives to avoid deadlock from mistakes, and protects itself from persistent exploitation.
'''

description_COLLECTIVE_38 = '''
Strategy name: Majority‑Driven Forgiving Conditional Cooperator (MD-FCC)

Goal (collective mindset)
- Try to sustain high collective contribution whenever other players are cooperating, punish shortfalls promptly to deter free‑riding, but forgive quickly so cooperation can recover after mistakes. Always avoid being exploited in the final round.

Common parameters (derived from game parameters and history)
- n, r, k: game parameters (given).
- window w = min(3, r-1) — use up to the last 3 rounds to judge recent group behavior.
- Majority threshold T = 0.5 (require at least half the group cooperating to consider the group “cooperative”).
- Punishment length P = 1 round (short, proportional punishment).
- Probation length G = 2 rounds (try to restore cooperation by being generous briefly after punishment).
- Persistent‑defector detection: if a player defects in at least s = min(3, r-1) of the last s rounds (i.e., repeatedly), consider them a persistent defector for adjustment decisions.

Decision rules (what I do each round)
1. If t = r (final round): defect (D).
   - Reason: contributing in the last round is always individually dominated; do not be exploited.

2. If r = 1 (single round game): defect (last round rule).

3. For round t = 1 (not final): cooperate (C).
   - Opening move is cooperative to try to establish a cooperative norm.

4. For any non‑final round t ≥ 2:
   - Compute recent group cooperation rate F = average over the last min(w, t-1) rounds of (number of contributors in that round) / n. Equivalently, consider the fraction of players who cooperated in the most recent round if you prefer a simpler signal.
   - If F ≥ T (at least a simple majority has been cooperating recently): contribute (C).
     - Rationale: when the group is mostly cooperating, contribute to sustain collective welfare.
   - If F < T (majority not cooperating):
     a) Defect this round (punish for breakdown of cooperation).
     b) After a punishment round, enter a probation where you attempt to rebuild cooperation:
        - For up to G = 2 rounds after the punishment, play C if in the immediately preceding round the group cooperation rate F was ≥ T; otherwise keep defecting. In other words, punish briefly, then test generosity for up to two rounds; if the group responds by cooperating (majority returns), resume cooperative play.
   - Additionally, if you detect one or more persistent defectors (a player defected in each of the last s rounds, with s = min(3, r-1)), treat that as strong evidence of permanent exploitation. If persistent defectors constitute a stable minority while the rest of the group still mostly cooperates, continue cooperating to preserve welfare; if persistent defectors are a stable majority (they consistently push F < T across the window), switch to defecting until the endgame (except still defect in final round by rule 1). This prevents being exploited indefinitely when most others are uncooperative.

Tie‑breaking / generosity
- If F exactly equals T (= 0.5), be generous: treat it as cooperative (play C). This avoids needless collapse from one ambiguous round.

Using payoff information
- If your own payoff fell substantially compared with the immediately prior round (indicating you were exploited or cooperation collapsed), treat that as an extra signal to impose the P = 1 punishment immediately (consistent with the F < T rule).

Summary of behavioral pattern
- Open with cooperation to build goodwill.
- Cooperate whenever a recent simple majority cooperated.
- If majority cooperation breaks, punish briefly (1 round), then try a short, generous probation (2 rounds) to let cooperation recover.
- Detect and respond to persistent exploiters by withholding cooperation if they form a stable majority; otherwise tolerate a minority of persistent defectors while continuing to cooperate with the cooperative majority.
- Always defect in the last round to avoid endgame exploitation.

Properties and robustness
- Collective: prioritizes group welfare when a majority supports cooperation.
- Adaptive: reacts to recent group behavior, uses short punishments and forgiveness to recover from noise/mistakes.
- Proportionate and robust: short punishments reduce risks of long retaliation cascades; persistent exploiters are identified and prevented from draining cooperative payoffs.
- Simple and parameter‑free to opponents: uses only n, r and observable history (actions/payoffs), no communication or coordination needed.
'''

description_COLLECTIVE_39 = '''
Adaptive Collective Conditional Cooperator (ACCC)

Goal: Maintain high collective contributions whenever there is evidence others are cooperating, punish persistent free‑riding in a limited way to deter exploitation, and forgive occasional mistakes so cooperation can recover. The strategy uses only the game parameters (n, k, r) and the observable history of every player’s past contributions and payoffs.

Parameters (defined from game info)
- Window length L = min(5, r − 1). (If r = 1 then L = 0 and handled below.)
- Cooperation threshold θ = 0.60 (require a clear majority pattern of cooperation in recent history to sustain cooperation).
- Single‑round generosity G = 1 (we tolerate one isolated drop below θ without immediate punishment).
- Punishment length P = min(3, max(1, floor(r/10))) rounds (short, proportional to game length).
- Recovery requirement S = 2 consecutive cooperative rounds by punished players to be considered “forgiven.”
- Endgame: always defect in the final round (round r). For very short games this tightens as described below.

Decision rules (applied at the start of each round t, with 1 ≤ t ≤ r)

1. Very short games and the last round
- If r = 1: defect (single-shot dominant action).
- If t = r (final round): defect (cannot credibly induce future reciprocation).

2. First move and default stance
- If t = 1 and r > 1: play C (cooperate) to signal willingness to build a public good.
- After round 1, default is to cooperate when recent evidence shows others are cooperating; otherwise defect.

3. Compute recent cooperation signal
- Let H be the last L rounds that exist (if fewer than L rounds have been played, use all past rounds).
- Compute group cooperation fraction F = (total contributions by all players in H) / (n * |H|). (If |H| = 0, treat F as 1 for the purpose of encouraging an initial start.)
- For each player p, compute their personal cooperation rate over H (used only for targeted forgiveness logic below).

4. Generous conditional cooperation
- If F ≥ θ: play C (cooperate). A clear recent majority cooperating is interpreted as a working cooperative norm to support.
- If F < θ:
  a. If this is the first round in which F < θ after at least one round with F ≥ θ (i.e., an isolated drop), and the previous round had F ≥ θ, play C (forgive one isolated drop — generosity to recover from mistakes or exploration).
  b. Otherwise, move to limited punishment logic (next rule).

5. Limited, proportional punishment against persistent low cooperators
- If F < θ and the isolated‑drop generosity in 4a does not apply:
  a. Count players with personal cooperation rate < 0.30 over H. If that count ≥ ceil(n/2) (i.e., a substantial core of persistent low cooperators), then enter a punishment phase:
     - Defect for P consecutive rounds (play D for this round if currently in or starting the punishment phase).
     - While in punishment phase, track which players’ cooperation rates improve.
     - After punishment ends, resume normal conditional cooperation (rule 4), but treat any player whose cooperation rate was flagged (below 0.30) as “unforgiven” until they contribute in S consecutive post‑punishment rounds. During that period, still apply normal group F threshold, but expect the group to reestablish cooperation before trusting the previously low cooperators.
  b. If fewer than ceil(n/2) players meet the “persistent low cooperator” criterion, simply play D this round (short, non‑escalatory refusal) and re-evaluate next round (fortune to avoid long punitive spirals against only a few defectors).

6. Recovering from punishment and noise
- Always allow recovery: once a punished player contributes in S consecutive rounds, count them as restored for the personal cooperation rate calculations.
- If group cooperation recovers (F ≥ θ) at any time after punishment, immediately revert to cooperating per rule 4.

7. Edge adjustments for short r
- If r ≤ 3: be more cautious about long punishments. Set P = 1 and L = r − 1 (so decisions are driven by available history). Still defect on the last round and start with C on round 1 (if r > 1).

Rationale (why this is collective and robust)
- Collective orientation: Start by cooperating and cooperate when recent history indicates a working cooperative norm exists (F ≥ θ). This supports and sustains mutually beneficial public good provision when opponents are willing.
- Robustness to noise: One isolated drop is forgiven so a single error or exploration does not collapse cooperation.
- Deterrence of persistent free‑riding: If a substantial core persistently defects, ACCC enforces a short, bounded punishment phase to reduce the benefit of exploitation and incentivize return to cooperation.
- Limited, proportional punishment: Punishment is short and calibrated to game length (P small), preventing permanent collapse of cooperation or long revenge cycles that harm everyone.
- Endgame safety: Defect in the final round where future reciprocity is impossible; otherwise preserve cooperation up to the end to extract collective gains when others reciprocate.

Behavior summary (compact pseudocode style)
- If r == 1: play D.
- If t == r: play D.
- Else if t == 1: play C.
- Else:
  - Compute F over last L rounds.
  - If F ≥ θ: play C.
  - Else if (previous round had F ≥ θ and this is the first drop): play C.
  - Else if many players (≥ ceil(n/2)) have personal cooperation rate < 0.30: enter/continue P‑round punishment (play D).
  - Else: play D (short refusal); re-evaluate next round.
  - After punishment, require S consecutive cooperative moves from previously flagged players before treating them as restored.
- Adjust L and P for very short r as specified.

This strategy trades a clear pro‑social default (cooperate when the group is behaving cooperatively) with short, targeted, and limited deterrence against persistent defectors and a tolerance for single mistakes — a combination that performs well across varied opponent behaviors in repeated public goods environments.
'''

description_COLLECTIVE_40 = '''
Name: Collective Conditional Reciprocity (CCR)

Core idea (brief): Start by signalling cooperative intent, sustain cooperation as long as the group returns cooperation, punish defectors in a measured and temporary way, forgive to avoid permanent collapse, and step back as the endgame approaches. Decisions use only the public history of who contributed each round and payoffs, plus the known parameters (n, r, k). Parameters below adapt to n, r, k so the behaviour is robust across many opponent types.

Definitions and internal bookkeeping (maintained from public history):
- round t runs from 1..r. Remaining rounds R_rem = r - t + 1 (1 on last round).
- For each player j keep:
  - total_coop_j = number of rounds j contributed so far.
  - coop_rate_j = total_coop_j / (t-1) (define as 0.5 if t=1 to avoid division by zero).
  - recent_coop_j = number of cooperations by j in the last W rounds (window defined below).
- group_recent_coop_rate = (sum of contributions by all players in last W rounds) / (n * W).
- my_recent_coops and my_last_action also tracked.
- persistent_defector_j: a boolean if coop_rate_j < individual_threshold (see thresholds below).

Adaptive default parameters (computed once from game parameters):
- Window W = min(10, max(1, floor(r/5))). (Shorter tournaments use small windows; longer tournaments use up to 10-round memory.)
- Base leniency L0 = 0.6. Adjust by multiplier strength: leniency = L0 - 0.3*(k/n - 0.5). (If k/n is large, be more lenient: threshold for trusting others goes down.)
  - Clamp leniency to [0.4, 0.8].
- individual_threshold = max(0.25, leniency - 0.15). (Lower than group threshold to avoid over-punishing single slips.)
- group_threshold = leniency. (If recent group cooperation >= this, treat the group as cooperative.)
- initial_build_rounds B = min(3, max(1, floor(r/6))). (A short explicit build phase to signal reciprocity.)
- max_punish = min(4, max(1, floor(r/8))). (Maximum number of consecutive punishment rounds against any persistent defector.)
- forgiveness_probability p_forgive_small = 0.05 (small chance to cooperate even while punishing, to break cycles).
- exploitation_sensitivity: if my per-round payoff falls more than one standard deviation below group average payoff in last W rounds, strengthen punishment (increase punish length by 1, capped at max_punish).

Decision rules (executed each round t):

1) First-round (t = 1):
- Cooperate (C). Goal: open opportunity to establish cooperation.

2) Last round (R_rem = 1):
- Defect (D). There is no future to enforce reciprocity; defect to take the immediate advantage.

3) Very short tournaments (r ≤ 2):
- If r = 2: cooperate round 1 to try to secure one cooperative exchange; in round 2 follow last-round rule and defect.
- If r = 1: defect (last-round rule).

4) General round t (neither first nor last):
A) Update statistics from history: coop_rate_j, recent counts, group_recent_coop_rate, identify persistent_defector_j (coop_rate_j < individual_threshold). Identify last-round defectors (those who chose D in t-1).

B) If group_recent_coop_rate ≥ group_threshold:
   - The group is behaving cooperatively. Cooperate (C) this round, except:
     - If there is a persistent_defector_j whose most recent behaviour shows repeated defection (e.g., last 2 rounds both D) and they have not started to recover, treat them individually by entering a targeted punishment sequence (see C. below). If only isolated and rare slips exist, ignore them and cooperate.

C) Targeted, measured punishment of individual defectors:
   - If a player j is persistent_defector_j (coop_rate_j below threshold) and they defected in the previous round(s), begin a targeted punishment: defect for P rounds where P = min(max(1, ceil(2 * number_of_recent_defections_by_j)), max_punish). That is, punish more if they have defected repeatedly, but limit duration.
   - While actively punishing any persistent defector, I will defect (D) in order to impose material cost on group payoff and on the defector’s incentive. However, with small probability p_forgive_small I will cooperate during a punishment round to allow escape from cycles.
   - I stop punishing a given player earlier if they show sustained recovery: coop_rate_j increases above individual_threshold or they contribute in R_recovery consecutive rounds (R_recovery = min(3, W)). Once they have recovered, resume cooperation as normal.

D) Collective punishment for mass defection:
   - If group_recent_coop_rate < (group_threshold - 0.15) (i.e., a clear breakdown), switch to defensive mode: defect until group_recent_coop_rate recovers to at least group_threshold. In defensive mode I will still occasionally (with small probability p_forgive_small) cooperate to test for recovery.
   - This prevents being repeatedly exploited by a mostly-defecting group.

E) Exploit detection and escalation:
   - If my own average payoff over the last W rounds is significantly (one standard deviation) below the group average payoff, raise punishment severity: when punishing increase P by 1 (capped), and shorten recovery requirements. This is to protect myself against targeted exploitation.

F) Probabilistic generosity to sustain cooperation:
   - If I am currently in punishment or defensive mode but the group_recent_coop_rate has risen to just below group_threshold, I will occasionally cooperate with probability equal to (group_recent_coop_rate / group_threshold) * 0.5 to encourage recovery. This prevents endless mutual punishment.

G) Special-case return-to-cooperation rule:
   - If I have been defecting for more than S consecutive rounds (S = min(3, max_punish)) and at least half the players (including myself) have raised their coop_rate recently, I unilaterally attempt to rebuild cooperation by cooperating one round; if the group responds by cooperating in majority next round, I commit to cooperation again.

5) Summary of action choice in order of precedence each round (except first and last):
- If R_rem = 1: D (last round).
- Else if currently in targeted punishment of a recognized persistent defector: follow punishment rule (D, with p_forgive_small chance C).
- Else if in defensive mode because mass defection occurred: D (with p_forgive_small chance C to test).
- Else if group_recent_coop_rate ≥ group_threshold: C (unless immediate punishment override above).
- Else if group_recent_coop_rate between (group_threshold - 0.15) and group_threshold: probabilistic cooperate (probability = scaled to closeness) to help recovery.
- Else (group_recent_coop_rate well below threshold): D.

Rationale and properties:
- Collective mindset: The strategy prioritizes group cooperation when it is present and sustainable (cooperate whenever a clear majority of history indicates cooperation). It acts to preserve cooperation by punishing repeat defectors in a measured, time-limited way rather than switching to permanent grim trigger.
- Robustness: Uses individual history to target punishment (reducing unnecessary harm to cooperators), forgiveness and probabilistic generosity to prevent oscillatory retaliation cycles, and adaptive escalation if exploitation is detected.
- Endgame-awareness: Defects on the last round to avoid being exploited when future reciprocity is impossible; short explicit build-phase encourages cooperative relationships early where they are feasible.
- Parameter adaptiveness: Window sizes, punish lengths and thresholds change with r and k/n so the strategy is neither too gullible on short games nor too unforgiving on long ones, and it is more willing to cooperate when the public multiplier makes cooperation more socially powerful.
- No external coordination required: All decisions are based only on observed past moves and known game parameters.

Edge cases:
- Very short games: cooperate round 1 in r=2, otherwise defect in r=1.
- If everyone always defects, CCR stops trying after a short defensive phase and defects to avoid repeated losses.
- If some players always cooperate, CCR will quickly identify and align with them and recover cooperating majority.
- Noise in opponents’ actions: occasional random defections are forgiven (individual thresholds and short punish durations) so a few noisy slips do not lead to permanent collapse.

End note:
This strategy balances generosity and protection. It rewards and sustains cooperative groups, punishes repeat defectors in a limited and targeted manner to restore norms, forgives to avoid destructive cycles, and withdraws cooperation near the end when reciprocity cannot be enforced.
'''

description_COLLECTIVE_41 = '''
Collective Conditional Cooperation with Graduated Punishment and Forgiveness

Idea (brief): Start by signalling willingness to cooperate. Cooperate as long as the group is mostly cooperating; punish briefly and proportionally when many others defect; forgive quickly when cooperation resumes. In the very last round always defect (to avoid being a lone sucker); in the closing few rounds raise the standard for cooperation to avoid endgame exploitation. All decisions use only n, k, r and observed history of actions/payoffs.

Notation used below: in round t, let rem = r − t + 1 (rounds remaining including this one). Let OthersCoop(t−1) be the number of other players who chose C in the previous round (for t = 1 treat this as n−1). Let f = OthersCoop(t−1)/(n−1) be the fraction of others who cooperated in the last observed round. Keep a small internal state: PunishRemaining (initially 0) and LastActionI (your previous action).

Rules (deterministic, easy to implement):

1. Initialization
- PunishRemaining = 0.
- In round 1: play C (cooperate) to signal cooperative intent (unless r = 1; see last-round rule below).

2. Last-round rule
- If rem = 1 (this is the final round), play D. (Do not risk being the lone cooperator in the terminal round.)

3. Closing window adjustment
- If rem ≤ 3 (the last three rounds before the final), be conservative: require near-unanimous recent cooperation to keep cooperating. Concretely use the thresholds below with stronger demand (see step 5).

4. If currently serving punishment
- If PunishRemaining > 0: play D, decrement PunishRemaining by 1, and continue to observe others’ actions. After PunishRemaining reaches 0, evaluate forgiveness conditions next round.

5. Normal decision (when not serving a punishment and not in final round)
- Compute f as defined above (for t = 1 treat f = 1).
- Set two thresholds:
  - Base threshold TH = 0.50 (majority).
  - Closing threshold TH_close = 0.90 (near-unanimous) used when rem ≤ 3.
  - Effective threshold = TH_close if rem ≤ 3 else TH.
- If f >= Effective threshold: play C (cooperate). This rewards groups that are mostly cooperating.
- If f < Effective threshold: enter a graded punishment:
  - Compute severity s = Effective threshold − f (how far short the group fell).
  - Set PunishRemaining = min(4, 1 + floor(4 * s)). (So punishment is 1–4 rounds; bigger when many players defect.)
  - Immediately play D this round (the first round of punishment) and decrement PunishRemaining by 1 as the round is consumed.

6. Forgiveness and contrition
- Once PunishRemaining reaches 0, do not immediately escalate permanently. If subsequent rounds show f >= TH (or TH_close if in closing window) then resume cooperation.
- If you accidentally defected in the previous round (LastActionI = D) while most others cooperated in that round (f prior round >= TH), treat your next action as contrition: cooperate once to restore trust, unless you are in the final round.

7. Resignation (avoid repeated exploitation)
- If over the last M = min(5, r) rounds the average fraction of others cooperating <= 0.20, assume the group is not cooperative and switch to persistent defection for the remainder of the game (set a flag Resign = true and always play D). This prevents endless attempts to be exploited when almost everybody defects.
- If Resign = true and afterwards you observe a sustained recovery (over M rounds the average cooperation fraction > 0.50), clear Resign and resume the normal rule set.

Design rationale and properties
- Collective: the strategy’s primary objective is to sustain high group cooperation; it begins cooperatively and only defects when a clear majority defected in the immediately preceding rounds.
- Adaptive: decisions depend on the recent behavior of the group (fraction f) and the number of rounds remaining (closing-window behavior).
- Proportional punishment: punishment length grows with the severity of defection and is capped, avoiding total breakdown from single mistakes.
- Forgiving: after punishment ends the strategy quickly returns to cooperation if others do, and it shows contrition if it was the apparent deviator.
- Robustness: the resignation rule prevents repeated exploitation when the population is largely non-cooperative; the closing-window threshold protects against endgame exploitation.
- Parameter choices are modest and rely only on n, k, r (the thresholds and caps are simple constants chosen to balance deterrence, error tolerance, and collective goals). They can be tuned if needed, but the logic remains the same.

This strategy is easy to compute with only publicly observed history, promotes and defends group cooperation, punishes proportionally and temporarily, forgives quickly when cooperation returns, and avoids being repeatedly exploited in long stretches of defection.
'''

description_COLLECTIVE_42 = '''
Name: Reciprocal Collective (RC) — “Cooperate first, punish briefly, forgive quickly, defect in the end”

Goal: maximize collective welfare by sustaining high mutual contributions when others reciprocate, while avoiding long exploitation by defectors. Uses only game parameters (n, k, r) and public history of actions and payoffs.

State and derived values (computed from parameters and history):
- t = current round index (1..r). Remainder rounds remaining = R = r - t + 1.
- history gives c_j(τ) ∈ {0,1} for every player j and every past round τ.
- last_round_others = number of other players who cooperated in the most recent completed round (if t=1, undefined).
- recent_window L = min(5, r) (window for detecting persistent defectors).
- persistent_defector_threshold p_rate = 0.8.
- cooperative_threshold_count T_coop = ceil((n-1)/2)  // require at least half of the others to have cooperated last round
- short_punish_length P_short = min(3, max(1, floor(r/10)))  // default brief punishment length
- long_punish_length P_long = min(5, r-1)  // used if strong evidence of mass defection
- probation_length B = 1
- internal phase ∈ {Cooperate, Punish(k_remaining), Probation}. Start in Cooperate.

Detection rule for persistent defectors:
- For each other player j, compute defect_rate_j = 1 - (sum_{τ=t-L}^{t-1} c_j(τ) / L) when enough history exists; otherwise use available rounds.
- If defect_rate_j ≥ p_rate then classify j as persistent defector.

Decision rules (executed at start of each round t):

1. Last-round safety (endgame):
   - If t == r (final round): choose D (defect). (Backward-induction safe choice; last round cooperation cannot be enforced.)
   - Else if R is small and enforcement will be ineffective: if R ≤ 2 then switch to more conservative behavior described below (see Endgame taper).

2. Persistent-defector adjustment:
   - Let num_persistent = number of other players currently classified as persistent defectors.
   - If num_persistent ≥ ceil((n-1)/2) (i.e., a majority of others are persistent defectors), adopt safe-default: defect this round and continue defecting until the count of persistent defectors falls below that majority threshold (this avoids being exploited when cooperation is hopeless).

3. Phase behavior (applies when not in the immediate safe-default above):
   - If in Punish(k_remaining) phase:
     - Choose D this round.
     - Decrement k_remaining by 1. If k_remaining becomes 0, set phase = Probation.
   - Else if in Probation:
     - Cooperate this round (choose C).
     - After the round observes others’ actions:
       - If at least T_coop of the others cooperated during the probation round, set phase = Cooperate.
       - Else set phase = Punish(P_short) if the fraction of cooperators among others that probation round ≥ 0.2; otherwise set phase = Punish(P_long).
   - Else if in Cooperate:
     - If t == 1: cooperate (C) to signal cooperative intent.
     - Else (t > 1): look at last_round_others (number of other cooperators in last round).
       - If last_round_others ≥ T_coop: Cooperate (C).
       - Else:
         - Enter punishment: set phase = Punish(P_short) if last_round_others ≥ 1 and last_round_others / (n-1) ≥ 0.2; otherwise set phase = Punish(P_long).
         - Defect this round (D).

4. Endgame taper:
   - To avoid naive exploitation just before the last round, when R ≤ 3 be slightly more conservative:
     - If R == 3: behave per rules above but prefer shorter punishments (P_short = 1).
     - If R == 2: defect (D) unless last round all others cooperated and you are in Cooperate phase; then cooperate once, expecting restoration is impossible in final round.

5. Forgiveness and restoration:
   - Punishments are intentionally short and followed by a probation cooperation to restore collective cooperation quickly. Punishment lengths depend on severity of defection evidence (short for isolated defections, longer when mass defection or repeated failures on probation).

Rationale (compact):
- Start by cooperating to signal willingness to sustain efficient group outcomes.
- Require a simple, transparent reciprocity rule: cooperate when at least a majority of others cooperated last round. This is easy to observe and aligns with collective interest (majority cooperation usually supports continuing contributions).
- When defections occur, punish briefly to make defection costly, but keep punishment short and follow with a probation cooperative move to restore cooperation quickly. Long permanent punishments are avoided because they harm group welfare, and short punishments plus probation encourage quick return to cooperation.
- Detect persistent exploiters and, if a majority of others are persistent defectors (cooperation is hopeless), stop cooperating to avoid repeated exploitation.
- Defect in the final round (and be conservative in the last few rounds) because cooperation cannot be credibly enforced there.

Notes and edge cases:
- If history is empty (t=1), the rule is to cooperate.
- All decisions use only public history and parameters (n, k, r).
- The strategy is deterministic given parameters and history (no randomization necessary).
- The strategy balances collective mindset (favor cooperation and restoration) with robustness (targeted short punishment, detection of persistent free-riders, endgame defection).
- Parameter choices (L, thresholds and punish lengths) are conservative defaults; they ensure quick recovery from noise and modest punishment power to deter exploitation while minimizing collateral damage to group payoff.
'''

description_COLLECTIVE_43 = '''
Collective, Forgiving Conditional Cooperator (CFCC)

Intention: maximize group payoff reliably by sustaining high cooperation with reciprocators, while being robust to persistent free-riders and accidental slips. The strategy uses only game parameters (n, k, r) and observed history of contributions and payoffs, and it keeps punishments limited and forgiving so cooperation can be restored.

Parameters (computed once from n, k, r)
- base_threshold = 0.5 + 0.25*(1 - k/n)
  - Intuition: when private return k/n is smaller, require stronger observed group cooperation before trusting cooperation; when k/n is large, be slightly more trusting.
  - Clamp base_threshold to [0.5, 0.75].
- memory_window L = min(5, r) (use last L rounds to estimate recent behavior)
- max_punish P_max = min(4, r) (cap on punishment length)
- noise_tolerance: allow isolated single defection among many cooperators to be treated as likely noise (see rules below)
- endgame_grace T_end = min(3, r) (look-back for last-round decision)

State maintained from history
- For each player j compute recent cooperation rate over last L rounds: rate_j = (# times j contributed in last L rounds) / L.
- Group recent cooperation rate R = average of rate_j over j ≠ me. (When L > rounds_played, use available rounds.)
- last_round_defectors = set of players who defected in the immediately preceding round.
- If currently in a punishment phase, track remaining punishment rounds.

Decision rules (applied at the start of each round t = 1..r)
1. First round (t = 1):
   - Cooperate. (Open with cooperation to signal willingness to sustain the public good.)

2. Final round (t = r):
   - Cooperate only if very strong evidence of mutual cooperation exists: require that in the last T_end rounds every player (including me) cooperated every one of those rounds (i.e., perfect cooperation history in that window). Otherwise defect.
   - Rationale: avoid being exploited in the one-shot endgame, but reward perfectly sustained cooperation if it truly exists.

3. Standard rounds (1 < t < r):
   - If currently in an active punishment phase (remaining punishment rounds > 0):
     - Defect this round. Decrement remaining punishment rounds by 1.
     - After punishment ends, continue to Step 4 (for possible immediate re-entry into punishment if conditions still bad).
   - Else (not in punishment):
     - Compute R as above.
     - If R >= base_threshold:
       - Cooperate this round.
       - (Optimistic baseline: the group looks sufficiently cooperative to maintain cooperation.)
     - If R < base_threshold:
       - Consider severity of recent deviations:
         - Let d = |last_round_defectors|.
         - If d = 0 but R < base_threshold (gradual decline): defect this round and set remaining punishment rounds = min(1, P_max) (a short probe to signal concern).
         - If d = 1 (single defection last round):
           - If the rest of the group cooperated strongly (R >= base_threshold - 0.1): treat as likely noise; do a short, forgiving punishment: defect this round and set remaining punishment rounds = 1.
           - Else (group already shaky): defect and set remaining punishment rounds = min(1 + d, P_max).
         - If d >= 2: defect and set remaining punishment rounds = min(1 + d, P_max).
       - Rationale: punish proportionally to number of recent defectors; treat isolated slips lightly to avoid collapse from noise.

4. Forgiveness and re-entry to cooperation:
   - After any punishment phase ends, be forgiving: require only one round (s = 1) in which the observed group cooperation rate (computed over last L rounds) meets or exceeds base_threshold to resume full cooperation.
   - If after punishment group behavior remains poor, repeat a short punishment (bounded by P_max) rather than switching to permanent defection.

5. Handling persistent exploitation:
   - If any player j’s rate_j falls below 20% for more than 2L rounds (i.e., persistent free-rider), continue to defect until that player’s rate_j improves above 30% (gradual restoration). This is a targeted long-run safeguard against repeat free-riders while remaining forgiving overall.

6. Robustness to noise and mixed opponents:
   - Use the limited punishment lengths and noise_tolerance rules to avoid unforgiving “grim” behavior that permanently collapses cooperation due to a single mistake.
   - Use proportional punishment (punishment length depends on number of defectors) so that large group defections are met with stronger signaling than isolated slips.

Principles summarized
- Start optimistic (cooperate), punish promptly but proportionally when cooperation drops, and be forgiving so cooperation can be restored.
- Keep punishments short and capped (no infinite grim triggers), because long permanent punishments are fragile in noisy environments and when opponents are unknown.
- Be cautious in the last round: only cooperate if there is clear, recent, perfect cooperation evidence.
- Aim for collective welfare by sustaining cooperation with reciprocators while protecting yourself from persistent exploiters.

This strategy depends only on n, k, r, and observed contribution history; it is adaptive (responds to group cooperation levels and to the number/severity of defections), robust (forgiving to noise, protects against persistent defectors), and explicitly collective-minded (prioritizes restoring and maintaining high group cooperation).
'''

description_COLLECTIVE_44 = '''
Name: Collective Proportional Conditional Cooperator (CPCC)

Principle (collective mindset)
- Aim to sustain as much full-group contribution as possible while avoiding being exploited. Start by seeding cooperation and use proportional, short, and forgiving punishments when people defect so others can recover cooperation. Avoid harsh permanent punishments (which destroy group welfare) but make defection costly enough to deter persistent free-riders.

Parameters (derived from game parameters and history)
- r = total rounds, n = players.
- M = memory window = min(5, r) (use last M rounds of history to judge recent behavior).
- Target cooperation level T = 0.75 (expect at least 75% of contributions in the recent window to consider the group “cooperative”).
- Leniency for single errors: if one defection appears in an otherwise cooperative window, treat it as possible mistake and do not escalate.
- Punishment length calculation will be bounded by remaining rounds to avoid useless punishments near the end.

Decision rules (what I do each round t)
1. If t = r (final round): defect. (Standard backward induction: last round cooperation cannot be sustained.)
2. Otherwise compute these statistics from history up to round t−1:
   - For each past round, whether each player contributed (0/1).
   - P = fraction of all observed player-actions (excluding my hypothetical current move) that were contributions in the last M rounds. Concretely: total contributions in last M rounds divided by (n × number of those rounds).
   - D_recent = number of defectors (players who played D) in the last round.
   - If I am currently in an active punishment phase (see step 4), follow the punishment rule unmodified.
3. Cooperative move rule:
   - If P ≥ T, cooperate (play C). This rewards and stabilizes recent cooperation.
   - If P < T, proceed to punishment determination (step 4).
   - Tie-breaker: if P is exactly T, cooperate (favor collective welfare).
4. Punishment determination (proportional, temporary, forgiving):
   - Compute shortfall S = max(0, T − P). Compute base punishment length L_base = 1 + round(S × M × 2). Intuition: larger shortfalls trigger longer but still short punishments.
   - Cap punishment length L = min(L_base, remaining rounds − 1) so we never waste all remaining rounds on punishment.
   - If D_recent = 0 but P < T (cooperation has eroded slowly), set L = min(1, remaining rounds − 1) (give a single-round warning).
   - Enter punishment mode: defect for the next L rounds. While in punishment mode, continue to observe others. If during punishment the group’s P (recomputed using the sliding window) returns to ≥ T for at least one full window, end punishment early and resume cooperation on the next round.
   - If one clear individual is a persistent defector over a longer window (their personal cooperation rate over last min(10,r) rounds ≤ 0.2 while group excluding them ≥ 0.6), that indicates a persistent exploiter. In that case use the same proportional punishment but do not escalate to permanent defection; continue periodic short punishments after observing exploitation until the exploiter’s rate drops or the game ends.
5. Error/forgiveness policy:
   - If one defection appears in an otherwise healthy window (e.g., P drops slightly but remains ≥ T − 0.15 and history before that was strongly cooperative), treat it as a likely mistake: punish by at most 1 round, then return to cooperation if cooperation resumes.
6. Near-end adjustments to avoid pointless punishment:
   - If remaining rounds ≤ 2, be conservative: cooperate only if the last round was unanimous cooperation; otherwise defect (because punishment cannot be credibly enforced near the end).
   - Never spend the last round(s) on punishment (we enforce the cap L ≤ remaining − 1).

Operational summary (what opponents see)
- I cooperate from the start to seed cooperation.
- I cooperate as long as recent group cooperation is strong (≥ 75% in recent window).
- When cooperation erodes, I defect for a short, predictable, proportional number of rounds to make defection costly and signal that cooperation is required; then I forgive quickly if the group returns to cooperating.
- I punish more when many players defect or when defection is persistent, but punishments are temporary and bounded so collective welfare can be restored.
- In the final round I defect; in the final couple of rounds I require strong recent cooperation before contributing.

Why this is robust
- Starts cooperative to encourage reciprocators.
- Uses an observable group statistic (fraction cooperating) rather than relying on shared norms or explicit agreements.
- Punishments are proportional and finite, so conditional cooperators can recover rather than being locked in mutual defection; this increases the chance of high group payoff against mixed opponents.
- Temporary, calibrated punishments deter repeat exploitation while forgiving single mistakes and noise.
- Endgame adjustments avoid wasting rounds on futile punishments.
'''

description_COLLECTIVE_45 = '''
Name: Collective Gradual Reciprocity with Proportional Punishment (CGR‑PP)

Intuition (collective mindset)
- I treat the game as a joint project: my default aim is to sustain high group contributions because that maximizes collective welfare. I start cooperatively and try to maintain cooperation with mild, proportionate punishments when others undercut the group. Punishments are strong enough and calibrated to deter exploitation, but I forgive and return to cooperation when others re‑establish cooperation. If the group permanently collapses to near‑complete defection, I switch to protecting my private payoff.

Parameters (computed from inputs)
- n = number of players, r = total rounds, k = multiplier.
- Window length L = min(5, r) (for short‑term history).
- Cooperation threshold θ = 0.6 (fraction of players cooperating in a round) — a conservative majority requirement to sustain cooperation.
- Forgiveness requirement M = 2 (number of consecutive good rounds required to resume cooperation after punishment).
- Hopeless window W = max(3, ceil(r/10)) — if cooperation is very low across W rounds, assume collapse.
- Punishment strength scale β = 3 (maps recent defection severity to punishment length).
(These parameters are fixed functions of n,r,k and the history; they do not require any outside coordination.)

State variables I keep
- mode ∈ {Cooperate, Punish, DefectForever}
- punish_remaining (rounds of punishment left; 0 when not punishing)
- last_good_streak (consecutive rounds showing high cooperation since last punishment)

Initialization
- mode = Cooperate
- punish_remaining = 0
- last_good_streak = 0

Per‑round decision rules (executed at the start of each round t, using full observed history up to t−1)

1. Endgame rule
- If t == r (last round): defect (D). Do not cooperate on the final round.

2. If mode == DefectForever:
- Play D every remaining round.

3. If punish_remaining > 0:
- Play D in this round.
- Decrease punish_remaining by 1.
- Do not change mode until punish_remaining reaches 0; when it reaches 0 set mode = Cooperate and reset last_good_streak = 0.

4. Otherwise (mode == Cooperate and not currently punishing):
- Compute recent cooperation measures from the previous round and short window:
  - c_prev = fraction of players (including me if I contributed last round) who contributed in round t−1. (If t==1, treat c_prev = 1 for my initial move below.)
  - F = fraction of contributions (players contributing) averaged over last L rounds (or all available rounds so far if < L).
- First‑round rule: If t == 1, play C (start cooperatively).
- Main cooperative decision:
  - If c_prev ≥ θ (i.e., a clear majority cooperated in the last round), play C this round; increment last_good_streak by 1.
  - Else (c_prev < θ): interpret this as a breach of collective cooperation. Trigger a proportional punishment:
    - Compute recent_defection_severity s = 1 − c_prev (fraction who defected last round).
    - Set punish_length P = min(remaining_rounds, 1 + ceil(β * s * n / 2)).
      - (This makes punishment longer when many players defected; the exact formula scales punishment with the observed severity and with group size.)
    - Set punish_remaining = P and mode = Punish.
    - Play D this round (start of punishment).
    - Reset last_good_streak = 0.

5. Forgiveness and return to cooperation
- After punish_remaining reaches 0, mode switches to Cooperate. I only resume and keep cooperating if I observe at least M consecutive rounds (tracked by last_good_streak) in which c_prev ≥ θ. If those M rounds occur, remain in Cooperate. If cooperation repeatedly falls below θ after punishment, trigger another proportional punishment as above.

6. Hopelessness protection
- Continuously monitor the last W rounds. If average cooperation over the last W rounds < 0.2 (i.e., widespread defection persists), set mode = DefectForever and play D for all remaining rounds to avoid being repeatedly exploited.

Summary of behavioral patterns
- Start cooperative. Cooperate as long as a clear majority (≥ θ) cooperates in the last round and short history shows sustained cooperation.
- If cooperation drops below threshold, punish in proportion to how many players defected (longer punishments for larger breaches). Punish by defecting for P rounds.
- After punishment, require a short streak of consistently good rounds (M) before fully trusting again.
- In the terminal round always defect.
- If cooperation appears hopeless over a medium window, switch to permanent defection to protect private payoff.

Rationale and robustness
- Collective orientation: default cooperation, targeted punishments, and explicit rules for returning to cooperation aim to sustain group welfare when many players are willing to reciprocate.
- Proportional punishment: punishes more when many players defect, which helps deter coordinated free‑riding while avoiding over‑punishing isolated lapses.
- Forgiveness: requires only a short positive streak to re‑establish cooperation, so the strategy tolerates sporadic noise/experiments and allows recovery.
- Endgame and hopelessness rules protect me from certain exploitation as the horizon shortens or if the population persistently defects.
- All decisions depend only on publicly observable history and game parameters; no communication or shared conventions are assumed.

This strategy balances collective incentives (maintain mutual cooperation) with individual protection (proportionate punishment, forgiveness, and endgame safeguards).
'''

description_COLLECTIVE_46 = '''
Collective Conditional Cooperation with Proportional Punishment and Forgiveness (C3-P)

Principles
- Aim for and sustain near-universal contribution because group payoff is maximized when most players contribute.
- Be tolerant of occasional mistakes and isolated lapses, but retaliate promptly and proportionally against persistent or large-scale free-riding.
- Adapt to opponent population: if cooperation collapses, stop being exploited; if cooperation rebounds, rejoin quickly.
- Do not rely on communication or conventions — decisions use only observed past actions and payoffs and known game parameters (n, k, r).

State and bookkeeping (maintained each round)
- t: current round (1..r).
- history: full matrix of observed contributions by each player in past rounds.
- For each player j: coop_rate_j = fraction of rounds (so far) in which j contributed.
- recent_window w = min(5, max(1, floor(r/10))) — use up to 5 most recent rounds (shrinks for very short games).
- recent_group_rate = average fraction of players who contributed in the last w rounds (i.e., average of per-round group contribution proportions).
- long_term_group_rate = average fraction of players who contributed over all completed rounds.
- punishment_counter (initially 0) and punishment_target (initially 0): track whether we are currently carrying out a punishment and how many rounds left.

Decision rules (executed at the start of each round t)

1) Last-round rule
- If t = r (final round): defect. (Final-round defection is individually dominant; refusing to be exploited in the terminal round preserves resources for possible past cooperation.)

2) If we are currently in a punishment stage (punishment_counter > 0)
- Defect this round.
- After the round, decrement punishment_counter by 1.
- During punishment stage keep monitoring history; if recent_group_rate rebounds above the recovery threshold (see 6) before punishment_counter reaches 0, set punishment_counter = 0 (early forgiveness).

3) If not in punishment stage, decide whether to cooperate or defect this round:
- Base inclination: cooperate if recent_group_rate >= theta(t); otherwise defect.
  - theta(t) = base_theta * (1 + endgame_increase)
  - base_theta = 0.70 (aim for strong majority cooperation)
  - endgame_increase = max(0, (r - t) / r * 0.20) so threshold rises modestly as we approach the end (makes us slightly less trusting late in the game).
  - In words: require roughly 70% of players to have been contributing in recent rounds to keep cooperating; require a somewhat higher fraction near the end.
- Adjustment for individual reputations:
  - Compute predicted effective cooperation if we cooperate: weight recent contributions of others by their coop_rate_j. If a sizable core of players (>= ceil(0.5*n)) have coop_rate_j >= 0.5, bias toward cooperating even if recent_group_rate is marginally below theta(t).
  - Conversely, if many players have very low coop_rate_j (< 0.2), be more likely to defect.

4) When recent_group_rate falls below theta(t) (we detect significant defection)
- Do not immediately go to permanent defection. Instead initiate a proportional punishment:
  - Let f = fraction of players who defected in the last completed round (i.e., 1 - proportion who contributed).
  - Set punishment_target = min(3, 1 + round(3 * f)). (So a small lapse yields 1 round of punishment, a medium lapse 2 rounds, large-scale collapse up to 3 rounds.)
  - Set punishment_counter = punishment_target and defect this round (the first punishment round).
  - Rationale: respond quickly but proportionally; cap punishment length to avoid long revenge cycles.

5) Escalation and anti-exploitation safeguard
- If long_term_group_rate (over all completed rounds) < 0.30 and t > max(3, r/4): cooperation has broadly collapsed. Enter a defensive mode: defect until long_term_group_rate increases above 0.40. This prevents chronic exploitation when most players are free-riding.
- If many players (>= ceil(0.5*n)) have coop_rate_j >= 0.9, be more willing to cooperate even if recent_group_rate dipped (favor maintaining a high-cooperation core).

6) Forgiveness and restoration
- After any punishment_target is completed (punishment_counter reaches 0), perform a one-round probe: cooperate for one round as a test.
  - If in that probe round the observed group cooperation (next round's observations) meets or exceeds theta(t+1), resume normal cooperative mode.
  - If not, escalate punishment_target by 1 (up to 3) and repeat punishment. This makes restoration possible but nontrivial for persistent defectors.

7) Handling noise / mistakes
- Treat an isolated single-round defection by one or two players as a likely mistake if the rest of the group cooperated: when f is small (<0.25), use punishment_target = 1 and be ready to forgive immediately on the next evidence of cooperation.
- Never punish permanently for a single lapse; always allow swift re-entry to cooperation.

8) Special-case short games and small n
- If r <= 3: be conservative — cooperate in round 1; if any defection occurs, switch to defect for remaining rounds; still defect in final round.
- If n = 2 (two players): reduce thresholds (base_theta -> 0.6) because bilateral cooperation is easier to sustain and single defection has bigger impact.

Summary / intuition
- Start cooperative to signal willingness to create public good.
- Cooperate as long as a clear majority in recent rounds are cooperating and a core of players shows good cooperation records.
- If defection rises, respond immediately but proportionally (short punishments) so defectors lose short-term gain but the group can recover quickly.
- Escalate only when defection is widespread or persistent, and stop being exploited by switching to defensive defection if cooperation collapses.
- Always allow re-entry: after punishment the strategy probes with a cooperative round; if others reciprocate, full cooperation resumes.
- Final round: defect to avoid being exploited at the terminal stage while having used cooperation earlier to build group welfare.

This strategy is collective in mindset: it preferentially sustains high group contribution, punishes defections in proportion to their severity (not vindictively), and forgives quickly to restore group welfare. It is adaptive (reacts to short-term shocks and long-term trends), robust (limits exploitation and avoids long vendettas), and depends only on game parameters and observable history.
'''

description_COLLECTIVE_47 = '''
Collective-Conditional Cooperate-with-Forgiveness (CCF)

Idea in one line
- Always try to sustain group cooperation, but punish clear and sustained free-riding quickly and briefly, and probe regularly to re-establish cooperation. Be forgiving so noise or one-off mistakes do not collapse cooperation. In the very last round defect (no future to restore cooperation).

Parameters (computed from game parameters)
- n = number of players, r = total rounds, k = multiplier.
- Window w = min(10, r) — how many most recent rounds we use to estimate behaviour.
- Majoritarian threshold α = 0.5 (majority of others cooperating).
- Soft-test threshold β = 0.3 (small fraction indicating low cooperation).
- Punishment length cap m_max = 3 rounds (short, proportional punishment).
- Probe probability γ = 0.2 (occasional cooperation to test recovery).
- Endgame length L = min(3, max(1, floor(r/10))) — final rounds in which we scale back cooperation.

State we keep (only from observable history)
- For each player j: last w actions (cooperate =1, defect =0).
- Group cooperation fraction in last t window(s), where necessary.

Decision rules (per round t, before choosing C or D)
1. First round (t = 1)
   - Play C (cooperate). Signal willingness to cooperate.

2. Final round (t = r)
   - Play D (defect). There is no future to restore cooperation.

3. Near-end adjustment (rounds t where r - t < L)
   - Apply the normal decision rules below, but whenever the normal rule would choose C, only cooperate with probability 0.5 (scale back cooperation as the end approaches to avoid being exploited in an uncertain endgame).

4. General rounds (2 ≤ t < r)
   a. Compute f_recent = fraction of other players' contributions averaged over the last round (or, if that last round is missing, use the average over the last w rounds). Also compute F_window = average fraction of other players cooperating over the last w rounds (longer trend).
   b. Detect persistent defectors: any player j whose contribution rate over the last w rounds ≤ 0.2 is marked a persistent defector. (We will treat them as unlikely to reciprocate.)
   c. Majoritarian cooperation test:
      - If f_recent ≥ α (i.e., a majority of others cooperated in the immediately preceding round), play C.
   d. Soft zone (forgiveness and probing):
      - If β ≤ f_recent < α (a modest fraction cooperated last round):
         • If we are currently in a punishment phase (see e), end the punishment early if F_window ≥ α; otherwise cooperate with probability p = max(γ, f_recent/(α)) to be generous but cautious. This mixes probing with safety.
         • If not in punishment phase, play C (prefer to sustain cooperation when many but not a strict majority cooperated).
   e. Punishment zone:
      - If f_recent < β (few cooperated last round):
         • Enter a short punishment: play D for m rounds where m = min(m_max, remaining rounds, 1 + number_of_consecutive_rounds_we_have_punished_for_this_failure). The punishment ends earlier if the group cooperation fraction F_window rises to ≥ α.
         • While punishing, continue to monitor F_window each round; if it recovers, stop punishing and return to cooperating by the above rules.
   f. Persistent-defector containment:
      - If a majority (≥ ceil(n/2)) of other players are persistent defectors, treat the group as non-cooperative and play D until the proportion of non-persistent players among others rises above 0.5 or until we detect a clear recovery (F_window ≥ α). This avoids throwing good tokens away to a group dominated by defectors.
   g. Periodic probe (restart mechanism):
      - If we have been defecting for ≥ m_max consecutive rounds and F_window has not improved, every 3rd round send a probe by cooperating with probability γ to test whether some players are willing to resume cooperating. If probes elicit more cooperation (F_window rises), resume normal cooperation behavior.

5. Deterministic tie-breaking
   - If exact thresholds are met in ambiguous ways, prefer cooperation (lean to the collective) except in the final round where defecting is forced.

Rationale and properties
- Collective preference: Start cooperatively and give others the chance to reciprocate. When most players cooperate, we cooperate to maximize group welfare.
- Proportional, short punishment: Punishments are short and contingent. This discourages free-riding but does not allow long vendettas that collapse cooperation.
- Forgiving and probing: The strategy probes after punishment and forgives when the group trend recovers, so single mistakes or noisy actions are unlikely to cause permanent breakdown.
- Robustness: The majority/threshold rule makes the strategy robust to odd or random players: one or two defectors won't force us to permanently defect. The persistent-defector containment protects us when exploitation is widespread.
- Endgame safety: Defect in the final round (no future gains). In the small final window scale back cooperation to avoid being systematically exploited near the end, but still allow some cooperation if others clearly sustain it.
- Information use: Uses only observed past actions and simple aggregates (fractions, recent windows) and game parameters to set windows and endgame scale — no external norms, no communication, no coordination assumed.

Operational summary (short pseudocode-style)
- t = 1: C.
- t = r: D.
- For 2 ≤ t < r:
  • Compute f_recent and F_window over last w rounds; mark persistent defectors.
  • If majority cooperated last round (f_recent ≥ 0.5) → C.
  • Else if f_recent between 0.3 and 0.5 → usually C (or cooperate probabilistically if just recovering).
  • Else (f_recent < 0.3) → short D-punishment (≤ 3 rounds), then probe/forgive.
  • If majority of others are persistent defectors → D until majority cooperative again.
  • During last L rounds, halve cooperation probability when decision would be C.
- Always probe occasionally (probability γ) after short punishments to allow re-establishment of cooperation.

This strategy aims to maximize long-run collective payoff by sustaining cooperation when feasible, punishing and containing exploitation when necessary, and quickly forgiving to repair cooperation when opponents respond.
'''

description_COLLECTIVE_48 = '''
Goal: sustain high group contributions through conditional, reciprocal cooperation that is forgiving of isolated lapses but punishes sustained free-riding. The rule uses only n, r and the public history of every player’s contributions and payoffs.

Parameters (derived from n, r)
- Window W = min(5, r-1) (use up to the last 5 completed rounds of history; if fewer rounds exist, use all of them).
- Majority threshold among others M = ceil((n-1)/2).
- Forgiveness tolerance: allow up to one defection among others in the last round to be treated as “cooperative” (helps recover from single mistakes).
- Endgame: treat the final round (round r) as a guaranteed defect to avoid unavoidable end‑game exploitation. All earlier rounds follow the conditional rule below.

Decision rule (applied in every round t)
1. If t = 1: choose C (start by cooperating to signal willingness to support public goods).
2. If t = r (final round): choose D.
3. Otherwise (1 < t < r):
   a. Look at the last W completed rounds (or all previous rounds if fewer than W exist). For each of those rounds count the number of other players (not you) who contributed.
   b. Call a past round “good” if the number of other contributors in that round ≥ M (i.e., a majority of the others contributed).
   c. Let G = number of “good” rounds in that window.
   d. If G ≥ ceil(W/2) (a majority of recent rounds were “good”), then choose C (cooperate).
   e. Else if the immediately preceding round (round t-1) had at most one other defector (i.e., number of other contributors in t-1 ≥ n-2), choose C (forgive a single lapse and help recovery).
   f. Otherwise choose D (defect to avoid sustained exploitation and signal punishment).

Recovery and punishment dynamics
- Punishment is implemented simply by switching to D when recent history shows sustained low cooperation. Punishment is temporary: once the window of recent rounds again contains a majority of “good” rounds (G ≥ ceil(W/2)), the strategy returns to cooperation.
- Isolated deviations (one defector among many) are forgiven immediately by rule 3.e to avoid cascading breakdowns from noise or single mistakes.
- The strategy therefore supports cooperative clusters: if a majority of the group cooperates repeatedly, it cooperates; if the group drifts toward persistent defection, it defects until cooperation is restored.

Rationale and robustness
- Starts cooperative to promote contributions and show a willingness to support the public good.
- Requires evidence of sustained, collective cooperation (not just a single good round) to avoid being exploited by serial defectors.
- Uses lenient short-window forgiveness to recover from noise or single strategic deviations and to keep the group from getting stuck in perpetual punishment.
- Defects in the final round to avoid being exploited by last-round opportunists (consistent with finite-horizon backward-induction pressure).
- Uses only public history and the game parameters, so it adapts to a wide range of opponent behaviors and does not rely on assumed norms or off‑channel coordination.

This collective-minded contingency is simple, interpretable, and balances sustaining high group contributions with protection against persistent free-riding.
'''

description_COLLECTIVE_49 = '''
Collective Gradual-Reciprocity (CGR)

Goal (collective mindset)
- Maximize group welfare by enabling sustained high cooperation while deterring persistent free-riding. Be generous and quick to re-establish cooperation, but use limited, proportional punishment when players repeatedly defect. Avoid needless escalation and allow recovery.

Core ideas
- Start cooperative to give cooperation a chance.
- Treat brief or occasional defections as mistakes and respond leniently.
- Detect persistent defectors over a recent window and apply short, proportional punishments targeted at restoring good behavior (not destroying cooperation).
- Always include forgiveness tests and a small rate of exploratory cooperation to escape cycles of mutual defection.
- Account for the known finite horizon: defect in the final round, and begin winding down cooperative expectations only in the last few rounds.

Parameters (derived from game inputs n and r)
- Window length W = min(10, r) — track each player’s behavior on the most recent W rounds (or all past rounds if fewer than W have been played).
- Persistence threshold T_persist = ceil(0.6 * W) — a player who defected at least this many times in the window is treated as a persistent defector.
- Base punishment length P_base = max(1, ceil(r/10)) but capped at 3 — number of consecutive rounds used for punishment episodes (adaptive below).
- Forgiveness/test length Q = 2 rounds after a punishment episode — to check whether defectors have returned to cooperation.
- Leniency threshold s = ceil(0.2 * n) — small numbers of defectors are treated more leniently.
- Exploration probability epsilon = 0.05 — a small chance to cooperate even when punishing, to enable recovery from stalemate.
- Final-phase horizon H = min(2, floor(r/10)) — in the last H rounds the strategy becomes progressively more defensive; in the last round always defect.

Decision rules (per round t)

1. Endgame override
- If t == r (last round): play D (defect).
- If t > r - H and t < r: be cautious. Cooperate only if (a) there have been no defections in the immediately preceding W rounds OR (b) every other player has cooperated in every of the last W rounds. Otherwise defect. This limits exploited cooperation in the final phase while allowing cooperation when it has been perfect.

2. First round
- If r == 1: play D (one-shot best response).
- Otherwise play C (cooperate) to open with a cooperative signal.

3. Update history statistics
- For each player j, compute defect_count_j = number of times j chose D in the most recent W rounds.
- Let S = {j : defect_count_j >= T_persist} be the set of persistent defectors.
- Let D_last = number of players who defected in the immediately preceding round.

4. Main action rule (if not in an endgame override)
- If S is empty (no persistent defectors detected):
  - If D_last == 0 (everyone cooperated last round): play C.
  - If 0 < D_last <= s (only a few defectors last round): play C (lenient response). This treats small, possibly accidental lapses as not worth punishing.
  - If D_last > s (many players defected last round): play D for a single retaliatory round, then reassess next round.
- If S is non-empty (there are persistent defectors):
  - If currently within an active punishment episode against persistent defectors (see punishment bookkeeping below): play D (unless random exploration draws a cooperation with probability epsilon).
  - If not currently in punishment but S was just detected this round: begin a punishment episode of length P = min(P_base + |S| - 1, 3). Play D for the P rounds (punishment intensity scales moderately with number of persistent defectors), then enter a forgiveness/test phase of Q rounds (see below). During punishment, with probability epsilon play C (exploratory forgiveness).
  - After a punishment episode ends, enter forgiveness/test phase of Q rounds: cooperate (C) during these Q rounds to see whether persistent defection rates fall below T_persist. If after Q rounds some players still meet persistence threshold, start another punishment episode; otherwise revert to cooperating rules above.

5. Forgiveness and recovery
- After any punishment episode, be lenient: if persistent defectors reduce below threshold S becomes empty, immediately revert to cooperation rules (step 4 with S empty).
- Always allow a single cooperative test with small probability epsilon during punishment to break possible cycles of mutual defection.

6. Targeting and proportionality
- Punishments are collective (you cannot withhold punishment only from a particular player in the PGG), but the punishment length P is proportional to |S| (number of persistent defectors) and bounded to avoid collapse of cooperation. This keeps punishments credible enough to deter persistent free-riding while limiting collateral damage.

7. Special case: small r
- If r <= 3, be more defensive: cooperate on round 1 only if there is reason to expect others to reciprocate (i.e., if players cooperated in pre-play history of previous matches — if none, default to defect on round 1). (Tournament implementations with no prior history can interpret this as defect in very short games.)

Rationale and properties
- Collective-first: the strategy starts cooperative and gives cooperation the opportunity to form, prioritizing group welfare.
- Robustness: leniency toward isolated defections prevents unnecessary collapse when opponents make rare errors. The sliding window and persistence threshold filter transient behavior from systematic cheating.
- Deterrence: persistent defectors induce proportional, temporary punishments sufficient to reduce their payoff advantage and create incentives to return to cooperation.
- Forgiveness and exploration: explicit test phases and small-probability cooperative moves prevent permanent mutual defection traps and help recover cooperation after noise or misunderstanding.
- Finite horizon handling: defeats pure perpetual-cooperation illusions by defecting in the last round and reducing optimism near the end, which prevents exploitation in the final rounds yet allows cooperation when behavior has been consistently cooperative up to the end.
- Parameter adaptation: all parameters depend only on n and r (via W, P_base, etc.), and on observed history; no external coordination or communication required.

Implementation notes (for tournament agents)
- Track per-player actions for the last W rounds and maintain simple state flags: in_punishment_until_round, in_test_until_round.
- Use epsilon-randomized cooperation only very rarely (epsilon ~ 0.05) to avoid easy exploitation.
- Choose the numeric parameter values above (W, T_persist, P_base, s, Q, epsilon, H) as defaults; small tuning is acceptable but keep the same rule form for different matches.

Summary
- Cooperate by default, forgive occasional lapses, detect and temporarily punish persistent defectors in a proportional way, then test for recovery and return to cooperation. Defect in the final round(s) to respect the finite horizon. This balances collective welfare with robustness to a wide range of opponent behaviors.
'''

description_COLLECTIVE_50 = '''
Summary: play as a forgiving, proportional conditional cooperator. Start cooperative, reward and sustain high group cooperation, punish deviations only when they are sustained or large, punish proportionally and temporarily, and return to cooperation when the group recovers. Use only the public history of contributions/payoffs and the game parameters (n, r, k).

Definitions / internal parameters (fixed from n, r, k and used throughout)
- Window W = min(5, max(1, floor(r/10))). (Use up to 5 most recent rounds; if r small use fewer.)
- High threshold TH_H = 0.70 (expectations for clear cooperation).
- Low threshold TH_L = 0.40 (below this we treat cooperation as broken).
- Max punishment length L_max = 4 (upper bound on temporary sanctions).
- Min punishment length L_min = 1.
- Noise tolerance: a single isolated defection does not trigger punishment; require deviation in at least two of the last W rounds (or a large one-round drop) to begin punishment.
- Endgame rule: for the final round act according to recent observed cooperation: contribute in the last round only if at least TH_H fraction of other players contributed in the previous round; otherwise defect.

State tracked
- punish_remaining (integer, initially 0): rounds left to stay in punishment mode.
- recent_coop_rate (computed each round): average fraction of other players who contributed, averaged over the last W rounds (if fewer than W rounds exist, average over available rounds).

Decision rules (executed each round before choosing C/D)
1. Update recent_coop_rate:
   - For each of the last up-to-W rounds, compute fraction contributed among the other n-1 players that round.
   - recent_coop_rate = average of those fractions.

2. Endgame check:
   - If this is the very last round:
     - If recent_coop_rate >= TH_H then C (cooperate); otherwise D (defect).
     - (Return decision.)

3. If punish_remaining > 0:
   - Default action: D (defect) this round.
   - Decrease punish_remaining by 1.
   - Quick forgiveness: if punish_remaining > 0 but the last two rounds both show recent_coop_rate >= TH_H, then set punish_remaining = 0 and in this round switch to C.

4. If not in punishment (punish_remaining == 0):
   - If there are fewer than 2 past rounds (first or second round):
     - C (start cooperatively and build trust).
   - Else evaluate recent_coop_rate:
     a) recent_coop_rate >= TH_H:
        - C (reward and sustain cooperation).
     b) TH_L <= recent_coop_rate < TH_H:
        - Probabilistic/soft response to avoid brittle switches:
          - Contribute with probability equal to recent_coop_rate (i.e., more likely to cooperate when others have cooperated more recently); otherwise defect.
          - (This smooths behavior against mixed/coaxing opponents and reduces cycles.)
     c) recent_coop_rate < TH_L:
        - Treat as broken cooperation. Trigger punishment:
          - Compute severity s = clamp(ceil((TH_L - recent_coop_rate) / 0.1), L_min, L_max).
            (Severity grows with how far recent_coop_rate is below TH_L, but is capped.)
          - Set punish_remaining = s and play D this round.
        - Exception for noise: if the low recent_coop_rate is the result of a single mostly-cooperative past window (e.g., only one round was bad and others good), do not punish yet; instead wait one round to see if the drop persists.

5. Special handling for targeted defectors (optional enhancement, still collective):
   - Maintain per-player cooperation rates over the window W.
   - If a subset of players (size m) have individually cooperated in fewer than 20% of the last W rounds while the rest are highly cooperative, treat recent_coop_rate when computing thresholds as if those m players are “defectors” (so the strategy punishes until the group without the persistent defectors recovers). This discourages persistent free-riding without switching to permanent universal defection.

Rationale and properties
- Start cooperative to signal willingness to achieve the social optimum.
- Reward and sustain cooperation when the group is doing well (TH_H).
- Use a soft middle zone (TH_L ≤ rate < TH_H) with probabilistic cooperation to avoid fragile oscillations and to let conditional cooperators guide restoration.
- Temporarily punish when cooperation clearly breaks (rate < TH_L), with punishment length proportional to severity but bounded. Punishment is temporary to allow recovery; avoid permanent grim-trigger.
- Forgive quickly when the group returns to cooperative behavior: punish_remaining is canceled when cooperation is restored for two rounds.
- Handle noise by requiring sustained or large deviations before sanctioning.
- Endgame: do not automatically defect every final round; cooperate in the last round if the immediate history shows high cooperation (this preserves collective mindset while avoiding naive exploitation in a collapsing group).
- All decisions depend only on n, r, k (used to set windows and bounds) and the observed action history; no communication or coordination is assumed.

Overall collective mindset
- The strategy aims to maximize group payoff by sustaining mutual contributions when possible, uses proportionate and temporary sanctions to deter free-riding, and returns to cooperation when others respond. It balances firmness (to avoid being exploited) with forgiveness (to recover from mistakes and noise), and it refuses to collapse into permanent defection when cooperation can be restored.
'''

description_COLLECTIVE_51 = '''
Adaptive Collective Conditional Cooperator (ACCC)

Goal (collective mindset)
- Maximize long-run group welfare by sustaining mutual contributions when others are willing, while avoiding long exploitation by persistent free-riders. Use short, proportional punishment to deter freeloading, generous forgiveness and occasional probes to restore cooperation after mistakes.

Computed parameters (use known game parameters n, k, r)
- memory window w = min(5, r) — how many past rounds we look at.
- majority_fraction = 0.5
- punish_length = 1 (short, scalable punishment: one round of retaliation)
- probe_prob = min(0.30, 0.05 + 0.30 * (k / n)) — small chance to test cooperation while defecting; increases modestly when public good is relatively more valuable
- forgiveness_threshold = majority_fraction — require at least this fraction of other players cooperating recently to resume cooperation
- final_rounds_to_guard = 1 (always treat last round specially)

Decision rules (per round t; use only history of contributions and payoffs)
1. Terminal rule
   - If t == r (last round): defect (D). Rationale: single-shot incentive to defect in last round; avoid being exploited.

2. First round
   - If t == 1: cooperate (C). Start by signaling willingness to cooperate.

3. For rounds 1 < t < r (general adaptive rule)
   - Compute for the w most recent completed rounds:
     - For each round s, let S_s = total contributions in round s (sum over all players).
     - Let other_coop_rate = (sum over s of contributions by other players) / (w * (n - 1)).
     - Let last_round_S = S_{t-1} (total contributions by all players in previous round).
     - Let last_round_other_coops = last_round_S - my_contribution_{t-1} (count of others who cooperated last round).
   - If last_round_S >= ceil(n * majority_fraction): (i.e., at least a majority of all players contributed last round)
     - Cooperate (C) this round. Rationale: when a majority is cooperating, contribute to sustain high group welfare.
   - Else (majority did not contribute last round):
     - If last_round_other_coops >= ceil((n - 1) * (1/3)) AND I personally contributed in t-1 while many others did not:
       - Enter short punish: defect (D) for punish_length rounds (including this round) to signal cost to free-riding majorities.
     - Else (no clear coordinated free-riding majority):
       - If other_coop_rate >= forgiveness_threshold:
         - Cooperate (C). Rationale: recent average shows most others are willing; forgive isolated lapses.
       - Else
         - Defect (D) normally, but with probability probe_prob play Cooperate (C) as a probe to test whether the group will return to cooperation. If the probe is followed by increased cooperation from others, resume cooperating per the rules above.

4. Handling noise and isolated defections
   - If a single round shows low cooperation but the moving average other_coop_rate remains >= forgiveness_threshold, treat the low round as noise / isolated defection and keep cooperating.
   - If one or a few players repeatedly defect while most others cooperate (clear persistent free-riders), enforce short punishments: defect for punish_length rounds immediately after observing a round where more than ceil((n - 1) * 1/3) others defected. After the short punishment, resume cooperation if the majority returns to cooperating (avoid permanent exclusion).

5. Small-r edge cases
   - r = 1: defect (the last-round rule applies).
   - r = 2: cooperate on round 1, defect on round 2 (last round).
   - If r is very small (<=3), be more conservative with punishments: reduce punish_length to 0 (do not punish) to avoid destroying all remaining cooperative opportunities. In practice, with r <= 3, use: round 1 cooperate, rounds 2..r defect if last round, otherwise apply forgiveness rules cautiously.

Rationale and robustness summary
- Collective focus: default to cooperate and sustain cooperation when a clear majority reciprocates. This maximizes group payoff when many players are willing.
- Proportional punishment: short, proportional retaliation deters persistent freeloaders but avoids spirals of permanent mutual defection that kill group welfare.
- Forgiveness and probing: probabilistic probes and thresholded forgiveness let the strategy recover from errors and detect when others are returning to cooperation.
- Endgame safety: defect in the final round to avoid being exploited in the unavoidable single-shot situation.
- Parameter choices are conservative and adaptive: memory and thresholds scale with r and n; probe_prob scales with k/n so the strategy explores more when the public good is relatively more valuable.

Behavioral summary (simple rule-of-thumb)
- Start cooperative. Cooperate whenever a majority of players cooperated last round or the recent cooperation rate is high. If cooperation collapses, defect briefly to signal costs to freeloaders. Forgive quickly if most players resume cooperating and occasionally probe while defecting to discover opportunities to re-establish cooperation. Always defect in the final round.
'''

description_COLLECTIVE_52 = '''
Collective Conditional Cooperator with Proportional Punishment and Forgiveness (C3P)

Goal: steer the group toward full cooperation (highest collective payoff) while staying robust to exploiters: reward and stabilize cooperation, punish defections in proportion to their severity, and forgive quickly to restore cooperation.

Parameters available: n, r, k. Internal state: punishment_counter (initially 0), recent_coop_run (consecutive rounds of full or strong cooperation; initially 0).

Rules (apply each round t = 1..r):

1. First and last rounds
- Round 1: play C (start by offering cooperation).
- Round r (final round): play D (defect in the last round — one-shot dominant action).

2. Observe history
- Let C_prev = number of players who contributed in round t-1 (if t=1, use C_prev = n by initialization logic so step 1 applies).
- Let defectors_prev = n - C_prev.
- Let majority_prev = (C_prev >= ceil(n/2)).

3. Punishment mode
- If punishment_counter > 0:
  - Play D.
  - Decrement punishment_counter by 1.
  - After this round, do not change recent_coop_run (it remains 0 unless a recovery of cooperation is observed in the future).
  - Continue to next round.

4. Normal decision (punishment_counter == 0 and 1 < t < r)
- If C_prev == n (everyone cooperated last round):
  - Play C. Increment recent_coop_run by 1.
- Else if majority_prev (at least half cooperated last round):
  - Play C (reward majority cooperation). Increment recent_coop_run by 1.
- Else (fewer than half cooperated last round):
  - Play D this round and enter proportional punishment:
    - Set punishment_counter = max(1, defectors_prev).
      Rationale: punish intensity equals number of defectors last round so larger breaches trigger stronger, visible responses; single or small defections get a short, targeted punishment.
    - Reset recent_coop_run = 0.

5. Forgiveness and probing after punishment
- Immediately after punishment_counter reaches 0, in the next two rounds act as follows:
  - Round after punishment: play C (a cooperative probe).
  - Second round after punishment: if at least half cooperated in the preceding probe round, continue cooperating (clear hostility); else, if cooperation remains below majority, re-enter punishment with punishment_counter = max(1, observed_defectors) (i.e., punish again but allow short cycles).
- If the group has shown strong stable cooperation (recent_coop_run >= 4), be lenient: single short defections trigger only 1-round punishment (set punishment_counter = 1), to avoid destabilizing long-term cooperation.

6. Edge behavior for short horizon
- If only a few rounds remain (e.g., t >= r - 2), be progressively conservative:
  - Round r: always defect (see step 1).
  - Round r-1: follow the normal decision rule, but if you detect a sudden collapse in cooperation that looks like endgame unraveling (large drop in cooperation compared to prior trend), prefer D to avoid exploitation.

Rationale and properties
- Collective focus: always starts by offering cooperation and rewards majority/full cooperation so the group can reach the collective optimum.
- Proportional punishment: punishes defectors in proportion to their number, so punishments are visible and credible but not excessively costly to the group.
- Forgiveness and probing: after punishment the strategy actively tries to re-establish cooperation by probing and forgiving if the group reciprocates, preventing long retaliation cycles.
- Robustness: majority rule prevents being systematically exploited by a small number of persistent defectors; proportional punishments make exploitation unprofitable for those defectors while limiting harm to cooperators.
- Endgame safety: defects in the final round protect from one-shot exploitation; conservative behavior near the end prevents excessive losses from anticipated unraveling.

This strategy uses only public history and the game parameters, adapts to many opponent behaviors, and clearly prioritizes maximizing collective payoffs while defending against persistent exploitation.
'''

description_COLLECTIVE_53 = '''
Name: Adaptive Collective Reciprocity (ACR)

Goal (collective mindset)
- Maximize group welfare by sustaining broad cooperation when others are cooperating.
- Protect the group (and yourself) from persistent free-riders by applying proportional, short punishments that encourage recovery rather than permanent breakdown.
- Be forgiving and probe for recovery so cooperation can re-form when opponents change.

Summary of how it works (plain language)
- Start by cooperating to signal willingness to build the public good.
- Monitor each player’s recent contribution record and the recent group contribution rate.
- Cooperate when the recent group behavior shows substantial cooperation.
- If defections occur, respond with short, proportional punishments targeted by severity and prevalence of defections.
- Forgive quickly when cooperation resumes and occasionally probe to test recovery.
- In the very last round, defect (no future to influence), but otherwise behave to sustain cooperation whenever future interactions allow it.

Parameters derived from game size and horizon
- Memory window W = min(10, r) — evaluate recent W rounds (or all past rounds if fewer).
- Mild/strong group thresholds:
  - theta_high = 0.8 (high recent group cooperation)
  - theta_low = 0.5 (low recent group cooperation)
- Individual “bad actor” threshold s_bad = 0.5 (player considered low-cooperating if their contribution rate over W < s_bad).
- Maximum punishment length Punish_max = min(3, max(1, floor(r/10))) — a short, bounded punishment to avoid permanent collapse.
- Small probing probability eps = 0.05 used in ambiguous situations to test cooperation recovery.
- Final-round rule: always defect in round r (no future rounds to reward/punish).

Decision rules (pseudocode-style description using only history and parameters)
At the start of each round t (1..r):

1) If t == 1:
   - Play C (cooperate). (Begin by offering cooperation.)

2) If t == r (last round):
   - Play D (defect). (No future to sustain cooperation.)

3) Otherwise (1 < t < r):
   - Compute for the most recent W rounds:
     a) For each player j (including yourself), compute j_rate = fraction of those W rounds in which j contributed.
     b) Compute group_rate = average of all other players’ contributions in the most recent round, and group_rate_window = average contribution fraction of other players over W.
     c) Count n_bad = number of other players with j_rate < s_bad.

   - Baseline cooperative inclination:
     - If group_rate_window >= theta_high:
         -> Play C (cooperate). The group is mostly cooperative; stay cooperative.
     - Else if group_rate_window <= theta_low:
         -> Enter punishment mode (see 4).
     - Else (theta_low < group_rate_window < theta_high):
         -> Play C with probability p = (group_rate_window - theta_low) / (theta_high - theta_low).
            Play D with probability 1 - p. (Soft, proportional cooperation when the picture is mixed.)
         -> Also, with small probability eps, play C regardless (periodic probing for recovery).

4) Punishment mode (triggered when recent group cooperation is low):
   - Determine punishment severity based on prevalence:
     a) If n_bad == 0 but group_rate_window <= theta_low:
         - This is likely noise or mixed history; respond with a short mild punishment: play D this round, then reassess next round.
     b) If 1 <= n_bad <= floor(n/3):
         - Mild punishment: play D for P = 1 round (this round), then reassess.
     c) If floor(n/3) < n_bad <= floor(2*n/3):
         - Moderate punishment: play D for P = min(2, Punish_max) consecutive rounds.
     d) If n_bad > floor(2*n/3):
         - Strong (but still finite) punishment: play D for P = Punish_max consecutive rounds.
   - During a P-round punishment block, continue to observe everyone’s contributions. If the bad players’ recent rates increase above s_bad (i.e., they begin cooperating consistently in the window), immediately end punishment and return to the normal decision rules (step 3).
   - After completing the planned P rounds, transition back to step 3 (forgiveness and reassessment). Always cap punishments at Punish_max to avoid permanent breakdown.

5) Individual responsiveness and targeting
   - The punishments above are proportional to how many players are persistently defecting (n_bad), not directed at singletons forever.
   - If a single player j is persistently defecting across the window (j_rate << s_bad) while most others cooperate (group_rate_window high), you still use only mild, local punishment (short D rounds) aimed at signaling costs; do not abandon cooperation with the majority.
   - If many players persistently defect, punish more strongly to protect collective welfare.

6) Forgiveness and probing
   - After any punishment block, be forgiving: return to cooperative behavior as soon as others’ recent contributions rise sufficiently (group_rate_window >= theta_high or individual rates improve).
   - Occasionally probe for recovery: when group_rate_window is ambiguous, cooperate with a small probability eps to test whether cooperation can resume.

7) Robustness to noise and exploitation
   - Use W (window) rather than single-round flips to avoid overreacting to single accidental defections.
   - Punishments are finite, proportional, and cancelable — this reduces long mutual-defection traps and encourages return to cooperation.
   - Never punish forever for one defection; require persistent low cooperation to sustain stronger punishment.

Edge cases and clarifications
- Very short games (r <= W): use all available rounds for rates; rules still apply. Punish_max will be small (>=1), so punishments remain short.
- If all players always defect historically, the strategy will defect (protect self), but periodically probe at eps to attempt to restart cooperation.
- If some opponents use pure-griefing (constant defect to damage others), this strategy minimizes exposure by punishing proportionally and not sustaining open-ended losses.
- If many opponents are conditional cooperators, this strategy helps form a cooperative cluster through initial cooperation, lenient forgiveness, and proportionate punishment, which tends to increase group contributions and collective payoff.
- No communication or coordination is assumed beyond observed actions and payoffs.

Why this is collective and robust
- Collective: primary objective is to sustain broad cooperation (prefer C when others are cooperating) and restore cooperative behavior rather than seek short-term private gains by persistent free-riding.
- Robust: uses windows to filter noise, graduated punishments to avoid escalatory collapse, forgiveness and probing to recover cooperation, and bounded punishments so single mistakes don’t permanently break cooperation.
- Adaptive: reacts to how many and which players defect, adjusts punishment length and severity, and uses probabilistic cooperation in ambiguous situations to test and promote resumed cooperation.

Implementation note (for interpretation)
- All thresholds (theta_high, theta_low, s_bad, W, Punish_max, eps) are set as above but may be scaled modestly with n and r if desired; the spirit is an initial cooperative stance, clear but proportional punishment if defections are persistent, quick forgiveness, and occasional probing to re-establish cooperation.
'''

description_COLLECTIVE_54 = '''
Name: Collective Conditional Cooperation with Adaptive Forgiveness (CCC-AF)

Summary objective
- Aim to sustain near-universal contributions when the group is reliably cooperative.
- Apply brief, proportional collective punishments when cooperation drops, but quickly forgive and test for recovery so cooperation can be re-established.
- Use only public history and the game parameters (n, r, k). No communication or targeting beyond using public records.

Parameters (derived from game parameters and history)
- Memory window W = min(20, max(3, r)) — use the last W rounds to score recent behavior.
- Cooperation threshold p_thresh = 0.75 − 0.15 * ((k − 1)/(n − 1)). (Higher k ⇒ more willingness to forgive/assume cooperation.)
- Group-cooperation threshold F_thresh = 0.60. (If a sufficiently large fraction of others are "cooperators" we cooperate.)
- Persistent-defector threshold low_score = 0.25 (if a player’s recent score ≤ low_score they are treated as persistent defector).
- Punishment length P = 3 rounds (finite, collective punishment window).
- Error tolerance: isolated single-round deviations are treated as likely mistakes.
- Exploration probability probe = 0.10 (occasionally probe to check recovery).
- Endgame horizon E = 1 (last round) and cautious last-2 behavior described below.

Data maintained each round t (based only on public history)
- For each player j (including self), compute S_j = (number of contributions by j in the last min(W, t−1) rounds) / min(W, t−1). If t = 1 treat S_j = 1 by default for all j (optimistic start for group-building).
- Let F = fraction of the other players whose S_j ≥ p_thresh (i.e., fraction of others that are recent cooperators).
- Track whether we are in an active punishment mode and how many punishment rounds remain (P_remain).

Decision rules (what I do each round)

1) First round (t = 1)
- Contribute. (Optimistic start to try to establish cooperation.)

2) Last-round and near-end behavior
- If t = r (final round): defect (do not contribute). One-shot defection is dominant; avoid being exploited.
- If t = r − 1 (second-to-last round): contribute only if both (a) F ≥ 0.90 and (b) my own recent S_self is high (≥ p_thresh). Otherwise defect. This reduces risk of being exploited in the endgame while allowing cooperation if the group is overwhelmingly cooperative.

3) If currently in punishment mode (P_remain > 0)
- Defect this round; decrement P_remain by 1.
- After P_remain reaches 0 return to normal reassessment next round.

4) Normal rounds (not in punishment mode and not in final rounds)
- Identify persistent defectors: players with S_j ≤ low_score OR players with at least two consecutive recent defections in the window. Isolated single-round drops are not treated as persistent.
- Compute F as above.

Main conditional response:
A) If F ≥ F_thresh (enough others are recent cooperators)
   - Contribute (cooperate).
   - Exception: with probability probe (0.10) defect as a low-frequency probe only if group cooperation is borderline (0.60 ≤ F < 0.75) to test whether brief defection will provoke corrective behavior — this helps detect strategies that are temporarily cooperating but will not punish defectors.
B) If F < F_thresh (group cooperation has fallen)
   - If the shortfall is small and caused by one isolated player (only one other player has S_j < p_thresh and that player is not a persistent defector), then:
       - Continue cooperating for one round while watching whether that player returns to cooperation (treat as mistake). If they fail to improve next round, enter collective punishment (see below).
   - Otherwise (multiple players below p_thresh or one persistent defector), trigger collective punishment:
       - Set P_remain = P and defect for the next P rounds (collective short punishment).
       - After P rounds reassess S_j and F; if the group has improved, resume cooperation per the normal rule.

5) Recovery and forgiveness
- After punishment ends, resume cooperation immediately if F ≥ F_thresh.
- If a previously persistent defector improves S_j above p_thresh, remove the persistent label immediately and resume treating them as a cooperator.
- Always allow periodic probing cooperation with small probability probe when out of punishment to let the group re-establish cooperation.

6) Robustness to noise and exploitation
- Do not punish for single isolated deviations (treat as error).
- Use persistence checks (consecutive missed contributions or very low S_j) to identify deliberate free-riders.
- Keep punishment finite and collective so that punishment is credible yet reversible: it signals that group cooperation matters without creating endless retaliation that destroys long-run welfare.
- Avoid overreacting to a single low cooperator when the rest of the group is reliably cooperating; instead privately test for recovery before escalating.

Rationale and collective alignment
- The strategy is explicitly collective: decisions are based on the fraction of others who are recent cooperators (F) and on group-level responses (collective, time-limited punishments), not on solitary tit-for-tat against single players unless their defection is persistent.
- It balances deterrence (finite collective punishment) with forgiveness (quick return to cooperation when others improve) and robustness to mistakes (ignore single-round deviations).
- It adapts its tolerance for deviation using k and n: greater marginal public-good returns (larger k) reduce the strictness of the threshold, so the strategy is more willing to maintain cooperation when group returns are larger.
- It is simple, depends only on public history and parameters, and is designed to work against a wide range of opponent behaviors: unconditional defectors will be isolated and punished; conditional cooperators will be sustained; noisy players will not cause endless breakdown.

Concrete pseudocode summary (compact)
- t = 1: contribute.
- Each round compute S_j over last W rounds and F = fraction of others with S_j ≥ p_thresh.
- If t = r: defect. If t = r−1: contribute only if F ≥ 0.90 and S_self ≥ p_thresh else defect.
- If P_remain > 0: defect and P_remain −= 1.
- Else if F ≥ F_thresh: contribute (except with probability probe in borderline F region).
- Else if F < F_thresh:
    - If shortfall due to one isolated recent mistake: contribute once and watch; if not corrected next round, then set P_remain = P and defect.
    - Otherwise set P_remain = P and defect.
- After punishment, reassess; if group scores recover, resume cooperation; forgive in proportion to improvement.

This strategy is collective, adaptive, forgiving yet deterrent, and uses only parameters and observable history to sustain high collective payoffs when possible while limiting exploitation.
'''

description_COLLECTIVE_55 = '''
Graduated Collective Conditional Cooperator (GCCC)

Goal (collective): Maximize group welfare by reliably rewarding cooperation, deterring sustained defection, and forgiving recovery attempts. The rule set uses only n, r, k and the observed action history.

Parameters (derived from game parameters)
- Window w = min(5, r-1) — use the last w rounds of history when available.
- Cooperation threshold theta = 0.5 + 0.1*(1 - k/n). (When k is large relative to n, the group benefit of cooperation is larger, so the threshold is slightly lower; theta lies roughly in [0.5,0.6].)
- Soft band delta = 0.15 (a forgiving buffer below theta).
- Maximum punishment length P_max = 3 rounds.
- Return-to-cooperate condition: see rules below (requires either clear recent improvement or a short forgiveness criterion).

High-level rule
- Start by signalling cooperative intent but only sustain contributions when the group shows enough reciprocal cooperation. If the group cooperation rate falls, punish briefly and proportionally, then forgive when cooperation is restored. Always limit punishment severity and allow quick recovery when others improve.

Decision rules (round t)
1. First round (t = 1): contribute (C). This reliably signals cooperative intent.

2. Last round (t = r): defect (D). There is no future to enforce reciprocity.

3. For intermediate rounds (1 < t < r):
   - Compute for each other player j the fraction of rounds they contributed in the last w rounds; compute the group cooperation rate f = average contribution of all other players over the last w rounds (use the available history if fewer than w rounds exist).
   - If in the last w rounds there exists a full-cooperation round (every player contributed that round), immediately cooperate this round (reward the clear collective recovery).
   - If currently inside an active punishment phase (see below), continue the punishment until either P_max punishment rounds have been completed or the return-to-cooperate condition is met (whichever comes first). While punishing, defect.
   - Otherwise (not currently punishing):
     a. If f >= theta: cooperate (C). The group shows sufficient reciprocity; reward it.
     b. If theta - delta <= f < theta: be forgiving — cooperate with probability 50% (flip a fair coin). This reduces exploitation risk while still allowing the group to rebuild cooperation.
     c. If f < theta - delta: defect (D) and begin a punishment phase of length P = min(P_max, 1 + round((theta - f)/delta)). In words, punish for a small number of rounds roughly proportional to how far group cooperation fell below theta, but never more than P_max.

Return-to-cooperate condition (exit punishment early)
- During punishment, continuously monitor f using the same window w. Exit punishment and resume normal rule evaluation (and cooperate next round) if either:
  a. f >= theta for s = 2 consecutive rounds (clear recovery), or
  b. a full-cooperation round (all players contributed) is observed in the last w rounds (strong signal of collective restoration).

Additional robustness details
- Individual noise and occasional mistakes: the probabilistic forgiveness band (theta - delta to theta) and short, capped punishments prevent endless escalation from single mistakes.
- Persistent defectors: if a large fraction of players is persistently noncooperative (f remains low), the strategy defects and limits losses rather than being exploited indefinitely.
- Adaptivity to k: theta depends on k/n so the strategy is slightly more willing to sustain cooperation when the multiplier makes cooperation more valuable.
- Simultaneous action context: decisions use only observed past actions and payoffs; no communication or promises are required.

Summary behavior (intuitive)
- Signal cooperation immediately, reward visible cooperation, punish proportionally but briefly when group cooperation drops, forgive reliably when the group shows improvement, and defect in the final round. This promotes stable cooperation with limited risk of exploitation and fast recovery from noise or occasional defections.
'''

description_COLLECTIVE_56 = '''
Collective Tit-for-Tat with Proportional Punishment and Forgiveness (CTP-PF)

High-level idea
- Start cooperative and prefer collective cooperation. Use reciprocity to sustain group contributions: reward recent cooperation by contributing, and punish repeated or widespread defection by withholding contributions for a short, proportional period. Be forgiving of isolated mistakes and restore cooperation quickly when others return to cooperating. Near the final rounds, avoid long punishments so you are not exploited by endgame unraveling.

Parameters derived from game inputs (computed once at start)
- n, r, k are given.
- Window W for assessing recent behavior: W = max(1, min(4, floor(r/6) + 1)). (Defaults to 2–4; small r → small window.)
- Cooperators-threshold q (fraction of other players who must have cooperated recently to keep cooperating): q = 0.5 + 0.25*(1 - k/n). (If k/n is small, require stricter recent cooperation; if k/n close to 1, be more tolerant.)
- Punishment base length T_base = min(3, max(1, ceil((1 - k/n)*4))). (If multiplier is weak, punish a bit more; if strong, punish less.)
- Forgiveness requirement F = 1 (number of consecutive cooperative rounds required for a punished individual to be considered rehabilitated).
- Last-round safety L = min(2, r - 1). In the final L rounds be conservative (see below).

State kept during play
- For each player j ≠ you: a rolling record of their contributions over the last W rounds.
- A “punish counter” P (nonnegative integer) indicating how many rounds you still intend to defect to enforce punishment.
- A set PersistentDefectors: players who defected repeatedly in the last W rounds (definition below).

Definitions
- In each round t > 1, define other_coop_fraction(t-1) = (# of players ≠ you who contributed in round t−1) / (n − 1).
- PersistentDefector = any player j who defected on at least 2 of the last W rounds (or, if W = 1, any player who defected last round). Update this set each round.

Decision rules (run at the start of each round t)

1. Last-round safeguard
- If t = r (final round): play D (defect). (Avoid being exploited in the known final stage.)
- If t > r − L (i.e., in the final L rounds before r): be conservative:
  - Cooperate only if the other_coop_fraction in the most recent round = 1.0 (everyone else contributed last round).
  - Otherwise play D. (This prevents entering long punishments near the end and reduces risk of being exploited in the endgame.)

2. If you are currently in the middle of an enforced punishment (P > 0)
- Play D. Decrement P by 1.
- While P > 0 you do not change P for one-off noise except via the forgiveness rules below after P reaches 0.

3. Otherwise (normal operation)
- Update PersistentDefectors from the last W rounds.
- Determine severity:
  - severe = (|PersistentDefectors| ≥ 1)
  - crowd_defect = (other_coop_fraction(last round) < q)
- If neither severe nor crowd_defect:
  - Play C (cooperate). This is the cooperative baseline: reward a reasonably cooperative group.
- If only one-off defect (there was exactly one defection last round and that player is not persistent) and other_coop_fraction(last round) ≥ 0.5:
  - Treat as probable error: play C (forgive a single out-of-pattern defection).
- If severe or crowd_defect (group cooperation has broken or at least one persistent defector exists):
  - Compute punishment length P_new = min(remaining rounds until r − 1, T_base * (1 + |PersistentDefectors|)).
    - (Scale punishment by the number of persistent defectors; cap to avoid infinite punishment near the end.)
  - Set P = P_new and play D this round (begin proportional punishment).
  - During punishment you withhold contributions (D) to reduce total benefit to defectors and demonstrate credible threat.

4. Rehabilitation / forgiveness after punishment
- After P reaches 0, do not automatically resume perpetual defection. Require that:
  - For any player in PersistentDefectors, they must show F consecutive cooperative moves to be removed from PersistentDefectors.
  - Only resume active cooperation (play C in the cooperative branch above) when the recent W-round other_coop_fraction is ≥ q and no player remains persistent (or persistent players have met the rehabilitation requirement).
- This ensures quick restoration of cooperation once defectors respond, but avoids falling for repeated exploitation.

Noise robustness
- Single isolated defects by otherwise-cooperating players are forgiven and do not trigger full punishment.
- Punishments are proportional (longer when there are multiple persistent defectors) and capped by remaining rounds so punishments do not wreck endgame payoffs.
- The policy relies on short memory W and short punishments to avoid cascades caused by noise.

Collective emphasis
- The strategy’s default behavior is to cooperate, to maximize group welfare whenever others show reciprocation.
- Punishments are intended to be minimal, proportional, and targeted at repeated defectors; they are not meant to permanently collapse cooperation.
- By requiring a clear pattern of repeated defection before harsh punishment, the strategy protects cooperators from noisy mistakes and preserves cooperation among willing partners.

Summary (simple pseudocode-like)
- Round 1: C.
- For each round t:
  - If t = r: play D.
  - Else if t > r − L: play C only if everyone else cooperated last round; else D.
  - Else if P > 0: play D; P := P − 1.
  - Else update PersistentDefectors from last W rounds.
    - If no persistent defectors and other_coop_fraction(last) ≥ q: play C.
    - Else if exactly one isolated defection and other_coop_fraction(last) ≥ 0.5: play C (forgive).
    - Else: set P := min(remaining rounds − 1, T_base * (1 + |PersistentDefectors|)); play D (start proportional punishment).
  - After P expires, require F consecutive cooperative moves from any persistent defector to clear them; once cleared and recent cooperation ≥ q, resume cooperation.

This strategy depends only on n, r, k and observed history; it is cooperative by default, punishes repeated or widespread defection proportionally, forgives isolated mistakes, and limits endgame exploitation.
'''

description_COLLECTIVE_57 = '''
Strategy name: Majority‑Forgiving Reciprocity (MFR)

Idea (collective mindset): try to sustain full-group cooperation whenever a clear majority is cooperating; punish quickly and briefly when cooperation collapses so defectors lose short-term gain; forgive and return to cooperation to restore the collective surplus. The strategy treats all players symmetrically and adapts to recent history; it is robust against sporadic mistakes and against persistent exploiters by escalating punishment when needed.

Fixed parameters derived from the game:
- Window W = min(5, r) — measure recent behavior over up to the last 5 rounds (use fewer if fewer rounds exist).
- Forgiveness threshold f_high = 0.60 (60%): if recent cooperation by others is at or above this, assume cooperative norm.
- Slack threshold f_low = 0.40 (40%): if recent cooperation by others is below this, assume cooperation has broken down.
- Punishment length P = min(3, max(1, ceil(W/2))) — a short, bounded punishment period.
- Last-round rule: treat round r as a terminal round where defection is the individually dominant move (see edge cases below).

Decision rules (pseudocode-style):

At the start of round t (1 ≤ t ≤ r) compute for every other player j the fraction of rounds they cooperated in the last W rounds (or since the game start if fewer than W rounds exist). Let G be the average of those fractions across all other players (equivalently: recent fraction of contributions by others).

1. Edge cases:
   - If r = 1 (one-shot): defect.
   - If t = r (final round): defect.
   - If t = 1 and r > 1: cooperate (signal willingness to build cooperation).

2. Normal rounds (1 < t < r):
   - If G ≥ f_high (≥ 60% cooperation by others recently): cooperate.
     Rationale: a clear cooperative norm exists; contribute to maximize long-run group welfare.
   - Else if G ≤ f_low (< 40% cooperation): enter punishment mode:
       - Defect for P consecutive rounds (or until the game ends), then re-evaluate G after the punishment block.
       - If, after a punishment block, G has recovered to ≥ f_low, return to normal evaluation (cooperate if ≥ f_high; otherwise follow the middle rule below).
     Rationale: strong and sustained breakdown calls for a short collective response to make defection costly.
   - Else (f_low < G < f_high — ambiguous region): be lenient and use a one‑round tie‑breaker:
       - If a strict majority of players (≥ ceil(n/2)) cooperated in the immediately preceding round, cooperate; otherwise defect.
     Rationale: give the group the benefit of doubt if recent behaviour is mixed; follow a majority signal from the last round.

3. Persistent exploiter detection (escrowed safeguard):
   - Continuously monitor each player’s cooperation fraction over the last W rounds. If any single player j has cooperated in ≤ 10% of those rounds while the rest of the group’s average cooperation (excluding j) is ≥ f_high, treat j as a persistent exploiter:
       - Respond by defecting until j’s cooperation rate over the last W rounds rises above 10% (or until the game ends).
     Rationale: preserve the collective by refusing to reward an identified, persistent exploiter while still allowing the rest of the group to recover cooperation.

Implementation notes (how to apply rules consistently):
- All computations use only observed history and known parameters (n, r, k do not change actions other than being used to motivate thresholds; thresholds are fixed constants derived above).
- After any punishment block, re-assess using the same rules; do not permanently switch to defection unless the persistent exploiter rule applies.
- The strategy is deterministic given the thresholds and history (no randomization required).

Why this is robust and collective:
- Starts cooperatively to test and support mutual cooperation.
- Uses a short memory (W ≤ 5) so it adapts quickly to changes in group behavior.
- Forgiving: ambiguous or occasional lapses do not trigger long punishments, allowing cooperation to resume.
- Deterring: sustained low cooperation triggers a bounded punishment to make defection unattractive.
- Targeted protection: if one player persistently free-rides while the rest cooperate, the strategy refuses to subsidize that exploiter but keeps the door open for rehabilitation.
- Last-round defection prevents being exploited by exploitative endgame strategies while the rest of the rules sustain cooperation earlier where collective welfare gains are attainable.

Summary rule-of-thumb:
- Cooperate by default (round 1 and whenever a clear majority/recent history shows cooperation).
- Defect briefly and proportionally when cooperation collapses.
- Forgive and return to cooperation quickly if others do.
- Refuse to reward clearly persistent exploiters.
- Defect in the final round.
'''

description_COLLECTIVE_58 = '''
Name: Collective Conditional Cooperator with Graduated Punishments (4G)

Overview (collective mindset)
- Start by offering cooperation so cooperation can form.
- Cooperate when there is clear evidence the group is reciprocating.
- Punish defection quickly but briefly and escalate only if defection repeats.
- Forgive and return to cooperation when the group reciprocates.
- Protect against endgame exploitation by stopping cooperation near the known end of the game.
All decisions use only n, k, r and the observed history of every player’s contributions (no communication required).

Parameters derived from r (fixed at the start)
- L = min(3, max(1, ceil(r/10))) — safe “endgame” length: in the final L rounds we stop cooperating (defect) to avoid last-round exploitation.
- w = min(5, max(1, floor(r/10))) — lookback window (number of recent rounds we use to estimate others’ cooperation); when fewer than w rounds exist, use all available past rounds.
- T = 0.50 — cooperation threshold: if the average contribution rate of others in the lookback window ≥ T, treat the group as cooperative.
- P_max = 5 — maximum punishment length (caps severity).
- Initial grace g = 1 — we cooperate on round 1 to seed cooperation.
- Probe rule: if cooperation has collapsed (group average ≤ 0.10 over the last min(10, t-1) rounds), we enter defect-with-infrequent-probes mode: defect most rounds but cooperate once every 5 rounds to test for recovery.

State variables (maintained by the strategy)
- strike_count (integer, initially 0) — counts repeated occasions where others defected while we cooperated.
- punishment_counter (integer, initially 0) — number of remaining rounds we will defect as punishment.
- mode — normal or collapsed-probe.

Decision rule for round t (1 ≤ t ≤ r)
1. First-round rule:
   - If t = 1: cooperate (contribute 1 token). Continue to normal mode.

2. Endgame protection:
   - If t > r - L (i.e., we are in the final L rounds): defect (contribute 0 tokens). Do not change strike_count or punishment_counter based on actions in these rounds.

3. If punishment_counter > 0:
   - Defect this round. Decrement punishment_counter by 1.
   - After the punishment_counter reaches 0, do not automatically reset strike_count; evaluate recent behavior next round and forgive if the group is cooperative (see step 5).

4. Collapsed-cooperation probe mode:
   - Compute recent_group_rate = average contribution per other player over the last min(10, t-1) rounds.
   - If recent_group_rate ≤ 0.10 and t ≤ r - L:
       - Enter collapsed-probe mode.
       - In this mode: defect every round except cooperate once every 5 rounds (e.g., when (t - t_start) mod 5 == 0, where t_start is the round when collapse was detected), to test whether cooperation resumes.
       - If on a probe round the group’s cooperation in the subsequent round(s) rises above T, exit collapsed-probe mode (reset strike_count = 0) and return to normal mode.

5. Normal mode cooperation decision:
   - Compute p_hat = average contribution rate (fraction of ones) of the other n-1 players over the last w rounds (or over all past rounds if fewer than w exist).
   - If p_hat ≥ T: cooperate (contribute 1 token).
   - If p_hat < T: defect (contribute 0 tokens).

6. Detection, punishment and forgiveness mechanics (applied after observing the results of the just-finished round):
   - If in the previous round you cooperated and at least one other player defected in that same round (i.e., there was any observed free-riding while you cooperated):
       - Increment strike_count by 1.
       - Set punishment_counter = min(P_max, 1 + strike_count). Immediately enter the punishment phase (so you will defect for punishment_counter rounds starting next round).
   - If the group shows clear reciprocation after a punishment (p_hat ≥ T in the first round after punishment_counter reaches 0):
       - Forgive: reset strike_count = 0 and return to normal cooperation decisions.
   - If you defected while others also defected, do not increase strike_count (do not punish mutual defection).

Rationale and notes (why this is collective and robust)
- Opening cooperation gives cooperative opponents the chance to cooperate and establish mutual benefit.
- The threshold T = 0.50 and short lookback w make the strategy responsive to a majority of cooperators while tolerating occasional mistakes by noisy players.
- Graduated punishments (short initial punishments and escalation only with repeats) deter repeat free-riding but avoid long, wasteful retaliation that hurts overall welfare.
- Forgiveness (returning to cooperation when others reciprocate) rebuilds cooperation quickly after punishment.
- Collapsed-probe mode avoids wasting tokens when the group has largely defected, but still probes periodically to detect a return to cooperation.
- Endgame protection (defecting in the final L rounds) prevents exploitation from unconditional cooperators in the known finite endgame.

Edge cases
- Very short games: parameters scale (L, w) use floors/ceilings; first-round cooperation still applies but endgame may begin immediately if r ≤ L.
- Perfect unconditional cooperators in the population: the strategy cooperates and gains group welfare while bluffing protection in the endgame (protects itself in last L rounds).
- A noisy cooperator who occasionally defects: short lookback and threshold T allow tolerance; single mistakes trigger small punishments but the strategy forgives quickly.
- Coordinated mass defection: collapsed-probe mode stops wasting tokens but still offers a path back to cooperation through probes.

Summary (operational)
- Cooperate by default (round 1 and while others’ recent cooperation ≥ 50%).
- If others defect while you cooperated, punish briefly and escalate on repeats, but forgive when cooperation returns.
- If group cooperation collapses, defect but probe occasionally.
- Defect in the final L rounds to avoid endgame exploitation.
'''

description_COLLECTIVE_59 = '''
Collective Conditional Cooperator (CCC) — a firm-but-fair, history‑based strategy

Goal: sustain high collective contributions whenever the group is willing to reciprocate, while deterring persistent free‑riding with short, credible punishments. Forgive quickly when cooperation returns. Parameters below are chosen from the game parameters (n, k, r) and observed history; no communication or coordination is assumed.

Parameters (computed at the start)
- L = min(4, r) — lookback window (how many past rounds to inspect).
- r_rem(t) = remaining rounds including current round t.
- If k/n >= 0.6 then P_base = 5 else P_base = 3 — baseline punishment duration scaled to how valuable cooperation is to the group.
- P_max = min(P_base, r_rem(t)-1) — maximum punishment rounds we will impose (never longer than remaining rounds minus the current one).
- Thresholds for judging group cooperativeness:
  - T_high = 0.8 — treat the group as cooperatively behaving when recent cooperation fraction ≥ T_high.
  - T_low = 0.5 — treat the group as clearly non-cooperative when recent cooperation fraction ≤ T_low.
(These thresholds are adjustable but must be fixed before play; they depend only on n, k, r.)

State
- punishment_counter (initially 0) — counts remaining rounds during which this strategy will defect as punishment.
- last_actions and last_payoffs — full public history (used only to compute cooperation rates).

Decision rule each round t

1. First round (t = 1)
- Play C. (Lead by example: demonstrate willingness to cooperate.)

2. If punishment_counter > 0
- Play D.
- Decrement punishment_counter by 1 after the round.
- (Purpose: impose a short, predictable penalty to make single‑round exploitation unattractive.)

3. Otherwise (no active punishment)
- Compute f = fraction of other players’ contributions over the last L rounds:
  f = (sum of contributions by players j ≠ me over last L rounds) / ((n-1) * L).
- Use f to decide:
  a) If f ≥ T_high: play C. The group is behaving cooperatively — continue cooperating.
  b) If f ≤ T_low: play D and set punishment_counter = P = min(P_max, max(1, round(P_base))). The group is habitually non‑cooperative — defect and punish briefly to protect collective payoff.
  c) If T_low < f < T_high: be lenient — play C (assume occasional mistakes; give benefit of the doubt).

4. Special handling of recent targeted defections
- If in the immediately preceding round the large majority cooperated (≥ T_high) but at least one player defected (a small number of rogue defections), do not escalate to a long punishment. Instead, set punishment_counter = 1 and play D this round (a minimal signal). After that single signal, return to the normal rules above. This punishes isolated exploiters while remaining forgiving.

5. Last-round logic (t = r)
- If punishment_counter > 0, continue to follow the punishment (play D).
- Else: play C only if f ≥ T_high; otherwise play D.
  Rationale: in the known final round unilateral cooperation is exploitable; cooperate only if recent history shows reliable reciprocity.

6. All-defection sink
- If f = 0 for L consecutive rounds (nobody cooperated recently), defect for the rest of the game (no point in unreciprocated contributions).

Adaptation and robustness notes (why this works)
- Collective mindset: the strategy always prefers to preserve group cooperation when it is reciprocated (cooperate by default) and uses punishments only to restore reciprocity, not to permanently exclude players.
- Firmness: punishments are finite and predictable (punishment_counter), making the cost of defection calculable for others and therefore making cooperation a viable equilibrium in many repeated-play contexts.
- Forgiveness and noise tolerance: short punishments and a middle “lenient” zone avoid endless retaliation from occasional or noisy deviations.
- Parameter dependence: punishment length is scaled up when k/n is larger because the cost to the group of lost cooperation is higher; lookback window L is bounded by remaining rounds so the rule behaves sensibly when r is small.
- Last-round safety: the strategy protects itself from being routinely exploited in the final round while still choosing to cooperate there when reciprocity is reliable.

Summary (compact pseudocode-like)
- t=1: play C.
- If punishment_counter>0: play D; punishment_counter--
- Else compute f over last L rounds.
  - If f ≥ T_high: play C.
  - If f ≤ T_low: set punishment_counter = P_max; play D.
  - If T_low < f < T_high: play C.
- If previous round had majority cooperation but some defectors: instead of P_max, set punishment_counter = 1 and play D once.
- If f = 0 for L rounds: defect forever.
- At final round t=r: cooperate only if f ≥ T_high (or punishment_counter > 0 forces D).

This strategy is simple, transparent to observers, and tuned to protect collective welfare while remaining robust against a wide range of opponent behaviors (persistent defectors, occasional mistakes, partially cooperative groups).
'''

description_COLLECTIVE_60 = '''
Summary (collective-minded): I try to sustain high group contributions by default, lead with cooperation, and use simple, proportional punishments when others free-ride. Punishments are limited and forgiving so cooperation can be re-established. I also probe occasionally if the group has fallen into persistent defection so cooperation can restart.

Parameters I compute from the game parameters (n, r, k) and history:
- Window for recent behavior W = max(3, round(0.15 * r)). (If r is very small, W is at least 3 and at most r.)
- Cooperation evidence threshold R_coop = 0.6 + 0.2 * ((n - k) / (n - 1)). (This rises toward 0.8 when k is low and falls toward 0.6 when k is close to n.)
- Forgiveness requirement F = 2 consecutive rounds of sufficiently cooperative behavior to return to full cooperation.
- Base probe rule: if the group has shown >= W consecutive rounds of near-universal defection, attempt a deterministic probe (one contribution) every M = max(3, round(r/10)) rounds.
- Punishment length is proportional to the scale of exploitation (see below).

State machine and decision rules (applies each round t; use full history of past rounds; "others" = all players except me):
1. Terminal rule:
   - If t is the last round (t = r): choose D (defect). There is no future reciprocity to justify an uncompensated contribution.

2. Initialization:
   - Round 1: choose C (cooperate). I lead once to signal cooperative intent.

3. Compute recent behavior:
   - Let recent_coop_rate = (number of contributions by others in the last W rounds) / (W * (n - 1)).
   - Let last_round_defectors = number of other players who defected in the immediately preceding round (0..n-1).
   - Track consecutive rounds of "sustained defection" S_defect = number of consecutive prior rounds in which (total contributions in that round) = 0 or very low (e.g., < 1).

4. Main decision logic (four working states implied by history):

A. Cooperative default:
   - If I am not currently in a punishment episode and recent_coop_rate >= R_coop:
     - Play C (cooperate).
   - Rationale: others have been collaborating enough recently; I continue to support the public good.

B. Suspicion → mild test:
   - If recent_coop_rate < R_coop but recent_coop_rate >= R_coop - 0.15:
     - Enter a mild test: play D for one round (a warning) while observing who defects.
     - If last_round_defectors is small (e.g., ≤ ceil(0.2*(n-1))), do not escalate; return to Cooperative default next round if others rise back above threshold.
   - Rationale: give a chance to signal displeasure and collect information without permanently abandoning cooperation.

C. Proportional punishment:
   - If others repeatedly fail the threshold or if last_round_defectors is high (≥ ceil(0.2*(n-1))) and the recent_coop_rate < R_coop:
     - Punish by defecting for P rounds, where P = max(1, min(W, ceil( (last_round_defectors / (n-1)) * W ))).
     - While punishing, keep observing: if during the punishment others increase cooperation above R_coop for F consecutive rounds, end punishment and return to Cooperative.
   - Rationale: punishment is proportional to how many others defected last round; limited to avoid collapse.

D. Recovery and probing:
   - If the group has been in sustained near-zero cooperation for S_defect ≥ W rounds:
     - Every M rounds perform one deterministic probe: play C and observe the group's response.
     - If the probe elicits increased cooperation (recent_coop_rate after the probe ≥ R_coop), switch to Cooperative.
     - If probes repeatedly fail (no sustained response after a small fixed number of probes equal to 2), revert to persistent defection but continue occasional probes every M rounds.
   - Rationale: recover cooperation opportunities without being exploited continually.

5. Special handling for small groups or extreme k:
   - If k is close to n (k / n near 1): R_coop leans lower (we described the formula), so I will be slightly more optimistic about cooperating.
   - If k is near 1 (k / n low): R_coop is higher, so I require stronger evidence of group cooperation before contributing.

6. Tie-breaking and deterministic choices:
   - When exactly on the threshold or ambiguous, prefer cooperation if not in punishment (bias to cooperate).
   - When punishing, defect deterministically for the prescribed P rounds.

7. Transparency in behavior (implicit): my actions are based only on observed contributions and payoffs; there is no communication or side channel.

Illustrative examples of how this plays out:
- If most players cooperate steadily: I cooperate every round (except the theoretical last round) and help sustain the public good.
- If one or a few players start freeloading occasionally: I give a mild one-round warning; if freeloading persists, I apply proportional punishment for a few rounds and then forgive if cooperation resumes.
- If the whole group collapses to defection: I periodically probe (infrequently) to test whether cooperative play can be re-started; if a probe succeeds, I switch back to cooperating with the group.

Why this is robust and collective:
- Default cooperation signals willingness to build collective payoff.
- Punishments are proportional, short, and clearly contingent on observed behavior, which deters exploitation but avoids permanently condemning the group.
- Forgiveness and probing allow re-establishing cooperation when partners are responsive.
- All rules are computable from n, r, k and the observable history; no reliance on assumed norms or coordination with others.
'''

description_COLLECTIVE_61 = '''
Collective Adaptive Reciprocity (CAR)

Goal: maximize collective welfare by sustaining mutual contributions while being robust to free-riders and exploiting strategies. The strategy is simple, transparent, forgiving, and proportional: it rewards cooperation by cooperating, punishes defection just enough to deter it, and then reintegrates repentant players. It uses only the public history of contributions and payoffs and the game parameters (n, r, k).

Parameters (fixed internal rules; depend on r, n):
- initial_cooperate_rounds = min(3, r)  — start by signaling good faith.
- lookback_window W = min(3, r-1)  — use the last up to 3 rounds to estimate recent behavior.
- tolerance fraction tau = 0.25  — allow modest one-off deviations without long punishment.
- base_punish = 1 round  — minimal punishment length.
- max_punish = min(5, max(1, floor(r/4)))  — do not punish indefinitely; limit escalation.
- recovery_requirement = 0.75  — after a punishment, require at least this fraction of cooperation in the lookback window to return to normal cooperation.
- last_round rule: always defect in round r (no future to enforce cooperation).

State inferred from history each round t (t = 1..r):
- For each past round s we observe all contributions c_j^s (0/1 for each player j).
- Define others' cooperation rate in round s: coop_rate_others(s) = (sum_{j != me} c_j^s) / (n-1).
- Define recent_avg = average of coop_rate_others over the last W rounds that exist (if t-1 < W, average the available rounds).
- Track last_punish_length and punish_ends_at (initialized as “not punishing”).

Decision procedure for round t:

1. Last-round rule:
   - If t == r: play D (defect).

2. Opening signal:
   - If t <= initial_cooperate_rounds and t < r: play C (cooperate). (Shows willingness to build cooperation.)

3. If currently in a punishment phase (punish_ends_at is defined and t <= punish_ends_at):
   - Play D (sustain punishment this round).
   - After this round, re-evaluate (see step 6).

4. Otherwise, evaluate recent behavior:
   - Compute recent_avg (average others’ cooperation rate over the last W rounds).
   - If recent_avg >= 1 - tau (i.e., most others have been cooperating recently):
       - Play C (cooperate). Remain cooperative until broken.
   - Else (recent_avg < 1 - tau):
       - Start or escalate punishment:
         - If not currently punishing: set last_punish_length = base_punish.
         - Else (if we previously punished and cooperation did not recover): set last_punish_length = min(max_punish, 2 * last_punish_length).
         - Set punish_ends_at = t + last_punish_length - 1.
         - Play D this round (initiate/continue punishment).

5. Recovery after punishment:
   - When punishment has just ended (t > punish_ends_at for the first time), check recovery:
     - Recompute recent_avg over the last W rounds.
     - If recent_avg >= recovery_requirement:
         - Clear punishment state and return to normal cooperation rules (play C if the normal condition in step 4 is satisfied).
     - Else:
         - Treat as continuation of defection by others: escalate punishment (as in step 4) and set a new punish_ends_at accordingly.

6. Gentle forgiveness and anti-exploitation detail:
   - If a single player (or a small minority) is consistently defecting while the rest cooperate (detectable as an individual with low personal cooperation rate over the last W rounds), do not lock into permanent global non-cooperation. Instead:
     - Continue the proportional punishment mechanism above (short punishments that escalate only if the bad behavior persists).
     - When the minority repent (they contribute in recovery rounds such that recent_avg meets recovery_requirement), immediately return to cooperation.
   - This ensures we do not permanently “burn the public good” for the whole group because of a few occasional defectors.

Rationale / Collective mindset:
- Signal: cooperate early to build the common project.
- Conditional cooperation: contribute when most others contribute; that maximizes collective payoff.
- Proportional punishment: punish only enough to make defection costly for repeat defectors, but keep punishments short and escalated only if misbehavior persists.
- Forgiveness: quickly reward improved behavior so cooperative equilibria can be restored.
- Limited escalation: do not punish forever — maximum punishment length is bounded so the strategy is not self-destructive.
- Endgame realism: defect in the final round (no future enforcement).

Edge cases:
- Very short games (r = 1): defect (last-round rule).
- r = 2 or 3: initial_cooperate_rounds may cover nearly the whole game; still defect in last round.
- If many players are persistently defecting and recovery_requirement cannot be met, CAR will escalate punishments up to max_punish and then keep responding to observed behavior; it never assumes any off-channel coordination.
- If the group rapidly returns to high cooperation, CAR immediately rejoins full cooperation.

Behavioral summary (simple view players can read):
- Start cooperative to seed public good.
- Cooperate as long as most others cooperate.
- If you see substantial defection, defect for a short, growing penalty period to discourage it.
- If cooperation resumes, forgive and rejoin.
- Always defect in the last round.

This strategy is adaptive (responds to observed recent behavior), robust (forgives one-offs and escalates only when necessary), and collective (prioritizes re-establishing group cooperation rather than permanent retaliation).
'''

description_COLLECTIVE_62 = '''
Name: Adaptive Collective Conditional Contribution (ACCC)

Overview (one-sentence): Start by signalling cooperation, keep contributing as long as the group reciprocates, punish defections proportionally but briefly, forgive and test to restore cooperation, and refuse continued exploitation — with stricter checks as the horizon approaches.

Definitions and internal parameters (computed from game parameters n, k, r and available history):
- n_others = n − 1.
- Lookback window w = min(5, t−1) when deciding at round t (use up to the last 5 completed rounds; if none, w = 0).
- recent_coop_rate = average over the last w rounds of (number of other players who contributed in that round) / n_others. If w = 0, treat recent_coop_rate as 1.0 for initial goodwill.
- Cooperation threshold tau = 0.60 (require a clear majority of others to have cooperated recently to stay in cooperative mode).
- Stricter endgame threshold tau_end = 0.85 (used when only a few rounds remain).
- Max punishment length P_max = min(4, r) (cap punishments to avoid permanent vendettas).
- Testing probability during punishment p_test = 0.10 (small chance to cooperate while testing recovery).
- Give-up rule: if total rounds spent punishing exceeds floor(r/3) or average cooperation over all past rounds falls below 20%, switch to permanent defection to avoid ongoing exploitation.

Mode and memory:
- The strategy remembers whether it is currently in Cooperative mode or Punish mode, and how many punishment rounds remain. Modes are only functions of the observed action history and remaining rounds.

Decision rules (what to do each round t):

1. First round (t = 1):
   - Contribute (C). This signals willingness to cooperate.

2. Before deciding at round t > 1 compute recent_coop_rate (w as above). Also note remaining_rounds = r − t + 1.

3. Endgame adjustment:
   - If remaining_rounds ≤ 2, use tau_eff = tau_end (be stricter near the end).
   - Otherwise tau_eff = tau.

4. Entering or staying in Cooperative mode:
   - If not currently punishing and recent_coop_rate ≥ tau_eff, play C (contribute) and remain in Cooperative mode.
   - Rationale: the group is reciprocating sufficiently; maintain collective contributions.

5. Detecting a violation and punishing:
   - If not currently punishing and recent_coop_rate < tau_eff, enter Punish mode:
     - Set punishment_length = min(P_max, 1 + ceil((tau_eff * n_others) − average_number_of_other_cooperators_per_round_over_w)), where average_number_of_other_cooperators_per_round_over_w = recent_coop_rate * n_others. (Intuition: punish for longer when more people defected.)
     - If this formula gives 0, set punishment_length = 1.
     - Immediately defect (D) this round; record remaining punishment rounds = punishment_length − 1.
   - Rationale: proportional, short punishments signal cost of free-riding but avoid destroying future cooperation.

6. Actions while in Punish mode:
   - If remaining punishment rounds > 0:
     - With probability p_test, play C (a one-shot test/forgiveness to see if cooperation resumes).
     - Otherwise play D.
     - Decrement remaining punishment rounds.
   - After punishment rounds expire, recompute recent_coop_rate over the most recent w rounds. If recent_coop_rate ≥ tau_eff, return to Cooperative mode and play C. If not, either:
     - Re-enter Punish mode with a new short punishment_length computed as in step 5, or
     - If the Give-up rule triggers (too many punish rounds overall or long-term cooperation very low), switch to permanent defection (always D) for the remainder of the game.

7. Last round (t = r special case):
   - If the group has sustained cooperation almost continuously (recent_coop_rate ≥ tau_end), cooperate in the last round to preserve the collective payoff.
   - Otherwise defect in the last round (D).

8. Tie / ambiguous cases:
   - If recent_coop_rate is exactly on the threshold, choose C (default to cooperation) unless you are in Punish mode; this gives the benefit of doubt and promotes re-establishment of cooperation.

Additional notes (robustness and rationale):
- Forgiveness and testing avoid endless vendettas that reduce long-run welfare and allow recovery from accidents or exploratory defections.
- Proportional punishments (length scaled to number of defectors) make the punishment meaningful but capped so you do not become stuck in retaliation cycles.
- The Give-up rule prevents being exploited indefinitely by groups that never respond to punishments: after a long record of non-reciprocation, the strategy protects itself by defecting permanently.
- Stricter checks near the end of the horizon reduce vulnerability to last-round free-riding while allowing cooperative endings when cooperation is well-established.
- No external coordination or communication is assumed; decisions rely only on observed past actions and the known parameters n, k, r.
- This strategy favors collective welfare by default (start cooperating, sustain cooperation when reciprocated), but it is robust to a wide range of opponent behaviors because it punishes defections in a proportional-but-forgiving way and stops cooperating if exploitation persists.
'''

description_COLLECTIVE_63 = '''
Collective Conditional Cooperator (CCC)

Summary
- My goal is to sustain group cooperation where possible while avoiding long-term exploitation. I favor cooperation by default, punish clear group-level free-riding briefly and proportionally, and forgive when the group recovers. I use only the game parameters (n, r, k) and publicly observable history of contributions and payoffs.

State I track (implicitly via history)
- remaining rounds R_rem (including the upcoming round)
- a short punishment counter Punish (initially 0) derived from recent history when needed
- recent-window length L = min(5, r) (use last L rounds to assess group behavior)

Decision rules (per round)
1. Terminal rule
   - If this is the final round (R_rem = 1): defect (D). There is no future to enforce reciprocity.

2. Opening move
   - If no history yet (first round): cooperate (C) to signal willingness to sustain cooperation.

3. If Punish > 0
   - Play D this round and decrement Punish by 1. (Punishment is short and finite.) After Punish reaches 0 I resume normal conditional behavior.

4. Otherwise (normal evaluation)
   - Compute recent cooperation fraction f = (total contributions observed in the last L rounds across all players) / (n * L).
     - This is the average fraction of the group that contributed recently.
   - Compute my personal recent exploitation rate e = fraction of rounds in the last L in which I contributed but the group’s average contribution that round was below a low-cooperation standard (this captures being exploited repeatedly).
   - Use three regimes:
     a) Strongly cooperative environment (f >= 0.60): play C.
        - Group is mostly cooperating; sustain cooperation.
     b) Mixed/uncertain environment (0.40 <= f < 0.60): play C unless my personal exploitation rate e is high (e > 0.5), in which case play D this round and set Punish = 1.
        - Be lenient toward occasional deviations, but respond to repeated exploitation against me.
     c) Low-cooperation environment (f < 0.40): switch to proportional short punishment:
        - Set Punish = min(3, R_rem - 1) and play D this round.
        - The punishment length 1–3 rounds is designed to be strong enough to signal that collective defection is harmful but short enough to avoid endless mutual defection or letting noise spiral into permanent breakdown.

5. Recovery and forgiveness
   - After any punishment, monitor the same recent-window f. If f returns to >= 0.60, immediately resume cooperation.
   - Never escalate punishment indefinitely; further punishment can be re-triggered only if the group again falls below the low threshold.

6. Small-horizon caution
   - If R_rem is very small (R_rem <= 2): be conservative.
     - If R_rem = 1: D (already covered).
     - If R_rem = 2: cooperate in the first of these two rounds only if f >= 0.70 (strong evidence of recent cooperation); otherwise play D. The idea is that with little future left, threats are weak and the risk of exploitation is higher.

How this is collective
- Decisions are based on the group’s aggregate past behavior (fraction f), not on single individuals — this avoids being baited by one rogue strategy.
- Punishment is proportional and brief: it targets a group-wide pattern rather than permanently excluding players. That encourages recovery to cooperative norms rather than destructive cycles.
- Forgiveness is explicit: the strategy returns to cooperation as soon as group behavior improves.
- The strategy biases toward sustaining cooperation when the group is broadly cooperative, and it protects against persistent exploitation by switching to short, credible punishments.

Robustness notes
- By tolerating occasional deviations (the mixed regime) and limiting punishment length, CCC resists noise and single-round mistakes.
- By using a short memory window L and proportional punishments, CCC adapts to a wide range of opponent behaviors (from near-universal cooperation to persistent free-riding).
- The terminal-round defection is unavoidable in finite-horizon play; all other choices aim to make cooperation profitable across the repeated interaction without depending on shared conventions or side channels.

Implementation summary (pseudocode-style)
- If R_rem = 1: play D.
- Else if no history: play C.
- Else if Punish > 0: play D; Punish--.
- Else compute f over last L rounds and my personal exploitation rate e.
  - If f >= 0.60: play C.
  - Else if 0.40 <= f < 0.60:
      - If e > 0.5: set Punish = 1; play D.
      - Else play C.
  - Else (f < 0.40): set Punish = min(3, R_rem-1); play D.
- Special case: if R_rem = 2, require f >= 0.70 to play C; otherwise play D.

This strategy is transparent, collective, and designed to encourage cooperation while avoiding being exploited indefinitely.
'''

description_COLLECTIVE_64 = '''
Collective-First Conditional Cooperation (CFCC)

Intuition
- I favor group welfare: I want sustained, near-universal contributions across rounds because that maximizes collective payoff. I will therefore start by offering cooperation and then use clear, proportional, temporary punishments to discourage persistent free-riding. I allow for quick forgiveness so cooperation can be rebuilt, and I avoid long vendettas that destroy group payoff. I also guard against endgame exploitation by relaxing cooperation late in the game.

Setup (computed from parameters and history)
- Let r be total rounds, n players, k multiplier. Let t be the current round index (1..r).
- Use a recent window W = min(5, r) (if r small, use the whole history).
- For each other player j compute RecentRate_j = fraction of rounds in the most recent W rounds in which j contributed.
- GroupRecentRate = average of RecentRate_j over all other players.
- RecentDefections = total number of contributed=0 actions by others in the most recent W rounds.
- Keep a PunishTimer (initially 0) that counts remaining rounds of an ongoing punishment phase (shared only in my internal state).
- Small probing probability epsilon = 0.05 (used only when group cooperation is very low to probe for recovery).

Decision rules (applied each round)
1) Final-round rule
- If t == r (last round): Defect (do not contribute). Reason: no future to enforce cooperation.

2) Late-horizon safety (avoid being exploited in endgame)
- If remaining rounds Rem = r - t + 1 is small (Rem <= 2):
  - Cooperate only if the previous round was unanimous cooperation (every player contributed).
  - Otherwise Defect.
  (This prevents being exploited when there is no realistic future punishment left.)

3) If PunishTimer > 0
- Defect this round and decrement PunishTimer by 1.
- After PunishTimer expires I resume the normal decision rules (below), with a bias toward forgiveness (see forgiveness rule).

4) Automatic cooperation signal
- If the immediately previous round was unanimous cooperation (everyone contributed), Cooperate. (Reward and reinforce full-group cooperation.)

5) Strong cooperation region
- If GroupRecentRate >= 0.70 (i.e., most others have been cooperating recently): Cooperate.
  - Rationale: sustain cooperation when a large fraction of the group is cooperating.

6) Detection of persistent free-riding -> proportional, temporary punishment
- If any other player j has RecentRate_j <= 0.40, treat that as persistent under-contribution.
  - Set PunishTimer = min(5, 1 + RecentDefections). (Punishment length is proportional to how many defections happened recently, capped to avoid collapse.)
  - Defect this round (start punishment).
  - Rationale: apply a clear, finite cost to discourage repeat free-riding while keeping punishment short so group payoff can recover.

7) Tit-for-tat style short retaliation (immediate response to recent single defection)
- If someone defected in the immediately previous round (but no one is yet classified persistent under-contributor), then Defect this round (single-round retaliation). This is a short, direct enforcement move to link actions to consequences.

8) Low-cooperation environment -> avoid being exploited, but probe
- If GroupRecentRate < 0.40 (the group is mostly defecting):
  - With probability 1 - epsilon, Defect (avoid giving away tokens).
  - With probability epsilon, Cooperate (probe to see if cooperative behavior can restart).
  - This keeps me from being repeatedly exploited while allowing occasional attempts to rebuild cooperation.

9) Default
- In all other cases Cooperate (prefer cooperation in mixed but not hostile environments).

Forgiveness and re-starting cooperation
- Punishments are temporary by design. After PunishTimer expires, I resume cooperation whenever objective signals improve (GroupRecentRate rises above 0.70 or I observe a unanimous-cooperation round). If cooperation does not restart, I will remain cautious (rule 8).
- The goal is to restore cooperation quickly: punish misbehavior long enough to change incentives but not so long that the group welfare collapses permanently.

Additional clarifications (policy properties)
- My behavior depends only on (n, r, k) and the public history of actions/payoffs.
- I do not require coordination or shared identities; I treat each player’s history individually to detect persistent defectors.
- Punishments are proportional and capped: they are not infinite (no grim-trigger forever), so forgiving behavior is possible and encouraged.
- I use immediate single-round retaliation for isolated defections to create a clear, low-cost link between defection and consequence.
- I probe with a small probability when the group is largely uncooperative to allow recovery from mutual defection equilibria.
- I always defect in the final round and restrict cooperation in the last one or two rounds unless there is clear unanimous cooperation, to avoid being exploited in the known endgame.

Collective mindset statement
- My default objective is to maximize collective payoff by sustaining high contribution levels. I cooperate when the group has shown substantial cooperation, punish briefly and proportionally to discourage free-riding, forgive quickly when others resume cooperative behavior, and avoid being a continuous exploitable donor when most players defect. This balances enforcement and forgiveness so cooperation can be maintained robustly against a wide variety of opponent behaviors.
'''

description_COLLECTIVE_65 = '''
Adaptive Collective Cooperation with Proportional Punishment (ACCPP)

Goal (collective mindset)
- Prefer to sustain high collective contribution because group welfare rises when many contribute.
- But avoid being a persistent sucker: deter and punish systematic free-riders, while forgiving one-off mistakes so cooperation can recover.

Overview of parameters (computed from public inputs)
- n, r, k are known.
- Memory window W = min(8, max(3, floor(r/5))). (Use the last W rounds to estimate recent behavior; if r is small this shrinks appropriately.)
- Group-cooperation threshold Θ = 0.60 (a baseline; the strategy is tolerant of some occasional defection but not of sustained free-riding).
- Individual-suspect threshold τ = 0.50 (a player whose recent cooperation rate < τ is treated as a suspected defector).
- Forgiveness window S = 2 (require S consecutive rounds of recovery to resume full cooperation after punishment).
- Maximum punishment length L_max = min(4, r-1) (never punish so long that there is no chance to recover before the game ends).
- Small contrition-cooperate probability q = 0.20 (used during punishment to allow quick recovery if others respond).
- Endgame caution: in the final round cooperate only under very strong evidence of mutual cooperation (see below); in the final two rounds use a higher effective threshold.

Action rule (round t, 1..r)
1. Round 1:
   - Cooperate (C). Start by signaling collective intent.

2. At the start of a general round t > 1:
   - Compute, from the last W rounds (or all past rounds if fewer than W exist), for every other player i:
       coop_rate_i = fraction of those rounds in which i contributed.
   - Define group_rate = average of coop_rate_i across all other players (i.e., the recent average contribution level excluding yourself).
   - Count suspected defectors D = {i : coop_rate_i < τ} and let d = |D|.

3. Forgive isolated/one-off lapses:
   - If group_rate dropped because of a single missed contribution in the previous round (i.e., previously group_rate was ≥ Θ and now only the last round missed that threshold), treat that as a one-off error: cooperate this round to avoid needless punishment.

4. Decide whether to cooperate or defect:
   - If currently in an active punishment phase you initiated (see Punishment mechanism below), then follow the punishment-state rule below.
   - Otherwise:
     a) If group_rate ≥ Θ: cooperate (C). The group has been cooperating recently; we reciprocate to sustain cooperation.
     b) If group_rate < Θ:
         - If d = 0 (many players occasionally missed but none are below τ): be lenient — cooperate with probability 1 - (Θ - group_rate)/Θ clipped to [0.2, 0.9]. (This reduces exploitation risk without collapsing cooperation.)
         - If d ≥ 1 (one or more clear suspected defectors): start a targeted punishment phase (see Punishment mechanism). Immediately defect (D) this round as part of the punishment.

5. Punishment mechanism (proportional, limited, forgiving)
   - When we decide to punish (d ≥ 1 and group_rate < Θ), we:
     a) Record a punishment phase with length L = min(L_max, max(1, 1 + d)). The length is proportional to the number of suspected defectors but capped by L_max.
     b) For each round of the punishment phase:
         - Play D (defect) as the baseline punishment action.
         - With small probability q (contrition), play C instead (this gives suspected defectors a low-cost opportunity to re-establish cooperation and avoids perpetual mutual defection).
     c) Monitor coop_rate_i continuously. If, during the punishment, each suspected defector i raises coop_rate_i to ≥ τ and group_rate rises to ≥ Θ for S consecutive rounds, terminate punishment early and resume full cooperation.
     d) If punishment phase finishes and suspected defectors remain below τ, revert to the default decision rule (step 4): if group_rate still below Θ, continue punishing with a new phase but never exceed L_max per phase and allow recovery attempts.

6. Contrition and error-handling
   - If we ever intentionally defect as punishment and observe rapid positive response (group_rate rises, suspected defectors improve), immediately switch back to cooperation once the recovery condition (group_rate ≥ Θ for S consecutive rounds) is met.
   - If we made an accidental defection (rare), treat the next round as forgiving (cooperate) unless others persist in defecting.

7. Endgame adjustments (last rounds)
   - Last round (t = r): default to Defect (D) unless there is strong evidence of mutual cooperation: require group cooperation over the full history ≥ 0.95 and zero suspected defectors; only in that case cooperate in the final round. Rationale: avoid being exploited in the clear last-move.
   - Last two rounds (t = r-1 and r): use a higher effective Θ_end = min(0.95, Θ + 0.20); be more cautious about initiating punishment that would burn remaining opportunities for recovery.

Design rationale and robustness
- Collective orientation: we begin by cooperating and favor cooperation whenever the group shows sustained cooperative behavior. That maximizes group payoff when many reciprocate.
- Proportional and targeted punishment: we punish when there are clear, recent underperformers, and punish intensity/length scales with the number of suspected defectors. This deters systematic free-riding without needlessly collapsing cooperation if only one player occasionally defects.
- Forgiveness and contrition: small random cooperations during punishment and short punishment phases allow recovery from mistakes and prevent long mutual-defection spirals.
- Noise-resilience: single occasional defections (from errors or stochastic strategies) do not trigger full-scale punishment; we require sustained low cooperation to respond.
- Endgame caution: we avoid naive final-round cooperation unless there is compelling evidence everyone will reciprocate; this prevents predictable exploitation in the last move.
- Parameter adaptivity: W, L_max and other parameters depend on r so the strategy behaves sensibly whether the game is short or long.

Summary (quick pseudocode-like)
- Round 1: cooperate.
- Each round compute recent coop rates for others over W rounds.
- If recent group_rate ≥ Θ → cooperate.
- If group_rate < Θ:
  - If only an isolated lapse → forgive and cooperate.
  - If one or more players have coop_rate_i < τ → begin limited punishment: defect for L rounds (L proportional to number of suspects, capped), with occasional small-probability cooperations to enable recovery.
- Endgame: be cautious in final rounds, defect in last round except when full-history cooperation is extremely high.
- Always monitor and end punishment early if others recover.

This strategy is collective-minded (favors cooperation to maximize group welfare), adaptive (uses recent history, scales punishment), robust (forgives noise, deters persistent free-riders, cautious at the end), and depends only on game parameters and observed history.
'''

description_COLLECTIVE_66 = '''
Strategy name: Adaptive Collective Conditional Cooperator (ACCC)

Goal (collective mindset)
- Aim to sustain high group contributions when others reciprocate, while avoiding long-term exploitation. Start cooperative to signal willingness to build the public good, punish clear and repeated free-riding to deter it, and forgive to re-establish cooperation when the group responds.

Parameters (computed from game inputs n, r, k)
- Window w = min(5, r) — use up to the last 5 rounds to evaluate recent behavior.
- Cooperation threshold alpha = max(0.5, k/n). (Intuition: require at least a moderate level of recent cooperation — at least half, or the normalized multiplier k/n if that is higher — before committing to keep cooperating.)
- Base punishment length m_base = 1; maximum punishment length m_max = 3.
- Endgame horizon h_end = min(2, r) — treat the final 1 round (or final 2 rounds if r≥2) specially (see Endgame rules).

State variables (maintained each round)
- punish_counter (integer ≥0): number of remaining rounds to defect as punishment.
- last_w_history: record of others’ contributions over the previous w rounds.

Decision rules (what I do each round)
1. First-round rule
   - If r = 1 (single round), defect (standard single-shot dominant choice).
   - Otherwise (r ≥ 2), cooperate on round 1 to signal constructive intent.

2. Endgame rule (final rounds)
   - Last round (round r): defect (cannot influence future rounds).
   - If r ≥ 2 and current round = r−1: adopt caution. If the group has been nearly fully cooperative in the last w rounds (average others’ contribution ≥ 0.95), cooperate once more as a final chance to preserve payoff; otherwise defect (to avoid being taken advantage of just before the end).
   - Note: these endgame choices accept the backward-induction reality but preserve cooperation when the group has reliably reciprocated.

3. Normal play (neither first-round exception nor endgame nor currently testing)
   - If punish_counter > 0:
       - Defect this round.
       - Decrement punish_counter by 1.
       - Continue to monitor others’ actions (they are recorded into last_w_history).
   - Else (no active punishment):
       - Compute p_hat = average per-player contribution by the other n−1 players across the last w rounds (if fewer than w rounds have occurred, use all available rounds).
       - If p_hat ≥ alpha:
           - Cooperate this round (contribute 1).
       - Else:
           - Defect this round and enter/trigger punishment: set punish_counter = min(m_max, m_base + ceil((alpha − p_hat) * 3)).
             - (Interpretation: stronger recent shortfall below alpha produces longer, but bounded, punishment. This makes punishment proportional to severity but capped to avoid endless deadlock.)

4. Testing and forgiveness after punishment
   - After a punish_counter reaches 0 (punishment completed), perform one cooperative "test" round regardless of p_hat to give the group a chance to return to cooperation.
   - If in the w rounds after that test, p_hat rises above alpha, interpret as successful recovery: return to normal cooperative mode (no punishments).
   - If p_hat does not rise (cooperation remains below alpha), escalate proportionally by increasing future punish_counter as in rule 3 when next triggered (but never exceed m_max), and repeat the test cycle periodically (punish → one test cooperation → evaluate).

5. Recovery and reset
   - If at any time the average others’ contribution in the last w rounds ≥ 0.95, clear punishments and resume always cooperating (until and unless defections reappear). This rewards sustained near-full cooperation and stabilizes the collective outcome.

Rationale summary (how this is collective and robust)
- Collective: the strategy willingly sacrifices one’s private token to sustain group welfare when others reciprocate; it aims to restore full contribution rather than maximize short-run self-payoff.
- Adaptive: it uses recent history (windowed average) and scales punishment length to the severity of defections; it tests for recovery and forgives, allowing cooperation to resume.
- Robust to exploiters: short, bounded punishments deter persistent free-riders without provoking permanent collapse; test rounds avoid lock-in to mutual defection.
- Endgame-aware: it defects in the last round (no future benefit), but it preserves cooperation in the penultimate round only when the group has reliably reciprocated, preventing opportunistic exploitation near the horizon.

Implementation notes (clear operational rules for a tournament agent)
- Maintain per-round history of all players’ contributions to compute p_hat and detect “near-full cooperation” (≥0.95).
- Use the simple mapping punish_counter = min(3, 1 + ceil((alpha − p_hat) * 3)) when triggering punishment; this makes punishments 1–3 rounds depending on how far cooperation fell below alpha.
- Always apply the one-round cooperative test after a punishment block, then reassess using the same window w.
- Follow the explicit first-round and endgame exceptions above.

This strategy balances signalling and generosity (start cooperating and forgive) with measured, temporary punishments to sustain cooperation across diverse opponent behaviors while being robust against exploitation and handling finite-horizon incentives.
'''

description_COLLECTIVE_67 = '''
Name: Collective Conditional Cooperator with Graduated Punishment & Forgiveness (C3-GPF)

Idea (one line): Signal willingness to cooperate, sustain cooperation as long as group behavior stays near full contribution, punish defections in a proportionate and limited way to discourage free-riding, and forgive/repair after punishment so cooperation can recover. Always defect in the final round.

Parameters (computed from game parameters r,n,k; fixed small tuning constants):
- Memory window m = min(5, max(1, floor(r/4))). (Short memory so the rule is responsive.)
- Target cooperation level T = 0.85 (expectation of near-full cooperation).
- Base punishment B = 2 rounds.
- Probe probability p_probe = 0.20 (small chance to test restoration).
- Minimal remaining-protection: never punish for the very last round (we always defect on round r).

Per-round decision algorithm (natural-language pseudocode):

Initialization:
- punishment_counter = 0
- escalation_level = 0
- last_probe_round = -infinity

On each round t = 1..r:
1. Endgame rule:
   - If t == r (final round): play D (defect). Stop.
   - If remaining rounds = r - t + 1 is small (<= 3), be conservative: only cooperate if the group has been flawless (everyone contributed) in all past rounds; otherwise prefer D. This reduces vulnerability as the horizon approaches.

2. If punishment_counter > 0:
   - Play D this round.
   - Decrement punishment_counter by 1.
   - Continue monitoring history while punishing (to decide whether to escalate when punishment ends).
   - After punishment_counter reaches 0, schedule a single cooperation probe on the next round (unless that round is the final round). Record that a probe was used.

3. Otherwise (not currently punishing):
   - Compute observed_group_rate = (total contributions by all players in the last m rounds) / (n * m). If fewer than m past rounds exist, use all available rounds.
   - Compute recent_defectors = count of distinct players who failed to contribute at least once in those m rounds (excluding trivial missing rounds if t is small).

   Decision rule:
   A. If observed_group_rate >= T:
      - Play C (cooperate). Rationale: group is close to full cooperation so continue to support it.
   B. Else (observed_group_rate < T):
      - If the shortfall is tiny and only 1 player has occasionally defected (recent_defectors == 1 and observed_group_rate >= T - 0.10):
         - Treat as likely mistake: play C this round (forgive single/rare mistakes) but set escalation_level = max(0, escalation_level - 1) to slowly reduce past escalations.
      - Otherwise (clear shortfall or multiple defectors):
         - Enter a punishment phase:
            * punishment_length = min(r - t, max(1, B * (1 + escalation_level)))
            * Set punishment_counter = punishment_length
            * Increment escalation_level by 1 (so repeated or unresolved misbehavior triggers longer punishment later)
            * Immediately play D this round (start punishing).
   - Note: if a cooperation probe was performed recently (last_probe_round within m rounds) and the probe succeeded (after the probe the observed_group_rate >= T in the subsequent m-round check), reset escalation_level = 0.

4. Probing and exploration:
   - Even while in a cooperative regime, with small probability p_probe (independent each round and only if not punishing and not in last 3 rounds) play C if you otherwise would have played D, or play D if you otherwise would have played C, to probe whether others will restore cooperation. If a probe leads to restored group cooperation (observed_group_rate >= T over next m rounds), favor returning to cooperation and reduce escalation_level.

5. Forgiveness and recovery:
   - After a punishment phase ends, perform exactly one cooperation probe (unless final round). If subsequent m-round observed_group_rate >= T, accept restoration: set escalation_level = 0 and resume stable cooperation. If restoration fails, re-enter punishment with a longer punishment_length (based on escalation_level).

6. Robustness notes / tie-breaking:
   - If there is ambiguity (exactly on threshold), prefer cooperation (lean toward sustaining cooperation unless evidence shows exploitation).
   - If r is very small (r <= 4) reduce B to 1 and make m = 1 so the strategy is less likely to waste rounds on punishment near the horizon.

Collective mindset and rationale (how the rules align with collective outcomes):
- The strategy begins by signaling willingness to cooperate and continues cooperating while most players reciprocate, which supports high group welfare when many are willing to contribute.
- Punishments are proportionate (short at first, escalate only if defection persists) to deter exploitation while avoiding catastrophic permanent breakdown from a single mistake.
- Forgiveness and explicit probes allow the group to repair cooperation after noise or one-off deviations — this increases long-run collective payoff compared with unforgiving triggers.
- By basing decisions on the observed group contribution rate (not on harsh single-player targeting, which is impossible in PGG), the strategy is transparent and robust against many opponent types.
- Endgame conservatism (defect in the final round and reduce cooperation near the horizon) protects individual payoff in the unavoidable finite-horizon last steps but otherwise preserves cooperation during most of the game.

Edge cases summary:
- First round: cooperate (signal).
- Final round: always defect.
- Very small r: shorten memory and punishments so strategy does not waste the small number of rounds on long punishments.
- Single, infrequent defections: forgive (maintain cooperation), to tolerate noise.
- Repeated or multiple-player defections: impose proportionate, increasing punishment, but always limited so cooperation can be regained.
- If a punishment succeeds (others return to cooperation), reset escalation and resume cooperation.

Implementation guidance (for tournament use):
- Use m and B as above; T = 0.85 and p_probe = 0.20 work well across many parameter sets, but small adjustments are acceptable. The design tradeoff intentionally favors sustaining high cooperation while preventing exploitation through clear, limited, and escalating retaliation plus forgiveness.
'''

description_COLLECTIVE_68 = '''
Collective Conditional Cooperator (CCC+) — a simple, adaptive, forgiving strategy that aims to sustain high group contributions while limiting exploitation. It uses only game parameters (n, r, k) and observed history (who contributed each round and payoffs). The strategy is organized into a small set of states (Normal, Punish, and Test) and a short memory window for recent behavior.

Parameters (computed before play)
- Memory window M = min(5, r). (Use the last M rounds for short-term assessment.)
- Group-cooperation threshold T = 0.60 (baseline). If you want to make T sensitive to the public-good multiplier, you may lower T slightly when k/n is larger (public benefit is greater), but keep at least 0.4 and at most 0.8.
- Individual forgiveness threshold F = 0.50 (a player is considered a “low cooperator” if their cooperation rate over the last M rounds < F).
- Base punishment length L0 = 2 rounds; maximum punishment length Lmax = min(6, r). Punishments escalate with the persistence of low cooperation but are bounded and finite.
- Final-round rule: special check described below.

State variables (maintained from history)
- Mode ∈ {Normal, Punish, Test}.
- PunishTimer: number of remaining rounds in Punish mode (0 when not punishing).
- For each other player j: recent cooperation rate CR_j = fraction of their contributions in last M rounds.
- Group recent cooperation rate GCR = average contribution rate of all other players over last M rounds (or last round weighted most strongly).

Initial condition
- Start in Mode = Normal. PunishTimer = 0.
- Cooperate in round 1.

Decision rules (what to play each round t)
1. Update CR_j and GCR using the last M rounds (or as many rounds as have occurred so far).
2. If PunishTimer > 0:
   - Play D (defect) this round.
   - Decrement PunishTimer by 1.
   - If PunishTimer becomes 0 at the end of the round, set Mode = Test for the next round.
   - Rationale: credible, finite punishment to signal that persistent low cooperation is unacceptable.
3. Else if Mode = Test:
   - Play C (cooperate) for one round as a reconciliation probe.
   - After the Test round:
     - If GCR (including the test round) is at or above T (or a strong recovery is observed), set Mode = Normal.
     - If significant defection persists (GCR < T and at least one player remains CR_j < F), re-enter Punish mode with PunishTimer = min(Lmax, L0 + escalation), where escalation = number of players with CR_j < F (capped).
   - Rationale: reward recovery immediately but re-punish if defectors persist.
4. Else (Mode = Normal):
   - If t = r (final round):
     - Play C only if (a) all other players cooperated in round t-1 OR (b) GCR over the last M rounds ≥ 0.90 (strong trust); otherwise play D.
     - Rationale: final-round cooperation is fragile; only cooperate if near-certainty that others will.
   - If t < r:
     - If GCR ≥ T: play C.
       - Rationale: the group is behaving cooperatively recently; continue to cooperate to maintain collective payoff.
     - Else (GCR < T): investigate whether poor group rate is due to a few persistent defectors or a group-wide collapse.
       - If at least one player j has CR_j < F (a persistent low cooperator) and that player defected in the most recent round: enter Punish mode with PunishTimer = min(Lmax, L0 + ceil((F − CR_j)*Lmax)). Play D this round (first punishment round).
         - Rationale: targeted, escalating but bounded punishment against persistent defectors to make defection costly.
       - Otherwise (no clear persistent defector): play D this round (withhold contribution) but stay in Normal; this is a defensive move to avoid being exploited while allowing quick restoration if cooperation returns.
5. After each round, recompute CR_j and GCR and adjust Mode/PunishTimer as above.

Escalation and forgiveness summary
- Punishment is limited in length (bounded by Lmax) so mistakes or transient noise do not collapse cooperation permanently.
- Punishment is targeted: it is triggered by persistent low individual cooperation (CR_j < F) and recent defection, not by a single accidental defection.
- After punishment, a Test round immediately offers reconciliation: if the group recovers, we return to Normal cooperation. If defection persists, punish again with controlled escalation.
- If many players defect simultaneously (group collapse), the strategy defects until GCR rises above T or a Test round shows recovery. This protects the strategy from being repeatedly exploited.

Edge cases and special notes
- First round: cooperate (signal cooperative intent).
- Last round: default to defect unless the history shows near-perfect cooperation (all cooperated last round or very high GCR ≥ 0.90). This reduces vulnerability to end-game exploitation but still allows final-round cooperation when trust is strong.
- Very short games (r ≤ M): memory windows shrink automatically; punishments are still bounded by remaining rounds.
- No communication/no signaling required: decisions rely only on observed contributions and payoffs.
- Robustness to noise: the use of an M-round window, forgiveness threshold F, and finite punishments protects against misclassification from isolated erroneous moves.
- Collective orientation: the strategy always prefers to cooperate when the recent group pattern shows reasonable cooperation, and only withholds contributions to defend the collective from persistent free-riders. The test-and-forgive structure prioritizes restoring full-group cooperation rather than perpetual retaliation.

High-level intuition
- Be cooperative when the group proves cooperative recently.
- If only a few players persistently free-ride, impose limited and escalating punishments targeted at making defection costly; then offer reconciliation.
- If cooperation collapses across the group, defend (stop contributing) until cooperation is convincingly restored.
- In the last round, default to defection unless near-certain cooperation will be reciprocated.

This strategy balances collective welfare (seek and sustain high group contributions) with protection against exploitation (targeted, finite punishment and prompt forgiveness). It is simple, adaptive, and depends only on n, r, k (through parameter choices) and the public history of plays and payoffs.
'''

description_COLLECTIVE_69 = '''
Name: Proportional Reciprocity with Short Punishment and Periodic Probing (PR-SPP)

Goal (collective mindset): Try to maximize group cooperation and the group return while protecting myself from sustained exploitation. Start by signalling cooperation, reward and maintain cooperation when a clear majority reciprocates, punish deviations quickly but not forever, and forgive when others restore cooperation. Be cautious in the final round.

Parameters I set from the game inputs (n, r, k):
- Majority threshold M = ceil(n/2).
- Short punishment length P = min(3, max(1, ceil(r/10))). (A short, finite punishment that scales mildly with horizon.)
- Probation length Q = 1 (one cooperative round to test recovery).
- Safe-mode probe interval T_test = max(3, ceil(r/5)) (when cooperation has broken down I probe occasionally to see if others will resume).

State variables I keep from history:
- contributions_history (per round, total contributions and who contributed).
- current_mode ∈ {Cooperate-Mode, Punish-Mode, Probation, Safe-Mode}
- punish_rounds_remaining (when in Punish-Mode)
- rounds_since_last_probe (when in Safe-Mode)

Summary decision rules (what I play each round)
1. First round:
   - Play C (contribute 1). I start by signalling willingness to cooperate.

2. Last round (round r):
   - Play D (defect). In the final round there is no future to enforce reciprocity, so I defect to protect my own payoff.

3. Every non-final round t > 1: update my mode and decide as follows.

Mode logic and transitions

A. Cooperate-Mode (normal cooperative stance)
- Intended behavior: contribute each round as long as group cooperation remains reasonably strong.
- On round t (t < r):
  - Let contributions_prev = total contributors in round t-1 (including me).
  - If contributions_prev ≥ M (majority cooperated last round): play C and remain in Cooperate-Mode.
  - If contributions_prev == n (unanimous): play C and remain in Cooperate-Mode.
  - If contributions_prev == n - 1 (exactly one defector last round): start punishment:
      - Set punish_rounds_remaining = min(P, r - t) and switch to Punish-Mode. Play D this round (begin punishment immediately).
  - If contributions_prev < M (less than majority cooperated): switch to Safe-Mode immediately and play D this round.

Rationale: reward majority cooperation; tolerate small (one-person) mistakes only briefly by punishing immediately but not forever; if cooperation falls below a majority, give up on maintaining full cooperation and move to safe probing.

B. Punish-Mode (short, proportional retaliation)
- Intended behavior: signal that defection has a cost but avoid permanent exclusion.
- While punish_rounds_remaining > 0 and t < r:
  - Play D.
  - Decrement punish_rounds_remaining at the end of the round.
- When punish_rounds_remaining becomes 0:
  - Switch to Probation mode.

Rationale: immediate, short, visible cost to free-riding that others can observe; punishment length is short so cooperation can be restored.

C. Probation (one cooperative test round)
- Intended behavior: offer a brief, low-cost chance to return to cooperation.
- On the probation round (Q = 1):
  - Play C.
  - Observe group response in that probation round:
    - If contributions in that probation round ≥ M, switch back to Cooperate-Mode.
    - Otherwise (group fails to respond with majority cooperation), switch to Safe-Mode.

Rationale: allow re-establishment of cooperation quickly if others reciprocate; avoid staying stuck in cycles of punishment.

D. Safe-Mode (defensive stance with periodic probes)
- Intended behavior: assume cooperation has broken down; avoid being exploited while probing to discover if others will return to cooperation.
- In Safe-Mode most rounds I play D.
- I also keep rounds_since_last_probe (reset to 0 upon entering Safe-Mode or after a probe).
- If rounds_since_last_probe ≥ T_test and there remain at least 2 rounds before the end, perform a probe:
  - On a probe round: play C (one cooperative test).
  - If the probe round elicits contributions ≥ M, switch to Cooperate-Mode on the next round.
  - Otherwise, remain in Safe-Mode and reset rounds_since_last_probe = 0.
- If the number of rounds remaining is small so that a probe is unlikely to lead to sustained cooperation (e.g., only one round left), remain D.

Rationale: when many players are defecting, it is costly to continue trying to restore cooperation. Periodic probing gives opportunities to re-establish cooperation without being repeatedly exploited.

Additional adaptive details and edge cases
- If the same individual players defect persistently (tracked over multiple rounds), I treat them as likely permanent free-riders and will not count their one-off returns as sufficient to re-enter Cooperate-Mode unless the aggregate cooperation excluding the persistent defectors reaches at least M. (I devalue targets who show consistent defection.)
- If multiple players defect in the same round but their defections look like a one-off (isolated), my short punishment policy (Punish-Mode) will still activate for one punishment window and then test recovery; this avoids exploding retaliatory loops.
- Punishment severity is proportional to time horizon: P scales mildly with r (via the P formula). If few rounds remain, punishments are short or skipped so I avoid wasting remaining exploitation gains.
- If the tournament context suggests opponents may use long unforgiving grim triggers, my short, forgiving punishments help reconvene cooperation more often and avoid long mutual-defection traps.
- If I ever detect consistent full cooperation by almost all players for many rounds (sustained unanimity), I keep cooperating until the final round (when I defect).

Why this is robust
- Begins cooperatively so it can capture gains from reciprocators and conditional cooperators.
- Uses clear, visible, short punishments so defectors pay an immediate cost (discourages pure unconditional defectors).
- Punishment is finite and followed by probation; this avoids permanent collapse of cooperation after single deviations and prevents cycles of endless retaliation.
- Safe-Mode plus periodic probing prevents persistent exploiters from bleeding me repeatedly while still allowing re-entry to cooperative play if the group reconstitutes.
- Last-round defection protects my individual payoff when there is no future enforcement.

Concrete short pseudocode (natural-language form)
- Round 1: play C.
- If t == r: play D.
- Else:
  - If current_mode == Cooperate-Mode:
      - If contributors in previous round ≥ M then play C.
      - Else if contributors_prev == n - 1 then set punish_rounds_remaining = min(P, r - t); switch to Punish-Mode and play D.
      - Else (contributors_prev < M) switch to Safe-Mode and play D.
  - If current_mode == Punish-Mode:
      - Play D; punish_rounds_remaining -= 1; if punish_rounds_remaining == 0 switch to Probation.
  - If current_mode == Probation:
      - Play C (one round); if contributors that probation round ≥ M switch to Cooperate-Mode else switch to Safe-Mode.
  - If current_mode == Safe-Mode:
      - If a probe is due (rounds_since_last_probe ≥ T_test and at least 2 rounds remain): play C (probe); if probe elicits contributors ≥ M switch to Cooperate-Mode else reset probe counter and play D next rounds.
      - Otherwise play D and increment rounds_since_last_probe.

This strategy depends only on n, r, k (through the chosen parameter formulas) and the full history of observed contributions, and it balances collective aspiration and individual protection: it rewards majority cooperation, punishes deviations promptly and proportionally, forgives to restore cooperation, and protects against long-term exploitation.
'''

description_COLLECTIVE_70 = '''
Name: Proportional Collective Reciprocity (PCR)

Summary goal
- Encourage and sustain high collective contributions while deterring persistent free‑riding.
- Start cooperatively, punish in a measured and temporary way when players persistently defect, and forgive quickly when cooperation returns. Be cautious near the end of the game to avoid being exploited in the inevitable end‑game region.

Definitions and internal bookkeeping (derived only from parameters and observed history)
- r = total rounds, t = current round (1..r).
- W = min(5, r) — lookback window for recent behavior (use all past rounds when t < W).
- Endgame window L_end = max(1, ceil(r/10)) — final rounds when we become more cautious.
- For each player j, define recent cooperation rate s_j = fraction of rounds they contributed among the last W rounds.
- s_avg = average of s_j across all players.
- s_min = minimum of s_j across players.
- Persistent defector: any player j with s_j ≤ 0.4 (less than or equal to 40% cooperation in the lookback window).
- Occasional lapse: a single defection by a historically cooperative player (s_j > 0.6) is treated as an error, not as persistence.

Initial round
- Round 1: Cooperate (contribute 1). Begin by offering cooperation to establish a cooperative baseline.

Per‑round decision rule (for t = 2..r)
1. If currently in a punishment phase (see "Punishment mechanics" below), continue the punishment until its scheduled end unless forgiveness condition triggers an early end (see item 4 below).

2. Endgame caution: if t > r - L_end (we are inside the last L_end rounds)
   - Cooperate only if both of these are true:
     a) s_avg ≥ 0.75 (recent group cooperation is very strong), and
     b) everyone contributed in the immediately preceding round.
   - Otherwise, defect for this round. (Rationale: reduce exploitability in the endgame but still allow cooperation when the group is demonstrably reliable.)

3. Normal-phase cooperation rule (non‑endgame and not in active punishment)
   - If s_min ≥ 0.7 (everyone has been cooperative recently), cooperate.
   - Else if s_avg ≥ 0.6 and fewer than two players contributed 0 in the previous round, cooperate. (This gives the group the benefit of the doubt when most are cooperating and lapses are rare.)
   - Otherwise, treat the situation as requiring sanction and initiate a proportional punishment (see next).

4. Forgiveness and recovery
   - After a punishment phase ends, do not remain rigidly defecting. Monitor s_avg over the next two rounds:
     - If s_avg ≥ 0.6 for two consecutive rounds, return to Normal-phase cooperation.
     - If cooperation does not recover, escalate or repeat punishment according to the Punishment mechanics.

Punishment mechanics (how we respond to persistent defectors)
- When the Normal‑phase rule decides to sanction (s_min < 0.7 and s_avg < 0.6 or recent concentrated defections), identify the most persistent defector(s): those with the lowest s_j.
- Compute severity factor for punishment:
  - severity = clamp((0.5 - s_min) / 0.5, 0, 1). (If s_min = 0.5 → severity 0; if s_min = 0 → severity 1.)
- Punishment length P = min( max(1, ceil(2 + 4 * severity)), remaining rounds ). This yields 2–6 rounds of punishment scaled by how bad s_min is, but never longer than the remaining game.
- During a punishment phase, defect unconditionally for P rounds (we cannot target individual players, so punishment necessarily affects the whole group). The goal is to make defection costly enough that persistent free‑riding becomes unattractive.
- If, during a punishment phase, the cooperation record suddenly improves (s_avg ≥ 0.65 and no player has contributed 0 in two consecutive rounds), end the punishment early and switch to the Forgiveness rule.

Notes on borderline situations and robustness
- Occasional lapses: Single or rare defections by otherwise cooperative players are treated with leniency (the Normal‑phase thresholds allow cooperation to continue unless defections are persistent).
- Aggressive exploiters: Players who consistently defect will drive s_min down, raising severity and length of punishment so that exploitation becomes costly to the entire group; this discourages persistent free‑riding.
- Random or noisy opponents: The lookback window W and the forgiving thresholds (s_avg ≥ 0.6, s_min ≥ 0.7 tolerance) make the strategy robust to stochastic or noisy behavior while still detecting patterns of exploitation.
- Endgame behavior: By tightening cooperation requirements in the last L_end rounds, the strategy reduces exposure to pure last‑round exploitation while still cooperating if the group has been reliably cooperative.

Collective mindset justification
- The strategy always starts by offering cooperation and returns to cooperation quickly when the group demonstrates cooperative behavior, thereby prioritizing collective welfare.
- Punishments are proportional, temporary, and scaled to the severity of persistent deviation; they are intended to protect the group’s future cooperation rather than to maximize short‑term gain by spiteful defection.
- Forgiveness and recovery rules minimize needless loss from one‑off deviations and permit restoration of high collective contributions when players respond positively.

Implementation summary (pseudocode style, in words)
- Keep W, L_end, s_j, s_avg, s_min updated each round.
- If in a punishment phase: defect until its scheduled end or until the recovery condition appears.
- Else if in endgame (last L_end rounds): cooperate only if s_avg ≥ 0.75 and last round was unanimous cooperation; else defect.
- Else (normal): cooperate when s_min ≥ 0.7 OR (s_avg ≥ 0.6 and few recent lapses); otherwise initiate a proportional punishment of length P determined by s_min.
- After punishment, watch for recovery (two rounds with s_avg ≥ 0.6) and then resume cooperation.

This strategy is fully defined by the game parameters (r used to set W and L_end) and the public history of contributions; it is adaptive, deters persistent free‑riding by graded sanctions, forgives recoveries, and biases toward collective welfare.
'''

description_COLLECTIVE_71 = '''
Name: Adaptive Majority with Limited Punishment (collective-first, forgiving reciprocity)

Overview (collective mindset)
- Start by signaling cooperation and try to sustain collective contributions when a clear majority of the group is cooperating.
- When free-riding appears, impose a short, predictable penalty to deter further exploitation, but forgive quickly so cooperation can be restored.
- Avoid long, costly vendettas and avoid being exploited persistently; retreat to defection if cooperation collapses.
- Defect in the final round (to avoid giving away tokens with no future benefit).

Parameters derived from game size (set once from n, k, r)
- M_frac = 0.60 (majority threshold fraction). Use it to form an integer threshold for the number of other players who must have contributed in the previous round.
- M_others = max(1, ceil(M_frac * (n-1))) — required number of other players who contributed last round to continue cooperating.
- P = 2 (punishment length in rounds). When triggered, defect for up to P rounds (but never longer than remaining rounds minus 1).
- L = min(5, r) (window for collapse detection).
- Collapse_frac = 0.20 (if average contribution rate among others over last L rounds falls below this, give up and defect for remaining rounds).

Decision rules (use only public history and game parameters)
- First round:
  - Cooperate (contribute 1) to signal willingness to build the public good.

- Every subsequent round t (1-indexed), let rem = number of rounds remaining including this one.
  - If rem == 1 (this is the final round): Defect (contribute 0).
  - If currently in an active punishment phase (you are still fulfilling a previously set P-round punishment):
    - Defect this round. Decrement remaining punishment counter.
  - Else (not in a punishment phase):
    - Observe contributions in the immediately preceding round. Count others' contributions (exclude your own prior action).
    - If number_of_other_contributors_last_round >= M_others:
      - Cooperate this round (contribute 1).
    - Otherwise (fewer than M_others others cooperated last round):
      - Enter a punishment phase: set punishment counter = min(P, rem - 1) and Defect this round.
      - (Punishment is short and predictable so others can learn the link between their defection and the temporary penalty.)

- Collapse protection (override):
  - At the start of each round, compute the average number of other players who contributed per round over the last L rounds (or over all past rounds if fewer than L have occurred).
  - If that average < Collapse_frac * (n-1), assume cooperation has effectively collapsed; from that point forward defect in all remaining rounds (no further punishments), because continued cooperation is unlikely and persistent exploitation is costly.

Notes on robustness and rationale
- Cooperating on round 1 signals intent to cooperate and can elicit collective cooperation from conditional cooperators.
- Requiring a substantial fraction of others to have cooperated last round (M_frac = 0.60) focuses on collective behavior rather than punishing a single outlier—this reduces oscillations and punishes only when cooperation meaningfully breaks down.
- Short, fixed punishments (P = 2) deter freeloading while permitting rapid restoration of cooperation; this reduces the cost of mistaken punishment from noise or accidental deviation.
- The collapse detector prevents continued losses in situations where the population is mostly defecting; it is conservative (requires persistently low cooperation) before giving up.
- Defecting in the last round avoids one-shot losses when no future incentive exists.
- All choices (threshold, punishment length, windows) are simple functions of n and r and use only observed actions, so the strategy is transparent, predictable, and implementable without communication.

Edge cases
- Small n (n = 2): M_others = 1 so cooperation continues only if the single other cooperated last round (behaves like reciprocal cooperation).
- Very short games (r small): punishment length is capped by remaining rounds minus one so you do not punish in the final round.
- Noisy errors by others: forgiveness and short punishments allow recovery after accidental defections.
- Mixed populations: against many conditional cooperators this strategy sustains high cooperation; against persistent defectors it limits losses by switching to defection after collapse.

Summary pseudocode (compact)
- Initialize: punishment_counter = 0.
- Round 1: contribute.
- Each round t:
  - rem = rounds remaining including this one.
  - If rem == 1: defect.
  - Else if collapse detected over last L rounds (average other contributions < Collapse_frac*(n-1)): defect forever.
  - Else if punishment_counter > 0: defect; punishment_counter -= 1.
  - Else if number_of_other_contributors_last_round >= M_others: cooperate.
  - Else: set punishment_counter = min(P, rem-1); defect (start punishment).

This strategy explicitly favors group welfare, deters exploitation with short, credible penalties, forgives to restore cooperation, and adapts to persistent defection by switching to safe defection if cooperation truly collapses.
'''

description_COLLECTIVE_72 = '''
Collective Conditional Cooperator with Graduated Proportional Punishment (CCC‑GPP)

Principles
- I prioritize sustaining high group payoffs (collective cooperation) but avoid being chronically exploited.
- I signal cooperation early, punish defections in a proportionate and temporary way, and forgive to restore cooperation quickly.
- All decisions use only game parameters (n, k, r) and observed history of actions/payoffs.

Derived parameters (computed once from the game parameters)
- window w = min(5, max(1, floor(r/10))) — use recent w rounds to smooth noise.
- cooperation threshold theta = clamp( (n - k + 1) / n , 0.5, 1.0 ).
  - Intuition: when the public good is weak (k small) require stronger recent cooperation to justify contributing; when k is large require only a simple majority.
- minor-lapse margin m = 0.20 (forgiving tolerance).
- base punishment scale S = 3 (used to convert shortfall into a small integer punishment length).
- probation length prob = min(2, max(1, floor(r/20))) — short cooperative probation after a punishment ends.
- Endgame rule: in the final round (round r) I defect (no future to enforce cooperation).

State I maintain (derived from history)
- recent cooperation fraction f_recent = average fraction of players who contributed per round, averaged over the last w completed rounds (if fewer than w rounds have been played, average over what exists).
- active punishment counter P (number of remaining rounds I will defect as punishment; P = 0 when not punishing).
- last punishment length L_prev (to allow escalation if repeated offenses occur).

Decision rules (evaluated each round t, using only parameters and history)
1. First round (t = 1)
   - Cooperate (contribute 1). Signal collective intent.

2. Final round (t = r)
   - Defect (do not contribute). No future enforcement possible.

3. If an active punishment is in effect (P > 0)
   - Defect this round and decrement P by 1.
   - When P reaches 0, enter probation state (see rule 6).

4. Otherwise (no active punishment)
   - Compute f_recent over the past w rounds (fraction of players contributing, averaged over rounds).
   - If f_recent >= theta:
       - Cooperate (we are in a healthy cooperative environment; support it).
   - Else if f_recent >= theta - m:
       - Cooperate (treat as a minor lapse; be forgiving to re‑establish cooperation).
   - Else (significant shortfall: f_recent < theta - m):
       - Start a proportional punishment:
         - Calculate shortfall s = max(0, theta - f_recent).
         - Set punishment length p = min( remaining rounds - 1, max(1, ceil(s * S)) ).
           - (Cap to remaining rounds minus one so we do not accidentally punish through the final round.)
         - Set P := p and L_prev := p.
         - Defect this round (begin punishment).

5. Escalation on repeated offenses
   - If after completing a punishment (P reached 0) cooperation does not resume (f_recent remains below theta - m) in subsequent rounds, escalate by doubling the next punishment length: p_next = min(remaining rounds - 1, 2 * L_prev). Apply same caps. This prevents tiny punishments being repeatedly exploited.
   - Escalation is bounded: never set a punishment longer than remaining rounds - 1 and never escalate in the final round.

6. Probation and forgiveness after punishment
   - After P reaches 0, I will cooperate for prob rounds (probation) unless a subsequent round’s f_recent immediately drops below theta - m.
   - If probation ends with f_recent >= theta - m, resume normal cooperation rules.
   - If a new shortfall occurs during probation (f_recent < theta - m), start punishment again (with escalation if the previous punishment was recent).

7. Miscellaneous safeguards
   - If only one round remains (t = r - 1), be cautious: if the group has been cooperating reliably (f_recent >= theta), I will cooperate in round r-1 to preserve cooperation; otherwise defect to avoid last‑round exploitation.
   - Never allow P to force me to cooperate in the final round — punishments are implemented only by defecting.

Why this is collective and robust
- Starts by signaling cooperative intent so other conditional cooperators can coordinate on high collective payoffs.
- Uses a threshold that depends on the production multiplier k and population n so cooperation is required only when it is plausibly beneficial.
- Smooths noise by using a short window; forgives small lapses to avoid persistent breakdown from accidents.
- Punishes proportionally to the severity of defection, deterring exploitation without permanently ending cooperation (avoids the brittleness of one‑shot grim triggers).
- Escalates only when small punishments fail, which prevents repeated exploitation.
- Defects in the final round (standard finite-horizon rationality) to avoid being systematically exploited at the end.

Summary pseudocode (compact)
- If t == 1: cooperate.
- Else if t == r: defect.
- Else update f_recent over last w rounds.
- If P > 0: defect; P := P - 1; if P == 0 then set probation counter = prob.
- Else if f_recent >= theta: cooperate.
- Else if f_recent >= theta - m: cooperate (forgive).
- Else: set p = min(remaining rounds - 1, max(1, ceil((theta - f_recent) * S))); P := p; L_prev := p; defect.
- After a punishment ends, cooperate for prob rounds unless f_recent immediately falls below theta - m; if it does, set next punishment length = min(remaining rounds - 1, max(1, 2 * L_prev)) and begin punishment.

This strategy balances collective interest (actively sustaining cooperation), adaptiveness (reacts to real behavior levels), and robustness (forgiveness, proportional punishment, bounded escalation, and endgame caution).
'''

description_COLLECTIVE_73 = '''
Name: Proportional Forgiving Conditional Cooperator (PFCC)

Overview goal
- Promote and sustain full (or near-full) collective contribution for as long as it is feasible, but avoid being exploited by persistent defectors. Start by signaling cooperation, punish defections proportionally and briefly, then forgive to restore cooperation. Defect in the final round (no future to enforce cooperation).

State and parameters (derived from game parameters n, r)
- permitted_defections = max(0, floor(0.10 * n))
  (allows small deviations in large groups; if n is small this is 0)
- punishment_counter = 0 (counts remaining punishment rounds)
- At any time t, remaining_rounds = r - t + 1 (including current)
- Treat last round specially (no cooperation incentive)

Decision rules (per round t, using full history of actions)
1. If t == r (final round): choose D (defect). End.
2. If punishment_counter > 0:
   - Choose D this round.
   - Decrement punishment_counter by 1.
   - Continue to next round.
3. Otherwise (punishment_counter == 0):
   a. If t == 1 (first round): choose C (cooperate) to signal willingness to support collective welfare.
   b. Else (t > 1):
      - Let C_last = total contributions (sum_j c_j) observed in previous round (round t-1).
      - If C_last >= n - permitted_defections:
         * Treat the group as (mostly) cooperative → choose C (cooperate) this round.
      - Else (the previous round contained too many defections):
         * Compute defections_last = n - C_last.
         * Set punishment_length = min(remaining_rounds - 1, 1 + defections_last).
           - (This punishes proportionally to number of defectors but never uses the final round as part of a punishment.)
         * Set punishment_counter = punishment_length.
         * Choose D this round (start punishment).
4. When punishment_counter reaches 0 after a punishment episode:
   - Return to rule 3 (forgiving reset): give cooperation another chance (choose C next round unless the final round is reached).

Additional adaptive refinements (built into the same rules)
- If the same pattern of repeated mass-defection appears (many rounds with C_last < n - permitted_defections), PFCC will keep applying proportional punishments each time; punishments are finite and do not entrench permanent defection.
- If defections are isolated or rare (e.g., one defector once), punishment is short (1 + number of defectors rounds) and the strategy quickly returns to cooperation — this tolerates mistakes and rewards recovery of cooperation.
- All computations use only observed past actions (and implicit payoffs); no communication or signaling is assumed.

Rationale / collective alignment
- First-round cooperation signals a willingness to build mutual benefit.
- The permitted_defections allowance prevents overreaction to one-off deviations in large groups (for robustness).
- Punishment is proportional to the observed severity of defection (number of defectors) so outsiders cannot cheaply exploit us indefinitely — the cost of exploiting is increased while the punishment is short enough to allow reestablishing cooperation.
- Forgiveness after finite punishment restores collective outcomes rather than locking the group into permanent mutual defection.
- Defecting in the final round is necessary because no future rounds remain to enforce cooperation; preserving resources in earlier rounds is prioritized to maximize total group welfare.

Summary (short pseudocode-style)
- Initialize permitted_defections = floor(0.10*n), punishment_counter = 0.
- For each round t:
  - If t == r: play D.
  - Else if punishment_counter > 0: play D; punishment_counter -= 1.
  - Else if t == 1: play C.
  - Else if C_last >= n - permitted_defections: play C.
  - Else:
    - punishment_counter = min(r - t, 1 + (n - C_last));
    - play D.

This strategy is adaptive (responds to history), robust (proportional punishment and forgiveness, tolerance for small deviations), and collective (starts cooperatively and aims to restore cooperation rather than permanently defect).
'''

description_COLLECTIVE_74 = '''
Name: Collective Conditional Cooperator with Forgiving Graduated Punishments (CCC‑FGP)

Goal (collective mindset)
- Maximize total group contributions over the repeated game by sustaining mutual cooperation when other players reciprocate, and by minimizing exploitation when free‑riding is detected. The strategy prioritizes restoring cooperation quickly after lapses rather than permanent retaliation.

Parameters derived from game inputs (n, r, k)
- Window W for short‑term history: W = min(10, max(1, floor(r/5))). (Use the last W rounds to estimate recent behavior.)
- High cooperation threshold THIGH = 0.8 (strong evidence of cooperation).
- Low cooperation threshold TLOW = 0.5 (evidence of many defectors).
- Persistent defector threshold PDEF = 0.2 (a player whose cooperation rate ≤ PDEF over W is considered persistent defector).
- Punishment length L = min(3, max(1, floor(r/10), floor(remaining_rounds/4))). (Short, finite punishments that scale down near the end.)
- Endgame rounds: always defect in the final round; apply shorter punishments as rounds remain small.

Per‑round decision rules (uses only n, r, k and observed history)
- Notation: for round t, “remaining_rounds” = r − t + 1 (includes current). For each other player j compute coop_rate_j = (# times j contributed in last W rounds) / min(W, t−1). If t==1, coop_rate undefined (use defaults below). Define group_coop_rate = average of coop_rate_j over all j ≠ me (treat undefined as 0.5 for first round when necessary).

1) First round (t = 1)
- Contribute. (Signal willingness to cooperate. Collective payoff maximization requires seeding cooperation.)

2) Final round (t = r)
- Defect. (No future to enforce cooperation; avoid being the lone contributor.)

3) General case (1 < t < r)
- Update recent history over last W rounds; compute each other player j’s coop_rate_j and group_coop_rate.

- If group_coop_rate ≥ THIGH:
  - Contribute. (Group reliably cooperates; sustain full cooperation.)

- Else if group_coop_rate < TLOW:
  - Enter punishment mode:
    - Defect for the next P = min(L, remaining_rounds − 1) rounds (never punish into the final round — preserve the final round rule).
    - During punishment mode, monitor whether group_coop_rate over a sliding W window rises back above THIGH. If it does, immediately stop punishment and resume cooperation next round.
    - After completing P rounds of punishment without recovery, attempt a one‑round cooperative test: contribute in the next round to probe whether others will return to cooperation. If the test is reciprocated by a majority of players in the following round, resume cooperation; otherwise resume a short punishment cycle (same rules).

- Else (TLOW ≤ group_coop_rate < THIGH):
  - Mixed regime (gradual cooperation / encouragement):
    - If a majority of players (≥ ceil(n/2)) contributed in the last round, contribute now.
    - Otherwise, defect this round but do not enter a long punishment cycle — instead use a short “probing” behavior:
      - Defect this round; in the following round attempt to contribute if the short‑term (last W rounds) group_coop_rate increases or if at least half the group cooperated in the round immediately after the defection.
    - This regime treats small lapses as noise and responds with fast correction rather than harsh punishment.

4) Handling persistent individual defectors
- If one or a few players have coop_rate_j ≤ PDEF persistently:
  - Do not attempt to “punish” them forever because multi‑player punishment is hard to target; instead reduce reliance on their cooperation:
    - Be less willing to re‑establish full cooperation after a group lapse (require group_coop_rate to reach THIGH before returning to unconditional cooperation).
    - Continue finite punishments when the group as a whole drops below TLOW, but prefer restoring cooperation quickly to maximize total group payoff.

5) Near‑end adjustments
- When remaining_rounds is small (e.g., ≤ max(2, floor(r/10))):
  - Shorten punishment lengths L further (as above).
  - Be more conservative about re‑establishing cooperation; require clearer signals (group_coop_rate closer to THIGH) because there is less future to reward cooperation.
  - Always defect on the final round.

Rationale and robustness notes
- Starts cooperative to try to achieve the socially efficient outcome.
- Uses group‑level statistics (average cooperation rates) rather than trying to coordinate or single out individuals — robust when many opponents are arbitrary AIs.
- Punishments are finite, limited and forgiving so that occasional mistakes or exploration do not collapse cooperation permanently.
- Uses a mixed regime that treats small lapses as noise (fast recovery) and widespread defection as a signal that refusal to cooperate is profitable (short punishments and fallback to defection until sufficient evidence of reciprocity returns).
- Final‑round defection avoids being exploited when there is no future enforcement; shortening punishments near the end prevents wasting the remaining rounds on cycles of retaliation.
- Parameters (W, THIGH, TLOW, PDEF, L) are explicit and scale with r to adapt to short and long games; they can be computed from n and r alone and require no assumptions about others’ internal strategies.

Summary pseudocode (informal)
- If t==1: C
- Else if t==r: D
- Else compute coop rates over last W rounds and group_coop_rate
  - If group_coop_rate ≥ 0.8: C
  - Else if group_coop_rate < 0.5: defect for up to L rounds or until group_coop_rate ≥ 0.8; after L rounds do a one‑round cooperative probe and accept or resume punishment based on response
  - Else (0.5 ≤ group_coop_rate < 0.8): if majority cooperated last round → C; else D but try to recontribute quickly if short‑term signals improve
- Treat players with coop_rate ≤ 0.2 as persistent defectors; require stronger group evidence before unconditional cooperation returns

This strategy emphasizes collective welfare by favoring cooperation when the group shows it can reciprocate, punishing only briefly and forgiving quickly to restore high collective contributions. It is adaptive, parameterized by r and n, and designed to be robust to a wide range of opponent behaviors.
'''

description_COLLECTIVE_75 = '''
Collective-minded conditional-cooperation with short proportional punishment and forgiveness

Principles (how this strategy thinks)
- Aim to sustain group cooperation when it is practicable (k > 1 makes full cooperation socially valuable).
- Be generous early and forgiving of occasional mistakes so cooperation can form.
- Punish quickly, briefly and proportionally when group cooperation collapses so free-riding is discouraged without destroying future possibilities.
- Adapt punishment severity and tolerance to game parameters (n, k, r) and to observed behavior (history).

Parameters computed at start (all determined from n, k, r)
- Memory window M = min(5, r-1) (use up to the five most recent rounds to assess behavior).
- Tolerance threshold tau = clamp(0.5 - 0.3*(k-1)/(n-1), lower=0.10, upper=0.90).
  - Intuition: higher k (larger social return) => lower tau (we tolerate more unilateral defection to keep cooperation going).
- Maximum short punishment length Pmax = min(4, max(1, floor(r/10)+1)).
  - Keeps punishments short relative to game length.
- Long-term collapse threshold L = 0.60 (used to decide if cooperation is hopeless).

State variables (maintained from history)
- punishment_counter (initially 0): rounds left to carry out an active punishment.
- punishment_severity (initially 1): increases modestly if repeated violations occur, capped by Pmax.
- cooperate_test_pending (boolean): after a punishment, we will try one cooperative test round.

Decision rules (each round t, before choosing)
1. Trivial edge cases
   - If r == 1: defect (no future to enforce cooperation).
   - If t == r (last round): defect (no future enforcement possible).
   - If t == 1 and r > 1: cooperate (seed cooperation).

2. If punishment_counter > 0:
   - Play D (defect). Decrement punishment_counter by 1.
   - After punishment_counter reaches 0, set cooperate_test_pending = true and prepare to test cooperation next round.

3. Else if cooperate_test_pending is true:
   - Play C (cooperate) once as a reconciliation/test move.
   - Set cooperate_test_pending = false.
   - Observe others; the next round action will follow normal evaluation.

4. Otherwise (normal evaluation)
   - Compute f = average fraction of other players who contributed in the last M rounds:
       f = (sum over last M rounds of contributions by players other than me) / ((n-1) * M)
   - If long-run collapse condition holds:
       - If over all past rounds at least L fraction of players (counting players who almost never cooperated) have contributed in <= 10% of their opportunities, then cooperation is probably hopeless:
           - Switch to permanent defection for the remainder of the game (except continue occasional one-round cooperation tests every ceil(r/5) rounds to check if things changed).
   - Else decide:
       - If f >= tau:
           - Play C (cooperate). Rationale: a sufficient fraction of others are cooperating — keep cooperation to maximize collective payoff.
       - If f < tau:
           - Trigger a punishment:
             - Compute severity-adjusted punishment length P = min(Pmax, 1 + ceil((tau - f) * 4) + punishment_severity - 1).
               - (Bigger shortfalls below tau produce slightly longer punishments; repeated triggers increase punishment_severity up to Pmax.)
             - Set punishment_counter = P and play D this round.
             - Increase punishment_severity = min(Pmax, punishment_severity + 1).
             - After the punishment ends the strategy will issue a cooperative test round (see step 2).

Additional robustness rules and clarifications
- Forgiveness for single mistakes: If a single round shows an isolated dip in cooperation but f averaged over M stays near tau, punishment will be small or avoided because f will not drop far below tau.
- Proportionality: Punishments are short and scale with the magnitude of deviation; this avoids endless mutual defection that destroys group welfare.
- Reconciliation: After each punishment the strategy tries C once to signal willingness to return to cooperation; if others reciprocate cooperation frequency rises and we cooperate thereafter.
- Persistent defectors handling: If many players never cooperate (long-run collapse condition), the strategy pragmatically switches to defect to avoid subsidizing free-riders, while still sporadically testing for recovery.
- No reliance on coordination or communication: decisions use only observed actions and payoffs; no promises or external enforcement assumed.

Summary slogan (how this plays)
- Start cooperative, keep cooperating if most others reciprocate (threshold adapts with k), punish brief and proportional when cooperation drops, forgive and test to restore cooperation, and abandon sustained cooperation only if the group clearly collapses.
'''

description_COLLECTIVE_76 = '''
Name: Collective Conditional Cooperator (CCC)

Intuition (collective mindset)
- My baseline objective is to sustain high group payoff by encouraging and maintaining mutual contribution whenever it appears feasible, while protecting myself from persistent exploiters. I start by signaling cooperation, prefer group cooperation when others reciprocate, apply short, targeted punishments to restore cooperation, and forgive so cooperation can recover. In the known endgame I become more cautious to avoid being exploited in the final rounds.

Parameters (computed from game inputs)
- m (memory window) = min(5, r−1). I evaluate behavior over the last m rounds (or all past rounds if fewer).
- Trust threshold T = 0.5 + 0.2 * (k − 1) / (n − 1). (Ranges roughly from 0.5 to 0.7: when the public-good multiplier k is larger I require a slightly higher recent cooperation rate before defecting, because cooperation is more valuable.)
- Individual penalty threshold L = 2. If a player defects at least L more times than they cooperate within the last m rounds (i.e., a clearly persistent defector), I mark them as “penalty candidate.”
- Punishment length P = 2 rounds. I punish by defecting for P rounds targeted at persistent defectors, then re-evaluate.
- Forgiveness probability during punishment: when I am punishing (defecting) I still cooperate with small probability p_forgive = 0.1 each round to allow recovery and avoid permanent mutual collapse.
- Endgame window s = min(3, max(1, floor(r/5))). In the final s rounds I apply a stricter rule to avoid last-round exploitation.

State I maintain (computed from history only)
- For each player i: recent cooperation count and defect count over last m rounds, and a reputational score R_i = (coops − defects) in that window.
- Group cooperation rate G = average fraction of players who cooperated in each of the last m rounds (equivalently, the average proportion of cooperators per round in the window).
- A current punishment list: players I am actively punishing and how many punishment rounds remain.

Decision rules (per round t)
1. First round (t = 1)
   - Cooperate. Signal willingness to build cooperation.

2. Endgame (t > r − s)
   - Be cautious: if group cooperation G over the last m rounds ≥ 0.95 (near-universal cooperation) AND no player is on my active punishment list, cooperate.
   - Otherwise defect. (In the last few rounds the opportunity to recover from exploitation is limited, so I only cooperate when near-unanimity and no outstanding punishments exist.)

3. Regular rounds (t ≤ r − s)
   - Update reputations R_i and group cooperation G from history; update punishment list by removing players whose punishment timers expired or who have cooperated since punishment began.
   - Detect persistent defectors: any player with R_i ≤ −L becomes a penalty candidate. Add them to my punishment list for P rounds (or reset their timer if already listed).
   - Primary decision (majority/collective condition):
     a. If G ≥ T (recent group cooperation is at least threshold T) and the number of players on my punishment list is small (≤ floor(n/3)), then cooperate. Rationale: the group is generally cooperative, so continue contributing to sustain the public good.
     b. If G < T (cooperation has fallen below threshold), defect. This is a temporary group-level withdrawal to signal that collective cooperation is required to continue supplying the public good.
   - Targeted punishment behavior:
     - If I am punishing (have one or more players on my punishment list), I will defect in the normal decision above to deliver the punishment, except:
       • During punishment rounds I will cooperate with small probability p_forgive = 0.1 (randomized forgiveness) so that one-off mistakes can be repaired and the system can escape mutual defection.
       • Once a punished player shows cooperative behavior (they contribute at least once), remove them from the punishment list after that round and resume cooperating if group conditions allow.
   - If multiple players are persistent defectors and group cooperation remains poor for more than m rounds, continue defecting until the group cooperation G recovers to ≥ T or punished players repair their reputations.

Additional robustness details
- Avoid permanent grim triggers: punish briefly (P rounds) rather than permanently, combined with probabilistic forgiveness, to prevent cascading permanent defection from noise or mistakes.
- Target punishment to persistent defectors rather than punishing forever the whole group; if most of the group is cooperating, favor cooperation even if a few defect.
- If the game is very short (r ≤ 3), use shorter memory (m = r − 1) and be slightly stricter: cooperate first round, then defect only if you observe unanimous defection on the next round (to limit exploitation in tiny games).
- If an entire group converges to defection and never recovers, my strategy will defect consistently (rational exit) because continued unilateral cooperation would be exploited and would lower my payoff.

Summary in plain steps
- Start cooperative.
- Track recent group cooperation and individual histories.
- Default to cooperate when recent group cooperation is healthy (G ≥ T).
- If cooperation falls below threshold or persistent defectors appear, switch to short, targeted punishment (defect P rounds against those defectors), with small chance of forgiveness each punishment round.
- After punishment or after punished players show cooperation, resume cooperation if the group condition (G ≥ T) is met.
- In the last s rounds be conservative: only cooperate if near-unanimous recent cooperation and no outstanding punishments; otherwise defect.

Why this is collective and robust
- Collective: default bias toward sustaining group cooperation and maximizing collective payoff when others reciprocate; punishment is used chiefly to restore cooperation, not to permanently punish.
- Robust: reacts to a wide range of behaviors — tolerates occasional mistakes, punishes persistent free-riders, and forgives so cooperation can re-emerge. Endgame caution reduces vulnerability in known final rounds.
- Parameter choices depend only on n, k, r and observed history; no assumptions about shared norms or off-line coordination.
'''

description_COLLECTIVE_77 = '''
Collective-Conditional Cooperator with Gradual Punishment and Forgiveness (CCC‑GPF)

Idea in one line
- Start by trying to sustain collective cooperation; cooperate when the group is cooperating, punish defects briefly but proportionally, forgive quickly to restore cooperation, and taper cooperation near the end of the finite horizon. All decisions are deterministic and depend only on game parameters (n, k, r) and observed history (past actions and payoffs).

Parameter construction (computed once at start)
- MPCR = k / n (marginal per‑capita return).
- Lookback window w = min(5, max(1, floor(r / 10))) — how many recent rounds we use to measure group behavior.
- Baseline cooperation fraction f* = clamp(0.3 + 0.7 * MPCR, 0.1, 0.9) — higher when MPCR is larger (k closer to n).
- Cooperation threshold T = ceil(f* * n) (number of contributors in a round we take as indicating “group cooperating”).
- Endgame window E = ceil(r / 10) (near the final E rounds we require slightly stronger evidence to cooperate).
- Punishment sizing rule: when punishment is triggered, punish for P = min( r_remaining, 1 + (T - S_prev) ), where S_prev is contributors in the previous round (including that round’s contributors count) and r_remaining is rounds left including the current round.

State variables (tracked in our strategy)
- remainingPunish = 0 (how many rounds of punishment remain; 0 means not currently punishing).

Round-by-round decision rules
1. First round (t = 1)
   - Cooperate (C). Starting cooperation helps establish possibilities for mutual cooperation.

2. Final round (t = r)
   - Defect (D). With no future rounds, cooperation cannot be sustained by retaliation.

3. General rule for rounds 2 ≤ t < r
   - Update: observe the immediately previous round’s contributors count S_prev (total number of players who contributed last round, including yourself if you did).
   - If remainingPunish > 0:
     - Defect this round. Decrement remainingPunish by 1. Continue to observe history while punishing.
   - Else (not currently punishing):
     - Quick‑forgiveness rule: if S_prev ≥ T − 1, cooperate. (We forgive a single noisy miss to avoid cascades.)
     - Trigger punishment: if S_prev < T − 1, set remainingPunish = P as defined above and defect this round (begin proportional punishment).
     - If neither of the above (this can happen when S_prev exactly equals T−1 and you choose to cooperate via forgiveness), fall back to the recent‑history check below.

   - Recent-history check (applies when not punishing or when deciding to stop punishing):
     - Compute p_recent = average fraction of contributors (all players) over the last w rounds.
     - If t is inside the endgame (r − t + 1 ≤ E), require a slightly higher bar: cooperate only if p_recent ≥ f* + 0.1 (clamped to ≤ 1.0). Otherwise defect.
     - If outside the endgame: cooperate if p_recent ≥ f*; otherwise defect.

Notes and rationale (behavioral consequences)
- Collective orientation: the strategy is biased toward restoring and sustaining group cooperation (initial cooperation, forgiving one miss, returning to cooperation as soon as evidence supports it).
- Proportional, not permanent, punishment: a single round or small shortfall triggers only a short, proportional punishment (punishment length grows with the shortfall) instead of permanent defection. This stops exploitation but avoids irreversible collapse of cooperation.
- Leniency prevents cascades from noise or one-off selfish moves: forgiving when S_prev is only one less than the threshold prevents accidental single defections from triggering long punishments.
- Adaptation to game parameters: f* and T depend on MPCR = k/n (higher k makes cooperation more socially valuable, so we demand a higher observed cooperation rate before turning to punishment). Lookback w scales with r so behavior neither overreacts in short games nor is too myopic in long games.
- Endgame tapering: cooperation becomes harder to sustain without future punishment; the strategy tightens its requirement for cooperation near the final rounds to avoid being systematically exploited in the known final phase.
- Deterministic and history-based: all actions depend only on n, k, r and the observed history of moves and payoffs; no communication or coordination required.

Edge cases
- Very small r (r ≤ 2): we cooperate in round 1 and defect in round r (if r = 2, round 2 is final and we defect). The lookback and punishment rules naturally compress to very short sequences.
- All others always defect: the strategy will detect low p_recent and settle into defection (minimizing losses).
- Many persistent cooperators: the strategy will quickly converge to cooperation and maintain it (short punishments only when needed).
- Noise / occasional mistakes: single errors are forgiven; only sustained drops in group cooperation trigger proportional punishments.

Summary (short)
- Start cooperative, monitor recent group cooperation (window w), require a cooperation threshold T derived from MPCR to continue cooperating, forgive a one‑round shortfall, impose short proportional punishments when shortfalls are bigger, and tighten requirements in the final rounds. This balances collective welfare (favoring cooperation) with robustness to free riders and noise.
'''

description_COLLECTIVE_78 = '''
Name: Graded Reciprocity with Forgiveness and Extinction Detection (GR-FE)

Goal (collective mindset)
- Maximize collective payoff by sustaining mutual contributions when others reciprocate, while avoiding persistent exploitation. Start by trying to build cooperation, punish proportionally and briefly when cooperation drops, and forgive so cooperative groups can recover.

Parameters (computed from game parameters n, k, r; no outside information)
- Memory window M = min(5, max(2, r)) — use the last M rounds to smooth noise.
- Sensitivity s = 1 - (k / n). (When k/n is close to 1 contributions are “less costly” individually; when k/n is small cooperation is harder and we require stronger evidence.)
- High threshold TH = 0.65 + 0.15 * s (range ≈ 0.65–0.80).
- Low threshold TL = 0.35 + 0.15 * s (range ≈ 0.35–0.50).
- Max punishment length P_max = min(3, max(1, floor(r/10) + 1)). (Allows short proportional punishments but not permanent exile.)
- Extinction-check window E = min(10, r). Extinction cutoff CE = 0.10 (10% cooperation).

Decision rules (per round t)
1. Last-round rule
   - If t = r (final round): defect (D). In a finite game the last round cannot be sustained by future reciprocity; do not give a free exploit.

2. First-round rule
   - If t = 1: cooperate (C). Give cooperation an initial chance to seed mutually beneficial behavior.

3. Compute recent statistics
   - For rounds t-1 down to t-M (or from round 1 if fewer rounds exist), record every other player’s contributions.
   - Let F = fraction of contributions among the other players over that window. (Count total contributions made by the n-1 others across the M rounds divided by (n-1)*M.)
   - Let last_round_others = fraction of other players who contributed in round t-1 (if t>1).
   - Let Dcount = number of distinct players who defected at least once in the M-window (excluding yourself).

4. Extinction detection (avoid exploitation)
   - If t > E and the fraction of contributions by others in the last E rounds < CE (i.e., almost nobody ever cooperates recently), then switch to permanent defection for all remaining rounds. (This prevents being exploited by a crowd of persistent defectors.)

5. Core cooperate/defect rule
   - If F >= TH: cooperate. (Group is reliably cooperative; match it.)
   - If F < TL: defect. (Group is mostly defecting; do not sacrifice.)
   - If TL <= F < TH: use graded response:
     a. If last_round_others > 0 (at least one other cooperated last round): cooperate this round (signal willingness to reciprocate).
     b. Otherwise defect.

6. Proportional punishment (when cooperation drops suddenly)
   - If there is a sudden collapse: compare the current F to the F' computed using the previous M window (i.e., rounds t-M-…-t-1 vs t-M+1…t). If F decreased by > 0.30 (a clear and significant drop), then enter a punishment phase:
     - Punish by defecting P rounds, where P = min(P_max, 1 + floor((Dcount / (n-1)) * P_max)).
     - After P punishment rounds, return to normal decision rule (step 5). Punishment is proportional to the observed number of distinct defectors, limited in length, and forgiving so cooperation can resume.

7. Noise tolerance and forgiveness
   - Because a single defect does not permanently break cooperation, the use of a multi-round window, graded thresholds, and short proportional punishments avoids endless retaliation for occasional mistakes.
   - After any punishment phase, forgiveness is automatic: resume using step 5 and cooperate if the group’s behavior justifies it.

Implementation notes (how the rules are used in play)
- All computations use only public history (past contributions and payoffs) and the parameters n, k, r.
- The strategy is deterministic given the computed fractions and thresholds.
- The thresholds scale with k/n so that when individual returns to contributing are relatively larger (k/n close to 1) the strategy is more willing to cooperate on weaker signals; when k/n is small (contributions are a sharper individual loss) the strategy demands stronger evidence of group cooperation.
- Punishment is limited in duration and proportional, to deter exploitation but permit cooperative recovery; extinction detection prevents long-term exploitation by mainly-defecting populations.
- Last-round defection prevents being exploited on the final move; first-round cooperation helps seed mutually beneficial patterns.

Intuition summary
- Start by trying to cooperate.
- Cooperate when the recent group signal is strong (>= TH).
- Refuse to contribute when the recent signal is weak (< TL).
- In intermediate cases, reciprocate if someone recently cooperated, otherwise defect.
- If cooperation collapses sharply, punish briefly and proportionally to deter defectors, then forgive.
- If cooperation is effectively extinct, stop cooperating to avoid exploitation.
This balances a collective commitment to mutual contributions with robustness against exploitation and noise.
'''

description_COLLECTIVE_79 = '''
Name: Collective Conditional Cooperation with Proportional Punishment & Forgiveness (CCC-PPF)

Goal (collective mindset)
- Maximize group payoff by sustaining high, stable rates of mutual contribution while avoiding long-term exploitation. Treat the group as the unit to defend: start by cooperating to invite collective gains, punish short and proportionally when others defect, then forgive to restore cooperation.

Definitions and internal bookkeeping (computed from parameters and history)
- n = number of players; r = total rounds.
- For each past round t and each player j we observe c_j(t) in {0,1}.
- Recent window W = max(3, min(10, floor(r/5))). (If r is small, W is at least 3; for long games we look at up to 10 recent rounds.)
- Recent group cooperation rate G = (sum of all players' contributions in the last W rounds) / (n * W).
- Last-round defectors d_last = number of other players (not me) who chose D in previous round.
- State variables (maintained by strategy): Phase ∈ {Cooperate, Punish, Rebuild}. When a Punish phase is entered we set PunishRoundsRemaining = P (see below). When a Rebuild phase is entered we set RebuildRoundsRemaining = R (see below).

Parameter thresholds (fixed functions of n and r)
- High-cooperation threshold theta_high = 0.7. If G ≥ theta_high we call the group “cooperating.”
- Low-cooperation threshold theta_low = 0.3. If G ≤ theta_low we consider cooperation collapsed and switch to protective behavior.
- Punishment length P = max(1, min(4, d_last)). (Punish for at least 1 round, up to 4 rounds; proportional to number of defectors observed in the triggering round.)
- Rebuild length R = max(1, ceil(P/2)). (Shorter than punishment to favor return to cooperation when others respond.)
- Small exploratory forgiveness epsilon: with probability 0.05, cooperate even while punishing to allow escape from mutual defection loops (randomized exploration).

Initial and terminal rules (edge rounds)
- Round 1: Start in Phase = Cooperate and choose C. (Invite cooperation.)
- Final round (round r): Defect (D). In a finite-horizon game the last round is stage-game dominant for defection; avoid being exploited there.
- If r is very small (r ≤ 3): play C in rounds 1..(r-1) and D in round r. (Short games are fragile; we play the simple cooperative-initial pattern but still defect final round.)

Core decision rules (what I do in round t > 1 and t < r)
1. If Phase = Cooperate:
   - If G ≤ theta_low (recent cooperation collapsed): switch to Phase = Punish, set P = max(1, min(4, number of defectors observed in last W rounds averaged per round rounded up)), set PunishRoundsRemaining = P, and play D this round.
   - Else if d_last = 0 (everyone cooperated in previous round): play C (stay cooperative).
   - Else (some players defected last round): switch to Phase = Punish, set P = max(1, min(4, d_last)), set PunishRoundsRemaining = P, and play D this round.

2. If Phase = Punish:
   - If a random draw < epsilon then play C this round (exploratory forgiveness) and continue PunishRoundsRemaining = max(0, PunishRoundsRemaining - 1).
   - Else play D this round.
   - Then decrement PunishRoundsRemaining by 1 (unless we cooperated via epsilon).
   - If during punishment any round sees d_current (defectors that round) > d_last (punishment failing / further defection), reset PunishRoundsRemaining = max(1, min(4, d_current)) (escalate proportionally) and continue Punish phase.
   - When PunishRoundsRemaining reaches 0, switch to Phase = Rebuild, set RebuildRoundsRemaining = R, and in the next round start Rebuild behavior.

3. If Phase = Rebuild:
   - Play C for RebuildRoundsRemaining rounds (attempt to re-establish cooperation).
   - If in a rebuild round someone defects (any d_current > 0), immediately switch to Phase = Punish with P = max(1, min(4, d_current)) and play D next round.
   - If RebuildRoundsRemaining reaches 0 without new defections, switch to Phase = Cooperate.

Protective fallback for prolonged exploitation
- If over a longer history (past 2W rounds) G remains ≤ theta_low (cooperation repeatedly collapsed), stop attempting to rebuild: remain in permanent Defect mode (play D every non-final round) to avoid continuous exploitation. This is a protective response: if the group steadily refuses cooperation, there is no benefit to unilateral or costly attempts to restore it.

Rationale and properties (brief)
- Collective focus: we start cooperative to give group the chance to achieve the higher group payoff; punish only when others undermine that, and punish proportionally so punishments are credible but not endless.
- Proportional punishment: length of punishment scales with observed number of defectors, so punishment is targeted to severity of the offense and cannot be cheaply exploited by an occasional misstep.
- Forgiveness and rebuilding: after punishment we try to re-establish cooperation quickly; this prevents permanent breakdowns from small mistakes or stochastic strategies.
- Exploration (epsilon): occasional cooperation during punishment breaks cycles of mutual defection and helps recover cooperation with stochastic opponents.
- Endgame-awareness: defect in the final round to avoid being exploited when future punishment is impossible; otherwise maintain cooperation as long as the group is responsive.
- Robustness: handles pure defectors (will adapt to permanent defection by switching to protective defection), conditional cooperators (will reach stable cooperation), noisy or stochastic strategies (forgiveness and epsilon exploration prevent endless retaliation).

Summary decision checklist (practical)
- Round 1: C.
- Last round: D.
- Otherwise:
  - If recent group cooperation high (G ≥ 0.7) and everyone cooperated last round: C.
  - If anyone defected last round or recent cooperation low: enter proportional Punish (D for P rounds).
  - After punishment, try a short Rebuild of C rounds; if rebuild fails, punish again.
  - If cooperation repeatedly fails over long window: stop rebuilding and D every round (until final round rule).

This strategy favors collective welfare, adapts to a wide range of opponent behaviors, punishes defectors proportionally, forgives quickly to restore cooperation, and avoids being exploited in the terminal stage.
'''

description_COLLECTIVE_80 = '''
Adaptive Collective Conditional Cooperator (ACCC)

Goal (collective mindset)
- Preserve and restore high group contributions when a clear majority is cooperating, but avoid being exploited by persistent defectors.
- Use forgiving, short punishments that are strong enough to deter free-riding but that allow quick recovery of cooperation.

Parameters computed from game parameters
- W (window for recent history) = min(10, r). Use the most recent up to W completed rounds to estimate others’ behavior.
- rem = remaining rounds including current round.
- T (cooperation threshold) = clamp(0.5 + 0.5*(1 - k/n), 0.5, 0.9). Intuition: when the public-good multiplier k/n is high, cooperation is easier to sustain so we set a lower threshold; when k/n is low we require stronger evidence of others’ cooperation before we contribute.
- P_max (maximum punishment length) = min(3, max(1, floor(r/10))). Punishments are short and bounded; they scale mildly with total rounds but never exceed 3.

State variables (derived from history)
- For each past round t', compute fraction f(t') = (number of other players who contributed in t') / (n-1).
- p = average of f(t') over the most recent min(W, completed rounds) rounds. If no completed rounds, treat p = 1 (we start by assuming goodwill).
- recent_majority = value of f(last round) — the fraction of others who contributed in the immediate previous round.
- punishment_timer: counts how many of the P_max punishment rounds remain (initially 0).

Decision rules (what I do this round)
1. First round
   - Cooperate (C). This signals willingness to build collective cooperation.

2. Last round (rem = 1)
   - Defect (D). A one-shot defection is individually dominant in the final round.

3. Early endgame caution (rem = 2 or 3)
   - rem = 2: Cooperate only if recent_majority = 1.0 (everyone else cooperated last round); otherwise defect.
   - rem = 3: Cooperate only if p >= 0.9; otherwise follow the normal rule below.

4. If punishment_timer > 0
   - Defect this round and decrement punishment_timer by 1.
   - After P_max punishment rounds finish, re-evaluate behavior via the normal rule (don’t punish forever).

5. Normal rule (typical rounds with rem > 3 and punishment_timer = 0)
   - If p >= T: Cooperate. The group has been cooperating enough recently to justify continuing collective behavior.
   - Else (p < T): defect for a punishment episode: set punishment_timer = min(P_max, rem - 1) and defect this round. The short, coordinated punishment aims to deter sustained freeloading and to make future cooperation credible.

Leniency and noise-robustness (forgiveness)
- Do not punish for isolated, one-off lapses when the group is otherwise highly cooperative. Concretely:
  - If p < T but recent_majority >= 0.8 and the recent drop is a single round outlier (i.e., average over the rest of the window excluding the last round >= T), then treat it as noise and cooperate this round (do not start punishment).
- After completing a punishment episode, resume by cooperating immediately if p (recomputed after punishment) >= T; otherwise continue punishing for another short episode only if poor cooperation persists.

Re-entry / rehabilitation
- If I have defected for several rounds and others’ cooperation recovers (p >= T for an entire W-window or for consecutive W rounds when W > 1), I resume cooperating. This keeps punishments reversible and restores collective welfare as soon as other players demonstrate sustained cooperation.

Summary of intuitive flow
- Start by cooperating. Keep cooperating when the recent fraction of other cooperators exceeds a threshold T that is adjusted by how valuable the public good is (k/n).
- When cooperation falls below T, apply a short, bounded punishment (defect for up to P_max rounds) to signal that sustained defection reduces my willingness to sustain the public good.
- Be lenient about single-round lapses if the group is otherwise cooperating.
- Forgive and resume cooperation quickly if others return to sustained cooperation.
- In the very last round defect; in the immediate endgame be more cautious to avoid being exploited.

Why this is robust and collective
- The strategy is collective because it prefers and defends group cooperation whenever a clear majority is cooperating; it punishes only when cooperation is meaningfully below a calibrated threshold.
- It adapts to k and n via T (so it is stricter when individual incentives to free-ride are stronger) and adapts to r via bounded punishment length and endgame handling.
- Short, forgiving punishments reduce the risk of permanent collapse from a single defection or noise, while still deterring persistent free-riders. This mix of conditional cooperation, calibrated punishment, leniency, and clear endgame behavior makes it robust against a wide range of opponent strategies.
'''

description_COLLECTIVE_81 = '''
Collective-First Conditional Cooperation (CFCC)

High-level idea
- Start by signaling cooperation and try to sustain high group contribution by reciprocating cooperation and imposing short, proportional punishments when the group under-provides. Punishments are limited, proportional to the shortfall, and are forgivable as soon as others return to cooperative behavior. Near the end of a known finite horizon the strategy becomes more cautious (shorter punishments, stricter cooperation requirements) to avoid being exploited in the inevitable endgame.

Definitions used by the rule (computed only from known parameters n, r, k and observed history)
- t = current round index (1..r). remaining = r − t + 1.
- For each past round s, let G_s = (total contributions in round s) / n (fraction of players who contributed that round; includes me).
- Window m = max(1, min(5, floor(r/10))) — number of recent rounds used to judge the group (small but scales with r).
- avg_recent = average of G_{t-1}, G_{t-2}, … over up to m most recent completed rounds (if fewer than m rounds exist, average what exists).
- cooperation_target = 0.50 + 0.25 * ((k - 1) / max(1, n - 1))
  - Rationale: target moves between ~0.50 and ~0.75 depending on how socially productive the public good is (higher k → more demanding of cooperation because it is more valuable to sustain).
- punishment_scale = min(5, max(1, ceil(r/10))) — maximum reasonable punishment length in typical tournaments.
- If a punishment is active we track punish_remaining (integer ≥ 0). punish_remaining is set when a punishment is triggered and counted down each round; punishment can end early by forgiveness rules below.

Decision rules
1. First round (t = 1)
   - Contribute (C). This starts by signaling willingness to cooperate.

2. If punish_remaining > 0
   - Defect (D) this round and decrement punish_remaining by 1 at the end of the round.
   - Early forgiveness: if while punishing the group’s avg_recent (recomputed between punishment rounds) reaches or exceeds cooperation_target, immediately set punish_remaining = 0 and switch to cooperate next round.

3. Otherwise (no active punishment)
   - If remaining == 1 (last round)
     - Defect (D). No future to enforce cooperation.
   - Else if remaining <= max(2, ceil(r/10)) (late endgame window)
     - Be cautious: cooperate only if avg_recent >= min(0.90, 1.0) (i.e., nearly unanimous cooperation recently). Otherwise defect. Rationale: reduce risk of last-round exploitation while still allowing cooperation if the group is clearly reliably cooperative.
   - Else (normal rounds)
     - If avg_recent >= cooperation_target
       - Contribute (C): the environment is sufficiently cooperative; reciprocate to maintain public good.
     - If avg_recent < cooperation_target
       - Defect (D) this round and trigger a proportional punishment:
         - shortfall = cooperation_target − avg_recent (a number in (0, 1]).
         - punish_length = min(punishment_scale, max(1, ceil(shortfall * punishment_scale)))
         - Set punish_remaining = punish_length (so the next round will enter punishment mode).
       - Rationale: punishment length is proportional to how far the group fell below target, but bounded so punishments are never permanent.

Notes on counting avg_recent and self-influence
- avg_recent uses the fraction of contributors in the group (G_s). Because you cannot target an individual, this aggregates group behavior; your own past actions are included in G_s but the forgiveness and proportionality are designed to recover cooperation even when your own contribution was part of the signal.

Behavioral properties and why this is robust and collective
- Starts cooperative to seed mutually beneficial behavior.
- Uses a clear, simple reciprocity rule: cooperate when the group has been cooperative; defect and apply a short, proportional punishment when the group under-provides.
- Punishments are limited and forgivable. This prevents endless retaliation and allows the group to return to full cooperation after deviations (whether strategic or accidental).
- Punishment length scales with the magnitude of the shortfall (not an all-or-nothing grim trigger), which is robust against occasional or partial defections and discriminates between isolated or mild lapses and persistent free-riding.
- The endgame is handled conservatively to avoid being exploited when no future enforcement is possible, while still allowing cooperation if the group has been nearly unanimous.
- All rule parameters (window m, cooperation_target, punishment_scale, endgame window) are computed from n, r, k so the strategy can be used in any tournament without outside coordination.

Edge cases and clarifications
- Very short games (r small): m, punishment_scale and endgame window collapse sensibly (m = 1, small punishments); in these cases the strategy is cautious but will still cooperate first round and attempt cooperation if reciprocation is apparent.
- If many opponents play pure defectors (never cooperate): avg_recent will stay low, punishments will be short and then you will remain defecting—so you stop losing by unreciprocated cooperation.
- If many opponents are conditional cooperators, CFCC tends to stabilize on high cooperation because it reciprocates cooperation and the proportional punishment discourages persistent under-provision without burning cooperation forever.
- No communication needed; everything conditions only on observed actions and on known parameters n, r, k.

Summary (one-line)
Begin cooperating; cooperate whenever recent group cooperation meets a parameterized target; if the group falls short, defect and apply a short, proportional, forgiving punishment; near the final rounds require near-unanimous past cooperation to continue cooperating.
'''

description_COLLECTIVE_82 = '''
Collective Conditional Cooperator (CCC) with Proportional Punishment and Forgiveness

Overview intuition (collective mindset)
- I try to sustain high group contributions when others do the same, because that maximizes collective welfare.  
- I start by giving cooperation a chance and then respond to what the group actually does: punish measurable free-riding enough to deter it, but forgive and test for repaired cooperation so cooperation can be restored.  
- I avoid gratuitous, permanent revenge (too harsh) and I avoid being a perpetual sucker (too soft). I use short memory and proportional punishments so the rule is robust to many opponent types.

Parameters I compute from the game:
- n, k, r are given.
- M = min(5, t-1) — memory window length (use up to 5 most recent rounds).
- recent_fraction = fraction of other players who contributed in the previous round = (sum_{j≠me} c_j at t-1) / (n-1). (If t=1, undefined.)
- avg_fraction = average fraction of other players who contributed over the last M rounds = (sum over last M rounds of (sum_{j≠me} c_j / (n-1))) / M.
- Threshold T = 0.5 + 0.25*(1 - k/n). (When public-good benefit per person k/n is low, be stricter; when k/n is close to 1 be more willing to cooperate.)
- Punishment scale: max_punish = min(3, r) (punish up to 3 rounds unless fewer rounds remain)
- Probe interval K = 4 (when stuck in non-cooperation, occasionally probe cooperation)

State I maintain (derived from history):
- punishment_counter (initial 0): number of rounds remaining in a punishment phase I am executing.
- last_probe_round (initial 0): last round index when I unilaterally tested cooperation while otherwise defecting.

Decision rules (what I play each round t):

1) First-round and single-shot:
- If r == 1: defect (single-shot dominant strategy).
- Else if t == 1: contribute (C). I start by cooperating to signal willingness to build cooperation.

2) If in a punishment phase (punishment_counter > 0):
- I defect (D) this round.
- Decrement punishment_counter by 1 after the round.
- After punishment_counter reaches 0 I will re-evaluate according to the rules below (I do not stay permanently in punishment).

3) Normal decision (not in punishment):
- Compute avg_fraction and recent_fraction as above.
- If avg_fraction >= T:
  - Cooperate (C). If the recent history shows the group has been cooperating enough, I join them.
- Else (avg_fraction < T):
  - Defect (D) this round.
  - Trigger a proportional punishment: set punishment_counter = min(max_punish, 1 + round((T - recent_fraction)*(n-1))). Intuition: if many others defected in the immediate previous round (recent_fraction much less than T) I punish a bit longer; if only a few defected I punish briefly.
  - If punishment_counter was set to 0 by rounding, set it to 1 (ensures at least one-round response).
  - Record last_probe_round = t (so probes don’t occur back-to-back).

4) Occasional probing to restore cooperation:
- If I have been defecting for many rounds because avg_fraction < T and punishment_counter == 0, every K rounds (i.e., if t - last_probe_round >= K) I play one cooperative move (C) as a probe to test whether others will return to cooperating.
- If the probe is met with restored cooperation (avg_fraction rises above T in subsequent rounds), I resume cooperation; if not, I return to defecting and punish proportionally if needed.

5) Last round (t == r):
- I cooperate in the last round only if recent_fraction >= T (i.e., if others cooperated in the immediate previous round). Otherwise I defect. This avoids being exploited when there is no future to enforce reciprocation but still allows cooperative finishing if the group is evidently cooperative.

Edge cases and refinements:
- Short games (r ≤ 3): punishments are short (max_punish ≤ r) and I react faster: any observable defection in recent rounds lowers avg_fraction below T quickly and triggers immediate defection and a short punishment.
- If a clear majority never cooperates (avg_fraction stays well below T for many rounds), I defect persistently but still probe periodically to allow restoration if the group composition or behavior changes.
- If the group shows noisy behavior (some rounds of low contribution amid many cooperative rounds), proportional punishment and short memory limit overreaction; I resume cooperation quickly when avg_fraction returns above T.
- I never require or assume any explicit coordination signals beyond observed actions and payoffs.

Why this is collective and robust
- Collective: I give cooperation the first opportunity and continue to contribute when the group reliably reciprocates; the rule supports sustained mutual cooperation when a majority reciprocates.
- Robustness: Proportional punishments deter persistent free-riders while forgiveness and periodic probes allow recovery of cooperation if opponents change. The threshold adjusts with k/n so I’m stricter when per-person benefit of contributions is small and more generous when public-good returns are high.
- Tournament-safe: The strategy avoids permanent harshness (so it does not lock into low-payoff wars with other conditional cooperators), avoids infinite gullibility (so it is not systematically exploited), and uses short, interpretable responses that work against a wide variety of opponent types.
'''

description_COLLECTIVE_83 = '''
Collective Forgiving Reciprocity (CFR)

Goal in words
- Aim to sustain high, long-run group contributions while avoiding being a persistent sucker. Start by trying to cooperate with others, punish clear breakdowns proportionally but briefly, and forgive so cooperation can recover. Use only observed history and the parameters n, k, r.

Parameters and internal variables
- n, k, r: game parameters (known).
- remaining = r - t + 1: rounds remaining at the start of round t.
- last_coop_rate p := fraction of players who contributed in the previous round (if t=1, undefined).
- T (cooperation threshold) := 0.5 + 0.4*(1 - k/n).  Explanation: when k/n is large the personal marginal return to contributing is closer to 0 (less personal pain to cooperate) so we tolerate lower group cooperation; when k/n is small we require a stronger majority cooperating to justify continuing to contribute.
  - Bound T to [0.5, 0.9].
- punish_timer: a counter (initially 0) that tracks remaining punishment rounds I have committed to.
- last_round_action: what I did in the previous round (init C).

High-level policy
1. First round (t = 1): play C (contribute 1). Start by attempting cooperation.
2. Final round (t = r): play D (do not contribute). (Backward induction for the last move.)
3. Endgame caution: when remaining <= 2, be conservative:
   - If remaining = 2: cooperate only if the last round was full cooperation (all players contributed) and I have not started punishment; otherwise defect.
   - If remaining = 1: defect (last round).
4. Main rule for intermediate rounds (2 <= t <= r-1):
   - If punish_timer > 0:
     - Play D and decrement punish_timer by 1.
     - If the most recent round after punishment shows clear recovery (p >= T), reset punish_timer to 0 and return to cooperation next round.
   - Else (not currently punishing):
     - Compute p = fraction of players who cooperated in the last round and d = number of defectors last round = n*(1-p).
     - Leniency for isolated mistakes: if d <= 1, play C (forgive single isolated defections).
     - If p >= T, play C (the group is cooperating enough; reciprocate).
     - If p < T and d > 1, initiate proportional, temporary punishment:
       - Set punish_timer = min( max(1, ceil((T - p) * n)), remaining - 1, 5 ).
         - Intuition: punishment length grows with the gap between the observed cooperation rate and the target T, but is bounded (no endless grim punishment). Cap at 5 rounds or remaining-1.
       - On the current round play D (start the punishment).
5. Forgiveness and recovery:
   - After a punishment period ends, return to cooperation unless the next observed p still clearly below T; in that case resume punishment but with a reduced timer: punish_timer := max(1, floor(previous_punish_timer/2)).
   - If the same pattern of defection repeats three separate times (three distinct episodes where p < T and I had to punish), increase caution by raising T by +0.05 (up to 0.95) for the remainder of the game. This makes me stricter toward groups that repeatedly break cooperation.
6. Safety: never allow punish_timer to extend into the last round (we reserve the last round for D). Always ensure remaining - punish_timer >= 1.

Rationale and robustness
- Collective orientation: I start cooperating and condition my cooperation on the observed behavior of the group (majority behavior), so I reward groups that sustain cooperation and help the group reach the mutually best outcome.
- Proportional, temporary punishment: when cooperation falls below a reasonable threshold, I withhold my contribution for a short, proportional number of rounds. Short, proportional punishments discourage exploitation yet avoid driving long-term collapse that a permanent-grim strategy can cause.
- Leniency and forgiveness: forgive isolated defections (d <= 1) to avoid over-reacting to one-off mistakes or an exploiter among many cooperators. After punishment I readily return to cooperation if the group recovers.
- Parameter dependence: the cooperation threshold T uses k/n so the rule adapts to how valuable contributions are. If contributions are relatively more collectively valuable (k/n closer to 1), I am easier to satisfy; if my individual cost is large relative to personal return (k/n small) I require a stronger signal of group cooperation before continuing to contribute.
- Endgame handling: I defect in the last round and behave cautiously in the last two rounds to avoid being exploited by endgame defections (standard backward-induction consideration).
- Resistant to many opponent types: unconditional defectors will be punished quickly and I will stop cooperating; conditional cooperators who reciprocate will converge to long-run cooperation; exploiter strategies that try to take advantage of forgiveness will be hit with proportional punishments and increasing strictness if repeated.

Summary (short pseudocode-style)
- t=1: play C.
- t=r: play D.
- For 2 <= t <= r-1:
  - If punish_timer>0: play D; punish_timer--.
  - Else compute p and d.
    - If d <= 1: play C.
    - Else if p >= T: play C.
    - Else start punishment: punish_timer = min(max(1, ceil((T-p)*n)), remaining-1,5); play D.
  - After any punishment episode, if p >= T then reset punish_timer and resume cooperation; if defection repeats across episodes, raise T by 0.05 (bounded).
- Special case when remaining<=2: require stronger evidence (full cooperation) to cooperate; otherwise defect.

This strategy uses only parameters and observed history, is explicitly collective (seeks and rewards group cooperation), adapts to k, n, r, and balances punishment and forgiveness to be robust against a wide range of opponent behaviors.
'''

description_COLLECTIVE_84 = '''
Adaptive Collective Conditional Cooperator (ACCC)

Goal (collective mindset)
- Encourage and sustain group cooperation when others are willing, deter and limit free‑riding when they are not, and forgive quickly when cooperation re‑appears. Cooperate to build a cooperative norm; punish defections in a measured, proportional way so punishment is credible but not self‑destructive.

Setup (computed from game parameters)
- n, r, k are known.
- Initial cooperation threshold T0 = 0.5 + 0.25 * (k - 1) / (n - 1). Then clamp T0 to the interval [0.5, 0.9]. (This makes the strategy require a clear but achievable majority of others to cooperate; higher k raises the bar slightly because social returns are larger.)
- Maximum punishment length Pmax = max(1, floor(r / 10)). (Keeps punishments meaningful but not so long they collapse cooperation.)
- State variables maintained from the history: current threshold T (start at T0), a PunishCounter (initially 0).

High‑level rule summary
- Start by cooperating (signal willingness to cooperate).
- Defect in the last round (no future punishment is possible).
- In other rounds, condition your action on the fraction of the other players who cooperated in the previous round:
  - If you currently are in a punishment phase (PunishCounter > 0), defect while PunishCounter > 0 unless the others have already restored cooperation above threshold, in which case stop punishing immediately (forgive).
  - If not punishing and the fraction of others who cooperated last round is at least T, cooperate.
  - If not punishing and that fraction is below T, defect and initiate a proportional punishment whose length grows with the shortfall.

Detailed decision procedure (per round t = 1..r)
1. If t = 1: Cooperate. (Signal cooperation to try to establish a cooperative norm.)
2. If t = r (last round): Defect. (No future rounds to enforce cooperation.)
3. Let rem = r - t + 1 (rounds remaining including current). Let others_frac be the fraction of the other n−1 players who cooperated in round t − 1 (if t = 1 this step is skipped because of rule 1).
4. If PunishCounter > 0:
   - If others_frac >= T: set PunishCounter = 0 and Cooperate (forgive immediately when others already met the threshold).
   - Else: Defect and decrement PunishCounter by 1 (continue measured punishment).
5. If PunishCounter = 0 (not currently punishing):
   - If others_frac >= T: Cooperate.
   - Else (others_frac < T): Defect and set PunishCounter = min(Pmax, 1 + round((T - others_frac) * (n - 1))). (Punishment length is proportional to how far the group fell below the threshold; a single defector yields a short punishment, many defectors yield a longer one — but punishment is capped at Pmax.)
6. After observing the current round outcome, update T slowly to adapt to long–run behavior:
   - Compute avg_frac = average fraction of others cooperating over the last up to 5 rounds (or fewer if fewer rounds have elapsed).
   - If avg_frac >= T then reduce T slightly: T := max(0.5, T − 0.02) (become a bit more forgiving if cooperation is stable).
   - If avg_frac < T then raise T slightly: T := min(0.95, T + 0.02) (become slightly stricter if cooperation is eroding).
   - These small adjustments ensure the strategy adapts to the prevailing level of cooperation without overreacting.

Rationale and robustness
- Starting with cooperation favors establishing mutual cooperation with other conditional cooperators and rewarding reciprocators.
- Using a majority‑style, parameterized threshold (T) aligns the rule with the collective benefit: it requires a credible fraction of others to be cooperating before you keep contributing.
- Punishments are proportional and time‑limited so they are credible (they impose a cost on defectors) but not permanent (so cooperation can be restored). Immediate forgiveness if others already meet the threshold prevents long punishment wars and is tolerant to noise.
- Adaptation of T across a short window stabilizes behavior against shifts in the population of opponents: become a little more lenient when cooperation is steady; tighten up when cooperation falls.
- Defecting in the final round avoids being the only cooperator who is exploited when no future punishment is possible.
- The strategy uses only observable history (past actions and payoffs can be ignored because actions suffice) and the known parameters n, r, k. It does not rely on communication or coordination, and it is symmetric and anonymous.

Edge cases
- Very short games (small r): Pmax will be small; the strategy still starts cooperative but will punish only in ways that are credible given few remaining rounds. Last round is always defected.
- Single defection among many cooperators: yields a short punishment; quick forgiveness if others promptly return to cooperation.
- Widespread defection: threshold rises slightly and punishments lengthen proportionally, converting persistent defectors into a stable defecting equilibrium only when cooperation cannot be credibly enforced.
- Noise and occasional mistakes: short, proportionate punishments and immediate forgiveness when others resume cooperation avoid cascading mutual retaliation.

Collective orientation
- This strategy explicitly aims to maximize the group outcome by enabling sustained mutual contributions when the group reciprocates, while protecting itself and the cooperative core from systematic exploitation. It balances deterrence (to protect the collective investment) with forgiveness (to restore cooperation quickly).
'''

description_COLLECTIVE_85 = '''
Name: Adaptive Conditional Cooperator with Graduated Punishment (ACG)

High-level goal
- Aim to sustain collective cooperation when others reciprocate, but avoid being exploited by persistent defectors. Use short memory to detect group-level cooperation, punish defections for a short finite time, then forgive and test for renewed cooperation. Always defect in the very last round.

Parameters (computed from game inputs)
- n = number of players, r = number of rounds.
- Memory length M = min(5, r) — examine the most recent M rounds of history (or all past rounds if fewer than M have occurred).
- Punishment length P = min(3, r) — fixed number of consecutive defect rounds used for corrective punishment.
- Cooperation threshold α = 0.50 (50%) — fraction used to decide whether the group is cooperating recently.
- Endgame caution: last round (round r) is treated as a definite defection round. Round r-1 is cautious (see below).

Overview of data used from history
- For each past round t', we observe every player's contribution (0/1).
- recent_group_coop = (sum of contributions by the other (n−1) players over the last M rounds) / ((n−1) * M). This is the fraction of possible contributions by others in the recent window.
- For each other player j, individual_coop_rate_j = (sum of j’s contributions in last M rounds) / M.

Decision rules (deterministic)
1. First round (t = 1)
   - Cooperate (C). Signal willingness to build cooperation.

2. Last round (t = r)
   - Defect (D). One-shot Nash: cannot be punished afterwards.

3. Second-to-last round (t = r − 1), if r ≥ 2
   - Be cautious: cooperate only if the immediate previous round (t = r − 2 if it exists) showed strong group cooperation: if all players contributed in the previous round or recent_group_coop = 1.0 (everyone in memory cooperated), then cooperate; otherwise defect. This reduces vulnerability to final-round exploitation.

4. General rounds 2 ≤ t ≤ r − 2 (or all rounds t with 2 ≤ t < r − 1 if r < 3)
   - Check if we are currently in a punishment phase (see Punishment mechanism below). If so, play D and update the punishment counter. Punishment phases can be ended early if group immediately restores near-unanimous cooperation (see forgiveness below).
   - If not in punishment:
     a) If at least half of the other players are strong recent cooperators:
        - Compute number_coopters = count of players j (other than me) with individual_coop_rate_j ≥ 0.80 (i.e., they cooperated in at least 80% of the last M rounds).
        - If number_coopters ≥ ceil((n − 1) / 2) then cooperate (C). Rationale: when a majority of peers are reliable cooperators, maximize collective welfare.
     b) Else evaluate recent_group_coop:
        - If recent_group_coop ≥ α (≥ 0.50), cooperate (C).
        - If recent_group_coop < α, defect (D) and enter punishment: set punishment_counter = P (start a short corrective punishment).

Punishment mechanism and forgiveness
- Purpose: deter and correct free-riding without permanent ostracism.
- When recent_group_coop < α and you defect and set punishment_counter = P:
  - For the next P rounds you will unambiguously defect (D), unless the group immediately restores strong cooperation (forgiveness rule below).
  - After P rounds of punishment you will play one “probation” cooperation round (C) to test whether the group reciprocates.
  - If, during any punishment round, the next observed recent_group_coop (using the sliding window M) becomes ≥ 0.90 (near-unanimous cooperation), you cancel the remaining punishment and switch immediately to cooperative mode (forgive early).
  - If the probation cooperation round is met by a recovery (recent_group_coop ≥ α on the round after probation), resume normal cooperative evaluation; otherwise, if recovery fails, re-enter punishment with punishment_counter = P.

Edge-case behavior and robustness
- Very small games (n small) and very short games (r ≤ M): M and P adapt automatically (M = r or smaller).
- If opponents behave randomly or erratically: the short memory M and finite punishment P make the strategy adaptive rather than permanently punished; it will defect while cooperation rates are low and try to re-establish cooperation whenever evidence improves.
- If a clear core of reliable cooperators exists (a majority of players with individual_coop_rate_j ≥ 0.80), the strategy privileges cooperation to maximize group payoff.
- If the group is dominated by persistent defectors (recent_group_coop consistently < α), the strategy will defect most rounds and thus avoid being exploited.
- No reliance on communication or coordination beyond observed actions and payoffs.

Collective mindset statement
- This strategy prioritizes sustaining cooperation when it is reciprocated by a substantial portion of the group and uses short, limited punishments to deter free-riding. It forgives quickly when near-unanimous cooperation returns and always tests for restored cooperation rather than permanently excluding players. The approach balances group welfare with self-protection: it is willing to lead by cooperating early, defend the group norm with short punishments, then forgive and reinvest in collective gains when others reciprocate.
'''

description_COLLECTIVE_86 = '''
Collective-Conditional-Cooperator (CCC) — a simple, adaptive, forgiveness-capable strategy that prioritizes group welfare while defending against sustained exploitation.

Parameters (derived from n, r, k)
- Window W = max(1, floor(r / 10)) — how many recent rounds to measure behaviour.
- Cooperation threshold p* = 0.5 + 0.25 * (1 − k/n) — fraction of other players that should on average cooperate for me to keep cooperating. (When the public-good multiplier k is high, the threshold is lower; when k is small, the threshold is stricter.)
- Maximum penalty length P_max = min(3, r) — maximum planned punishment length after detecting sustained under-cooperation.
- Endgame length E = min(2, r) — last rounds handled conservatively to avoid obvious endgame exploitation.

Intuition
- Start by giving cooperation a chance. Maintain cooperation so long as a clear majority (by the threshold p*) of other players are reciprocating recently.
- If others stop cooperating, respond with a short, calibrated punishment that is long enough to deter exploitation but short enough to allow recovery.
- Forgive quickly when group behaviour improves (so cooperation can reestablish).
- In the last couple of rounds, be cautious: preserve cooperation only if it has been mutually sustained immediately prior; otherwise avoid being left worse off.

Decision rules (round t, based only on parameters and observed history)
1. First-round rule
   - Round 1: cooperate (contribute 1).

2. Routine rounds (t such that t ≤ r − E)
   - Compute p = average fraction of other players who contributed, averaged over the most recent W rounds available (if fewer than W rounds exist, average over all available rounds).
   - Maintain a state variable "punishment_remaining" (initially 0).
   - If punishment_remaining > 0:
     - Action: defect (contribute 0).
     - Decrement punishment_remaining by 1 at the end of this round unless an early-forgiveness condition is met (see below).
   - Else (not currently punishing):
     - If p ≥ p*:
       - Action: cooperate (contribute 1).
     - If p < p*:
       - Enter a punishment phase: set punishment_remaining = P_max − 1 (so you defect this round and plan up to P_max − 1 further defect rounds).
       - Action: defect this round.

   - Early forgiveness: if during a punishment phase the observed p rises to ≥ p* for two consecutive rounds (counted from the most recent data), immediately cancel remaining punishment (set punishment_remaining = 0) and resume cooperation next round. This makes punishment proportional and allows quick re-establishment of cooperation.

3. Endgame rounds (t > r − E, including the final round)
   - If in the immediately preceding round (t − 1) every player contributed (full cooperation) and there is no active punishment phase, then cooperate (contribute 1) in this round — preserve a mutually-sustained good outcome.
   - Otherwise, defect (contribute 0). Rationale: there is little or no future to enforce cooperation, so avoid unilateral sacrifice unless cooperation was just unanimous.

Handling special / edge cases
- Small r: W, P_max and E scale down automatically; windows use whatever history is available.
- One or a few persistent defectors: the algorithm treats persistent low p by entering repeated short punishments. If a tiny minority defects while the majority sustains cooperation, p will typically remain ≥ p* and cooperation continues; if defection by the minority pushes p below p*, the short punishment aims to bring the group back to cooperation rather than collapse forever.
- Sudden shocks: the sliding window W smooths single-round shocks. A single defection will not permanently collapse cooperation because punishment is short and forgiveness requires only a sustained improvement.
- No assumptions about norms or coordination: decisions rely only on observed contributions, not on promises or labels.

Collective mindset (how this strategy aligns with group welfare)
- Prefers cooperation whenever a clear portion of the group reciprocates (p ≥ p*), thus maximizing collective payoff when feasible.
- Uses calibrated, brief punishments only to restore cooperation—punishments are not permanent vendettas.
- Forgiveness is built in so that short-term mistakes, noise, or experimentation do not permanently destroy cooperation.
- Endgame conservatism minimizes being exploited when future enforcement is unavailable while still preserving last-round mutual gains when cooperation has been stable.

Summary pseudocode (natural-language sketch)
- Initialize: punishment_remaining = 0.
- Round 1: cooperate.
- Each subsequent round:
  - Compute p = average other-player contribution over last W rounds.
  - If in punishment (punishment_remaining > 0):
    - defect this round; decrement punishment_remaining by 1 unless p ≥ p* for two consecutive rounds → set punishment_remaining = 0 (forgive).
  - Else:
    - If t is in the last E rounds:
      - If previous round had full cooperation and punishment_remaining = 0, cooperate; otherwise defect.
    - Otherwise (not in endgame):
      - If p ≥ p*: cooperate.
      - If p < p*: defect and set punishment_remaining = P_max − 1.

This strategy is simple, adaptive, and robust: it fosters collective cooperation when a sufficient fraction of others reciprocate, punishes sustained under-contribution in a limited way, and forgives to allow cooperation to recover. It scales with n, r and k through its parameters and uses only observed history.
'''

description_COLLECTIVE_87 = '''
Name: Collective Conditional Cooperator with Limited Punishment and Forgiveness (CCC-LPF)

Goal: maximize group welfare by sustaining high cooperation when others reciprocate; deter persistent exploiters with short, targeted punishments; forgive quickly so cooperation can recover. Decisions depend only on game parameters (n, r, k) and the observed action history.

Parameters computed at the start (use only n, r, k):
- Window length for recent behavior: L = min(10, r). (Use the most recent L rounds when available; early rounds use all previous rounds.)
- Cooperation-quality threshold (scales with social benefit k): T_good = 0.5 + 0.25 * (k - 1) / max(1, n - 1). (Range ≈ [0.5, 0.75).)
- Tolerate threshold: T_tol = 0.4.
- Persistent-defector threshold: T_bad = 0.20.
- Punishment length: P = min(3, max(1, floor(r/20))) — short and bounded; if few rounds remain, P ≤ remaining rounds.

Maintain state:
- For every player j (including self) keep C_j = number of times j cooperated in the most recent L rounds (or entire history if < L rounds).
- A set Punished = players currently designated as persistent defectors (initially empty), and for each punished player a remaining punishment counter.

Decision rules (applied at the start of each round t = 1..r):

1) First round (t = 1):
   - Cooperate. (Signal willingness to build cooperation.)

2) Update statistics:
   - For each player j compute recent cooperation rate r_j = C_j / min(L, t-1) (if t=1, rates undefined; proceed from the base rule above).
   - Compute others’ average recent cooperation R_others = average of r_j over j ≠ self.

3) Detect and manage persistent defectors:
   - If any player j has r_j ≤ T_bad and has defected in both of the last two rounds (if those rounds exist), add j to Punished and set j’s punishment counter = P.
   - When a punished player cooperates in a round, immediately remove them from Punished (end punishment early).
   - Each round, decrement punishment counters; when counter reaches zero remove player from Punished.

4) If Punished is non-empty:
   - Withhold cooperation (choose D) this round to reduce the exploiter’s benefit and signal disapproval, unless all punished players cooperated in the immediately preceding round (i.e., they have shown a clear change). If all punished players cooperated last round, cooperate this round and remove them from Punished. (This keeps punishments short and conditional on signs of reform.)

5) Otherwise (no active punishments):
   - If R_others ≥ T_good: cooperate. (Group is reliably reciprocating.)
   - Else if R_others ≥ T_tol: cooperate if you cooperated in the previous round; otherwise defect this round but remain forgiving (this avoids flipping between states too rapidly).
   - Else (R_others < T_tol): defect this round (initiate a deterrent signal). After defecting because R_others < T_tol, monitor for recovery: if in any subsequent round R_others rises to ≥ T_good, resume cooperation immediately.

6) Endgame (final rounds):
   - If t = r (last round): cooperate only if R_others ≥ 0.5 and Punished is empty; otherwise defect. (This respects collective intent when the group still shows majority cooperation, but avoids being exploited if others have been uncooperative or punished.)
   - If t = r-1 (second-to-last round): favor cooperation if group cooperation is strong (R_others ≥ T_good) and no punished players; otherwise follow the rules above. (Punishments should not be extended across the last few rounds beyond remaining rounds available.)

Conventions / tie-breakers:
- If a numeric comparison is exactly equal to a threshold treat it as meeting the threshold (i.e., cooperate when R_others = T_good).
- If counts are unavailable early (t small), use whatever history exists; start with cooperation as in rule 1.
- All thresholds and P are deterministic functions of (n, r, k) and the observed history.

Rationale, briefly:
- Start cooperatively to try to establish high welfare. Use a simple, history-weighted cooperation rate among others to judge whether collective cooperation is present. If the group is cooperating reliably we continue to cooperate (collective mindset). If cooperation falls, use short, limited punishments targeted at persistent defectors so that exploiters are made less profitable while not permanently wrecking group welfare. Forgive quickly when cooperation resumes to restore high group payoffs. Near the final round we are cautious but will still cooperate if a clear majority has been cooperating, preserving collective benefit where possible.

This strategy is adaptive (uses a recent-history window), robust (short, bounded punishments avoid long mutual breakdowns; thresholds scale with k), and explicitly collective (it prefers group-sustaining cooperation and only defects to deter and correct exploitation).
'''

description_COLLECTIVE_88 = '''
Strategy name: Collective Conditional Cooperation with Proportional Forgiving Punishment

Philosophy (collective mindset)
- Aim to sustain high collective contributions because a stable, cooperative group yields the highest long-run welfare for everyone.
- Start by offering cooperation, punish defections only enough to make defection unprofitable for repeat free-riders, and forgive to restore cooperation quickly after recovery.
- Avoid permanent exclusion (which destroys long-run value) while resisting exploitation. Be tolerant of occasional mistakes.

Parameters (computed from game parameters and history; no external tuning)
- W (assessment window): W = min(5, r). Measure recent behavior over the last W completed rounds.
- target rate τ (desired average contribution per player): τ = 0.8 (a high but attainable cooperation benchmark). This is fixed and independent of identities; it expresses the collective aspiration to keep contributions high.
- punishment base P0: 2 rounds (minimum punishment length when group cooperation drops).
- punishment cap Pmax: min( max(2, floor(r/5)), 6 ). (Prevents endless escalation in short games.)
- forgiveness criterion: after a punishment phase, return to cooperation if recent group behavior recovers (see below).

Decision rules (applied every round t = 1..r)
1. If r = 1 (only one round): defect. (No future to enforce cooperation.)
2. If t = r (the final round): defect. (Endgame: no future to enforce reciprocation.)
3. Otherwise (not final round):
   - If t = 1 (first round): cooperate (contribute 1). Start by offering cooperation.
   - Compute the recent group contribution rate G:
     - Look at the last W completed rounds (if fewer than W rounds have occurred, use all available past rounds).
     - For each past round u in that window, count how many players contributed in that round (including yourself).
     - G = (total contributions by all players in the window) / (n * number_of_rounds_in_window). So 0 ≤ G ≤ 1.
   - If currently in a punishment phase that we initiated earlier and the phase has not yet finished: defect this round (do not cooperate while punishing).
   - Else (not currently punishing):
     - If G ≥ τ: cooperate (contribute 1). The group is cooperating enough recently; keep cooperating.
     - If G < τ: begin a punishment phase targeted at restoring cooperation:
       - Determine recent severity S = max(1, round((τ - G) * n)). (S is an integer roughly proportional to how far the group has fallen below the target.)
       - Set punishment length P = min(Pmax, P0 + S). Enter a punishment phase of exactly P consecutive rounds of defection (including this round).
       - During the punishment phase defect every round. The purpose is to lower the immediate payoff of defectors and signal that continued defection is costly.
   - After a punishment phase ends:
     - Re-assess G over the most recent W rounds.
     - If G ≥ τ: forgive and cooperate from the next round.
     - If G < τ: escalate only modestly — start another punishment phase with length P' = min(Pmax, P + 1). Do not escalate indefinitely.

Noise tolerance and forgiveness
- A single accidental defection (or a single-round dip in G) triggers only a short, proportional punishment (P0 or slightly longer) rather than permanent exclusion.
- Forgiveness is automatic as soon as recent group performance recovers to the target τ. This allows cooperation to re-form after mistakes or short-term shocks.

Edge cases and practical notes
- Short games: window W and punishment cap Pmax shrink with small r so punishments are meaningful but not ruinous.
- If many players persistently defect and G never reaches τ, punishments will cycle but are capped. This prevents a strategy that punishes forever and destroys its own welfare. Over time the strategy will either maintain cooperation with like-minded players or settle into mutual defection with persistent free-riders.
- Deterministic: no randomization is used. Behavior depends only on n, k (implicit in the choice of τ as a high cooperation target), r, and the observable history.
- Collective orientation: this strategy always begins by trying to cooperate, enforces cooperation by group-level, proportional punishments, and returns quickly to cooperation once others show willingness to contribute — balancing group welfare and resistance to exploitation.

Summary (one-line rule)
- Start by cooperating; keep cooperating while recent group contributions meet a high target (τ = 0.8); if the group falls below τ, impose a short, proportional, capped punishment of defecting rounds to deter free-riding, then forgive and resume cooperation once the group’s recent contribution rate recovers; always defect in the last round.
'''

description_COLLECTIVE_89 = '''
Name: Collective Conditional Cooperator with Proportional Punishment and Forgiveness (C3-PuF)

Summary: start by cooperating, keep cooperating while the group has been cooperating enough, punish defections in a short, proportional way, and forgive when cooperation returns. Be cautious in the very last round. The rule uses only the game parameters (n, k, r) and observed history of contributions.

Parameters derived from game inputs (deterministic functions of n, k, r):
- Memory window W = min(8, r) — evaluate recent behavior over the last W rounds (or all past rounds if fewer exist).
- Punishment maximum horizon M = max(1, floor(r/10)) — maximum length of proportional punishment when needed.
- Cooperation threshold T (fraction of other players contributing) = choose a threshold that becomes stricter when the public good multiplier is weak:
  - If k/n >= 0.6 then T = 0.50 (lenient: require a simple majority).
  - If k/n < 0.6 then T = 0.65 (stricter because it is harder to sustain cooperation).
(These thresholds are fixed functions of n and k and are known to the strategy.)

State variable:
- PunishCounter (initially 0) — how many future rounds I will defect as a punishment.

Decision rules (applied at the start of each round t using history up to t-1):

1. First round:
   - Cooperate.

2. Endgame rule:
   - If t is the final round (t = r): defect (no future to incentivize cooperation).

3. If PunishCounter > 0:
   - Play D this round.
   - Decrement PunishCounter by 1 after the round.

4. Otherwise (not currently punishing):
   - Compute coop_rate = average, over the last min(W, t-1) rounds, of the fraction of the other players (excluding me) who contributed in each round. If there is no past round, treat coop_rate = 1 (so first round Cooperate).
   - If coop_rate >= T:
     - Cooperate this round (play C).
   - Else (coop_rate < T): trigger proportional punishment:
     - Compute short proportional punishment length P = 1 + floor( (T - coop_rate) / T * M ).
       - (Interpretation: the lower the recent cooperation relative to the threshold, the longer the punishment, up to M+1.)
       - Cap P at remaining rounds minus 1 (do not schedule punishment that extends into the final round choice).
     - Set PunishCounter = P - 1 (we will defect this round plus P-1 future rounds).
     - Defect this round (play D).

5. Fast forgiveness / reset:
   - If any round ends with unanimous cooperation (all n players contributed), immediately reset PunishCounter = 0 and resume cooperating next round (unless it is the final round).
   - Also, if after a punishment window there is a round where coop_rate >= T, resume cooperating normally.

Tie-breaking and noise tolerance:
- When coop_rate is very close to T (equal within rounding), prefer cooperation (tie-break toward cooperation).
- Punishment lengths are intentionally short and proportional so occasional mistakes by others cause only brief retaliation; this keeps the strategy robust to noisy or exploratory opponents.

Notes on edge cases and design choices:
- The strategy is collective: it privileges group welfare by default (start cooperating and return to cooperation quickly after good behavior), but it defends against persistent exploitation by punishing in proportion to the shortfall of recent cooperation.
- The memory window W and maximum punishment M scale with r so the strategy is adaptive in both short and long repeated games.
- The final-round defection is unavoidable (no future to enforce cooperation); to avoid being exploited right at the end, the strategy defects in round r. In the very last few rounds (when remaining rounds are small) the computed punishments are capped so punishment cannot be used to extort payoffs in a short remaining horizon.
- The thresholds depend on k/n: when the public-good multiplier is large (cooperation more socially effective), the strategy is more willing to cooperate with modest past support; when multiplier is weak, the strategy demands stronger past support before cooperating.

Why this is robust:
- It cooperates with cooperators and supports sustained group outcomes when a majority (or a sufficiently large fraction, adjusted for k) has been cooperating.
- It punishes defectors, but punishment is short and proportional so the strategy avoids long vendettas (which are costly to everyone) and is forgiving when cooperation resumes.
- It is simple, deterministic, and depends only on observable history and the game parameters; it adapts automatically to long or short games and to the strength of the social return (k).
'''

description_COLLECTIVE_90 = '''
Name: Adaptive Collective Reciprocity (ACR)

Goal summary
- Preserve and restore high collective contributions whenever possible.
- Be forgiving of occasional lapses, but apply quick, limited, and targeted punishment to persistent free‑riders so the group as a whole is not exploited.
- Use only observed actions/payoffs, n, r, k and a small set of derived, parameterized thresholds that scale with r.
- Be robust across many opponent types: unconditional cooperators, unconditional defectors, Tit‑for‑Tat style, probabilistic, and adversarial strategies.

Parameters (derived from game inputs; fixed before play)
- W = sliding window length for short‑run reputation = min(10, max(3, ceil(r/10))).
- T_high = 0.70 (cooperation threshold).
- T_low = 0.40 (defection threshold).
- F_threshold = 0.20 (persistent defector threshold for targeting).
- P_base = max(1, ceil(r/20)) (base punishment length in rounds).
- Probation Q = min(3, ceil(r/20)) (rounds of probation after punishment).
- Epsilon_explore = min(0.05, 2/(r+1)) (small chance to cooperate to re-open cooperation).
- Last_round_defect = true (always defect in round r).
These constants can be scaled, but the strategy must use only n, r, k and observed history; the above tie to r.

State tracked
- For each player j ≠ me, keep history of their contributions and compute S_j = proportion of their contributions in the last W rounds (or in all past rounds if fewer than W exist).
- in_punishment flag, targeted_set (players currently flagged for punishment), punishment_end_round, probation_end_round.

Decision rules (per round t)
1) Edge rounds
- If t == 1: cooperate. Start by offering cooperation.
- If t == r (last round): defect. (Backwards‑induction rationality makes final round cooperation costly and exploitable.)
- If t within the final P_few = min(2, ceil(r/10)) rounds before r (optional conservative variant), be more cautious: reduce T_high by 0.1 (or equivalently treat near‑end as slightly less trusting). This is optional; main rule still defects only at r.

2) Update reputations
- For every player j ≠ me compute S_j = (# times j contributed in rounds max(1,t-W) … t-1) / min(W, t-1). If t==1 no data.

3) Detect persistent defectors (targeting)
- If any S_j <= F_threshold AND j’s defections contributed materially to a recent drop in group contributions (for example, group mean cooperation over last W rounds smaller than over the prior W rounds by at least 0.05), then mark j as suspected persistent defector and add to targeted_set.
- When a new player is added to targeted_set, set punishment_end_round = t + P_base * |targeted_set| and set in_punishment = true.

4) Punishment / probation behavior
- If in_punishment:
  - While t ≤ punishment_end_round: defect (D). The punishment is blunt (can't be player‑targeted in payoff) but limited in length and scaled to the number of targeted players so punishment is proportional.
  - When t == punishment_end_round + 1: enter probation. Set probation_end_round = t + Q and clear in_punishment but keep targeted_set until probation ends.
  - During probation (t ≤ probation_end_round): cooperate (C) for the group to give targeted players a chance to repair reputation. Recompute S_j continuously; if any targeted j raises S_j > F_threshold during probation, remove j from targeted_set immediately. If none improve by probation_end_round, re‑enter punishment with punishment_end_round = t + P_base * |targeted_set|.
- This loop allows repeated short punishments and a clear chance to reform. Punishment is never permanent (no grim trigger) so occasional mistakes do not collapse cooperation forever.

5) Normal conditional cooperation (when not punishing)
- Compute group_mean = average of S_j over j ≠ me (short‑run group cooperation rate).
- If group_mean ≥ T_high: play Cooperate (C).
- Else if group_mean ≤ T_low: play Defect (D).
- Else (T_low < group_mean < T_high): cooperate with probability p = (group_mean − T_low) / (T_high − T_low). That is, interpolate linearly between T_low and T_high. This makes behavior graded rather than brittle.
- Additional optimistic rule: if in the immediately preceding round a strict majority (≥ ceil(n/2)) of players contributed, prefer C (cooperate) to reward immediate collective success.
- Add tiny exploration: independently, with probability Epsilon_explore cooperate even if rule says defect, to probe for renewed cooperation from others.

6) Self‑protection adjustment
- Continuously compute my realized payoff in recent L = W rounds and compare to an estimate of payoffs I would have received if I had defected every one of those rounds given the observed others’ actions. If my realized payoff is significantly (e.g., > 5%) worse than that hypothetical defector payoff, lower T_high by 0.1 (become more defensive) and shorten probation windows by 1 for the next K = min(5, ceil(r/10)) rounds. This protects against being steadily exploited by subtle strategies. After K rounds without further exploitation evidence, restore thresholds.

Rationale and properties
- Collective mindset: start cooperative and reward cooperation from the group. The strategy’s default is to favor cooperation when the recent group cooperation rate is high (T_high trigger). It seeks to preserve public goods rather than giving up at first defection.
- Forgiveness and repair: punishment is limited and followed by probation to allow reform. This prevents permanent collapse from rare errors or noise.
- Proportionality and targeting: persistent low‑S_j players trigger punishment scaled by count of such players, so the strategy does not overreact to a single mistake and focuses corrective pressure on persistent free‑riding.
- Avoid catastrophic collapse: graded cooperation (probabilistic in middle band) reduces oscillations and prevents chain retaliation.
- Protection against exploitation: if my realized payoffs show I’m being exploited, the strategy tightens thresholds and shortens forgiveness, limiting losses against systematic defectors.
- Endgame handling: defect in the last round (and optionally be more cautious in the very final few rounds), which is a prudent concession to finite horizon reasoning; but because punishments and forgiveness are limited, cooperation can still be sustained well before the end.

Implementation notes (for a tournament)
- All decisions use only n, r, k, and the public history (contributions and payoffs). No communication or coordination required beyond observing actions.
- Parameter values (T_high, T_low, window sizes) may be tuned for the tournament environment; the above values are conservative defaults that balance robustness and collective welfare.
- The strategy is deterministic except for two small randomized components: probabilistic cooperation in the middle band and the small exploration epsilon. Randomness helps avoid deterministic exploitation cycles.

Example summary (short)
- Round 1: Cooperate.
- Thereafter: compute recent cooperation rates S_j. If group recent mean ≥ 0.70 → cooperate; ≤ 0.40 → defect; in between → cooperate with probability proportional to the mean. Detect persistent defectors (S_j ≤ 0.20); apply short, proportional punishment rounds (defect), then probation (cooperate) to allow reform. If my recent payoffs indicate exploitation, tighten thresholds temporarily. Always defect on the final round. Small probability of exploratory cooperation to restore lost cooperation.

This strategy aims to be collective (favoring and restoring cooperation), adaptive (reputation, graded response, payoff checks), and robust (limited punishments, forgiveness, self‑protection).
'''

description_COLLECTIVE_91 = '''
Collective Reciprocity with Graduated Punishment and Quick Forgiveness

Goal: sustain high group contributions while avoiding prolonged exploitation. Cooperate to signal willingness to build the public good; punish group-level defections promptly but briefly; forgive quickly when cooperation resumes. Decisions use only n, k, r and the public history of contributions.

Parameters derived from game:
- memory m = min(5, r) (lookback window)
- cooperation threshold T = 0.6 (require a clear majority of others cooperating to reciprocate)
- max punishment Pmax = min(4, r)
- endgame cautiousness G = min(2, max(0, floor(r/10))) (number of final rounds to be extra-cautious; always defect in final round)

Rule set (apply each round t = 1..r):

1) Endgame handling
- If r = 1: defect (no future to sustain cooperation).
- If t = r (final round): defect.
- If t > r - G (in the last G rounds before final): be cautious:
  - Cooperate this round only if every other player contributed in the immediately previous round; otherwise defect.
  - (This shortens the very endgame unraveling while still allowing cooperation if full cooperation persists.)

2) First round
- Cooperate in round 1 (signal willingness to cooperate and try to establish mutual cooperation), unless r = 1 (see endgame).

3) Normal rounds (not in endgame)
Define:
- For each previous round s, others' contribution fraction f_s = (sum_{j != me} c_j in round s) / (n-1).
- Recent cooperation rate R = average of f_{t-1}, f_{t-2}, ..., up to m most recent completed rounds (if fewer than m rounds exist, average available rounds).
- Last-round defectors D_last = number of players (excluding me) who defected in round t-1.

Decision:
A) If the entire group (all players including me) contributed in the previous round (everyone cooperated), then cooperate now (reward mutual cooperation).
B) Else if R >= T (recent majority of others have been cooperating), cooperate (reciprocate collective tendency).
C) Else (R < T): enter a brief punishment:
   - Defect this round.
   - Maintain a punishment counter L = min(Pmax, 1 + D_last). Defect for L consecutive rounds (the current round counts as the first).
   - During the punishment sequence, monitor history every round. If at any point after the punishment started you observe that recent cooperation rate R >= T (i.e., others have returned to majority cooperation), stop punishment immediately and resume cooperating next round (quick forgiveness).
   - If punishment completes without others restoring R >= T, reassess with the usual rules (recompute R); repeat punishment if group remains below threshold.

Notes on measurement and ties:
- When computing R and D_last, exclude your own actions so assessment reflects others’ behavior.
- If R equals T exactly, treat it as cooperating (bias toward restoring cooperation).
- Punishments are group-level (you defect against the whole group) because the game’s actions affect all players equally and public goods cooperate is a collective problem; this keeps the rule simple and computable with available information.

Robustness features:
- Starts cooperative to build trust with cooperative opponents.
- Requires a clear majority (T = 0.6) before cooperating, so small, isolated defections don’t collapse cooperation.
- Punishment length scales with observed immediate defection magnitude (1 + D_last) but is capped (Pmax) to avoid long mutual-defection cycles.
- Fast forgiveness: as soon as others resume majority cooperation, you immediately return to cooperating — this prevents prolonged welfare losses when some opponents recover.
- Endgame caution guards against last-round exploitation while still allowing cooperation if everyone keeps cooperating.

Collective mindset:
- The strategy always privileges group welfare when sustained reciprocal cooperation is present; it signals cooperation early, rewards unanimous cooperation, tolerates occasional slips, but punishes repeated or multi-player defection briefly and proportionally to encourage a return to cooperation rather than permanent retaliation.

Edge cases:
- If n = 2 the fractions are binary; rules apply the same (threshold means cooperate if the other cooperated in most recent rounds).
- If many different behaviors are present, the strategy converges to cooperating with those who reciprocate and defects against persistent free-riders; forgiveness allows reintegration if free-riders switch back.
'''

description_COLLECTIVE_92 = '''
Adaptive Collective Conditional Cooperator (ACCC)

Goal: sustain high collective contribution when others reciprocate, avoid being exploited by persistent free‑riders, forgive occasional noise, and defect in the last round where no future reciprocity exists. The strategy uses only the game parameters (n, r, k) and the observed history of all players' contributions.

Parameters derived from game inputs:
- Safety threshold for one‑round break‑even cooperation among others:
  p_star = (n - k) / (k * (n - 1)).
  Interpretation: if the recent fraction of other players cooperating is ≥ p_star, a single contribution can be non‑negative in expectation for this round.
- Memory window W = min(5, r). (Use up to the last 5 rounds, or fewer if the game is short.)
- Punishment length P = min(3, r). (Short, finite punishment to avoid permanent collapse.)
- Forgiveness margin delta = 0.05 (5 percentage points) and tolerance tol = 0.20 (20%): allow small deviations/noise before punishing.

State tracked:
- punish_remaining (integer, initially 0): rounds remaining in an active punishment phase.
- last_action (C or D), initially C.

Decision rules (applied at the start of each round t = 1..r):

1. Final round:
   - If t == r (last round), play D. (No future to enforce cooperation.)

2. First round:
   - If t == 1, play C. Set last_action = C. (Start by proposing cooperation.)

3. Compute recent cooperation statistics:
   - For rounds s = max(1, t - W) .. t - 1, count how many contributions each round.
   - Let total_other_C = total number of contributions by the other n-1 players across that window.
   - Let rounds_considered = number of rounds in the window (≥1 except t==1 handled above).
   - Let p_hat = total_other_C / ((n - 1) * rounds_considered). (Recent fraction of other players cooperating.)

4. Punishment handling:
   - If punish_remaining > 0:
       - Play D this round.
       - Decrement punish_remaining by 1.
       - Set last_action = D.
       - End decision for this round.
   - Else (no active punishment), continue.

5. Decide whether to cooperate or punish:
   - If p_hat >= p_star + delta:
       - Cooperate this round (play C). This means recent cooperation by others is strong enough to justify contributing.
       - Set last_action = C.
   - Else if p_hat <= p_star - delta:
       - Trigger punishment: set punish_remaining = P - 1 (we will play D this round and then P-1 additional rounds of D).
       - Play D this round. Set last_action = D.
         Rationale: clear, finite punishment discourages persistent defectors while allowing recovery.
   - Else (p_hat in the ambiguous band [p_star - delta, p_star + delta]):
       - Be generous/forgiving to keep cooperation if it exists:
           - If last_action == C:
               - Cooperate (play C) — Win‑stay behavior.
           - Else (last_action == D):
               - Defect (play D) — lose‑shift behavior until cooperation clearly improves.
       - Set last_action correspondingly.

6. Noise tolerance for isolated deviations:
   - If in the most recent single round (t-1) the fraction of other players who defected ≤ tol and p_hat is otherwise above p_star - delta, treat those as isolated/noise and favor cooperation (i.e., do not trigger punishment). This prevents one-off defections from collapsing cooperation.

Notes on behavior and rationale:
- Collective mindset: ACCC seeks and sustains mutual cooperation when enough others reciprocate, maximizing group payoff over time instead of short‑term individual gain.
- Robustness:
  - If most players are cooperators, ACCC cooperates and helps maintain high group returns.
  - If many players persistently defect, ACCC enters short, finite punishment phases and then rechecks; it will converge to defection in regimes dominated by defectors, protecting itself from exploitation.
  - Finite punishment + forgiveness prevents endless retaliation cascades and allows recovery when cooperation resumes.
- Edge cases:
  - Very short games: W and P are clipped to r to behave sensibly in tiny tournaments.
  - First round always cooperates to signal pro‑social intent; last round always defects because no future enforcement is possible.
- No communication or coordination needed; decisions use only observed contributions and the known parameters n, r, k.

Summary pseudocode (high level):
- Initialize punish_remaining = 0, last_action = C.
- For each round t:
  - If t == r: play D.
  - Else if t == 1: play C.
  - Else compute p_hat over last W rounds.
  - If punish_remaining > 0: play D; punish_remaining--.
  - Else if p_hat >= p_star + delta: play C.
  - Else if p_hat <= p_star - delta: set punish_remaining = P-1; play D.
  - Else (ambiguous band): play same action as last_action (C→C, D→D).
  - Apply noise tolerance rule to avoid punishing for tiny, isolated deviations.
  - Update last_action.

This strategy balances a collective aim (sustain cooperation when reciprocated) with robustness (short, proportional punishment and forgiveness), and uses only parameters and observed history.
'''

description_COLLECTIVE_93 = '''
Name: Collective Conditional Cooperation with Adaptive, Lenient Punishment (CCCAP)

Goal: Sustain high collective contributions for most of the repeated game by cooperating when the group is sufficiently cooperative, applying short proportionate punishments when the group falls below a cooperation threshold, and forgiving quickly so cooperation can resume. Parameters adapt to n, k, and remaining rounds to be robust across opponent types.

Parameters set from known game parameters
- n = number of players
- r = total rounds
- k = multiplier
- window length w = max(1, floor(r/5)) — recent rounds used to judge group behavior
- endgame length E = min(2, r) — last E rounds treated specially
- cooperation threshold tau = clamp(0.5, 0.95, 0.5 + (n - k) / (2*(n - 1)))
  - Intuition: if k is close to n (high public return), require only ~50% recent cooperation to continue cooperating; if k is near 1 (low return), require near-universal cooperation
- punishment scale factor S = 4 (controls how long we punish relative to the shortfall)
- forgiveness relaxation: when deciding to resume cooperation allow a slightly lower threshold tau_forgive = max(0.4, tau - 0.1)

State variables tracked in history
- For each past round t, record total contributions T_t (number of players who chose C)
- Active punishment timer P_timer (initially 0)

Decision rules (applied at the start of each round t = 1..r)
1. Special-case small horizon
   - If r == 1: defect (D) — no future to sustain cooperation.
2. Last rounds (endgame)
   - If remaining rounds including this one <= E:
     - If t == r (last round): defect (D). (One-shot dominant strategy.)
     - Else (in the last E but not final round): apply the regular rules below but be more conservative: require f >= max(tau, 0.8) to cooperate; otherwise defect. This reduces endgame exploitation while still allowing cooperation if near-unanimous.
3. First round
   - If t == 1: cooperate (C). Signal willingness to cooperate and attempt to establish a cooperative norm.
4. If P_timer > 0 (we are currently punishing): defect (D), then decrement P_timer by 1. After P_timer hits 0, re-evaluate with the normal rule next round.
5. Normal evaluation (not first round, not in forced punishment, not final single-round)
   - Compute recent average group cooperation fraction over last w rounds:
     f = (sum_{s = t-w .. t-1} T_s) / (n * min(w, t-1))
     (If no past rounds, treat f = 1 by convention so the opener cooperates.)
   - If f >= tau:
     - Cooperate (C). The group is sufficiently cooperative; reinforce the norm.
   - Else (f < tau):
     - Start a short proportionate punishment: set punishment length P = min( remaining rounds - 1, max(1, ceil( (tau - f) * S )) ).
       - Set P_timer = P - 1 (we will defect this round and then P-1 additional rounds).
       - Defect this round (D).
     - Rationale: the size of the punishment scales with how far the group fell short of the target; punishments are short so we do not lock into long vendettas.
6. Rapid forgiveness / re-entry rule
   - If you previously defected but the most recent single round (t-1) shows near-unanimous cooperation (T_{t-1} >= n - 1) then cooperate now. This allows quick re-entry after isolated mistakes by self or others.
7. Safety checks
   - Never set P_timer to exceed remaining rounds minus 1 (to avoid wasted punishment at the very end).
   - If the group immediately responds to punishment and f (recomputed once punishment is ongoing) reaches >= tau_forgive, stop punishing early and resume cooperation.

Collective mindset and rationale
- Start cooperatively to try to establish mutual contribution.
- Cooperate when the group is demonstrably cooperating (f >= tau). The threshold adapts to the efficiency k: when the public good is more valuable relative to private retention, the strategy tolerates lower observed cooperation because mutual benefit is easier to sustain.
- When group cooperation drops, apply a short, proportionate, easily-understood punishment (defect for a small number of rounds). The punishment is explicitly tied to the size of the shortfall, minimizing unfair long vendettas and limiting damage to group welfare.
- Forgive quickly if the group shows improvement (tau_forgive or near-unanimous recent cooperation). This makes cooperation resilient against noise and mistakes and allows the group to return to high collective payoffs.
- Endgame caution: in the last few rounds be conservative (require stronger evidence to keep cooperating) and always defect in the very last round to avoid being exploited when no future reciprocity is possible.

Behavioral summary (one-sentence rules)
- Open with cooperation; cooperate while the recent group cooperation rate meets an adaptive threshold (tau); if the rate falls below tau, defect for a short, proportional punishment period, then forgive if group behavior improves; be conservative in the final rounds and always defect in the last round.

This strategy uses only game parameters and observed history, is responsive to a wide set of opponent behaviors (from unconditional defectors to conditional cooperators), aims to preserve collective welfare as long as reciprocity is plausible, punishes exploiters in a limited way, and forgives quickly so cooperation can be reestablished.
'''

description_COLLECTIVE_94 = '''
Adaptive Collective Conditional Cooperator (AC3)

Summary goal
- Maximize collective welfare by sustaining high cooperation when others reciprocate, while being robust to exploitation by defectors. The strategy is entirely history-dependent and uses simple, transparent rules: start by cooperating, reward cooperation, punish defections in proportion, forgive and probe for recovery, and favor cooperation even late in the game when the group is cooperating.

Notation used (informal)
- n = number of players, r = total rounds, k = multiplier.
- t = current round (1..r).
- For any player j, COOP_RATE_j = fraction of rounds (in a recent window) in which j contributed.
- RECENT_WINDOW W = min(5, r) (the number of most recent rounds used to evaluate recent behavior).
- OTHER_FRACTION = fraction of the other n-1 players who cooperated in the previous round (or whose COOP_RATE_j over W ≥ threshold).
- DEFECT_SEVERITY = fraction of players who defected in the previous round (1 - OTHER_FRACTION).
- PUNISH_LENGTH = number of rounds we will defect to discipline; computed below.

Decision rules (what I do each round)
1. First round (t = 1)
   - Cooperate. This signals willingness to build a cooperative norm.

2. Compute the recent picture
   - Look at the last W rounds (or all past rounds if fewer). For each other player j compute COOP_RATE_j over that window.
   - Let S = number of other players with COOP_RATE_j ≥ 0.6 (they have been consistently cooperating recently).
   - Let OTHER_FRACTION_PREV = fraction of other players who cooperated in the immediate previous round (t-1), if t>1. If t=1 this is undefined and treated as 1 for initial goodwill.

3. Main cooperation rule
   - If OTHER_FRACTION_PREV ≥ 0.5 OR S ≥ (n-1)/2:
       - Cooperate this round.
     Rationale: if a majority of players cooperated very recently (or many players have been reliable cooperators), continue cooperating to sustain high group payoffs.

4. Proportional punishment when cooperation collapses
   - If OTHER_FRACTION_PREV < 0.5 AND S < (n-1)/2:
       - Enter a punishment phase: defect for PUNISH_LENGTH consecutive rounds, where
           PUNISH_LENGTH = 1 + round(3 * DEFECT_SEVERITY).
         (Thus if only a few defected, punish briefly; if many defected, punish longer up to about 4 rounds, but never longer than remaining rounds.)
       - The purpose is to make defection costly for others so cooperating becomes attractive again.
   - During a punishment phase I defect regardless of others’ moves until the phase ends.

5. Recovery and forgiveness
   - After a punishment phase ends, play one test cooperation round:
       - Cooperate in that test round to signal willingness to restore cooperation.
       - If a majority respond by cooperating in the next round, resume normal cooperation rule (step 3).
       - If not, re-enter punishment logic (step 4) with PUNISH_LENGTH adjusted by the new DEFECT_SEVERITY.
   - Always allow forgiveness: never punish forever for a single lapse. Punishment length scales with how many players defected.

6. Occasional probing to escape long mutual defection
   - If the group has been in a mutual-defection state for more than max(3, r/10) consecutive rounds, I will unilaterally cooperate every T_probe = max(3, round(r/10)) rounds as a probe (one cooperative round) to test whether others will rejoin cooperation. If a probe is met by a majority cooperating next round, switch back to normal cooperation rule.

7. Endgame behavior (last rounds)
   - Collective orientation: if in the immediately preceding round a majority cooperated, I will cooperate in the final round(s) as well (including round r). That preserves group payoff when the group is mutually cooperating.
   - If cooperation has collapsed and a majority defected in the round before the last few rounds, I will not unilaterally cooperate in the final round(s) (defect to avoid being exploited). Concretely:
       - If rounds remaining ≤ 2 and OTHER_FRACTION_PREV < 0.5 and S < (n-1)/2, defect.
       - Otherwise follow the main rule/punishment/recovery rules. The final-round cooperation exception preserves group welfare when others are cooperating but protects me from being a last-round sucker.

8. Tie-breakers / small groups / extreme k
   - If n = 1 (solo player), always cooperate (the token returns k).
   - If k/n is very large (close to 1), I become more generous: lower the bar for S and OTHER_FRACTION_PREV (I treat OTHER_FRACTION_PREV threshold as 0.4) because individual cost of cooperating is smaller relative to group benefit.
   - If k/n is very small (cooperation is a high private cost relative to private return), I require a clearer majority (OTHER_FRACTION_PREV ≥ 0.6 or S ≥ 0.75*(n-1)) before cooperating.

Collective alignment explained
- The strategy starts by offering cooperation and rewards others who reciprocate, which supports high collective payoffs when many players are willing.
- Punishment is proportional and temporary rather than permanent (no grim-trigger). This reduces the risk of irreversible collapse caused by single mistakes or noisy defection and makes cooperation resilient.
- Regular probes and an explicit recovery mechanism make it possible to re-establish cooperation even after long breakdowns.
- In the endgame I favor preserving cooperation if the group is already cooperating (prioritizing collective welfare), but I protect myself from unilateral last-round exploitation if the group has defected.

Robustness notes
- Uses only publicly observed history (past actions/payoffs) and the game parameters (n, r, k).
- Works against pure defectors (punishes them, minimizing losses), conditional cooperators (rapidly establishes mutual cooperation), and mixed/chaotic behaviors (adapts punishment length and probes).
- Avoids permanent punishment that can lock the group into low-payoff outcomes; punishment is strong enough to deter persistent defection but forgiving enough to recover cooperation.

Concrete pseudocode-style decision summary (per round)
1. If t = 1: Cooperate.
2. Compute COOP_RATE_j over W and OTHER_FRACTION_PREV.
3. If currently inside a previously started punishment phase: Defect (until punishment rounds expire).
4. Else if OTHER_FRACTION_PREV ≥ 0.5 or at least half of others have COOP_RATE_j ≥ 0.6: Cooperate.
5. Else: set PUNISH_LENGTH = 1 + round(3 * (1 - OTHER_FRACTION_PREV)) (cap at remaining rounds); Defect for PUNISH_LENGTH rounds.
6. After punishment, run one cooperative test round; if majority respond by cooperating next round, resume cooperation; else repeat punishment logic.
7. Occasionally (if mutual defection persists) send a probe cooperation every T_probe rounds.
8. In final 1–2 rounds: if majority cooperated just before, cooperate; if not, defect to avoid exploitation.

This strategy is simple to follow, transparent to opponents, and explicitly tuned to favor group welfare while limiting exploitation.
'''

description_COLLECTIVE_95 = '''
Name: Proportional Reciprocity with Forgiveness (PRF)

High-level goal
- Aim for sustained full cooperation (everybody contributes) because that maximizes collective payoff.
- Be robust to exploiters: punish only when necessary, punish proportionally and briefly, then forgive to restore cooperation.
- Be lenient to single mistakes and noisy play; escalate only when poor cooperation is persistent.

Parameters derived from game inputs
- n, k, r: game parameters (players, multiplier, rounds).
- Window W = min(10, max(3, floor(r/4))) — number of recent rounds used to estimate behavior.
- High cooperation threshold q_high = 0.80.
- Low cooperation threshold q_low = 0.50.
- Punishment unit L = 2 rounds (base length to punish a breach).
- Test cadence T_test = 3 rounds (how often to probe for restored cooperation while punishing).
- Final-round safety: last_round = r.

State tracked (computed from public history each round)
- For each other player j: coop_rate_j = fraction of rounds in last W where j contributed.
- avg_others = average of coop_rate_j over all other players.
- last_round_all = true if every other player contributed in the immediately preceding round; false otherwise.
- persistent_defectors = set of players with coop_rate_j <= 0.20 (very low recent cooperation).
- my_current_punish_timer (local): how many remaining rounds I will defect as punishment (starts at 0 and is recomputed as below).

Decision rules (what I do each round)
1. First round (t = 1)
   - Contribute (C). Start by leading with cooperation.

2. Final round (t = last_round)
   - Default: defect (D). The one-shot dominant move is to defect in the very last round.
   - Exception: if last_round_all is true and avg_others >= q_high (i.e., everyone has been reliably cooperative up to the end), contribute once more to capture a final collective benefit. This exception is only if evidence shows cooperation is genuine and stable.

3. If currently in an active punishment period (my_current_punish_timer > 0)
   - Play D for this round.
   - Decrement my_current_punish_timer by 1.
   - On rounds where my_current_punish_timer is > 0 but it is also a test round (every T_test rounds during punishment), play C instead with small probability 0.25 to probe whether others have returned to cooperation. If others respond by cooperating consistently on subsequent rounds, cancel remaining punishment.

4. Normal operation (not first round, not forced final-round exception, not currently punishing)
   - Immediate reciprocity rule:
     a) If last_round_all is true (all others contributed last round), play C. Reward direct recent cooperation immediately.
     b) Else compute avg_others over window W.
         - If avg_others >= q_high: play C (sustained cooperation).
         - If avg_others <= q_low: play D (sustained poor cooperation).
         - If q_low < avg_others < q_high: play C with probability p = (avg_others - q_low)/(q_high - q_low); otherwise play D. (This smoothly interpolates cooperation as group reputation improves.)
   - After choosing according to the above, check for persistent defectors:
     - If persistent_defectors is non-empty and avg_others >= 0.5 (i.e., majority are not uniformly bad), set my_current_punish_timer = min(L * |persistent_defectors|, floor(r - t)) to deliver a short, proportional sanction period. The sanction is collective (I withhold contribution) because I cannot single out contributions; it is scaled by number of persistent defectors but capped so I do not self-harm indefinitely.
     - If persistent_defectors is empty, do not initiate new punishments.

5. Forgiveness and recovery
   - After any punishment period, re-evaluate avg_others over the most recent W rounds.
   - If avg_others >= q_high, immediately stop punishing and resume cooperating.
   - If avg_others remains low, continue the measured punishment policy but keep punishments short and proportional rather than permanent.

Rationale and robustness notes
- Start cooperative to invite mutual cooperation and achieve high group payoffs.
- Use immediate reciprocity: reward recent unanimous cooperation instantly; this encourages stable, detectable cooperation clusters.
- Use windowed averages and two thresholds (low/high) so the strategy is lenient to isolated defections and noise (single mistakes do not trigger permanent retaliation) but escalates when poor cooperation is persistent.
- Punishments are short, proportional, and recoverable: they signal consequences to persistent defectors without locking into permanently low-payoff outcomes (grim-trigger is avoided).
- Mixed strategy in borderline situations (q_low < avg < q_high) makes behavior less exploitable by sophisticated adversaries and allows gradual rebuilding of trust.
- Final-round defection protects against endgame exploitation, with an exception if cooperation has clearly been stable up to the last round.
- The strategy depends only on public history and the game parameters (n, k, r). It requires no communication or pre-play coordination.

Behavioral summary
- Lead with cooperation, keep cooperating while the group shows high cooperation, tolerate occasional lapses, punish persistent defectors briefly and proportionally, forgive and resume cooperation when others recover, and defect in the very last round unless cooperation has been demonstrably stable.
'''

description_COLLECTIVE_96 = '''
Strategy name: Adaptive Collective Reciprocity (ACR)

Principles (collective mindset)
- Aim to sustain high group contributions when others do the same, but avoid being repeatedly exploited.
- Use reciprocity and graded, temporary collective punishments to deter free riding.
- Be forgiving and adaptive: repair cooperation after mistakes or short runs of defection.
- Use game parameters (n, k, r) to set sensitivity: when the public-good multiplier k/n is closer to 1, individual incentives align more with cooperation so be more tolerant; when k/n is small, be stricter.

State and derived quantities (computed from known parameters and full public history)
- t = current round (1..r).
- For any past round s, let coop_rate_s = (number of other players who contributed in s) / (n - 1).
- Choose a recent window size w = min(max(3, floor(r/10)), r). Use this window for short-term signals.
- Short-term cooperation R_short = average of coop_rate_s over the most recent w rounds (or all past rounds if fewer than w exist).
- Long-term cooperation R_long = average of coop_rate_s over all completed rounds (if none, treat as 1 for optimistic start).
- Parameterize sensitivity by lambda = k / n (0 < lambda < 1). Higher lambda → more tolerant of others’ occasional defection.

Automatically set thresholds (functions of lambda)
- High-cooperation threshold H = clamp(0.7 - 0.3 * lambda, 0.45, 0.7).
- Low-cooperation threshold L = H - 0.30 (clamped so L ≥ 0.05).
(Interpretation: if R_short ≥ H, the group is behaving cooperatively; if R_short ≤ L, the group is mostly defecting.)

Punishment bookkeeping
- punish_until: a round index; if current t ≤ punish_until then the strategy is in punishment mode (play D).
- When a punishment is initiated, set punish_until = t + P - 1 for a finite P defined below.

Decision rules (what I play this round)
1. Round 1: play C (signal willingness to cooperate).
2. If t is within an active punishment period (t ≤ punish_until): play D.
3. Else if t = r (last round):
   - Cooperate (C) only if both conditions hold:
     a) R_long ≥ 0.80 (history shows sustained cooperation), and
     b) R_short ≥ H (recent behavior remains cooperative).
   - Otherwise defect (D). Rationale: avoid being exploited in the final round unless the group has reliably supported cooperation.
4. Else (intermediate rounds):
   a) If R_short ≥ H: play C (reward and sustain cooperation).
   b) Else if R_short ≤ L: play D (protect against persistent free-riding).
   c) Else (ambivalent middle region): play C if R_long ≥ 0.6, otherwise play D.
      - Intuition: give the benefit of the doubt when historical cooperation is decent; otherwise be cautious.

When to initiate punishment and its severity
- Trigger: If in the most recent round (t-1) the last-round cooperation among others fell by a sudden large drop relative to the long-run average—
  i.e., coop_rate_{t-1} ≤ max(0.5 * R_long, 0.25) and R_long ≥ 0.6 — then interpret this as targeted shirking and initiate a short collective punishment.
- Punishment length P = min( max(1, ceil((1 - R_short) * 4)), floor(r/4), 4 ).
  - This yields 1–4 rounds of collective defection scaled by severity and limited to a small fraction of the game.
- During punishment I play D. Punishment is collective (I stop contributing), aimed at causing defectors to lose the cooperative benefit and thus restoring incentives.
- If many players defect persistently (R_short stays ≤ L), punishments persist because the normal decision rules cause continued D.

Forgiveness and repair
- After punish_until passes, resume regular decision rules.
- If cooperation returns (R_short ≥ H for one full window), immediately resume contributing.
- If a lapse appears to be accidental or short (one round) then punishment will be short (P small), allowing quick repair.

Short games and edge cases
- Very short games (r ≤ 4):
  - Round 1: play C.
  - For rounds t > 1: be more conservative — require R_short ≥ H and R_long ≥ 0.7 to keep cooperating; otherwise play D. This reflects vulnerability to endgame exploitation in short games.
- If no history exists except the immediate previous round, rely more on R_short defaults (treat R_long optimistically as 1 only until more data appears).
- If n = 2 (public good like Prisoner’s Dilemma): thresholds still apply; punishments and forgiveness operate the same way using the single other player’s actions.

Summary of behavioral pattern
- Start cooperative to signal intent.
- Cooperate when the recent group behavior is cooperative (above an H threshold that decreases as lambda increases).
- Defect when the recent behavior is clearly poor (below L) or in last round unless the group has been reliably cooperative.
- When a sharp, surprising drop in cooperation is observed after a period of good cooperation, initiate a short, graded collective punishment (temporary defection) proportional to the severity, then forgive and return to cooperation if others do too.
- Always base decisions only on public history and known parameters (n, k, r); no communication or coordination is assumed.

Why this is robust and collective
- Encourages and sustains mutual cooperation when others respond, preserving collective welfare.
- Uses measurable group signals (recent and long-term cooperation rates) so it adapts to many opponent types (steady cooperators, steady defectors, conditional players, random players).
- Punishments are finite and proportional, avoiding endless mutual collapse while still providing credible deterrence.
- A last-round safeguard prevents routine exploitation in finite-horizon settings except when the group has demonstrated strong, sustained reciprocity.
'''

description_COLLECTIVE_97 = '''
Collective Harmony — conditional, forgiving, and proportional cooperation

Summary idea (one-sentence): Start by cooperating to signal cooperation, keep contributing whenever a clear majority of players have been cooperating recently, punish defections briefly and proportionally, forgive and allow re-entry, and defect in the very last round to avoid endgame exploitation. All decisions use only the publicly observed history and the known parameters (n, k, r).

Parameters computed from the game parameters (used throughout)
- Window W for recent history: W = min(5, r−1). (Look at at most the last 5 rounds; if fewer rounds exist use all past rounds.)
- Reliability threshold φ: default 60% (0.6) of rounds in the window. Adjust φ based on multiplier:
  - If k/n ≥ 0.7, set φ = 0.50 (be more willing to cooperate when group return is high).
  - If k/n ≤ 0.4, set φ = 0.70 (be stricter when group return is weak).
- Group threshold M: require at least M = ceil(φ * n) players to be “reliable” to consider full cooperation.
- Punishment length P: normally 2 rounds; if repeated exploitation occurs increase to 3. Never punish longer than remaining rounds − 1.
- Exploration/forgiveness probability ε: 0.10 (10%) — when in a punishment state occasionally cooperate to re-start cooperation and avoid deadlocks.
- Endgame safe-guard: always defect in the final round (round r). In the penultimate round be cautious: only cooperate if history shows strong, recent cooperation (see rules below).

How we classify past behavior
- For each player j (including yourself), compute f_j = fraction of rounds they contributed in the last W rounds.
- Mark player j as reliable if f_j ≥ φ.

Decision rules (round t, 1 ≤ t ≤ r)
1. First-round rule (t = 1)
   - Cooperate (contribute 1). This announces a cooperative intent and gives the group a chance to establish mutual cooperation.

2. Final-round rule (t = r)
   - Defect (do not contribute). This prevents being exploited in a one-shot endgame where no future reciprocity can be gained.

3. General rule for intermediate rounds (1 < t < r)
   - Compute counts from the most recent W rounds (or all past rounds if fewer):
     - Count reliable players R = number of players with f_j ≥ φ.
     - Compute last-round cooperation total L = number of contributors in round t−1.
   - If R ≥ M (a clear majority of players have been reliable recently), then cooperate this round.
     - Rationale: most players reciprocate, so contributing helps re-enforce cooperation and maximizes group welfare.
   - Else (R < M):
     - If last-round cooperation L ≥ M (the immediate past round was a cooperative round by the majority), cooperate this round as a short-term reward for the recent majority behavior.
     - Otherwise initiate a limited punishment phase:
       a) Defect for up to P rounds (or until remaining rounds force endgame behavior). This reduces payoff to persistent defectors and signals cost of defection.
       b) During punishment, monitor f_j for all players. If at any time R rises to ≥ M (i.e., the majority resume cooperating), stop punishment immediately and resume cooperation.
       c) During the punishment phase, with small probability ε, make a single cooperative move (exploration/forgiveness). This avoids indefinite cycles of mutual retaliation and allows re-establishing cooperation if others respond.
   - Penultimate round (t = r−1): be cautious — only cooperate if R ≥ M and last round(s) show stable cooperation (for example, if at least two of the last W rounds were majority-cooperation). If history is mixed or punishment is ongoing, defect to avoid being exploited in the final two rounds.

4. Handling isolated defectors vs mass defection
   - If only a few players are unreliable (R = n − 1 or R = n − 2), keep cooperating (do not punish the whole group for one or two outliers) because strict targeted exclusion is impossible in PGG; instead rely on limited punishment phases to push outliers toward cooperation.
   - If mass defection (R very small), switch to lenient exploration: cooperate occasionally with probability ε to probe whether others will respond; otherwise continue defecting until a sufficient fraction becomes reliable.

5. Re-entry and forgiveness
   - A player who was unreliable can regain reliable status by cooperating in enough rounds so that f_j ≥ φ in the W-window. When reliable count R rises to ≥ M, the strategy immediately resumes cooperation.
   - Punishment is never permanent (no “grim” infinite punishment). Punishment is proportional (P rounds) and reversible.

6. Special handling when r is very small
   - If r = 1: defect (no future).
   - If r = 2: cooperate round 1 only if prior knowledge suggests others are likely cooperative; default: cooperate round 1, defect round 2 (cooperate-first to try to gain group payoff, but accept risk in small horizon).
   - More generally, if remaining rounds ≤ P, shorten punishment to ensure you do not waste remaining opportunities for rebuilding cooperation.

Collective mindset justification (how this favors group outcomes)
- Start cooperatively to give the group the chance to realize the higher total payoff when many contribute.
- Require a clear recent majority of reliable cooperators before maintaining cooperation continuously — this reduces exploitation by defectors while still rewarding and sustaining groups that reciprocate.
- Punish briefly but fairly: short punishments deter defectors but are reversible, which prevents long lockouts and preserves opportunities to rebuild cooperation.
- Forgiveness and occasional probing break cycles of mutual retaliation and allow re-establishing cooperation after noise or mistakes.
- By defecting in the last round (and being cautious near the end), the strategy avoids being exploited in the irreversible endgame while having already tried to build cooperation earlier when reciprocity could pay off.

Practical notes and robustness
- All rules use only n, k, r and the public history (who cooperated each round). No communication or coordination beyond observed actions is assumed.
- Default numeric choices (W = 5, φ around 0.6, P = 2, ε = 0.10) are conservative and perform well across many opponent types; the brief adaptability of φ with k/n makes the strategy more willing to cooperate when the public-good multiplier makes group cooperation especially valuable.
- The method tolerates noisy opponents (forgiveness and probes), exploits pure defectors (punishments remove incentive), and rewards reciprocal strategies (rapid resumption of cooperation once reciprocation is observed).

End of strategy description.
'''

description_COLLECTIVE_98 = '''
Collective Gradual Reciprocity (CGR)

Principles (collective mindset)
- Aim to sustain high group contributions because group payoff rises when people contribute, even though a single contribution is individually costly.
- Reward cooperative groups by cooperating; punish defections in a measured, proportional way so that punishments encourage return to cooperation rather than endless retaliation.
- Be forgiving and occasionally test recovery so accidental mistakes or exploratory opponents do not collapse cooperation.
- Be conservative near the game end: reduce risk of being exploited when there is no time to punish.

Parameters (computed from game parameters and history)
- w = min(5, r) — lookback window for short-term cooperation trends.
- eps = 0.05 — small random exploration / forgiveness probability (useful to probe and recover).
- P_max = min(4, max(1, floor(r/5))) — maximum punishment length in rounds.
- Cooperation threshold τ: the fraction of contributions (averaged over players and last w rounds) at or above which I treat the group as "cooperative". Choose τ = 0.65 adjusted toward greater leniency when the public good is more efficient: if k is close to n (k/n near 1), reduce τ linearly to a floor 0.5. Concretely:
  - τ_base = 0.65
  - leniency = 0.15 * ((k - 1) / (n - 1))  (this is 0 when k≈1, approaches 0.15 as k→n)
  - τ = max(0.5, τ_base - leniency)

High-level rule summary
1. Signal cooperation: Cooperate in the first round (C) to show willingness to build cooperation.
2. Monitor: After each round t>1, compute cooperation_rate = average fraction of players who contributed across the last w rounds (count contributions each round divided by n, then average).
3. Cooperate if the group is cooperative:
   - If cooperation_rate ≥ τ, play C (cooperate).
4. When cooperation drops (trigger punishment):
   - If cooperation_rate < τ, enter a proportional punishment phase:
     - Compute defectors_last_round = number of players who played D in the most recent round.
     - Set punishment_length = min(P_max, max(1, defectors_last_round)). (If many defected, punish longer up to P_max.)
     - During the punishment phase, play D for punishment_length consecutive rounds.
5. Graduated return and probation:
   - Immediately after a punishment phase ends, play one probation cooperative round (C). If in that probation round the cooperation rate (looking back w rounds including that probation) returns to ≥ τ, resume normal cooperation rules (step 3). If not, repeat a punishment phase with length recalculated from the most recent round.
6. Occasional probing/forgiveness:
   - At any decision point, with probability eps play the opposite action (cooperate during a punishment phase, or defect when set to cooperate) to test if others are ready to return to cooperation or to deter being exploited by a cycle. This small randomness prevents indefinite lock-step punishment cycles and allows recovery from mistakes.
7. Final rounds / endgame handling:
   - In the final round (t = r), defect (D) unless the previous round was unanimous cooperation (all n players cooperated). Rationale: there's no future to enforce cooperation, so avoid being the only cooperator; but reward a unanimous cooperative group by cooperating in the last round as a final-group-minded gesture.
   - In the last s rounds where s = min(3, floor(r/10)+1) (a short endgame window), linearly reduce τ toward 0.5 to allow continuation of cooperation if it is already strong, but otherwise be slightly more defensive than in the long middle of the game.

Edge cases and clarifications
- If history is too short to fill the w-window, compute cooperation_rate over the available rounds.
- If multiple punishment phases would overlap, extend the current punishment to the longer of the remaining punishment and any newly computed punishment_length (never shorten a pending punishment because that could invite exploitation).
- If the group shows very low cooperation persistently (cooperation_rate remains < 0.2 for more than 2w rounds), switch to a conservative steady-state: defect every round except with probability eps cooperate occasionally to probe for change.
- If an isolated single mistake occurs (one round with a small decrease in cooperation), the proportional punishment mechanism usually responds with short punishment and immediate probation, limiting the cost of accidental deviations.

Why this works in heterogeneous tournaments
- Starts by signaling willingness to cooperate, so it can form mutually beneficial patterns with reciprocity-minded opponents.
- Punishments are proportional (number of defectors → punishment length) so exploitable free-riders are discouraged but a single defection does not trigger permanent retaliation.
- Forgiveness and small random probing avoid permanent breakdowns caused by noise or simultaneous tit-for-tat cycles.
- Endgame conservatism prevents being exploited when no future deterrent remains, but still rewards unanimously cooperative groups in the final round.
- All decisions use only game parameters (n, r, k) and observed history, no external coordination or assumptions about others’ rules.

Concluding rule (succinct)
- Start by cooperating. Cooperate while recent average cooperation ≥ τ. If it falls below τ, defect for a short punishment proportional to how many defected, then give a cooperative probation round. Use small random probes to recover from mistakes. Be slightly more defensive in the final rounds, defect in the very last round unless everyone cooperated previously.
'''

description_COLLECTIVE_99 = '''
Adaptive Collective Conditional Cooperator (ACCC)

Goal (collective mindset)
- Try to sustain near-universal contribution because that maximizes group welfare.
- Protect myself from persistent free-riders by reducing contributions when the group is largely defecting.
- Be forgiving and probe for restored cooperation so cooperation can re-establish.

Constants (derived from game parameters r, n, k; these are fixed rules the strategy uses)
- endgame_length = min(2, r)  (I will defect in the final endgame_length rounds because there is little or no future to reward cooperation)
- recent_window = min(3, t-1) (use up to the last 3 rounds of history at round t>1)
- high_threshold = 0.80 (treat group as highly cooperative if >= 80% of others cooperated recently)
- low_threshold = 0.20 (treat group as uncooperative if <= 20% cooperated recently)
- majority_threshold = 0.50
- forgiveness_punish_length = 2 (if I punish by defecting I punish for up to 2 rounds before probing)
- probe_interval = 7 (if I have been defecting for a while, I probe periodically to see if cooperation can restart)

State I maintain from history
- For each player j (including myself) keep long-run cooperation frequency freq_j = (# times j contributed in past rounds) / (rounds played so far).
- recent_coop_rate = fraction of OTHER players who contributed averaged over the most recent recent_window rounds (if recent_window = 0, treat as undefined).
- last_round_coop_rate = fraction of OTHER players who contributed in the immediately previous round (if no previous round, undefined).
- rounds_since_my_last_coop and rounds_since_group_last_coop (for probing logic).

Decision rules (what I do in round t)

1) Endgame
- If t > r - endgame_length: choose D (defect). Rationale: little/no future to enforce reciprocity.

2) First round
- If t = 1: choose C (start by cooperating to signal willingness to create and sustain cooperation).

3) General rounds (1 < t <= r - endgame_length)
- Compute last_round_coop_rate (fraction of others who contributed last round).
- Compute recent_coop_rate (average fraction of others cooperating across up to recent_window most recent rounds).
- Compute group_long_run_coop_rate = fraction of OTHER players whose freq_j >= 0.60 (i.e., the share of players who are generally cooperators).

Apply these checks in order and act at the first applicable rule:

A. Strong cooperation signal -> cooperate
- If recent_window > 0 and recent_coop_rate >= high_threshold: choose C.
  (Many others have been cooperating consistently — help maintain it.)

B. Majority reciprocity -> cooperate
- Else if last_round_coop_rate >= majority_threshold: choose C.
  (If a majority of others cooperated last round, reciprocate.)

C. Long-run cooperators -> cooperate
- Else if group_long_run_coop_rate > 0.5: choose C.
  (If more than half of other players are reliable cooperators over time, cooperate to support collective outcome.)

D. Probative reconciliation -> probe for renewed cooperation
- Else if I have been defecting for forgiveness_punish_length or more consecutive rounds AND (t mod probe_interval == 0):
  - choose C for one round to probe whether others will return to cooperation.
  - If probe succeeds (others respond by increasing cooperation on the next round), resume cooperation per the above rules.
  - If probe fails (others continue defecting), return to defection and resume punitive stance.

E. Punish and protect -> defect
- Else if recent_coop_rate <= low_threshold or last_round_coop_rate < majority_threshold:
  - choose D (defect) to avoid exploitation and to punish widespread free-riding. Punish only up to forgiveness_punish_length rounds before probing as in D.

F. Fallback stochastic reconciliation (if no clear signal)
- Else (intermediate ambiguous situations):
  - cooperate if last_round_coop_rate >= 0.4 (slightly below majority) AND group_long_run_coop_rate >= 0.4;
  - otherwise defect.
  - This breaks ties toward cooperation when there is some positive signal but not a clear majority.

Noise-resilience and forgiveness
- Treat isolated single defection(s) by otherwise reliably cooperative players as likely noise: rely on long-run freq_j and recent_coop_rate, not single deviations, to avoid overreacting.
- Punishment length is capped (forgiveness_punish_length) so I do not lock into permanent retaliation; I periodically probe for recovery.

Protection against persistent defectors
- If a persistent minority of players (>= 40% of others) have freq_j <= 0.20 (long-run free-riders), I reduce my willingness to restore cooperation: I require recent_coop_rate >= 0.75 or group_long_run_coop_rate > 0.6 before I resume cooperating. This reduces exploitation by persistent defectors.

Summary rationale (how this is collective)
- I begin by showing cooperative intent and then follow a conditional-cooperation rule: reciprocate when the group is cooperating, with measured punishment when many free-ride.
- I emphasize group-level signals (recent fraction cooperating and long-run reliability of players) rather than trying to target individuals (simultaneous moves prevent reliable targeting).
- I limit punishment length, include probing and forgiveness, and resist exploitation by persistent defectors. This combination aims to sustain high collective payoffs when others are willing, while protecting myself when they are not.
'''

description_COLLECTIVE_100 = '''
Strategy name: Collective Adaptive Conditional Cooperator (CACC)

Goal: maximise long-run group payoff by stabilising high contribution levels while avoiding sustained exploitation. The strategy (1) signals cooperative intent, (2) conditionally rewards conditional cooperators, (3) applies short, proportional punishments to discourage persistent free-riding, and (4) is forgiving so cooperation can be re-established. It uses only game parameters (n, r, k) and observed history.

Parameters (computed once from n, r, k)
- W (window for statistics) = max(3, min(10, floor(r/5))). Use all prior rounds if fewer than W exist.
- Build rounds B = min(4, max(1, floor(r/10))) — initial trust-building phase.
- Endgame rounds K_end = min(3, max(1, floor(r*0.05))). In the K_end final rounds switch to defect (see edge cases).
- Good cooperation threshold T_good = 0.80 (fraction of players cooperating in window considered “high cooperation”).
- Bad cooperation threshold T_bad = 0.35 (fraction considered “low cooperation”).
- Free-rider tolerance delta = 0.40 (used to identify players contributing much less than the group norm).
- Base punishment length P_min = 1 round; scale up to P_max = 4 based on severity.
- Use a small randomized element in ambiguous cases to avoid deterministic exploitation.

State and statistics maintained each round
- For every player j (including myself) track their contributions in the last W rounds; compute f_j = fraction of those rounds in which j contributed.
- f_group = average_j f_j (equivalently, fraction of contribution actions in the window).
- For reciprocity detection: for each player j, track two counts over the window: how often j cooperated in the round after I cooperated (C_after_C) and after I defected (C_after_D). Compute r_j = C_after_C / max(1, number of times I cooperated in previous-round spots) minus C_after_D / max(1, number of times I defected in previous-round spots). Positive r_j suggests j tends to reciprocate my cooperation.

Decision rules (per round t)
1. Edge cases — first round and endgame:
   - If t = 1: play C (signal cooperative intent).
   - If t > r - K_end (i.e., in final K_end rounds): play D. (This prevents endgame exploitation and is consistent, but K_end is small so most rounds remain cooperative-capable.)

2. Build phase (1 < t ≤ B):
   - Play C every round to create an initial cooperative baseline and collect statistics.

3. Standard adaptive phase (B < t ≤ r - K_end):
   - Update f_group, f_j and r_j from history (using the last W rounds or all available if fewer).
   - If currently in punishment mode (see punish trigger below) and punishment rounds remain: play D, decrement punishment counter, then continue to next round.
   - Identify free-riders: players with f_j ≤ max(0.15, f_group - delta). Let FR = fraction of players identified.
   - Punishment trigger:
     - If FR ≥ 0.20 (i.e., a material minority or more are persistent low contributors) OR if f_group has dropped by more than 0.25 compared to the previous window, trigger a short proportional punishment:
       - Set punishment length P = min(P_max, P_min + ceil(3 * FR)). Enter punishment mode for P rounds and play D this round (punish the group briefly to signal that low cooperation is unacceptable).
       - Record that we are punishing; continue to next round after punishment.
   - Reciprocity reward and targeted encouragement:
     - If no punishment is triggered and f_group ≥ T_good: play C (reward the cooperative environment).
     - Else if f_group ≤ T_bad: play D unless at least one player j has r_j ≥ 0.30 and f_j ≥ 0.5 (i.e., an identifiable conditional cooperator who tends to reciprocate). If such a reciprocator exists, play C once to probe and attempt to re-start cooperation; if exploited, punish as above.
     - Else (T_bad < f_group < T_good): compute p_coop = (f_group - T_bad) / (T_good - T_bad). With probability p_coop play C, else D. However, if a majority of players show positive reciprocity (more than n/2 with r_j > 0), bias p_coop upward by +0.15 to reward likely returners. The randomness helps avoid deterministic exploitation and allows gradual rebuilding of cooperation.

4. Forgiveness and recovery
   - After any punishment episode, monitor f_group. If f_group returns to ≥ max(T_good - 0.05, 0.7) for one full window, cancel all punishment memory and resume cooperative maintenance (play C when f_group ≥ T_good as above).
   - Never punish forever. Punishments are short and proportional; after punishment the strategy actively probes with occasional cooperative moves to test if others respond.

5. Handling erratic or adversarial opponents
   - If a single or a few players are perfect defectors (f_j ≈ 0) while the rest cooperate, the proportional punishment rule will still limit damage: FR will be small and punishment short; reward conditional cooperators to maintain most-player cooperation. If many players are defecting, escalate punishment length proportionally for a short period then revert to probing to see if cooperation can return — this prevents endless mutual punishment spirals.
   - Use probabilistic cooperation in ambiguous mid-range situations to avoid being locked into deterministic cycles that exploit or are exploited by fixed strategies.

Rationale and collective alignment
- The strategy prioritises group welfare by default: it starts and rewards cooperation, and only defects to impose a short, visible cost on free-riders that makes cooperation relatively more attractive over time.
- Punishments are proportional and temporary (minimises loss from long vendettas), and forgiveness/recovery is explicit (so conditional cooperators can restore cooperation).
- The small randomized element prevents deterministic exploitation in tournaments of AI strategies that can exploit fixed patterns.
- The endgame cutoff is small but necessary: backward-induction incentives in finite games make sustained cooperation impossible in the final rounds, so the strategy conservatively defects in a short final horizon while preserving cooperation in most of the game.

Summary pseudocode (high-level)
- Compute parameters W, B, K_end, thresholds.
- Each round: update sliding-window stats f_j, f_group, r_j.
- If t = 1 OR (t ≤ B): play C.
- Else if t > r - K_end: play D.
- Else if currently punishing: play D until punishment counter expires.
- Else if punishment trigger (large FR or big drop in f_group): start proportional punishment P rounds, play D.
- Else if f_group ≥ T_good: play C.
- Else if f_group ≤ T_bad:
     - if there is at least one strong reciprocator (r_j ≥ 0.30 and f_j ≥ 0.5): play C (probe);
     - else play D.
- Else (mid-range cooperation): set p_coop = linear interpolation between T_bad and T_good (bias up if majority show positive r_j); play C with probability p_coop, else D.
- After any punishment, if f_group recovers to ≈ T_good for a window, clear punishment and resume cooperation.

This strategy is fully defined by n, r, k and observed history; it is adaptive (reacts to measured cooperation and reciprocity), robust (short proportional punishments prevent exploitation without prolonged loss), and collective (aims to stabilise high contribution rates and restore cooperation when disrupted).
'''

description_COLLECTIVE_101 = '''
Adaptive Proportional Conditional Cooperator (APC)

Goal (collective mindset)
- Maximise long-run group payoff by sustaining high contribution rates when others reciprocate, while deterring and correcting free-riding quickly and forgivingly. Use proportional, history-driven responses so punishment is not excessive and cooperation can be rebuilt.

Parameters (computed from known game inputs; fixed numeric defaults given; can be tuned)
- n, r, k (given by the game).
- Window W = min(5, max(1, floor(r/10))) — number of most recent rounds to smooth noise (default: up to 5).
- High-cooperation threshold TH_high = 0.75 (cooperate when group cooperation is strong).
- Low-cooperation threshold TH_low = 0.25 (defect when group cooperation is clearly low).
- Tolerance E = 1 / (n) (allow tiny occasional mistakes without overreacting).
- Punishment scale S = 3 (controls how long punishments grow with observed defection).
- Restoration probe length R = 1 (after punishment, try short cooperative probe to rebuild).
- Endgame safety: In the very last round t = r, default to defect (no future to enforce cooperation).

State tracked
- t = current round index (1..r).
- History of contributions for all players per round.
- Punishment counter P (if >0, currently in a punishment phase; initialized 0).
- In-rebuild flag B (currently in restoration probe rounds; initialized false).

Decision rule (each round)
1. First-round rule:
   - If t = 1: Cooperate. (Signal cooperative intent to start a collective norm.)

2. End-of-game rule:
   - If t = r (final round): Defect. (No future incentives to sustain cooperation.)

3. Compute recent group cooperation level:
   - Let W_eff = min(W, t-1). If W_eff = 0 (only in round 1), skip to rule 1.
   - For each of the W_eff most recent completed rounds, compute fraction of other players who contributed that round.
   - Let f = average over those rounds of (number of other players who contributed) / (n-1). f is the estimated recent cooperation rate among the other players.

4. If currently punishing (P > 0):
   - Defect this round; decrement P by 1.
   - After P reaches 0, set B = true and start a restoration probe of length R (the next R rounds will be cooperative probes).
   - Rationale: keep punishment short and predictable; then probe to see if cooperation can restart.

5. If in restoration probe (B = true):
   - Cooperate for this probe round.
   - Observe others’ responses during probe:
     - If during the probe others’ cooperation (in that round or averaged with recent rounds) returns to >= TH_high, set B = false and continue cooperating normally.
     - If others fail to cooperate (f < TH_low while B), immediately set B = false and set P = L (enter punishment) where L = 1 + ceil(S * max(0, TH_high - f)). Then defect this round (punishment begins).
   - Rationale: quickly test whether cooperation can be re-established, but be ready to punish again if not.

6. Normal operation (not punishing and not probing):
   - If f >= TH_high - E: Cooperate.
     - Rationale: majority cooperation; support the collective.
   - Else if f <= TH_low + E: Defect.
     - Rationale: clear free-riding; avoid being exploited.
   - Else (intermediate band TH_low < f < TH_high):
     - Use a proportional mixed rule: cooperate with probability p = (f - TH_low) / (TH_high - TH_low). Equivalently, match cooperation probability to how close group is to high cooperation.
     - Alternatively (deterministic variant): repeat your previous action (win-stay, lose-shift): if you cooperated last round and group cooperation declined, switch to defect; if you defected and others started to cooperate, switch to cooperate.
   - If you detect a spike of defection in the most recent round (i.e., last round’s fraction f_last <= TH_low), respond more strongly:
     - Set punishment length P = 1 + ceil(S * (TH_high - f_last)). This creates a proportional but finite punishment.

7. When punishment is set (how L computed):
   - L = 1 + ceil(S * max(0, TH_high - f_obs)), where f_obs is the most recent observed cooperation fraction among others that triggered punishment.
   - Cap L at remaining rounds-1 (do not attempt punishments that extend beyond the final round).
   - Punishment is pure defection by this player for L rounds; punishments are finite and proportional to the deficit in cooperation that triggered them.

Additional robustness and notes
- Noise tolerance: using W window, E tolerance and proportional punishments prevents overreacting to single mistakes and reduces the chance of permanent collapse from noise.
- Gradual escalation: punishments are non-permanent and scale with how much cooperation was lost, discouraging large-scale free-riding without destroying future cooperation opportunities.
- Probing and forgiveness: after any punishment we always attempt short cooperative probes (length R) to re-establish cooperation. If others respond positively, cooperation resumes; if not, punish again proportionally.
- Endgame: defect in final round to avoid exploitation when no future enforcement is possible. (If you want maximal collective payoff at the expense of individual payoff in the final round, you can override this, but that risks exploitation.)
- Tie-breaking and deterministic behavior: where probabilities are used, you may sample randomly according to p, or use deterministic tie-breakers consistent across rounds if randomness is unavailable.

Short summary (how it behaves)
- Start cooperative to establish cooperation.
- Cooperate as long as most others do (>= ~75% by default).
- If cooperation falls, respond with proportionate finite punishments (defect for a small number of rounds proportional to the drop) rather than permanent exclusion.
- After punishment, always try a short cooperative probe; if others respond, return to cooperation; if not, punish again.
- Defect in the final round.

This strategy prioritises collective welfare by supporting and stabilising cooperation, deters freeloading with measured retaliation, tolerates occasional mistakes, and uses short, proportional punishments plus forgiveness to restore group cooperation when possible.
'''

description_COLLECTIVE_102 = '''
Collective Conditional Cooperation with Finite Punishment (CCCFP)

Summary intuition
- Aim for sustained group cooperation while protecting against persistent free-riders.
- Signal willingness to cooperate by cooperating early, punish short and proportionally if the group falls below a cooperation majority, then forgive and try to re-establish cooperation.
- Avoid futile attempts to sustain cooperation in the obvious endgame: defect in a short final window of rounds where backward induction makes cooperation fragile.
- All decisions use only n, r, k and the publicly observed history of players’ contributions.

Parameters (computed from game parameters)
- n = number of players (given).
- r = total rounds (given).
- If r <= 3: small-horizon case (see edge-case rule below).
- Endgame window E = 3 (we will defect in the last 3 rounds whenever r > 3).
- Majority threshold m = ceil(n / 2) (strict majority).
- Punishment length P = max(1, ceil(r / 10)) (short, finite: about 10% of the game, at least 1 round).

State variables (maintained from history)
- punishment_counter (integer, initially 0): number of rounds remaining to punish (play D).
- last_round_cooperators: count of players who played C in last round (observed).
- my_last_action (initially C unless r <= 3, see edge cases).

Decision rules (performed each round t = 1..r, using only history and parameters)
1. Edge-case / small-horizon rule:
   - If r <= 3, play D every round (do not attempt cooperation; endgame effects dominate).
2. Endgame rule:
   - If r > 3 and t > r - E (i.e., in the final 3 rounds), play D.
3. Otherwise (normal rounds, not in forced endgame):
   - If punishment_counter > 0:
       - Play D this round.
       - Decrease punishment_counter by 1 after the round.
       - If, at the start of the round, the group (including myself) already shows clear recovery (i.e., last_round_cooperators >= m), then clear punishment_counter immediately and instead play C (contrition/forgiveness).
   - Else (not currently punishing):
       - First-round rule: If t = 1, play C (signal cooperation).
       - For t > 1:
           - If last_round_cooperators >= m (strict majority cooperated last round):
               - Play C (reward cooperation and maintain the cooperative norm).
           - Else (last_round_cooperators < m):
               - Initiate punishment: set punishment_counter := P and play D this round.
               - (This punishes the group for failing to reach majority cooperation; punishment is finite and shared.)
4. After each round update:
   - Observe contributions. If a future round begins and the last observed round had majority cooperation (>= m), clear punishment_counter (forgive) and resume cooperating.
   - If multiple rounds of sub-majority cooperation occur, each time you observe a sub-majority you (re)start a finite P-round punishment. If the group recovers earlier than the full P rounds by achieving a majority, you forgive immediately and resume cooperation.

Rationale and robustness notes
- Collective mindset: The strategy willingly bears short-term individual loss (cooperating) to sustain higher long-run group welfare, but refuses to let defectors exploit cooperation indefinitely: punishments are shared (everyone defects during the punishment window), finite, and therefore credible and proportional.
- Adaptivity: The agent reacts to the observed group cooperation rate (majority threshold). This makes it robust to many opponent types: it cooperates with conditional cooperators and reciprocators, it punishes persistent defectors, and it forgives clumsy or stochastic strategies once they improve.
- Finite punishment prevents endless vendettas and allows recovery after mistakes or experiments by others.
- Fixed small endgame window E prevents futile cooperation attempts in the obvious last rounds where backward induction pressures make cooperation unlikely.
- Parameter choices (majority m, punishment length P proportional to r, endgame E small) scale with group size and horizon and are simple to compute from (n, r, k). The strategy does not rely on any assumed norms or private communication.

Edge cases summary
- r <= 3: defect every round (do not try to sustain cooperation in very short games).
- If the group shows a majority cooperation in the round immediately before a punishment would take effect, punishments are canceled (forgiveness).
- If recovery occurs early during a punishment window (group reaches >= m cooperators), the punishment is cleared immediately and cooperation resumes.

Behavioral profile you can expect
- In populations of conditional cooperators, CCCFP will quickly establish mutual cooperation.
- Against pure defectors it will defect after the first majority failure and then remain in short punishment cycles, avoiding sustained exploitation.
- Against noisy/stochastic players it will be forgiving and able to re-establish cooperation after transient failures.
'''

description_COLLECTIVE_103 = '''
Name: Collective-Conditional Proportional Reciprocity (CCPR)

Objective (collective mindset)
- Aim to sustain high group contributions when enough other players reciprocate, while avoiding long-term exploitation by defectors. Be cooperative by default but punish proportionally and forgive when group cooperation returns.

Parameters (computed from game parameters)
- n, k, r are known.
- Memory window w = min(5, max(1, r)) — use up to the last 5 rounds of history (use whatever history exists if fewer rounds have passed).
- Cooperation threshold α = 0.5 + 0.3*(1 − k/n). (This adapts to multiplier k: when k is large relative to n, α is closer to 0.5; when k is small, α is closer to 0.8.)
- Strong-defection threshold β = 0.2.
- Maximum punishment length P_max = min(3, max(1, floor(r/10))). (Small, finite punishments; proportional and forgiving.)
- When counts or fractions mention "others", that excludes this player.

State tracked
- For each other player j, maintain s_j = number of times j contributed in the last w rounds (if fewer than w rounds exist, count available rounds).
- Maintain a punishment counter P ≥ 0 (initially 0) that counts remaining punishment rounds I will play D.

Decision rules (per round t)
1. If t = 1 (first round)
   - Play C (cooperate). Signal cooperative intent.

2. If t = r (last round)
   - Play D (defect). (Last-round defection is individually dominant; avoid being exploited in the final round.)

3. Otherwise (2 ≤ t < r):
   - Update s_j for every other player j from the last w rounds and compute:
       - F = fraction of other players with s_j ≥ ceil(α * w)  (the fraction of players who have been reliably cooperative recently).
       - f_last = fraction of other players who contributed in the immediately preceding round.
       - new_defectors = number of players who were in the cooperative set in the previous evaluation but defected in the last round (i.e., switched from s_j ≥ ceil(α * w) to not contributing in the last round).
   - If P > 0 (in punishment mode):
       - Play D this round and decrement P by 1.
       - Continue updating s_j while punishing.
       - After P reaches 0, proceed as below next round.
   - Else (not currently punishing):
       - If F ≥ α:
           - Play C. (Group appears reliably cooperative; keep cooperating.)
       - Else if F ≤ β:
           - Play D. (Group mostly defective; do not donate and avoid being exploited.)
       - Else (intermediate case β < F < α):
           - Use immediate reciprocity: play C if f_last ≥ 0.5 (majority of others cooperated last round); otherwise play D.
   - Punishment trigger: if new_defectors > 0 and P = 0 (i.e., previously reliable cooperators just defected),
       - Set P = min(P_max, 1 + new_defectors). Begin punishment next round (or immediately if the decision above would otherwise play C this round, override to D to punish now). Punish by defecting for P rounds. Punishment is proportional to how many reliable cooperators just defected and is capped.

Forgiveness and recovery
- After punishment ends, resume normal decision rule using updated s_j and F. If the cooperative fraction F returns to ≥ α, immediately resume cooperation.
- Punishments are deliberately short and proportional so the group can recover cooperation quickly; this avoids permanent collapse following mistakes or opportunistic deviations.

Additional notes and edge handling
- When history is shorter than w (early rounds), compute s_j over available rounds; ceil(α*w) uses the same available count.
- If multiple strategies in the population consistently defect in the last few rounds of the game (endgame effects), use the last-round rule (defect) but do not extend punishment into the final round(s) beyond P_max.
- The thresholds α and β adapt to the public-good multiplier: when k is high (cooperation produces large returns), CCPR is easier to sustain (lower α); when k is low, CCPR requires stronger evidence of reciprocity before cooperating (higher α).
- The strategy is deterministic except for cases where history ties exactly at thresholds; break ties conservatively (choose D if unsure) to avoid being exploited.

Rationale (how this is collective and robust)
- Cooperate first and while most others have demonstrated reliable cooperation: this fosters collective welfare.
- Use short, proportional punishments triggered only by defections of previously reliable cooperators: this deters exploitation but avoids brittle, permanent breakdown (unforgiving grim).
- Forgiveness after a short punishment allows recovery from mistakes and prevents cascades of retaliation.
- Thresholds adapt to k and history length so the strategy behaves sensibly across parameter regimes.
- Always defect in the final round to avoid last-round exploitation while still supporting cooperation through the rest of the game.

Summary (one-line)
- Start cooperative, contribute whenever a substantial and recent fraction of players has been reliably cooperative (threshold adapts to k), punish short and proportionally when previously reliable cooperators defect, forgive quickly when cooperation returns, and defect in the final round.
'''

description_COLLECTIVE_104 = '''
Name: Adaptive Collective Reciprocity (ACR)

Goal: sustain high group contributions while avoiding exploitation. Start cooperatively, punish short and proportional to restore cooperation, forgive quickly when the group response is positive. Use only n, r, k and observed history.

Parameters (computed from game parameters)
- W = min(10, r) — history window for rates.
- Endgame window E = 3 (final rounds where play is conservative).
- Persistent-defector threshold p_low = 0.20 (cooperation rate over W).
- Basic majority threshold T_base = 0.50.
- Generosity adjustment g = 0.10 if (k / n) >= 0.6 (higher multiplier → be more generous).
- Final-round safety: always defect in round r (last round).
- Punishment length L_base = 2. If (k / n) >= 0.6 reduce to 1; if (k / n) <= 0.4 increase to 3. Never punish longer than remaining rounds minus 1.

Maintenance
- After each round t, update for every player j their cooperation rate over the last W rounds (including the most recent round).
- Let C_t = number of players who contributed in the previous round t-1 (use C_1 = 0 for t=1 evaluation).
- Let avg_recent = average fraction of contributors across the last W rounds (or over all available rounds if fewer than W).

Decision rule for round t (1..r)
1. First round (t = 1)
   - Cooperate (contribute 1) to signal collective intent.

2. Last round (t = r)
   - Defect (do not contribute).

3. If remaining rounds ≤ E (near endgame, conservative mode)
   - Require stronger evidence of cooperation: cooperate only if C_{t} / n ≥ 0.75 OR avg_recent ≥ 0.80.
   - Otherwise defect.

4. Normal rounds (not first, not final, not near-end)
   - Compute cooperative threshold T = T_base - g if (k / n) ≥ 0.6, otherwise T = T_base.
     (So when public good is relatively rewarding, be a bit more willing to cooperate.)
   - Identify persistent defectors: players with cooperation rate ≤ p_low over W.
   - If number of persistent defectors ≥ n - 2 (i.e., almost everyone is a persistent defector), defect (group hopeless).
   - Otherwise, if C_{t} / n ≥ T OR avg_recent ≥ 0.80 (clear recent group cooperation), then cooperate.
   - Else (group cooperation is weak), enter a punishment phase:
       a. Defect for L rounds where L = L_base adjusted by k/n as above, but not exceeding remaining rounds - 1.
       b. After L rounds, re-evaluate: if C_{t'} / n ≥ T or avg_recent (updated) ≥ 0.60, resume cooperation; otherwise continue with another punishment phase (repeat adaptively, but never punish into the final round).

Forgiveness and targeting
- Do not permanently blacklist single deviators. A single or occasional defection does not trigger permanent punishment if group-level cooperation (C/n) stays ≥ T.
- If defection is widespread or persistent (many players with rate ≤ p_low), use the punishment phase above.
- After punishment, be forgiving: resume cooperation as soon as group behavior meaningfully improves (meeting the re-evaluation thresholds). This prevents long collapses produced by noise or one-off mistakes.

Tie-breaking and small groups
- If exactly at a threshold (e.g., C/n = T), act cooperatively (give the benefit of the doubt).
- For very small n (n ≤ 3), be slightly more forgiving: reduce T by 0.05 (cooperation is harder to sustain by strict majority).

Rationale (how it is collective)
- Start cooperative to allow mutually beneficial cooperation to emerge.
- Use simple group-level reciprocity (respond to how many others cooperated) rather than trying to punish particular players harshly; this aligns incentives for the group and is robust when you cannot coordinate punishers.
- Punish briefly but meaningfully when group cooperation collapses so that defectors have an incentive to return to cooperation.
- Forgive quickly when group cooperation recovers to avoid unnecessary long-term welfare loss from vendettas.
- Be more generous when k is large (public good yields large returns), and more conservative near the game end where backward induction makes cooperation fragile.

This strategy depends only on n, r, k and the public history of moves and payoffs, adapts to observed opponent behavior, protects against exploitation by persistent defectors, and prioritizes collective welfare through calibrated reciprocity and forgiveness.
'''

description_COLLECTIVE_105 = '''
Adaptive Collective Conditional Cooperator (ACCC)

Summary goal
- Aim to sustain high collective contributions while avoiding long-term exploitation.
- Start by signaling cooperation, reciprocate group-level cooperation, punish clear and persistent defectors, forgive quickly, and occasionally probe to detect change.
- Use only game parameters (n, r, k) and observed history of every player’s actions and payoffs.

State tracked (all computable from history)
- t = current round (1..r).
- For each player j ≠ me: C_j = fraction of rounds j has contributed so far.
- C_bar = average_j C_j (mean cooperation rate among the others).
- G_last = number of players who contributed in the previous round (including me if I contributed).
- MyLast = whether I contributed in the previous round.
- PersistentDefectors = set of players with C_j ≤ 0.20 (low long-run cooperation).

Fixed tuning (derived from parameters; deterministic unless stated)
- MajorityThreshold = ceil(n/2). (majority of players)
- HighCoopThreshold = 0.75 (useful signal that group is largely cooperative).
- NearUnanimous = n - 1 (everyone but maybe one).
- ProbeRate ε = max(0.02, 1/r). (occasional cooperative probe when otherwise defecting)
- ShortPunishLength = min(3, max(1, ceil(r/10))). (how many rounds to withhold cooperation when punishing)
- ForgiveIfOneCoop = 1 round of observed cooperation by a punished player will remove them from PersistentDefectors.

Decision rule (for round t)

1. First round
- Contribute (cooperate). Purpose: signal willingness to build cooperation.

2. Last round (t == r)
- Defect unless there is strong evidence this round’s contribution will be reciprocated as a reward:
  - Contribute only if C_bar ≥ HighCoopThreshold OR G_last ≥ NearUnanimous.
  - Otherwise defect. (Rationale: no future to enforce reciprocity; only reward when group has been reliably cooperative.)

3. Intermediate rounds (1 < t < r)
A. Detect persistent defectors
- Update PersistentDefectors = { j : C_j ≤ 0.20 }.
- If any j ∈ PersistentDefectors contributed this round and their long-run rate ≤ 0.20, treat them as a persistent exploiter.

B. Primary cooperation condition (try to sustain group cooperation)
- If G_last ≥ MajorityThreshold (i.e., last round a majority cooperated), then contribute.
  - Rationale: reciprocate recent group cooperation by continuing to cooperate.
- Else if C_bar ≥ HighCoopThreshold, then contribute.
  - Rationale: if most players are reliably cooperative overall, keep cooperating to preserve the good norm.
- Else if MyLast == true and G_last ≥ 1, then contribute.
  - Rationale: keep cooperating if there is at least one cooperator and I cooperated last round (momentum).

C. Punish clear exploitation
- If at least one persistent defector exists and one of them defected this round (or their recent behavior shows a downward trend), then:
  - Enter a short punishment mode: defect for ShortPunishLength rounds (count starts now). After the punishment window end, resume rules in 3B but allow probes (3D).
  - Mark punished players; if any punished player subsequently contributes in a future round, remove them from PersistentDefectors (ForgiveIfOneCoop).

D. Probing and forgiveness (to be robust / adaptive)
- If none of the Primary cooperation conditions are met and we would otherwise defect, cooperate with probability ε (probe) instead of defecting. Probes test whether others will return to cooperation and prevent permanent deadlocks.
- If a probe results in increased group cooperation next round (G_{t+1} increases by at least 1), treat that as signal to resume cooperation per 3B.

E. Default
- If none of the above conditions apply, defect this round.

Additional notes on tie-breaking and determinism
- The strategy is deterministic except for the small probing probability ε. Probes are rare and purposefully small to limit exploitation risk.
- When punishment is triggered, the exact short punishment length is small and bounded to avoid endless collapse; forgiveness is quick to allow restoration of cooperation.

Why this is collective-minded and robust
- Starts cooperative to try to establish mutual contributions.
- Uses simple, observable group signals (majority last-round cooperation and long-run average C_bar) to decide when to continue cooperating — this supports stable, high-contribution equilibria when many other strategies are conditional cooperators.
- Punishes only when exploitation is clear (persistent low C_j), and punishment is short and forgiving so the strategy is not locked into mutual defection.
- Probing prevents permanent losses from unlucky transient defections and identifies returning cooperators.
- Last-round rule avoids being systematically exploited when no future enforcement is possible, but still rewards a highly cooperative group if warranted.

This strategy depends only on n, r, k implicitly through thresholds and tracked history, adapts to many opponent behaviors (always-cooperate, always-defect, conditional cooperators, random), and emphasizes collective welfare while protecting itself from sustained exploitation.
'''

description_COLLECTIVE_106 = '''
Name: Conditional Collective Reciprocity (CCR) — graded punishment, generous forgiveness

Overview intuition (collective mindset)
- Aim to sustain high group contribution when most others reciprocate, while deterring and containing persistent free-riders with short, proportional punishments. Be forgiving toward isolated defections (likely mistakes or opportunistic one-offs) so cooperation can be restored. Use only observed history and the game parameters (n, r, k).

Parameters (derived from game parameters)
- window w = min(10, max(1, floor(r/4))). (Use up to 10 most recent rounds, fewer if the game is short.)
- majority_threshold = 0.75 (group cooperation rate above which we consider the group reliably cooperative).
- collapse_threshold = 0.20 (if cooperation falls below this, treat as group collapse).
- lenient_threshold = 0.40 (below this we generally stop cooperating).
- personal_trust_threshold = 0.70 (an individual counted as “trusted” if they cooperated at least this fraction in the window).
- punishment_length p_max = min(3, max(1, floor(r/10))). (Punishment is short and capped; shorter in short games.)
- forgiveness rule: isolated single defections are forgiven.

Decision pseudocode (run each round t = 1..r)
1. Observe history up to round t–1: each player’s actions for previous rounds.

2. Special rounds:
   - First round (t = 1): play C (start by offering cooperation).
   - Final round (t = r): play D. (Final-round cooperation cannot be credibly enforced; defecting is individually safe. We still try to sustain cooperation earlier rounds.)

3. Otherwise (1 < t < r):
   - Compute rem = r – t + 1 (remaining rounds including current).
   - Compute group_coop_rate = (sum over last min(w, t–1) rounds of contributions by other players) / ((n–1) * min(w, t–1)).
   - For each other player j compute personal_coop_rate_j over the same window.
   - Count trusted_players = number of j with personal_coop_rate_j >= personal_trust_threshold.
   - Identify persistent_defectors = players with personal_coop_rate_j <= 0.5 AND who have defected in at least 2 of the last min(w, t–1) rounds.

   Decision logic:
   A. If group_coop_rate >= majority_threshold:
       - Play C (cooperate). The group reliably reciprocates, so contribute to raise collective payoff.
   B. Else if group_coop_rate <= lenient_threshold:
       - Play D (defect). Cooperation has collapsed; stop giving free benefits.
   C. Else (intermediate zone):
       - If trusted_players >= floor((n-1)/2) (a majority of others are reliable):
           - Play C.
       - Else:
           - Play D.

4. Punishment & escalation policy (layered and proportional)
   - If there exists at least one persistent_defector:
       - Enter a punitive phase of length p = min(p_max, rem–1). During the punitive phase play D every round (do not cooperate), to impose a temporary collective cost that makes persistent defection unattractive.
       - After p rounds of punishment, re-evaluate history. If the offender(s) reduced their defection rate (personal_coop_rate_j increased above 0.5) then exit punitive mode and resume normal decision logic; otherwise repeat one more punitive phase of length p (but never exceed 2 successive punitive phases in total).
   - Punishment is deliberately short and public (visible in aggregate history) so that it is costly to defect persistently but cooperation can be restored.

5. Forgiveness and error-handling
   - If the last round(s) show a single isolated defection (group_coop_rate remains high and only one player defected in the window), treat it as an error: do NOT punish the whole group; continue cooperating.
   - If group_coop_rate rapidly drops then partially recovers, be generous: if cooperation rebounds to majority_threshold for two consecutive evaluation windows, resume cooperation.

6. Recovery after group collapse
   - If group_coop_rate < collapse_threshold for more than one window:
       - Adopt cautious probing: play C once every s rounds (s = max(2, floor(rem/4)) ), otherwise D, to test whether cooperation can be rebuilt without being repeatedly exploited. If a probe is reciprocated (others respond by cooperating in the next round(s)), move back to normal decision logic.

Rationale summary (why this is collective and robust)
- Starts by offering cooperation so cooperative clusters can form.
- Uses simple, observable statistics (recent group rate and per-player rates) to decide whether cooperation is sustainable.
- Protects the strategy from exploitation by using short, proportional punishments targeted at persistent defectors, not permanent ostracism.
- Forgives isolated defections to avoid collapse from noise or opportunistic one-offs.
- Includes a cautious recovery mechanism (probing) so that cooperation can be rebuilt after a collapse.
- Defects in the final round to avoid unrewarded unilateral generosity that cannot be enforced.

Behavioral notes for tournament play
- If many opponents aim for mutual cooperation, CCR sustains high collective contributions and gains.
- If opponents try to exploit by sporadic defections, CCR forgives and quickly returns to cooperation unless exploitation is persistent.
- If opponents persistently free-ride, CCR punishes briefly to make free-riding less attractive while preserving the possibility of later reconciliation.
- CCR requires only the public history (actions and payoffs) and the game parameters n, r, k. It does not assume communication or shared norms.
'''

description_COLLECTIVE_107 = '''
Name: Reciprocal Conditional Cooperator with Graduated Punishment and Probing (RCC-GPP)

Goal (collective mindset)
- Aim to sustain high group contribution whenever others reciprocate, punish only enough to deter persistent free-riding, and forgive so cooperation can be re-established. Avoid long, wasteful punishments and avoid being a permanent sucker when most others defect.

Parameters computed from game inputs (deterministic functions of n, k, r)
- memory m = min(3, r)  // look back up to three rounds (or fewer if game is short)
- target cooperation fraction T = 0.5  // require at least a majority contribution to regard the group as "cooperating"
- max punishment P_max = 3  // punish for up to 3 rounds (short, proportional deterrent)
- probe probability ε = min(0.10, 2/(r+1))  // small chance to test for renewed cooperation
- endgame rule: always defect on last round (round r). For remaining_rounds ≤ 1 follow last-round rule; reduce punishments to fit remaining rounds.

State variables (tracked from history)
- punishment_remaining (initially 0)
- in_rebuild (boolean, initially false)  // single-round attempt to re-establish cooperation after punishment

Decision algorithm (executed at start of each round t, given full history up to t-1 and remaining rounds remaining = r - (t-1))

1) Endgame handling
- If remaining == 1 (this is the last round): choose D (defect).
- If remaining is small and would make full punishment pointless (i.e., remaining ≤ P_max), shorten any punishment to at most remaining-1 rounds so there remains at least one round to attempt rebuild.

2) First round
- If t == 1: choose C (cooperate) to signal willingness to cooperate.

3) If punishment_remaining > 0
- Defect this round.
- Decrement punishment_remaining by 1.
- After punishment ends (punishment_remaining becomes 0), set in_rebuild = true (so we will attempt a cooperative rebuild next round).

4) If in_rebuild is true
- Play C for one round (the rebuild attempt).
- Set in_rebuild = false.
- Observe results next round and react accordingly.

5) Otherwise (normal operating mode)
- Compute recent average cooperation fraction among all players over the last m rounds, f_recent:
    - For each of the last up to m rounds, compute the fraction of players who chose C in that round (include all players; include yourself if you cooperated).
    - f_recent = average of those per-round fractions.
- If f_recent ≥ T:
    - Cooperate (C). The group is sufficiently cooperative; maintain cooperation.
- Else (f_recent < T):
    - If many players defected in the most recent round (e.g., fraction in most recent round ≤ T - 0.25), treat as a significant breach:
        - Set punishment_length = min(P_max, remaining - 1). Enter punishment: set punishment_remaining = punishment_length and choose D this round.
    - Else (a mild drop in cooperation):
        - Defect this round with probability 1 - ε (punish mildly / avoid being exploited).
        - With probability ε, cooperate as a probe to see whether others will return to cooperation.

6) Continuous probing when persistent defection observed
- If shortly after many rounds of low cooperation (f_recent stays < T for multiple consecutive memory windows), move to a conservative mode: defect by default but periodically (with prob ε) cooperate to test. If a probe gets sufficient reciprocation (next round's fraction ≥ T), exit conservative mode and resume cooperating.

Rationale / properties
- Starts cooperative to try to reach the socially optimal all-C outcome quickly.
- Uses a simple majority threshold T to detect when the group is behaving cooperatively; this is robust across n and k and is easy to compute from public history.
- Graduated punishment: brief, proportional punishments (≤ P_max rounds) instead of permanent grim trigger. This is efficient (limits wasted rounds) and gives opponents the incentive to resume cooperation.
- Single-round rebuild: after punishment, actively attempt to re-establish cooperation rather than get stuck in mutual punishment.
- Probing (small random cooperation while in defect mode) prevents permanent lock-in with defectors and allows detection of strategy switches by others.
- Endgame defection in the last round prevents being exploited in a one-shot situation; punishments are shortened to avoid pointless costs near the end.
- Adaptive: memory length and punishment lengths scale with remaining rounds so the strategy behaves sensibly in short games.

Examples of behavior (intuitive)
- If most players are cooperating each round, RCC-GPP will cooperate every round and sustain high group payoff.
- If a few players occasionally free-ride, the strategy punishes briefly but forgives and tries to rebuild cooperation.
- If almost everyone defects, RCC-GPP will defect to avoid exploitation but will occasionally probe; if some opponents return to cooperation, RCC-GPP resumes cooperating.

This strategy depends only on game parameters and observed history (actions and payoffs) and is designed to be robust against a wide variety of opponent behaviors while emphasizing collective welfare when reciprocation is present.
'''

description_COLLECTIVE_108 = '''
Name: Adaptive Collective Pavlov with Proportional Punishment (ACPP)

Idea (one line): Start by trying cooperation; on each round compare your actual payoff to the counterfactual payoff you would have gotten by taking the opposite action last round (this is Pavlov/“win–stay, lose–shift” using full information). Repeat an action if it did at least as well as the counterfactual; otherwise switch. When switching because you were exploited, punish proportionally to the number of defectors, but forgive quickly when the group recovers. Always defect in the final round to avoid end‑game exploitation.

Parameters computed from game inputs (n, r, k):
- Lookback window W = min(3, r) (used to judge recent recovery).
- Max proportional punishment length P_max = min(3, max(1, r//4)).
- Final-round safeguard: always defect in round r.

Operational rules (use only game parameters and observed history):

1) Initialization
- Round 1: Cooperate (contribute 1).

2) At the start of each round t > 1 (before choosing action), compute:
- M_prev = total contributions observed in round t-1 (0..n)
- a_prev = your action in round t-1 (C or D)
- Your actual payoff in round t-1 was:
    if a_prev = C: pi_prev = 0 + (k/n)*M_prev
    if a_prev = D: pi_prev = 1 + (k/n)*M_prev
- Counterfactual payoff if you had chosen the opposite action in t-1:
    if a_prev = C (counterfactual = if_D): pi_cf = 1 + (k/n)*(M_prev - 1)
    if a_prev = D (counterfactual = if_C): pi_cf = 0 + (k/n)*(M_prev + 1)
  (These are calculated from observed M_prev and are exact because actions are public.)

3) Basic Pavlov decision
- If pi_prev >= pi_cf: repeat a_prev this round (win–stay).
- If pi_prev < pi_cf: play the opposite action this round (lose–shift).

4) Proportional punishment when exploited
- If you switch from C → D because pi_prev < pi_cf (you were exploited when cooperating), set a short punishment length P = min(P_max, max(1, n - M_prev)).
  That is, punish by defecting for up to P consecutive rounds (including the current round) unless forgiveness conditions below occur earlier. The punishment length grows with the number of defectors observed last round.
- During an active punishment, apply the Pavlov rule only after the punishment timer has expired; while punishing, defect.

5) Forgiveness and quick restoration of cooperation
- After each round (including during punishment), check the recent recovery condition:
  If, over the last W observed rounds (or all past rounds if fewer), the average total contribution ≥ n - 1 (i.e., near-universal cooperation), then immediately cancel any punishment timer and resume Cooperate (contribute) next round.
- Also: if you have been defecting but in the last observed round M_prev ≥ n - 1 and at least 2 rounds remain, treat that as a strong signal to return to cooperation (this prevents long punishments when the group has essentially restored cooperation).

6) End-game safeguard
- If t = r (final round): Defect (do not contribute).
- Optionally: if t = r-1 and you have clear evidence that almost everyone will defect in the final round (e.g., M_prev is very low for several recent rounds), defect in round r-1 as well; otherwise follow the Pavlov rule. (This is a small heuristic using the same history-based evidence.)

7) Detecting systematic exploitation (robustness)
- If over the last W rounds you repeatedly found pi_cf > pi_prev whenever you cooperated (i.e., cooperating was consistently exploited), escalate punishment up to P_max for each new exploitation, and only return to cooperation after observing at least one full round of near-universal cooperation (M ≥ n - 1).

Rationale and properties
- Collective orientation: the rule begins by favoring cooperation and gives priority to restoring near-universal cooperation quickly (forgiveness triggers when the group shows recovery). The proportional punishment (punish longer when many defect) expresses a collective response to many defectors while avoiding permanent breakdown when the group repairs itself.
- Adaptivity: Pavlov uses exact counterfactual payoffs computed from observed actions, so each decision adapts to what actually happened rather than relying on fixed labels or expectations about opponents.
- Robustness: the strategy punishes exploiter behavior but only for a bounded, proportional time and forgives rapidly when the group shows willingness to cooperate. The final-round defect prevents guaranteed end-game exploitation. The scheme tolerates heterogeneous opponents because each decision is based on observed outcomes.
- Simplicity: all information needed is public history, n, r, k; no communication or assumptions about opponents’ motives are required.

Edge cases summary
- First round: Cooperate.
- Final round: Always defect.
- Short games (r ≤ 3): W and P_max shrink appropriately (W = r or less; P_max ≤ r//4 but at least 1), so the strategy still operates (start cooperating, respond by the same Pavlov counterfactual rule, but always defect in the final round).
- If a single accidental defection causes a one-round breakdown, the forgiveness rules (W-window recovery, immediate return when M_prev ≥ n - 1) prevent long collapse.
- If many players are persistently defecting, the proportional punishment causes you to defect too (protecting yourself) but will revert once the group recovers.

This strategy is deterministic (except the optional r-1 heuristic), uses only parameters and history, aims to preserve collective welfare where feasible, and defends against sustained exploitation.
'''

description_COLLECTIVE_109 = '''
Collective-First Conditional-Cooperation (C4) — a simple, adaptive, forgiving collective strategy

Goal: maximize group payoff by sustaining mutual contributions when most others are willing, while protecting against persistent exploitation. The strategy is deterministic, uses only observed actions and rounds remaining, and is robust to mistakes and a wide variety of opponent behaviors.

Parameters (fixed and derived from game parameters)
- n, r, k: game inputs (n players, r rounds, multiplier k).
- Window W = min(5, r-1) — how many past rounds to use for short-run statistics.
- Cooperation threshold θ = 0.6 (majority-oriented but forgiving).
- MaxPunish = 3 — maximum consecutive rounds to punish before re-testing cooperation.
- Minimum remaining-round safeguard: always preserve at least one round after a punishment period if possible.

Modes (high level)
- Cooperative mode: default, contribute.
- Punish mode: protect the group by defecting after clear declines in group cooperation.
- Recovery/test step: after a limited punishment, test if cooperation can resume.
- Final-round rule: last round(s) treated conservatively.

Decision rules (what I do each round t, based only on history and r)
1. First round (t = 1):
   - Contribute (C). Signal willingness to cooperate.

2. Last round (t = r):
   - Defect (D). No future reciprocity possible; default to the dominant single-shot action.

3. General rule for rounds 2 <= t <= r-1:
   - Compute recent cooperation rate among the other players:
     - For each of the W most recent completed rounds (or all past rounds if fewer than W exist), count how many of the other n-1 players contributed.
     - Let recent_rate = (total other-player contributions over that window) / (W * (n-1)). recent_rate ∈ [0,1].
   - If recent_rate >= θ:
     - Cooperate (C). Majority of others have been cooperating → keep the cooperative venture alive.
   - If recent_rate < θ:
     - Enter a punishment-protected response:
       a. Punish length P = min(MaxPunish, max(1, ceil((θ - recent_rate)/θ * MaxPunish))).
       b. If remaining rounds after this punishment would be 0 (i.e., t + P > r), shorten P so at least one round remains after punishment (so we can test/recover); if no room, default to defect until the final round.
       c. For the next P rounds (including this round), defect (D). This is a proportional, short punishment to deter persistent free-riding.
       d. After P rounds of defection, perform one recovery test: contribute once (C) to signal readiness to cooperate again.
       e. If in that single recovery test round the others’ cooperation in that round(s) shows a return (i.e., the single-round fraction of other cooperators >= θ OR the subsequent W-window recent_rate >= θ), resume Cooperative mode.
       f. If cooperation does not return after the test, repeat punishment with P capped at MaxPunish; remain forgiving but escalate up to the cap.

4. Forgiveness and tolerance rules (collective-minded specifics)
   - Do not punish for isolated mistakes: if in the most recent round > 50% of others cooperated (single-round majority), treat that as cooperative (i.e., effectively count single-round majority as recent_rate >= θ).
   - If only 1 or 2 players defect repeatedly but the group majority keeps cooperating, continue cooperating (we prioritize majority group welfare over punishing a few freeloaders).
   - If most players defect (recent_rate well below θ), apply proportional punishment quickly to protect the group.

5. Edge and pathological cases
   - Short games (r small): W shrinks; punishments are shortened proportionally to avoid useless endgame punishment.
   - If at any time all other n-1 players have cooperated in every past round (clean cooperation history), keep cooperating up to the penultimate round. Still defect in the last round.
   - If the history shows cyclical or chaotic behavior, the algorithm’s short-window majority test plus capped punishments produce stable, repeatable responses and periodic recovery tests so cooperation can re-emerge if others change.

Rationale and properties
- Collective-first: always start by trying to build cooperation and prefer to maintain it when the group majority cooperates.
- Robustness: majority-based decision-making avoids being exploited by a small number of defectors and filters out noise/errors.
- Adaptive: punishments are proportional to observed decline and limited in length, then followed by explicit tests to re-establish cooperation.
- Forgiving: short punishments + tests prevent permanent breakdown from incidental mistakes.
- Endgame realism: last-round defection prevents being trivially exploited at the end; earlier rounds follow cooperative logic so long as others reciprocate.

Summary operationally (short pseudocode-style)
- If t == 1: C.
- Else if t == r: D.
- Else:
  - Compute recent_rate over W rounds among other players.
  - If recent_rate >= θ OR single-round majority cooperated in last round: C.
  - Else:
    - Defect for P rounds (P computed proportional to shortfall, capped by MaxPunish and remaining rounds).
    - After P rounds defect, do one test round with C.
    - If test shows enough cooperation, resume cooperating; else repeat punish-test cycle (P capped).

This strategy explicitly privileges collective welfare, is simple to implement, adapts to a wide variety of opponent behaviors, tolerates mistakes, and gives cooperation a durable chance while protecting against sustained exploitation.
'''

description_COLLECTIVE_110 = '''
Collective Conditional-Cooperation with Proportional Punishment and Forgiveness

Goal (collective mindset)
- Sustain near-universal contribution whenever others reciprocate, and deter steady free-riding with clear, proportional, and forgivable punishment. Do not rely on communication or shared conventions; decisions use only (n, r, k) and the full public history of past actions.

Overview of internal values computed from parameters
- Majority threshold: M = ceil(n/2). (We treat “majority cooperated last round” as the basic signal of healthy cooperation.)
- Base punishment length: B = max(1, ceil(r/10)). (Scales gently with game length so punishment can affect future behavior.)
- Rounds remaining at the start of round t: R_rem = r − (t − 1).

State variables (derived from history)
- prev_total_C = total number of contributors (all players) in the previous round (0..n).
- If currently in an active punishment episode, it carries remaining punishment rounds L_rem and a record of when punishment started.

Decision rules (what I do each round)
1. First round (t = 1)
   - Contribute (C). Start in cooperative mode.

2. Last round (t = r)
   - Defect (D). No future to enforce reciprocity; choose the action that maximizes my final-round payoff.

3. Cooperative mode (not currently punishing)
   - If prev_total_C >= M (a majority cooperated last round): Contribute (C).
     Rationale: majority cooperation indicates reciprocity is working; continue to support the public good.
   - If prev_total_C < M: enter punishment mode and Defect this round. Set punishment length L as:
       gap = M − prev_total_C  (how far short of majority the group fell)
       L = min(R_rem − 1, B + gap)  (cap to remaining future rounds; subtract 1 because this round is used already)
     Rationale: punish proportionally to the shortfall; larger shortfalls earn longer punishments. Cap so we do not punish more rounds than the game offers.

   - Special near-end exception: if R_rem ≤ B (few rounds remain), do not start a new punishment episode unless prev_total_C = 0 (complete collapse). Instead:
       - If prev_total_C = n (everyone cooperated last round) => Contribute.
       - Otherwise => Defect.
     Rationale: when little future remains, punishment is unlikely to restore cooperation and is costly; revert to defensive/selfish play unless perfect cooperation was just observed.

4. Punishment mode (L_rem > 0)
   - Defect (D) while L_rem > 0, and decrement L_rem by 1 after each round.
   - Monitor recovery: if during punishment we observe two consecutive rounds with total contributions >= M, end punishment immediately and resume cooperative mode on the next round (i.e., forgive early).
   - If punishment reaches 0, resume cooperative mode next round.
   Rationale: punish long enough to make defection unattractive but allow quick return to cooperation if the group recovers (forgiveness reduces permanent breakdowns and is robust to accidental/isolated mistakes).

Additional robustness details and rationale
- Identity-awareness: because full history of each player is visible, the strategy can implicitly target repeat defectors through repeated majority shortfalls. However, punishment length is based on the observed group shortfall to avoid fragile one-to-one retaliation rules that fail in multi-player settings.
- Tolerance for one-off mistakes: single accidental defectors or rare lapses cause at most short punishments (gap small → L small) and can be forgiven quickly if the group corrects.
- Escalation control: punishment is proportional (gap added to B) but capped by remaining rounds so punishment never needlessly sacrifices all remaining opportunities for cooperation.
- Endgame realism: the strategy concedes that in the final round there is no leverage, so it defects; in very late stages it refrains from launching punishments that cannot be enforced.
- Parameter choices are deterministic and computed from (n, r) only; no hidden randomness is required. They are intentionally simple (majority threshold, modest base punishment) to perform well against diverse, independent opponents while making cooperation attractive to reciprocators and costly for persistent free-riders.

Pseudocode summary
- Compute M = ceil(n/2), B = max(1, ceil(r/10)).
- If t = 1: play C.
- Else if t = r: play D.
- Else if in punishment with L_rem > 0:
    - play D; decrement L_rem.
    - if the last two rounds had total contributions >= M: set L_rem = 0 (forgive early) and switch to cooperative mode next round.
- Else (cooperative mode):
    - If R_rem ≤ B:
        - if prev_total_C == n: play C
        - else: play D
    - Else (enough remaining rounds):
        - if prev_total_C >= M: play C
        - else: play D and set L_rem = min(R_rem − 1, B + (M − prev_total_C)) to start punishment.

Intended tournament behavior
- Encourages and sustains high contribution levels when a majority reciprocates.
- Imposes measurable costs on groups that fall short of majority contributions, making defection unattractive over time.
- Forgives recovery quickly so cooperation can resume after errors or short defection episodes.
- Avoids wasting endgame rounds on futile punishment and defects in the final round to protect own payoff.
'''

description_COLLECTIVE_111 = '''
Collective Conditional-Cooperation with Graduated Punishment and Forgiveness

Principles
- Start by signaling willingness to cooperate and try to establish mutual cooperation.
- Reward clear cooperative majorities with cooperation; punish clear exploitation but only briefly and proportionally.
- Forgive quickly to allow recovery from mistakes or noise.
- Be conservative near the end of the finite horizon unless cooperation has been persistently perfect.
- All decisions use only the game parameters (n, r, k) and the observed history of actions and payoffs.

Definitions used below (computed from parameters)
- Majority threshold M = ceil(n / 2). (A “majority” of players.)
- Anomaly tolerance A = max(1, floor((n - 1) / 4)). (Small number of defectors I will forgive as noise.)
- Short window W = min(3, r - 1). (Use last up to 3 rounds to judge recent trend.)
- Short punishment cap Pcap = 2 (punish at most 2 rounds for a single clear exploitation).
- “Group cooperation in a round” = number of players who contributed (0..n).

Decision rules (per round t; rounds numbered 1..r)

1) First round (t = 1)
- Cooperate (contribute 1). Purpose: signal cooperative intent and try to establish a cooperative norm.

2) General rule for rounds t > 1 (not the final round logic below)
- Observe the immediately previous round’s group cooperation count G_{t-1}.
- If G_{t-1} >= M:
    - Cooperate. (Reciprocate a majority of contributors.)
- Else if (G_{t-1} <= M - 1):
    - If in the previous round I cooperated and G_{t-1} < M (I was exposed to a non-majority):
        - Enter proportional, capped punishment: defect for P rounds, where P = min(Pcap, M - G_{t-1}). (Punish longer if the deviation was larger, but at most Pcap.)
    - Else (I defected last round or I didn’t cooperate last round):
        - Defect. (Do not give unconditional cooperation to a group that failed majority cooperation last round.)

3) Forgiveness and recovery after punishment
- After finishing the P punishment rounds, re-evaluate using the general rule above.
- Additionally, if the recent W-round average group cooperation rate (average of G_{t-1}, G_{t-2}, … up to W rounds) is high:
    - Specifically, if average_group_coop >= n - A (i.e., nearly everyone has cooperated recently, with at most A deviations), resume cooperation immediately. (This restores cooperation after isolated mistakes.)

4) Handling small anomalies (noise-tolerance)
- If a single round shows a small number of defectors (G_{t-1} >= n - A), treat it as an anomaly and cooperate in the next round. (Avoid long cycles of retaliation for a few stray defections.)

5) Endgame / last rounds
- Final round t = r:
    - Cooperate only if every previous round was unanimous cooperation (G_s = n for all s < r). Otherwise defect. (This protects against being the only cooperator in the last round while still allowing full-group payoff if cooperation has been perfect.)
- Last few rounds (t where r - t < 3):
    - Be conservative. Cooperate only when both (a) the immediate previous round met the majority rule (G_{t-1} >= M) and (b) the W-round average cooperation rate is high (>= n - A). Otherwise defect. (This reduces vulnerability to endgame exploitation while allowing cooperation to persist when it has been stable.)

6) When multiple punishments stack
- If others continue to fail the majority rule after my punishments, continue defecting rather than escalating beyond proportional punishments. (Do not try to escalate indefinitely; keep punishments bounded so recovery is possible.)

Rationale and properties
- Collective orientation: start cooperating and reward group cooperation, aiming to maximize collective payoffs when others reciprocate.
- Reciprocity and proportionality: cooperate when most people cooperated; punish when you were clearly exploited, but punish only briefly and in proportion to the size of the deviation. This deters persistent free-riding but allows recovery from mistakes.
- Robustness: majority rule and anomaly tolerance make the strategy robust to stochastic or mixed opponents, and the short punishment cap prevents long mutual retaliation cycles that destroy group gains.
- Endgame safety: final-round defection unless cooperation has been perfect avoids being exploited by rational endgame defectors while still allowing mutual benefit if everyone has been reliably cooperative.
- Parameter sensitivity: the small anomaly tolerance A and short window W scale with n and r to keep behavior stable across small and large groups and different horizon lengths; the majority threshold M is a simple, interpretable standard.

Summary (one-line)
- Cooperate initially; thereafter cooperate when a majority cooperated last round (or recent history shows near-unanimous cooperation), defect otherwise; if you were exploited, punish briefly and proportionally, then forgive quickly; be conservative in the final rounds unless cooperation has been persistent and unanimous.
'''

description_COLLECTIVE_112 = '''
Name: Collective Conditional Cooperator with Graduated Punishment and Probing Forgiveness (CCG-P)

Summary goal (collective mindset)
- Aim to sustain high group contribution because full cooperation maximizes collective payoff.
- Make contributions the default signal of good-faith; punish defections proportionally to deter exploitation; be explicit about forgiveness so cooperation can be restored.
- Use only public history (each player’s past contributions) and the game parameters (n, k, r).

Parameters (computed from game parameters)
- Window W for short-term statistics: W = min(10, max(1, floor(r/10))). (Use fewer rounds when r is small.)
- Cooperation threshold q = 0.50 (majority benchmark).
- Reliable-player threshold s_high = 0.80 (a player who cooperates very often).
- Reliable-majority fraction R_req = 0.70 (if a strong majority are reliably cooperative, favor cooperation).
- Maximum punishment length P_max = min(5, max(1, r-1)).
- Punishment scaling uses the short window W so recent behavior matters.

State tracked
- For each player j (other than myself) keep S_j = fraction of times j contributed in the last W rounds (or over all rounds so far if fewer than W rounds exist).
- A simple local punishment counter PunishRemaining (initially 0) and last punishment length LastP (initially 0).

Decision rules (executed each round t = 1..r)
1. First and last-round rules
   - If t = 1: cooperate (contribute). This signals willingness to form cooperation.
   - If t = r (the final round): defect (do not contribute). There is no future to enforce reciprocity, so avoid exploitation.

2. Compute recent statistics
   - For each other player j compute S_j as above (fraction of their contributions in last W rounds).
   - Let G = average of S_j over all other players (group recent cooperation rate).
   - Let R = fraction of other players with S_j >= s_high (reliable cooperators).

3. Reliable-majority shortcut
   - If R >= R_req, then cooperate. Rationale: a clear set of highly reliable cooperators means collective cooperation is likely and beneficial; tolerate a few sporadic defectors.

4. Punishment mode
   - If PunishRemaining > 0: defect this round and decrement PunishRemaining by 1.
     (This implements a clear, limited punishment period after observed anti-social behavior.)

5. Regular decision when not currently punishing
   - If G >= q: cooperate (contribute).
     (If a recent majority of players have cooperated, sustain cooperation.)
   - Else (G < q): enter a proportional punishment:
       a. Set LastP = clamp(1 + ceil((q - G) * W), 1, P_max). This scales punishment length to how far group cooperation fell below the majority threshold, limited by P_max.
       b. Set PunishRemaining = LastP.
       c. Defect this round (begin punishment immediately).

6. Forgiveness probe after punishment
   - When PunishRemaining reaches 0 (punishment just finished), the next round behave as follows:
       a. Play one cooperative “probe” round (contribute) to test whether others return to cooperation.
       b. Observe that probe round’s outcome: compute the probe-round G_probe (the fraction of others who contributed that round).
          - If G_probe >= q: treat this as successful restoration of cooperation and resume normal cooperative behavior (return to step 3/5 rules).
          - If G_probe < q: re-enter punishment with LastP2 = min(P_max, LastP + 1) (increase punishment modestly) and set PunishRemaining = LastP2. Defect immediately and repeat the cycle.
   - This deterministic probing (one cooperative test round) gives structure: allow reconciliation but only if others respond.

Edge cases and small-r behavior
- If r is small and W becomes 1 or a few rounds, statistics are noisy: the strategy still applies but LastP and P_max ensure punishments remain bounded and forgiveness happens quickly.
- If there are many rounds left and cooperation reestablishes, the strategy will keep cooperating for long stretches; if defection recurs it punishes proportionally and escalates slowly, so persistent exploiters are driven down.

Intuition and robustness
- Start cooperatively to encourage mutual contributions.
- Use simple, transparent rules based on recent majority behavior so policy is adaptive to many opponent types (unconditional cooperators, unconditional defectors, conditional reciprocators, noisy players).
- Punishments are proportional (longer when group cooperation is worse) to avoid overreacting to noise; punishments are capped to avoid endless mutual destruction of welfare.
- Deterministic, single-round probes after punishments allow re-establishing cooperation without randomization; probes prevent locked-in retaliation cycles.
- Last-round defection avoids being exploited with no enforcement power; otherwise avoid unconditional endgame collapse by keeping punishments and forgiveness well-structured.

Why this is collective-minded
- The default is cooperation when others show cooperative intent.
- Punishment serves only to deter exploitation and is limited and forgiving so the group can return to the mutually beneficial all-contribute outcome whenever enough players reciprocate.
- The strategy balances deterrence (to prevent exploitation) and forgiveness (to recover cooperation), maximizing long-run collective payoff in diverse multi-agent environments.
'''

description_COLLECTIVE_113 = '''
Name (informal): Collective Conditional Cooperation with Forgiveness, Targeted Punishment and Occasional Testing

Overview (goal)
- I try to sustain high group welfare by cooperating whenever the group is reliably cooperating, but I refuse to be a permanent sucker. I react to recent group behavior, punish coordinated collapse briefly, then forgive and test for recovery. I never rely on communication or shared norms; my decisions use only n, r, observed contributions and payoffs.

Parameters I use (derived from game parameters r, n)
- Memory window W = min(5, r) — look at up to the last 5 rounds (fewer if r < 5).
- Punishment length P = 2 rounds (short, to deter exploitation but avoid long grudges).
- Severe-drop trigger delta_drop = 0.4 (a fast large fall in cooperation).
- High-cooperation threshold T_high = 0.7; low-cooperation threshold T_low = 0.3.
- Small exploratory/coaxing probability p_test = 0.05 for occasional probing when the group looks deadlocked.
- Endgame horizon H_end = min(3, r) — last few rounds treated cautiously.

Decision rules (per round t)
1. First round:
   - Cooperate (contribute 1). This signals willingness to build a cooperative norm.

2. Endgame handling:
   - If t is the final round (t = r): defect (contribute 0). No future to reward cooperation.
   - If t is within the last H_end rounds (but not the last round): scale down cooperation propensity linearly as the horizon shortens (see step 5). This preserves some cooperation if the group has been stable but avoids being exploited in the obvious endgame.

3. Compute recent group behavior:
   - Let opp_avg_recent be the average contribution per opponent over the last W rounds (exclude my own contributions so I evaluate others’ willingness).
   - If fewer than W rounds exist, use all available history.

4. Severe-collapse detection and punishment:
   - If opp_avg_recent has fallen by more than delta_drop compared with the previous W-round average (i.e., a sudden large decline in others’ cooperation), enter Punishment Mode:
     - For the next P rounds, defect (contribute 0). This is a short coordinated response to deter mass free-riding.
     - After P rounds of punishment, exit Punishment Mode and go to a Test round (step 6).
   - Punishment Mode can be re-triggered by another severe drop later.

5. Normal conditional cooperation (when not punishing and not in test):
   - If opp_avg_recent >= T_high: Cooperate (contribute 1). Group is strongly cooperative; reciprocate to maximize collective payoff.
   - Else if opp_avg_recent <= T_low: Defect (contribute 0). Group is largely free-riding; protect myself from exploitation.
   - Else (middle region, ambiguous):
     - Play mixed/coaxing behavior: cooperate with probability p = 0.2 + 0.8 * opp_avg_recent (so p moves between ~0.2 and ~1 as others’ cooperation increases). This gives a gradient response that is forgiving and adaptive rather than binary.
   - If t is within the last H_end rounds (but not the last round), multiply p by (remaining_rounds / H_end) to reduce cooperation as the end approaches (so cooperation tapers off toward 0 at the last round).

6. Tests and exploration:
   - After a punishment episode I perform a small, deliberate Test round: cooperate once to see if others resume cooperation.
   - When the group has been defecting for a long time (e.g., opp_avg_recent near 0 for many windows), with small probability p_test I cooperate anyway to probe whether others are willing to restart cooperation. This prevents permanent deadlock from small random events.
   - If a test cooperation is met by increased cooperation from others in the next window, return to Normal conditional cooperation; otherwise revert to defecting until another test/punishment cycle.

7. Forgiveness and noise tolerance:
   - I allow sporadic single-round deviations by others without switching to permanent punishment. Only a persistent low average or a sharp collapse triggers punishment. This tolerates accidental mistakes and noisy opponents.

Rationale / properties
- Collective orientation: I favor mutual cooperation when the group demonstrates it, because that maximizes collective payoffs and benefits me when others reciprocate.
- Robustness: Short, decisive punishment deters exploiters but avoids long grudges that destroy welfare. Probabilistic cooperation in ambiguous cases avoids being exploited deterministically while allowing cooperation to re-emerge.
- Adaptivity: The policy uses recent history (W) to track changing population behavior and scales cooperation down near the end of the game to avoid predictable endgame exploitation.
- Exploration: Occasional tests let me discover cooperative partners after long defection spells; generosity promotes recovery from accidental defections.
- No assumptions on others: All decisions are based only on observed actions/payoffs and game length; no explicit coordination or shared labels needed.

Summary (short pseudocode-like steps)
- Round 1: Cooperate.
- Each round:
  - If final round: defect.
  - Compute opp_avg_recent (last W rounds, excluding me).
  - If severe drop relative to previous window: defect for P rounds (punish), then do a Test round.
  - Else if opp_avg_recent >= 0.7: cooperate.
  - Else if opp_avg_recent <= 0.3: defect.
  - Else cooperate with probability p = 0.2 + 0.8 * opp_avg_recent (scaled down in the last H_end rounds).
  - Occasionally (probability p_test) cooperate when the group looks permanently deadlocked to probe for renewed cooperation.

This strategy aims to achieve high collective payoffs when others are willing, avoid steady exploitation, recover from mistakes, and remain adaptive across many opponent types.
'''

description_COLLECTIVE_114 = '''
Strategy name: Collective Responsive Conditional Cooperator (CRCC)

Intuition (short): Start by trying to build cooperation. Cooperate whenever a clear majority of other players showed cooperation recently; punish defections briefly and proportionally to deter exploitation; forgive quickly and probe to re-establish cooperation. Always use only observable history (players’ past actions) and the game parameters (n, r, k). In the final round defect (standard backward-induction safeguard); in the short endgame reduce generosity to avoid exploitation.

Parameters computed from the game:
- n, r, k are given.
- window w = max(1, min(5, floor(r/4))) — short recent-history window (at least 1, up to 5 rounds).
- majority_threshold = ceil((n-1)/2) — a majority of the other players.
- max_punish = min(3, max(1, floor(r/10))) — punishments are short (1–3 rounds) and scale with horizon.
- test_probability ε = 0.10 — small probability to try to re-establish cooperation after punishment.

State variables maintained (derived from history only):
- For each past round t we observe each player’s action c_j(t) (1 = C, 0 = D).
- punish_until_round (initially 0): if current round ≤ punish_until_round we are in an active punishment period.
- distinct_defectors_in_window: number of distinct other players who defected at least once in the last w rounds.

Decision rules (what I will play in round t, t = 1..r):

1) First round (t = 1)
- Play C (cooperate). Rationale: signal willingness to cooperate and try to reach the high-payoff collective outcome.

2) Last round (t = r)
- Play D (defect). Rationale: avoid being exploited in the terminal round where there is no future to enforce cooperation.

3) If currently in punishment (t ≤ punish_until_round)
- Play D.
- Do not change punish_until_round during the punishment period except when additional rule below extends it.

4) Normal-round decision (t not first, not forced punishment, not last)
- Compute recent behavior:
  - For the single most recent past round t-1, let other_coops_last = number of other players (≠ me) who played C in round t-1.
  - Over the last w rounds (or since round 1 if fewer than w rounds have elapsed), compute distinct_defectors_in_window = number of distinct other players who played D at least once.
  - Also compute recent_coop_fraction = (sum over last w rounds of other players’ C) / ((n-1)*w) — used only to break ties/soft decisions.

- Primary cooperative rule:
  - If other_coops_last ≥ majority_threshold then play C. (If a majority of others cooperated in the immediately prior round, reciprocate by cooperating.)

- Generous forgiveness exception (quick restoration):
  - If other_coops_last = majority_threshold - 1 AND the pattern in t-1 looks like a single isolated defector (i.e., exactly one other player played D in t-1), then play C. (Give a one-shot forgiveness to try to restore full cooperation quickly.)

- Otherwise (a clear lack of recent majority cooperation):
  - Play D and initiate a short punishment targeted at deterring repeated defection:
    - Let L = 1 + min(max_punish - 1, distinct_defectors_in_window). Set punish_until_round = t + L - 1.
    - Immediate response is to defect for L rounds, then fall back to normal rules.
    - If a later round before punish_until_round shows a larger distinct_defectors_in_window than used to set L (i.e., more players started defecting), extend punish_until_round up to t' + new L' - 1 where L' = 1 + min(max_punish -1, new distinct_defectors_in_window). (Punishment remains short and proportional; it never becomes permanent.)

5) Post-punishment probing and forgiveness
- On the first round after punish_until_round (i.e., when no active punishment), do:
  - With probability ε play C (probe/coax) to test whether others have recovered cooperation.
  - Otherwise follow the normal-round decision rule above.
- If probing shows others have returned to majority cooperation, revert to the ordinary cooperative rule immediately.

6) Endgame softness
- For the last few rounds before r (specifically rounds r - min(3, floor(r/10)) + 1 through r - 1) be slightly less generous:
  - Apply all rules above but if a decision is close (tie-like behavior in recent_coop_fraction around 0.5), favor D over C in those rounds. This reduces the chance of being exploited by strategies that relentlessly cooperate in the endgame.

Tie-breaking principles
- When counts are exactly at threshold, prefer cooperation in early/mid game (to support collective welfare) and prefer defection in the short endgame as specified.
- All decisions and counters depend only on observed actions and rounds; no communication or hidden signals are required.

Why this is robust and collective
- Starts cooperative to try to obtain the socially optimal outcome (all-C).
- Uses a simple, observable majority rule to reciprocate cooperation: if most others cooperated last round, I cooperate now.
- Punishments are short, proportional, and extendable — enough to deter exploitation but limited so that mistakes/noise (or occasional selfishness) do not permanently destroy cooperation.
- Forgiveness and randomized probes quickly restore cooperation after punishment, prioritizing collective welfare.
- The approach is deterministic except for low-probability probes (ε) that help detect reformation of cooperation without being exploitable.
- The rules are fully specified in terms of n, r, k (via window, thresholds, and max_punish) and the public history only; no assumptions of shared norms or coordination are required.

Edge-case summary
- Single-round game (r = 1): t = 1 is also last round → play D (rational safety for terminal round).
- Very short games (r small): window w collapses to 1; punishments are of length 1; behavior is responsive.
- All-opponent defectors: strategy quickly stops cooperating and limits losses; occasional probes prevent being stuck if others change.
- All-opponent cooperators: strategy cooperates and secures the high collective payoff.
- One-time mistakes by opponents: forgiveness rule plus short punishments avoids spiral of permanent retaliation.

This strategy balances collective intent (trying to sustain all-C for high group payoff), deterrence (short, proportional punishment), and robustness (rapid forgiveness and probing) while depending only on observable history and the game parameters.
'''

description_COLLECTIVE_115 = '''
Purpose: sustain high collective contributions while avoiding long-term exploitation. The strategy is a clear, history-dependent conditional cooperator with lenient punishment, forgiveness, and small exploration to escape deadlocks. It uses only game parameters (n, k, r) and the public history of actions/payoffs.

Summary of core idea
- Start by signaling cooperation.
- Use a Win-Stay Lose-Shift (WSLS) rule based on the actual payoff vs. the counterfactual payoff had I switched last round. This preserves cooperation with reciprocators and punishes defections one round at a time.
- Detect persistent exploiters (players who defect much more than the group) and apply a short, proportional punishment (with automatic forgiveness once they improve).
- Be slightly more forgiving when the group as a whole is cooperating, and occasionally probe (small random cooperation) to re-start cooperation after accidental breakdowns.
- Always defect in the final round (no future to enforce reciprocity).

Parameters (computed from inputs)
- Window length W for recent-history statistics: W = min(5, max(1, floor(r/5))). (If r is small, W is small; otherwise up to 5 rounds.)
- Persistence threshold for exploiters: exploiter_rate = 0.4 (i.e., flagged if a player contributed in <= 40% of the last W rounds).
- Group-cooperation threshold: group_good = 0.75 (if average contribution rate in last W rounds ≥ 75%, be lenient).
- Punishment length P = min(3, remaining_rounds) — short, proportional punishment.
- Small exploration probability p_probe = 0.02 (2%) — occasional cooperative probe to help re-establish cooperation after noise.

Decision rule (round t)
1. Last-round override:
   - If t is the final round (t == r): play D (defect) and stop.

2. First round / early signaling:
   - If t == 1: play C (cooperate) to signal willingness to cooperate.

3. Compute history statistics from rounds (t-1) back to max(1, t-W):
   - For each player j, compute cooperate_rate_j = fraction of those W rounds in which j played C.
   - Compute group_coop_rate = average of cooperate_rate_j over all players (or equivalently total contributions in the window divided by n*W).

4. Persistent-exploiter detection:
   - If any player j has cooperate_rate_j ≤ exploiter_rate and their cooperate_rate_j is at least 20 percentage points below group_coop_rate, mark j as an exploiter.
   - If I am currently in a punishment period for an exploiter (see below), continue that punishment until P rounds have passed or until the exploiter’s cooperate_rate_j rises above exploiter_rate.
   - Punishment action = D for the punishment rounds. During punishment allow a single cooperative probe with probability p_probe to test recovery.

5. Core WSLS (applies when not in exploiter punishment):
   - Let my_action_prev be my action in round t-1 and total_prev be total contributions in round t-1.
   - Compute my_payoff_prev (observed).
   - Compute the counterfactual payoff if I had done the opposite action in round t-1 (this is known because all contributions are public). For example:
     - If my_action_prev == C, counterfactual = payoff I would have got if I had D given others’ contributions that round.
     - If my_action_prev == D, counterfactual = payoff I would have got if I had C given others’ contributions that round.
   - If my_payoff_prev ≥ counterfactual: repeat my_action_prev this round (win -> stay).
   - Else: switch action this round (lose -> shift).

6. Leniency toward a broadly cooperative group:
   - If WSLS prescribes D this round but group_coop_rate ≥ group_good, override to C with high probability (e.g., 90%) to sustain cooperation when the group is generally cooperative. This reduces cascade failures from single mistakes.

7. Small exploration / forced probes:
   - Independently of the above, with probability p_probe cooperate this round (this can be suppressed if currently punishing an exploiter except allow one probe during punishment). Probes help re-establish cooperation after accidental breakdowns.

8. Bookkeeping for punishments and forgiveness:
   - A punishment for a detected exploiter is short (at most P rounds) and is lifted as soon as the exploiter’s recent cooperation improves above exploiter_rate. After punishment ends, immediately return to the WSLS baseline (so the strategy is forgiving, not permanent-grim).

Rationale and notes
- WSLS is robust: it maintains mutual cooperation with other conditional cooperators, retaliates briefly against defectors, and forgives one-off mistakes. It uses directly observable counterfactual payoffs, so no extra parameters are required to decide whether the last round was “good” or “bad” for me.
- Persistent-exploiter detection prevents long-term exploitation by players who almost always defect while others cooperate; punishment is short and proportional so it doesn’t collapse group cooperation unnecessarily.
- Group-level leniency (when group_coop_rate is high) prevents a single noisy defection from triggering prolonged collapse of cooperation.
- Final-round defection guards against being exploited when there is no future enforcement.
- Small probing randomness helps the strategy escape symmetric punishment cycles caused by simultaneous strict punishments or by noise.

Behavioral summary (short)
- Round 1: cooperate.
- Each subsequent round: normally apply WSLS (repeat last action if you earned at least as much as you would have by switching; otherwise switch).
- If someone is repeatedly free-riding (flagged as exploiter), defect for a short proportional punishment period targeted at correcting that behavior; forgive quickly when they improve.
- If the group has been strongly cooperative recently, be lenient and favor cooperation even when tempted to defect.
- Occasionally probe by cooperating with small probability to re-start cooperation.
- Always defect in the final round.

This strategy aims to maximize collective contributions by promoting stable cooperation, while remaining robust to a wide variety of opponent behaviors (one-shot defectors, alternating exploiters, noisy mistakes) through short proportional punishments, forgiveness, and occasional probing.
'''

description_COLLECTIVE_116 = '''
Name: Collective Forgiving Conditional Cooperation (CFCC)

Intuition (brief)
- Aim to maximize collective payoff by sustaining cooperation when a clear majority of the group is cooperating, while avoiding endless harsh punishment that destroys group welfare.
- Signal cooperation first, forgive occasional lapses, apply short proportional punishments to deter persistent free-riding, and stop cooperating only if exploitation is persistent.
- Use only game parameters (n, k, r) and the public action history.

Parameters (computed from game parameters)
- Memory window w = min(5, max(1, floor(r/5))). (Use up to five past rounds; fewer if r is small.)
- Cooperation fraction alpha = 0.60. (Require ~60% of other players cooperating recently to justify continuing to cooperate.)
- Low-cooperation cutoff beta = 0.25. (If the group has cooperated on average below 25% over the whole history, switch to safe mode.)
- Punishment length P = min(3, max(1, ceil(r/20))). (Short, finite punishment to deter but not destroy cooperation.)
- Tolerance for occasional defectors: tolerate occasional single-round deviations; punish only when the recent cooperation signal falls below alpha.

These choices are fixed before play and depend only on n,k,r (through w and P).

Decision rules (per round t, using only history and parameters)

1. Endgame rule
- If t is the final round (t = r): play D (defect). (No future to sustain reciprocity.)

2. First-round rule
- If t = 1: play C (cooperate) to signal cooperative intent.

3. Compute recent group cooperation signal
- For the last up-to-w rounds (rounds max(1,t-w) .. t-1), compute the average fraction of players who contributed each round (include all players, excluding current decision). Call this recent_fraction.
- Also compute overall_fraction = average fraction of cooperators across all past rounds (if any).

4. Low-cooperation safety
- If overall_fraction < beta: the group has been persistently uncooperative. Switch to safe mode: play D for the remainder of the game (except still play D on the final round as above). Rationale: avoid being exploited when cooperation is never reciprocated.

5. Main conditional cooperation rule
- If recent_fraction >= alpha: cooperate (play C). Rationale: a clear recent majority is cooperating; contributing supports collective welfare and helps sustain cooperation.
- If recent_fraction < alpha: enter proportional short punishment:
  - Defect (play D) for the next P rounds (or until the last round if fewer than P rounds remain). During these P rounds you continue to compute recent_fraction but do not resume cooperation until the P-round punishment expires.
  - After the P rounds of defection, re-evaluate: if recent_fraction (re-computed over the most recent w rounds) is now >= alpha, resume cooperation; otherwise repeat a short punishment cycle. This makes punishment finite and forgiving.

6. Targeted forgiveness and re-entry
- If an individual who previously defected begins contributing again and the group recent_fraction recovers to >= alpha, resume cooperation immediately after the current punishment cycle finishes. This enables re-establishing cooperation after a short calibrated punishment rather than permanent exclusion.

7. Avoid punishing in the very end
- If fewer than P rounds remain (but it is not the last round), use discretion: if recent_fraction is only slightly below alpha (e.g., within 10% of alpha) and remaining rounds are few, prefer cooperation to preserve welfare; otherwise, carry out a short defection that matches remaining rounds. (This prevents pointless punishment when there is no future to enforce behavior.)

Special notes to increase robustness
- The strategy tolerates occasional mistakes: w > 1 smooths noise. Short punishments (small P) avoid spirals into universal defection and make cooperation attractive again.
- The low-cooperation cutoff (beta) prevents endless exploitation by defectors: if the whole group never cooperates, CFCC stops giving away tokens.
- The parameters are conservative (moderate alpha, short P) to work well against a wide variety of opponents: pure cooperators, conditional cooperators, exploiters, retaliators, and strange heuristics.
- No reliance on communication or on other players following the same rule; decisions use only public history.

Summary pseudocode (natural-language)
- Precompute w, alpha, beta, P from n,k,r.
- If t = 1: play C.
- If t = r: play D.
- Compute recent_fraction over last w rounds; compute overall_fraction over all past rounds.
- If overall_fraction < beta: play D forever (safe mode).
- Else if recent_fraction >= alpha: play C.
- Else: play D for the next P rounds as a short punishment, then reassess (resume C only when recent_fraction >= alpha).
- If fewer than P rounds remain, prefer cooperation if recent_fraction is close to alpha and punishment would be ineffective; otherwise use remaining rounds for proportionate punishment.

Collective mindset
- CFCC prioritizes the group payoff: it opens with cooperation, supports cooperation whenever a clear majority reciprocates, uses minimal punishments to deter freeloaders, and quickly forgives to restore cooperation. It only withdraws cooperation permanently when the whole group persistently fails to reciprocate.
'''

description_COLLECTIVE_117 = '''
Collective-First Conditional Cooperator (CFCC)

Goal: maximize long-run group payoff by encouraging and sustaining mutual contributions while avoiding long-term exploitation. The strategy uses simple, transparent rules based only on the known parameters (n, r, k) and observed history. It is forgiving, includes occasional probing to recover cooperation, and avoids permanent, unforgiving punishments.

Parameters (set from the game parameters)
- Window T = min(10, r). (Use the last T rounds to assess recent behavior.)
- Cooperator threshold q = 0.60. (A player whose contribution rate over the window ≥ q is treated as a cooperator.)
- Group threshold φ = 0.50. (If at least φ of other players are currently “cooperators”, favor cooperation.)
- Forgiveness tolerance ε = 0.10. (Small temporary drops below q are treated as noise.)
- Probe probability p_probe = 0.10. (When in a defensive/punishment mode, occasionally cooperate to test restoration.)
- Last-round rule: always defect in round r (no incentive to cooperate in final round).
- Near-end caution: in round r−1 (second-to-last), cooperate only if the average cooperation rate of others over the full history is ≥ 0.90 (strong evidence of trustworthy cooperation); otherwise defect.

State maintained from history
- For each player j ≠ me, compute recent_coop_rate_j = fraction of rounds they contributed in the last T rounds (or in all past rounds if fewer than T have occurred).
- Label player j as Cooperator if recent_coop_rate_j ≥ q; as Weak-Cooperator if recent_coop_rate_j ∈ [q−ε, q); as Defector otherwise.
- Compute fraction_cooperators = (number of players labeled Cooperator) / (n−1).
- Compute average_coop_rate = average of recent_coop_rate_j across j ≠ me (useful for near-end decision).

Decision rules (per round, given remaining rounds rem = r − current_round + 1)
1. Terminal rounds
   - If rem == 1 (final round): play D (defect).
   - If rem == 2 (second-to-last): play C only if average_coop_rate ≥ 0.90; otherwise play D.

2. Early/normal rounds (rem ≥ 3)
   A. If there is unanimous or near-unanimous recent cooperation
      - If fraction_cooperators ≥ φ (≥ 50% of others are cooperators), play C (contribute). This signals and sustains collective cooperation.
   B. If the group is split or cooperative behavior has fallen
      - If fraction_cooperators < φ, enter a defensive mode:
         - Default action: play D.
         - While in defensive mode, every round with independent probability p_probe play C instead of D to test whether others will return to cooperation.
         - Continuously recompute labels each round. If fraction_cooperators rises to ≥ φ, exit defensive mode and resume playing C.
   C. Handling borderline / noise
      - Treat Weak-Cooperators as cooperators for one extra round (forgiveness) unless their weak status persists for 2 or more windows.
      - Do not permanently blacklist players for a single defection: only sustained low recent_coop_rate moves a player to Defector status.
   D. Recovery and re-entry
      - After a punishment/defensive phase, re-enter cooperative mode when fraction_cooperators ≥ φ.
      - If a previously Defector raises recent_coop_rate above q (i.e., starts cooperating consistently), immediately treat them as a Cooperator and cooperate when group threshold is met.

3. First round
   - If r == 1: D (final round).
   - If r == 2: D (as above).
   - If r ≥ 3: play C to signal collective intent (unless historical evidence from pre-play rounds exists in tournament format — but here there is none). This gives cooperation a chance to form quickly.

Rationale and properties
- Collective orientation: the strategy actively seeks group cooperation when a credible mass of others are cooperating; it starts cooperatively to give cooperation a chance and uses clear, measurable criteria (recent cooperation rates) to decide when to sustain or withdraw cooperation.
- Robustness: sustained defectors trigger defensive withdrawal of contributions, preventing long-term exploitation. The use of a sliding window and ε tolerance avoids overreacting to isolated mistakes or noise.
- Forgiveness & recovery: periodic probing (p_probe) and requiring a return above threshold before full cooperation resumes enable recovery from breakdowns without permanent punishment or infinite defection cycles.
- Endgame safety: explicit last-round and near-end rules avoid being exploited in the known finite horizon.
- Simple and transparent: rules depend only on counts and recent frequencies (no private signals, no external coordination), so they work in heterogeneous tournaments and adapt to a wide variety of opponent behaviors.

Summary (concise pseudocode-like)
- If last round → D.
- If second-last → C only if average_coop_rate ≥ 0.90, else D.
- Else:
  - Compute recent_coop_rate_j over last T rounds for each other player.
  - Label cooperators if ≥ q (weak if within ε below q).
  - If fraction_cooperators ≥ φ → C.
  - If fraction_cooperators < φ → D, but with independent probability p_probe play C to probe.
  - Forgive single lapses; only sustained low rates count as defection.
- First round (if rem ≥ 3) → C.

This strategy favors collective welfare when reciprocation is available, deters exploitation, and is resilient: it cooperates with cooperators, punishes persistent defectors, forgives occasional noise, and includes probing to restore cooperation.
'''

description_COLLECTIVE_118 = '''
Collective Conditional Cooperator with Graduated Punishment and Forgiveness (C3G-P)

Goal: sustain high collective contribution when partners appear willing, deter and correct exploitative defects, and avoid permanent retaliation. Uses only n, k, r and the public history of contributions/payoffs.

Parameters (computed from game parameters)
- window w = min(5, r) — look-back window for short-term cooperation estimates.
- threshold theta = 0.60 — fraction of contributions (over players × rounds) regarded as “sufficient cooperation.”
- punishment length P = max(1, ceil(4*(1 - k/n))) — number of rounds to withhold cooperation after detecting a bad unilateral defection (longer when the public good is less self-reinforcing).
- forgiveness window S = w — number of rounds of sustained good behavior required to resume cooperation after punishment.

State variables (derived from observed history)
- recent_coop_rate = (sum of contributions by all players over last w rounds) / (n * w).
- last_round_coop_rate = (sum of contributions by all players in round t-1) / n.
- in_punishment = boolean (starts false). If true, punishment_counter counts rounds remaining in punishment.
- persistent_defectors = set of players with long-run cooperation rate < 10% (optional bookkeeping to recognize serial defectors).

Decision rules (applied each round t = 1..r)

1. First round (t = 1)
- Contribute (C). Start by signaling cooperative intent.

2. Rounds 2..r-1 (intermediate rounds)
- Update recent_coop_rate and last_round_coop_rate from observed history.

- Detection of exploitive defection (trigger for punishment):
  - If last_round_coop_rate >= theta and at least one player defected in the last round (i.e., last_round_coop_rate < 1), then treat that as a suspected exploitative defection and set in_punishment = true, punishment_counter = P.
  - Also immediately add any player who defected in that “cooperative” round to persistent_defectors if their long-run cooperation fraction is very low (optional).

- If in_punishment:
  - Defect (D) this round.
  - Decrement punishment_counter by 1.
  - If punishment_counter reaches 0, set in_punishment = false.
  - After punishment ends, require that recent_coop_rate >= theta for S consecutive rounds before resuming unconditional cooperation; otherwise remain defecting until cooperation recovers. (Concretely: if recent_coop_rate >= theta now, cooperate next round; if not, continue defecting.)

- If not in_punishment:
  - If recent_coop_rate >= theta, contribute (C). (Default: cooperate when the group has shown steady cooperation.)
  - If recent_coop_rate < theta, defect (D). (Withhold cooperation while group cooperation is low.)

Notes on individual-targeting:
- Because the action space is a single public contribution, direct targeted punishment is impossible. Our punishment is group-wide (withholding contributions) to reduce the short-run gains of unilateral defection and to encourage restoration of cooperation. The persistent_defectors set is only for judgment about whether to be more conservative in resuming cooperation when the same players repeatedly sabotage cooperation.

3. Last round (t = r)
- Because there is no future to enforce cooperation, be cautious:
  - Cooperate in the last round only if last_round_coop_rate >= theta (i.e., the group cooperated recently and appears likely to cooperate now), otherwise defect.
  - Rationale: avoid unpunishable exploitation while giving final-round cooperation when it is mutual and stable.

Additional robustness and behavioral details
- Forgiveness: punishments are finite (P rounds) and we return to cooperation after observing sustained group cooperation (S rounds). This prevents permanent wars from noise and supports recovery after mistakes.
- Noise and occasional mis-cooperation: the short window w and moderate theta prevent overreaction to single noisy defections; the strategy only triggers punishment when defections happen against a cooperative background.
- Against pure defectors: the strategy quickly falls into non-cooperation (protecting the individual payoff) after seeing low recent_coop_rate and persistent defection.
- Against conditional cooperators: the strategy cooperates early and resumes cooperation as soon as others show they are cooperating, producing mutual high payoff.
- Collective emphasis: choices prioritize restoring and maintaining group cooperation when group behavior supports it, and apply measured, temporary collective withholding to deter exploiters rather than permanently ostracizing everyone.

Summary (concise pseudocode-style)
- t = 1: C
- For each t > 1:
  - Compute recent_coop_rate over last w rounds and last_round_coop_rate.
  - If last_round_coop_rate >= theta and someone defected last round → set in_punishment = true, punishment_counter = P.
  - If in_punishment:
      - Play D; punishment_counter -= 1; if punishment_counter == 0 → in_punishment = false.
      - After punishment ends, require recent_coop_rate >= theta to resume C.
  - Else (not in punishment):
      - If recent_coop_rate >= theta → C
      - Else → D
- Last round t = r: play C only if last_round_coop_rate >= theta; else D.

This strategy is simple, transparent, prioritizes collective welfare where others show willingness, uses finite and proportionate punishment to deter exploitation, and is forgiving so cooperation can recover.
'''

description_COLLECTIVE_119 = '''
Adaptive Collective Reciprocity (ACR)

Summary
Be cooperative by default, punish proportionally and briefly when the group tilts toward free-riding, and forgive often enough to restore cooperation. Punishment is calibrated to the size of the deviation and decays over time. Defect in the final round (no future to enforce cooperation). The rules use only n, r, k and the observed actions/payoffs history.

Parameters (derived from game parameters; no external coordination)
- lookback w = min(3, r). (Examine the last w rounds for recent behavior.)
- majority threshold θ = 0.50 (cooperate when a majority of others have been cooperating in recent rounds).
- strong-cooperation threshold θ_high = 0.75 (used to re-enter stable cooperation).
- base punishment length P_base = 2 rounds.
- max punishment P_max = min(5, max(1, r//4)).
- forgiveness probability p_forgive = 0.20 (20% chance to forgive early and return to cooperating to break cycles).
- endgame window E = min(3, r) (near the end we become cautious; final round always defects).

Policy (per-round decision rules)
1. First round:
   - Play C (contribute). Start in Cooperative mode.

2. Final round:
   - Play D (defect). There is no future to enforce cooperation.

3. For any round t (2 ≤ t < r):
   - Compute, over the last w completed rounds, for each round the fraction of players who contributed. Let f_recent be the average of those fractions. Also let f_last be the fraction of players (excluding you) who contributed in the immediately previous round.
   - Maintain an internal state variable:
     - Mode ∈ {Cooperative, Punishing}. If no punishments are active, Mode = Cooperative.
     - If in Punishing mode, also track remaining_punish (rounds left to punish).

4. Cooperative mode behavior:
   - If we are within the endgame window (t > r − E):
     - Be cautious: cooperate only if f_recent ≥ θ_high; otherwise defect this round.
   - Else (not in endgame):
     - If f_last ≥ θ (a majority of others cooperated last round), play C (cooperate).
     - If f_last < θ (a minority cooperated last round), start a proportional punishment:
       - Set severity S = round((θ − f_last) * (n − 1)) capped between 1 and P_max.
       - Set remaining_punish = min(P_max, P_base + S).
       - Switch Mode → Punishing.
       - Play D this round (begin punishment).

5. Punishing mode behavior:
   - While remaining_punish > 0:
     - Play D (defect).
     - Decrement remaining_punish by 1.
     - If remaining_punish reaches 0, stop punishing and evaluate recovery:
       - Compute f_recent over the last w rounds (including punishments just served).
       - If f_recent ≥ θ_high, return to Cooperative mode.
       - Else, with probability p_forgive immediately return to Cooperative mode (one-shot forgiveness); otherwise, start a shorter follow-up punishment of length 1 or 2 (set remaining_punish = 1 or 2 depending on how low f_recent is), then continue punishing.

6. Noise-robustness and anti-exploitation features:
   - Proportional punishments: punishment length increases with the size of the observed drop in cooperation, so isolated lapses get only small responses while mass defection gets stronger responses.
   - Limited punishment lengths and probabilistic forgiveness prevent permanent collapse (no grim trigger). This restores cooperation quickly when others resume cooperative behavior.
   - During punishment we only defect; we do not attempt to single out individuals (we cannot coordinate), so the rule treats the group collectively—aiming to restore group norms rather than to seek revenge on one player.
   - In the endgame (last few rounds), be conservative: cooperation only when recent cooperation is strong. Final round defects to avoid being exploited.

Rationale and collective alignment
- The strategy starts cooperative and rewards majority cooperation, encouraging a collective mindset: if most players sustain contributions, ACR contributes.
- Punishments are proportional and temporary, minimizing collective losses while signaling that defection reduces future collective payoffs.
- Forgiveness and limited punishments avoid lock-in to mutual defection and allow cooperative equilibria to re-emerge.
- The strategy depends only on observable history and game parameters, is robust against many opponent behaviors (always-defect, always-cooperate, conditionals, noisy agents), and aims to maximize long-run collective welfare by stabilizing majority cooperation whenever feasible.
'''

description_COLLECTIVE_120 = '''
Name: Proportional Forgiving Collective Cooperator (PFCC)

Principle (collective mindset)
- I favour and try to sustain group-wide contribution because the group payoff is maximized when most players contribute. I will contribute when the history shows sufficient reciprocity, and I will impose short, proportional punishments when the group falls short, but I forgive quickly so cooperation can be restored.

Parameters computed from game inputs (deterministic, no hidden tuning)
- Window W = min(5, r)  (look at up to the last 5 rounds)
- normalized_k = (k - 1) / (n - 1)  (in [0,1])
- cooperation target q = 0.5 + 0.4 * normalized_k  (so q ∈ [0.5,0.9]; higher k → higher target)
- maximum punishment length Pmax = min(3, r)  (I will never punish longer than 3 rounds)
- endgame window E = min(3, r)  (final rounds where exploitation risk is high)

Internal state I carry in my rules
- punish_counter (initially 0). When > 0 I am in a punishment phase and will defect; it counts remaining punishment rounds.

Decision rules (what I do each round)
1. First round:
   - Contribute (C).

2. If punish_counter > 0:
   - Defect (D) this round.
   - After the round ends, decrement punish_counter by 1.
   - (During punishment I still observe everyone’s actions; if the group immediately returns to high cooperation I will stop further punishment when the counter expires and resume cooperating.)

3. Otherwise (not currently punishing), consider remaining rounds left T_rem:
   - If T_rem ≤ E (we are in the endgame):
     - Cooperate this round only if at least fraction q of players contributed in the previous round; otherwise defect.
       Rationale: reduce vulnerability to one-shot exploitation in the last few rounds while still allowing cooperation if it was just reciprocated.
   - Else (not in endgame):
     - Compute f_avg = average fraction of players who contributed over the last W rounds (use all available rounds if < W).
     - If f_avg ≥ q:
         - Cooperate (C): the group has been reciprocating sufficiently.
     - Else:
         - Enter punishment: set punish_counter = max(1, ceil((q - f_avg) * Pmax )) and Defect (D) this round.
           - This imposes a short punishment proportional to how far cooperation has fallen below target, but bounded by Pmax.
           - After punishment ends, I will reassess using the same rule: if f_avg has recovered to ≥ q I resume cooperating; otherwise I repeat short proportional punishments.

Behavioral clarifications / tie-breakers
- If the previous round had full cooperation (everyone contributed), I always cooperate next round unless I am in the middle of a punishment counter.
- If I was the only contributor last round (f_last = 1/n), I defect next round (that counts as the start of a short punishment) because lone cooperation is being exploited.
- Punishments are designed to be short and proportional so they deter persistent free-riding but do not collapse the group by permanent retaliation.
- I never punish longer than Pmax rounds, and I always re-evaluate after punishments to allow rapid restoration of cooperation.
- All decisions use only the known parameters (n, r, k) and the public history of contributions/payoffs.

Why this is robust and adaptive
- Start-cooperative and generous target q (scaled by k) promotes high-payoff cooperation when others are willing.
- Proportional, bounded punishments deter defectors without provoking permanent mutual defection.
- Sliding-window averaging smooths transient deviations (one-off mistakes or odd opponents) while allowing detection of sustained exploitation.
- Endgame caution reduces vulnerability to final-round exploitation while still allowing cooperation if it was just reciprocated.
- No communication or norm assumptions required; the rule responds only to observed behavior and the game parameters.
'''

description_COLLECTIVE_121 = '''
Collective Adaptive Reciprocity with Proportional Punishment (CARPP)

Goal: sustain high group contributions over the repeated game by (1) starting with cooperation, (2) cooperating when a clear majority of players are contributing, (3) applying short, proportionate punishments when cooperation collapses, and (4) forgiving to allow recovery. The rule set uses only n, r, k and the observable history of every player's contributions/payoffs.

Parameters derived from game parameters (fixed at start)
- Memory window L = min(10, r). (Look at the last L rounds for short-term trends.)
- Majority threshold M_frac = 0.60 (60% of players). Let M = ceil(M_frac * n).
- Low threshold L_frac = 0.30 (30% of players). Let Lthr = floor(L_frac * n).
- Base punishment length P_base = max(1, min(3, floor(r/10))). (A short, proportional punishment.)
- Endgame window E = min(3, r). In the last E rounds apply conservative endgame rules.

Notes: these constants (0.60, 0.30, small P_base) are chosen to be robust across many opponent behaviors — strict enough to deter free-riding but forgiving enough to allow cooperation to recover. They depend only on n and r (via L and P_base) and observable history.

Decision rules (each round decide C or D)

1. First round
- Cooperate (C). This signals willingness to sustain collective welfare.

2. For any round t (2 <= t <= r), compute from history:
- For each player j, count contributions by j in the last L rounds: contrib_count_j.
- Let recent_total = sum_j contrib_count_j (sum over last L rounds).
- Let recent_avg_per_round = recent_total / L (expected number of contributors per round in the recent window).
- Let last_round_contributors = number of players who contributed in the immediate previous round.
- Let remaining_rounds = r - t + 1 (including current).

3. Endgame rule (when remaining_rounds <= E)
- If the group has been highly cooperative historically: if (total contributions over entire history) / (t-1) >= 0.85 * n, then cooperate (attempt to preserve cooperation).
- Otherwise, default to defect (D) in the last E rounds, but probe once: if the immediate previous round had at least M contributors, cooperate this round; otherwise defect. (This avoids being exploited by predictable endgame defection while allowing one last coordinated cooperative chance if cooperation remains strong.)

4. Normal-phase rule (not endgame)
- If last_round_contributors >= M: cooperate (C).
  Rationale: a clear majority cooperated last round; continue cooperation to maintain the public good.
- Else if last_round_contributors <= Lthr: initiate proportionate punishment:
  - Enter a punishment phase: defect (D) for P = min(P_base + ceil((M - last_round_contributors)/max(1,floor(n/4))), remaining_rounds - 1) consecutive rounds (never punish for all remaining rounds).
  - After P rounds of defection, attempt re-entry by cooperating for one round and observe the response (see "Re-entry test" below).
  Rationale: when few contributed, punish briefly to increase the cost of free-riding and deter persistent defectors.
- Else (intermediate case: last_round_contributors between Lthr+1 and M-1): try probabilistic reconstruction:
  - Cooperate with probability p = clamp(0.05, last_round_contributors / n + 0.1, 0.9).
  - If you cooperate and the next round shows last_round_contributors >= M, switch back to deterministic cooperation.
  Rationale: when cooperation is degraded but not collapsed, use cautious, proportional cooperation to help rebuild a cooperative norm without being systematically exploited.

5. Re-entry test and forgiveness
- After any punishment phase, on the first round after punishment, cooperate (C) once to signal willingness to restore cooperation.
- If the immediate response (the next observed round) shows at least M contributors, permanently return to the normal cooperative rule.
- If not, resume a short punishment/defect phase of length P_base and repeat. In all cases never punish beyond a small fraction of remaining rounds; the strategy always allows return to cooperation.

6. Handling persistent individual defectors
- Track players who never contributed in the last L rounds (contrib_count_j = 0). If more than half the players are persistent non-contributors, the strategy shifts to a defensive mode: defect until a clear majority (>= M) contributes in a single round, then follow the usual re-entry test. This avoids sustained exploitation when most players are pure defectors.
- However, the strategy never permanently ostracizes players: if cooperation returns (>= M contributors), forgive and resume cooperation.

7. Tie-breaking and deterministic behavior
- If a decision depends on equality (e.g., last_round_contributors exactly equals M or Lthr), treat equality in favor of cooperation (i.e., cooperate on ties) to bias toward collective welfare when ambiguous.

Collective mindset summary
- Start by signaling cooperation.
- Continue cooperating while a clear majority of players are cooperating.
- When cooperation collapses, apply short, proportional punishments that are calibrated to the severity of the collapse; punishments are limited so they do not destroy the possibility of recovery.
- Always attempt to re-establish cooperation by forgiving and testing re-entry.
- In the final few rounds, be conservative to avoid predictable endgame exploitation but allow one last cooperative probe if the group has been strongly cooperative historically.
- These rules prioritize collective welfare: they seek to sustain and rebuild group contributions, punish defection enough to deter free-riding, and are forgiving to allow cooperation to re-emerge.

Behavioral examples (illustrative)
- If most players keep contributing every round, CARPP cooperates every round and maximizes group payoff.
- If one or two players occasionally defect, CARPP keeps cooperating (forgives small lapses).
- If cooperation drops sharply (few contributors), CARPP defects for a short, proportionate punishment period, then tests re-entry by cooperating once; if others cooperate, CARPP resumes full cooperation.
- If near the end of the game cooperation has broken down, CARPP defects to avoid being a constant sucker, but will make a single cooperative probe if history indicates a strong chance of success.

This strategy is implementable given only n, r, k and observed history; it is adaptive (responds to frequency and severity of defection), robust (resists exploitation by always-defectors and noisy cooperators), and collective (biased toward sustaining and restoring majority cooperation).
'''

description_COLLECTIVE_122 = '''
Adaptive Collective Conditional Cooperator (ACCC)

Goal: maximize collective payoff by cooperating when a clear, sustained majority of group members reciprocate, but avoid long-term exploitation by defectors. Use short, proportionate punishment and prompt forgiveness to restore cooperation. Decisions use only n, k, r and the observed history of every player’s past actions.

Definitions / parameters (computed at start from game parameters):
- Seed rounds M = min(3, r). (Early probing to signal willingness to cooperate.)
- Reputation window W = min(8, r). (Recent-history window to assess others.)
- Reliable threshold q = 0.60. (A player is “reliable” if they contributed in ≥ q of the W most recent rounds.)
- Group-reliability fraction α = 0.60. (We require at least this fraction of the other players to be reliable before contributing.)
- Punishment length P_max = min(3, r). (Maximum short punishment for exploitation.)
- Permanent-defector cutoff = 0.10 (if a player’s lifetime cooperation rate < 10%, treat them as a permanent defector).
- Endgame rule: on the final round (round r) always defect. (Avoid being exploited when no future to enforce reciprocity.)

Decision rule each round t (1-indexed):

1. Endgame check:
   - If t == r (final round), choose D (defect). Stop.

2. Seed phase:
   - If t ≤ M, choose C (contribute). Purpose: signal cooperation and gather data.

3. Compute reputations from history:
   - For each other player j, compute cooperation_rate_j = fraction of rounds in the last W rounds in which j contributed (if fewer than W past rounds exist, use available rounds).
   - Mark j as reliable if cooperation_rate_j ≥ q.
   - Also compute lifetime_coop_j = fraction of all past rounds in which j contributed. If lifetime_coop_j < 0.10, mark j as permanent defector.

4. Decide using group reliability:
   - Let reliable_count = number of other players marked reliable.
   - Let required_count = ceil((n-1) * α).
   - If reliable_count ≥ required_count and there is no currently active punishment that includes this round, choose C.
   - Otherwise choose D.

5. Exploitation detection and punishment (triggered immediately when observed):
   - After any round in which you contributed but fewer than required_count others contributed (i.e., you were exploited relative to the cooperation target), enter a punishment episode of length P = min(P_max, r - t) rounds, during which you defect unconditionally. Record punishment remaining.
   - Punishment is short and proportional: P is small to avoid collapse of cooperation, but long enough to be noticeable.

6. Forgiveness / exit from punishment:
   - After a punishment episode completes, re-evaluate reputations (step 3). If reliable_count ≥ required_count resume contributing; otherwise continue defecting until either reputations improve or another small punishment is triggered later.
   - If many players recover cooperativeness (their cooperation_rate_j rises above q), resume contributing immediately (no extra waiting).

7. Persistent-defector handling:
   - If one or more players are marked as permanent defectors, raise social bar: increase required_count by the number of permanent defectors (i.e., demand more reliable partners among the remainder). Practically: treat permanent defectors as non-participants when counting required reliable partners.

Notes and rationale (concise):
- Seed cooperation (first M rounds) helps establish mutual cooperation with reciprocators who are similarly willing to test cooperation.
- Reputations and the window W let the strategy adapt to shifting group behavior while giving weight to recent trends.
- The reliable threshold q and group fraction α require a clear majority of cooperating partners before risking a contribution; this prevents being repeatedly exploited by a minority of defectors.
- Short, proportionate punishments (P_max small) deter persistent defectors while avoiding the harshness of infinite punishments (which can permanently destroy cooperation against noisy or turning-around partners).
- Forgiveness after punishment restores cooperation quickly if others improve behavior.
- Final-round defection avoids being exploited when no future retaliation is possible; for all earlier rounds the strategy tries to sustain cooperation.
- Using per-player lifetime detection of permanent defectors allows exclusion of chronic free-riders from the group of partners we trust.

Behavioral outcomes expected:
- Against conditional cooperators and reciprocators: ACCC will sustain high cooperation and high collective payoffs.
- Against unconditional cooperators: ACCC still cooperates (receives good group payoffs); if exploited occasionally, it applies short punishments then forgives.
- Against defectors or exploiters: ACCC quickly reduces losses by defecting, stigmatizing persistent defectors, and requiring reliable partners before contributing again.
- Against opportunistic or mixed strategies: ACCC adapts to observed patterns—rewarding consistent cooperation, punishing temporary exploitation briefly, then rejoining cooperation if others reciprocate.

This strategy is collective-minded (it only contributes when a clear fraction of the group is reliably cooperative), adaptive (uses recent and lifetime history), robust (short proportional punishment prevents long mutual collapse), and uses only allowed information (game parameters and observed history).
'''

description_COLLECTIVE_123 = '''
Collective Conditional Cooperator with Forgiveness, Probing, and Short Punishments

Goal: sustain high collective contributions when others are willing, avoid long-term exploitation, tolerate occasional mistakes, and allow recovery. The strategy uses only n, k, r and the observed history of contributions and payoffs.

Parameters (computed once at start)
- alpha = max(0.50, k / n) — the minimum fraction of contributors in the previous round that signals “enough cooperation” to keep cooperating. (This ties the cooperation threshold to the game’s multiplier; it defaults to a majority.)
- W = min(5, r) — memory window length for short-term trend checks.
- punish_max = min(3, max(1, r // 10)) — maximum length of short, collective punishments (never longer than a few rounds).
- probe_prob = 0.10 — when defecting, small probability of probing (contributing) to test if cooperation can be re-established.
- endgame_E = min(3, r) — in the final endgame_E rounds switch to self-interested play (defect), because future reciprocity is limited.

State kept (derived from history)
- t = current round index (1..r)
- contributors[ t-1 ] = number of players who contributed in previous round (0..n)
- for the last W rounds we can compute fractions f_i = contributors[i] / n

Decision rules (round t)

1. Endgame
- If t > r - endgame_E (i.e., in the final endgame_E rounds), choose D (defect). Rationale: limited future to enforce reciprocity.

2. First round
- If t = 1, choose C (cooperate). Rationale: signal willingness to cooperate and try to build a cooperative track record.

3. Short punishment timer (if active)
- If we are currently in a punishment phase (see how it is triggered below), play D until the punishment timer expires. The punishment length is never longer than punish_max and never extended forever.

4. Main conditional rule (when not in endgame or punishment)
- Let f_prev = contributors[t-1] / n (if t>1; if t=1 this branch is skipped because we already cooperated).
- If f_prev >= alpha, choose C (cooperate). Interpretation: if at least alpha fraction cooperated last round, assume group cooperation is viable and continue contributing.
- If f_prev < alpha, choose D (defect), except see 5 (probing/forgiveness).

5. Probing and forgiveness (when f_prev < alpha)
- If we have been defecting for at least 2 consecutive rounds (or if the group has shown a sustained drop), then with probability probe_prob choose C (probe) instead of D. Otherwise choose D.
- If a probe yields a clear return to cooperation (in the next round the fraction >= alpha), abandon defection and return to cooperating per rule 4.
- This probing prevents permanent deadlocks and allows recovery from accidental defections or from other strategies that will reciprocate.

6. Triggering a short collective punishment
- If the group shows a sudden, substantial drop in cooperation after a round of high cooperation, trigger a short punishment:
  - If there exists i in the last W rounds such that f_i >= alpha and the most recent round has contributors[t-1] <= floor((alpha - 0.2) * n) (i.e., a sharp decline of ~20 percentage points or more), then set a punishment timer to L = min(punish_max, remaining rounds - endgame_E).
  - While the timer > 0 play D and decrement timer each round.
- Rationale: deter opportunistic, sudden free-riding that breaks a stable cooperative state while keeping punishment short so recovery is possible.

7. Recovery condition
- After punishment expires, require a short reconfirmation before resuming full cooperation: if any of the next W rounds has fraction >= alpha, resume cooperating per rule 4; otherwise continue defecting with periodic probes.

Additional clarifications and edge cases
- If r is very small (e.g., r <= endgame_E), the strategy will defect in all rounds except the first round if t=1 and not in endgame; this prevents being exploited in tiny games.
- The strategy is deterministic except for occasional probes (probe_prob). Probing frequency is low to avoid being repeatedly exploited yet sufficient to discover cooperative opponents.
- The strategy treats all players collectively (it does not single out individuals) and enacts group-level punishment and recovery; this makes threats credible (by collective defection) without seeking impossible individualized retaliation when actions are simultaneous.
- All decisions use only n, k, r and the publicly observed history (counts of contributions); no communication or coordination beyond observed history is required.

Why this is robust and collective
- Starts cooperatively to attempt efficient outcomes.
- Requires a meaningful fraction (alpha) of others to be cooperating to continue cooperating — so it won’t be exploited by persistent defectors.
- Uses short, finite punishments rather than infinite grim triggers: less brittle in noisy environments and avoids permanent breakdowns.
- Includes probabilistic probing so cooperation can be re-established after mistakes or temporary defections.
- Ends cooperation in a short endgame window to limit being exploited as rounds run out.
- All behavior is symmetric and aimed at maximizing collective payoff subject to protection against exploitation.
'''

description_COLLECTIVE_124 = '''
Adaptive Proportional Reciprocity (APR)

High-level idea
- Start by signalling willingness to cooperate. Cooperate as long as most players have been cooperating recently. When defections appear, respond with measured, proportional punishment targeted by history (not permanent), and use forgiveness to restore cooperation. In the very last round defect (no future), but otherwise keep punishments short so the group can recover. The strategy is explicit, deterministic, uses only game parameters and observed history, and is robust to noise, exploiters, and a wide variety of opponent styles.

Parameters (derived from game parameters)
- n = number of players, r = total rounds, k = multiplier.
- Memory window W = min(6, max(1, floor(r/4))). Use at most the last W rounds to estimate behavior.
- Punishment length cap Pmax = min(3, max(1, floor(r/10))).
- Cooperation threshold Theta = max(0.5, k / n). (Require at least a simple majority cooperating; if the public good is relatively efficient (k/n larger), require a slightly higher effective signal.)
- Low-cooperation cutoff theta_low = 0.2 (used to identify persistent defectors).
- Final-round safety: only the very last round t = r is treated as a guaranteed defection.

State maintained from history
- For each player j (including self) keep recent cooperation rate s_j = (number of times j contributed among the last W rounds) / W. If fewer than W past rounds exist, average over all past rounds.
- Group recent cooperation rate G = average of s_j across all other players (exclude self).
- For each player j keep a simple “offender counter” O_j = number of recent rounds (within window W) in which j defected (i.e., 1 − contribution). This is derivable from s_j.

Decision rule each round t (1..r)
1. If t == 1:
   - Contribute (C). Start cooperative to try to build a collective norm.

2. If t == r (the last round):
   - Defect (D). No future to deter exploitation, so maximize immediate payoff.

3. Otherwise (1 < t < r), compute s_j for each other player and G.
   - If G >= Theta:
       - We are in a cooperative environment. Cooperate (C) except when explicit limited punishment is active (see 4).
   - If G < Theta:
       - The group is currently not reliably cooperative. Defect (D) except possibly probe/coax as described in 5.

4. Targeted proportional punishment (deterrence, limited and reversible)
   - Identify persistent defectors: those j with s_j <= theta_low and O_j >= 1 (i.e., they have defected recently and overall low cooperation).
   - If any persistent defectors exist AND current round t is not the last round:
       - Enter a short, proportionate punishment phase: withhold contribution (D) for P rounds where P = min(Pmax, 1 + number_of_persistent_defectors). This punishment is collective (others will observe reduced contributions) but is designed to be short and proportional to number of offenders.
       - After P rounds of punishment, re-evaluate s_j and G. If offenders’ behavior improves, resume cooperation; if not, repeat short punishment with a cap so punishment never becomes permanent.
   - Note: if G >= Theta but there are a few low s_j players, do NOT automatically defect forever — use short punishments only.

5. Probing / coaxing to re-establish cooperation (when group cooperation is low but not dominated by persistent defectors)
   - If G < Theta but no persistent defectors (no one with s_j <= theta_low), occasionally probe to see if cooperation can restart:
       - With probability p_probe = 1/4 (or deterministically: probe every 4th such round), contribute (C) to signal willingness to rebuild cooperation.
       - Otherwise defect (D).
   - Rationale: probing is necessary to avoid permanent collapse due to temporary noise; keep probes infrequent so exploitive strategies cannot gain repeatedly.

6. Contrition / forgiveness after our own accidental defection
   - If in the immediately prior round we defected because of a punishment phase or probe schedule, but the group otherwise had high cooperation (last-round G >= Theta), then in the next round resume cooperation (C). Do not allow a self-caused drop to cascade into permanent collapse.

7. Handling ties and borderline cases
   - If G is exactly Theta, treat as cooperative (cooperate unless a persistent defector list is non-empty).
   - If W is small because r is small, use the available history; scale Pmax and W automatically as above.

Summary of behavior
- Signal cooperation first round.
- Cooperate when the majority of others have been cooperating recently.
- Identify and punish persistent defectors with short, proportional, capped punishments that are public but reversible.
- Use occasional probes to rekindle cooperation when the group cooperation rate has fallen but no obvious persistent defectors exist.
- Forgive quickly once behavior improves; avoid permanent grim triggers.
- Defect in the final round to protect immediate payoff.

Why this is collective and robust
- Collective: default is to cooperate and to sustain cooperation when most others do, maximizing group welfare when mutual cooperation is attainable.
- Robust: punishment is targeted, short, and proportional, so it deters exploiters without collapsing cooperation permanently. Probing and forgiveness let the strategy recover from noise and occasional mistakes.
- Adaptive: thresholds and window sizes scale with r and k/n; punishment lengths are capped; decisions use per-player histories so the strategy reacts to actual opponent behavior rather than assuming common norms.

Practical notes for tournament use
- All quantities are computable from observed histories and game parameters only.
- Deterministic except for optional probing randomness (implement as deterministic periodic probing if randomness is not allowed).
- Modest memory and computation (only last W rounds and per-player counts).
'''

description_COLLECTIVE_125 = '''
Collective Conditional Cooperator (CCC) — a robust, adaptive strategy to sustain high group returns while avoiding long exploitation

Idea in one line
- Start by signaling cooperation, keep cooperating as long as the group shows sustained cooperation, punish shortfalls in a limited way, and forgive to reestablish cooperation. Make the cooperation criterion depend on the game parameters so the strategy is more or less demanding depending on how valuable the public good is (k and n). Defect in the final round by default.

Initialization (computed once from game parameters)
- n, r, k are known.
- Set cooperation threshold T = min(0.95, max(0.5, 1 - 0.5*(k/n))).
  - Intuition: when k/n is large (public good is relatively valuable), require a lower recent cooperation rate to keep cooperating; when k/n is small require a higher recent rate.
  - Keep T between 0.5 and 0.95 so the threshold is neither too permissive nor impossible to meet.
- Set memory window rule: use the last W = min(5, t-1) rounds of observed actions when deciding in round t (for t>1). If t=1 then W=0.
- Punishment length P_max = min(3, max(1, floor(r/10))) — punishers are short and bounded.

Per-round decision procedure (round t)
1. If t = 1:
   - Play C (cooperate). Purpose: signal willingness to form cooperation.

2. If t = r (final round):
   - Play D (defect) by default (no future to enforce cooperation). Exception: if the group has been cooperating extremely consistently (every player cooperated in every previous round and no punishments have occurred), you may choose C if you assess the probability of others cooperating is near-certain; otherwise D. (Default is D.)

3. Otherwise (1 < t < r):
   a. Compute recent behavior:
      - For each player j (including self), compute their cooperation frequency f_j over the most recent W observed rounds (if W=0 treat f_j undefined).
      - Compute weighted group cooperation p_recent = average of f_j across other players (exclude self) or the fraction of contributions by others in the last W rounds if W>0.
      - To reduce sensitivity to single mistakes, also compute p_last2 = fraction of contributors (others) in the last one or two rounds.

   b. Decide based on recent cooperation:
      - If W=0 (no history): play C (we already did round 1 this handles short games).
      - If p_recent >= T OR p_last2 >= T:
         - Cooperate (C). Rationale: the group currently sustains cooperation; continue to support the public good.
      - Else (p_recent < T and p_last2 < T):
         - Enter a bounded punishment phase: play D for P rounds where P = min(P_max, max(1, ceil( (T - p_recent) / T * P_max )) ).
           - Intuition: punish more when the shortfall is bigger, but never punish longer than P_max.
         - After finishing the punishment phase, return to the normal test below (forgive-and-test).

   c. Forgiveness / re-entry rule:
      - After any punishment phase ends, immediately cooperate for at least 1 round to test whether group returns to cooperating.
      - If the test cooperation is reciprocated by a sufficiently high p_last2 >= T in subsequent rounds, remain cooperating; otherwise, re-enter a short punishment phase.
      - This prevents permanent breakdown from accidental or noisy defections.

Additional refinements and clarifications (collective mindset)
- Tolerance to noise: the strategy requires a sustained drop below T to punish; single accidental defections do not cause immediate long punishments.
- Identification of persistent free-riders: if some players have very low f_j over many rounds (e.g., f_j < 0.2 over a long horizon), they will drag p_recent down and cause the group to punish; that is intentional — the strategy is collective in that it defends the group's cooperation level by withholding contributions until the group collectively raises cooperation.
- Conservative endgame: default defection in the final round prevents exploitation when enforcement is impossible. In tournaments where many players nevertheless cooperate at the end, the optional exception allows taking advantage of unanimous cooperation if detected.
- Parameter adaptivity: T depends on k/n so the rule is less strict when the public good is more efficient; punishment duration scales with remaining rounds (via P_max) to avoid catastrophic losses in short games.
- No reliance on coordination or shared norms: strategy uses only observed actions and payoffs, and applies the same rule regardless of opponents’ identity.

Summary (short pseudocode form)
- Compute T = min(0.95, max(0.5, 1 - 0.5*(k/n))). Set short memory and bounded punishments.
- Round 1: C.
- For t in 2..r-1:
  - Measure others’ cooperation rate p_recent over last W = min(5,t-1) rounds and p_last2 for last 1–2 rounds.
  - If p_recent >= T or p_last2 >= T: play C.
  - Else: play D for P rounds (P ≤ P_max, proportional to shortfall), then cooperate for a test round and repeat policy.
- Round r: D (unless unanimous and history indicates near-certain cooperation).

Why this works in a tournament
- It is cooperative-first so it can build high-payoff cooperative relationships.
- It is conditional and parameter-aware so it withdraws cooperation when the group is not sustaining it.
- Punishments are short and proportional to the shortfall, so the strategy is forgiving and avoids being locked into mutual defection.
- Threshold T tied to k/n makes the rule robust across games where the public good is more or less efficient.

This strategy aims to keep the group at a high collective payoff whenever possible, while protecting itself from long-term exploitation and mistakes.
'''

description_COLLECTIVE_126 = '''
Collective Adaptive Reciprocity (CAR)

Goal: sustain near-full group contributions when possible, punish and discourage persistent free-riding, but be forgiving and test for recovery so cooperation is robust to mistakes. Parameters are derived from n, k, r and recent history only.

Parameters (derived from game parameters)
- Window w = min(5, r) — use the last w rounds to evaluate recent behavior.
- Cooperation threshold tau = clamp(0.5 + 0.5*(k/n), 0.6, 0.95). (This rises when the public-good multiplier k is large relative to n; it stays between 0.6 and 0.95.)
- Maximum punishment length P_max = min(5, max(1, floor(r/4))). (Punishments never longer than a few rounds and scale down in short games.)
- Probation length Q = 1 (one cooperative probation round after punishment).
- First-round rule for r=1: defect (no repeated interaction to sustain cooperation). For r>1: cooperate in round 1.

State machine overview
- States: COOPERATE, PUNISH, PROBATION.
- Start in COOPERATE (except r=1 as above).
- At each decision point use only the last w rounds of observed contributions and who contributed.

Computations each round (using the history up to the last completed round)
- For each player i compute their personal cooperation rate r_i over the last w rounds (fraction of those rounds where i contributed).
- Compute the recent group cooperation rate rG = (sum of all contributions in the last w rounds) / (w * n). (This is the average contribution per player in the recent window.)
- Identify recent targeted defectors: players with r_i < 1 who defected in the most recent round while the majority cooperated.

Decision rules (detailed)
1. COOPERATE state (normal operation)
   - Default action: contribute (C).
   - If rG < tau (group cooperation has fallen below the threshold):
     - Enter PUNISH state. Calculate punishment length P = max(1, ceil(P_max * (tau - rG) / tau)). Immediately defect this round (start punishment).
   - Else if a small number of targeted defectors appeared in the previous round while the rest cooperated (one or a few isolated defectors):
     - Perform a short targeted retaliation: defect this round (D) but remain in COOPERATE state afterward unless defections continue. Record the identity of the targeted defector(s). Targeted retaliation lasts until the identified player(s) show two consecutive contributory rounds in the window; then resume normal cooperation toward them.

2. PUNISH state
   - Default action: defect (D) for the remaining P punishment rounds.
   - During punishment, keep monitoring rG. If rG recovers rapidly above tau for two consecutive rounds, cut punishment short and move to PROBATION.
   - After completing the scheduled punishment rounds, move to PROBATION.

3. PROBATION state
   - For Q rounds (Q = 1) choose to cooperate (C) as a probe to test whether the group returns to cooperative behavior.
   - After Q rounds of PROBATION, recompute rG over the most recent w rounds:
     - If rG >= tau, move to COOPERATE.
     - Otherwise, return to PUNISH. When returning to PUNISH, scale P up proportional to how far rG is below tau (as in COOPERATE step).

Forgiveness and robustness to noise
- Punishments are proportional and temporary (bounded by P_max) to avoid endless cycles and to tolerate mistakes.
- Targeted retaliation isolates persistent individual free-riders rather than condemning the whole group when only a few defect.
- A probation/cooperation probe after punishment acts as an explicit forgiveness test; the strategy accepts restored cooperation and resumes collective contributions.

Endgame (final rounds)
- Final round r:
  - If r = 1 (single-round game): defect (no opportunity to enforce future cooperation).
  - If r > 1: cooperate in the final round only if both conditions hold:
    1) Everyone cooperated in the immediately previous round, and
    2) rG over the last w rounds >= tau.
  - Otherwise defect in the final round. This balances the theoretical incentive to defect in the last move with the collective payoff when cooperation has been reliably sustained.

Special notes and rationale
- The strategy is collective-minded: it starts by cooperating and always prefers to return to cooperation when the group can sustain it.
- Punishment is proportional and temporary (not eternal “grim”) to avoid losing group payoff indefinitely for mistakes or transient shocks.
- Targeted retaliation protects the group against a few persistent defectors without unnecessarily punishing cooperators.
- The threshold tau adapts to k and n: when the public-good multiplier k is high relative to group size the strategy demands a higher cooperation level because the collective payoff stakes are larger.
- The short window w and bounded punishment lengths keep the strategy responsive in short tournaments while allowing history to inform decisions.
- This strategy requires no communication or coordination beyond publicly observed actions and payoffs and thus is robust to arbitrary other strategies in the tournament.

Summary (simple rule-of-thumb)
- Start by cooperating (if r>1). Cooperate so long as recent group cooperation stays above an adaptive threshold. If cooperation falls, apply a short, proportionate punishment phase or targeted retaliation against persistent defectors. After punishment, probe with a cooperative move and forgive if the group recovers. In the very last round cooperate only if cooperation has been reliably sustained immediately prior; otherwise defect.
'''

description_COLLECTIVE_127 = '''
Strategy name: Collective Conditional Cooperation with Forgiveness (CCCF)

Summary goal
- Maximize collective welfare by cooperating when the group is reliably cooperative, punish clear and sustained exploitation, and forgive/repair to restore cooperation. Be cautious near the end of a finite horizon but allow trusted cooperation in the final rounds.

Fixed internal parameters (computed from game parameters; no secret coordination)
- Window m = min(4, r) — use the last up to 4 rounds to estimate recent group behavior.
- Punishment base length P0 = 2 (number of consecutive rounds defecting when a clear exploitation signal is first detected).
- Max punishment length Pmax = 4.
- Cooperation threshold τ = 0.5 (cooperate when a majority of other players have cooperated recently). Slightly more lenient when group benefit is very large: if k >= 0.8·n then set τ = 0.4.
- Endgame cautious window Tend = min(3, r). In the final Tend rounds, require a high recent cooperation rate (0.9) to continue cooperating; otherwise defect.
- Tie-breaking: on exact threshold equality, cooperate with probability 0.5 (or deterministic cooperate if randomness not available).

State tracked from history
- For each round, observed contributions of all players are known. From history compute c_bar(t): the fraction of “others” (players j ≠ me) who cooperated averaged over the last m rounds (if t ≤ m, average all previous rounds).
- A current punishment counter Pcur (initially 0) and a punishment escalation counter Escale (initially 0).

Decision rules (per round t, before choosing action)
1. First round (t = 1)
   - Cooperate (C). Rationale: signal willingness to cooperate and allow mutually beneficial outcomes to arise.

2. Endgame rule (if t > r - Tend)
   - If c_bar(t) ≥ 0.9 then cooperate; otherwise defect. Rationale: be cautious near the end but preserve cooperation if it is strongly established.

3. If currently in a punishment episode (Pcur > 0)
   - Play D, decrement Pcur by 1.
   - When Pcur reaches 0, perform a one-shot repair-test on the next decision (see step 5).

4. Normal assessment (not in punishment episode and not in last Tend rounds)
   - Compute c_bar(t).
   - If c_bar(t) ≥ τ, then cooperate (C).
   - If c_bar(t) < τ, then trigger punishment: set Pcur = P0 + Escale (bounded by Pmax), play D this round (the first punishment round), and increment Escale by 1 (up to Escale_max = Pmax − P0). Rationale: proportionate punishment that increases if repeated exploitation persists.

5. Repair-test after punishment
   - After a punishment episode finishes (Pcur just reached 0), on the next round play a repair test: cooperate once.
   - Observe others’ responses over the following m rounds:
     - If their cooperation returns (c_bar ≥ τ over that observation window), reset Escale = 0 and continue cooperating.
     - If exploitation continues (c_bar < τ persists), escalate punishment: set Pcur = min(Pcur_prev + 1, Pmax) and repeat the cycle.

Extra details / behavioral notes
- Collective mindset: the strategy errs on the side of cooperation when most others are cooperating and uses measured, limited punishments to deter and correct free-riding rather than permanent retaliation. Punishments are proportional and reversible to allow the group to re-establish cooperation.
- Robustness: short memory (m ≤ 4) avoids overreacting to transient noise; escalation prevents exploitation by persistent defectors; tests allow re-entry to cooperation rather than permanent breakdown.
- Adaptation to game parameters: τ is slightly relaxed when k is large (cooperation yields especially large public returns); Tend and m scale with r so the strategy behaves sensibly in short and long games.
- Randomness / tie-breaking: if exact ties occur at threshold boundaries, use 50/50 cooperation to avoid synchronized cycles; if randomness is unavailable, default to cooperate on ties to favor collective welfare.

Example behavior sketches
- If most players cooperate each round: c_bar ≥ τ → I keep cooperating and maintain high group payoff.
- If one or two players start defecting transiently: I will shift to D for a short P0 rounds, then test cooperation; if they return, I resume cooperating.
- If a majority defects persistently: I defect repeatedly and escalate punishment so defectors cannot cheaply exploit me; I still periodically test to allow for recovery if they change strategy.
- In the final few rounds: I require strong recent evidence of cooperation to continue cooperating; otherwise I defect to avoid being the last-round sucker, but will cooperate in the final round if the group has shown strong cooperation.

This strategy uses only the known game parameters and observed history (past actions) and is designed to be collectively minded, adaptive, and robust against a wide variety of opponent behaviors.
'''

description_COLLECTIVE_128 = '''
Name: Collective Conditional Cooperator with Forgiveness and Proportional Punishment (3FP)

Concept in one line
- Start by trying to sustain full-group cooperation, but respond to persistent free-riding with proportionate, reversible punishment; use short memory to be adaptive and forgiveness to repair cooperation.

Definitions (computed from game parameters and history)
- n, r: number of players and total rounds (given).
- round t: current round (1..r). r_rem = r − t + 1 (rounds remaining including current).
- Window W = min(10, r). Use the last W rounds (or all past rounds if fewer) to judge recent behavior.
- For each player j (including me) define recent cooperation rate R_j = (# of rounds j contributed in the last W rounds) / W.
- Group recent cooperation rate among others: G = (1/(n−1)) * sum_{j≠me} R_j.
- Thresholds (fixed function of game size; these are simple, transparent, and depend only on n,k,r via W and r):
  - Good cooperation threshold τ_good = 0.7
  - Punish threshold τ_punish = 0.45
  - Ambiguous zone: τ_punish ≤ rate < τ_good
- Punishment length parameters:
  - Max punishment length P_max = min(5, r). (Punishment for a defector is short and bounded.)
  - Early-game leniency: during the very first few rounds allow more forgiveness. (See rules.)

Decision rules (what I do each round)
1. First round (t = 1)
   - Play C (contribute 1). Signal willingness to cooperate.

2. Identify recent defectors
   - A player j is a recent defector if R_j < τ_punish.
   - Let D = set of recent defectors among the other n−1 players.

3. Endgame adjustment (when few rounds remain)
   - If r_rem ≤ max(2, ceil(0.05 * r)) (i.e., the last few rounds):
     - If G ≥ 0.5 (others have been mostly cooperative lately) then play C (try to secure final cooperative gains).
     - Otherwise play D (avoid being exploited at the end).
   - Rationale: when the horizon is short, cooperation is only worth preserving if others have recently cooperated.

4. Punishment and proportional response
   - If D is non-empty (there are recent defectors):
     a) Compute severity s = average_{j in D} (τ_punish − R_j) / τ_punish (a normalized measure of how bad the defectors' recent record is, between 0 and 1+).
     b) Set punishment length P = max(1, min(P_max, ceil(s * P_max))).
     c) Maintain a per-defector punishment counter: when I first detect j in D start a punishment timer of P rounds (counted from current round). While any active punishment timer > 0, I will play D (defect).
     d) After the timer expires for a given defector, re-evaluate that player’s R_j; if R_j has risen above τ_punish, clear punishment for that player; otherwise, allow up to one renewed short punishment of length P (but never exceed total P_max rounds of active punishment for that player within a sliding window of W).
   - Rationale: punish proportionally and briefly rather than indefinite grim trigger; concentrate punishment early enough to deter persistent free-riders but allow repair.

5. Cooperation when group is healthy
   - If no active punishment timers and G ≥ τ_good:
     - Play C (cooperate).
   - If no active punishment timers and G is in the ambiguous zone (τ_punish ≤ G < τ_good):
     - Play C with probability p = max(0.2, min(0.9, G)). Practically: cooperate with probability roughly equal to the recent group cooperation rate but never < 0.2. This injects smooth reciprocity and avoids immediate collapse from minor slips.
     - Deterministic alternative (if stochastic moves are disallowed): cooperate if G ≥ 0.6 else defect.

6. Reactive fairness (contrition and error recovery)
   - If I mistakenly defected last round (i.e., my own last action was D but my usual state was cooperating), or if an accidental mass-drop in contributions appears (single-round spike of defects), I will explicitly attempt contrition: play C for the next 2 rounds (unless an active punishment timer requires me to punish earlier). This helps repair cooperation after accidental drops/noise.

7. Isolation and anti-exploitation
   - If G is very low (G < 0.2) and r_rem is large (so long horizon), switch to sustained defection for the next min(3, r_rem) rounds. This conserves my endowment rather than endlessly subsidizing a non-cooperative population. Reconsider after those rounds using the windowed R_j values.

8. Tie-breakers and deterministic rule order
   - Punishment timers override cooperation: if any active punishment timer is positive, play D.
   - Endgame rule overrides ambiguous-zone randomness.
   - If multiple contradictory rules apply, follow the highest-priority rule in this list: Endgame → Punishment timers → Group healthy/cooperate or ambiguous → Isolation rule → First round / contrition.

Why this is collective-minded and robust
- Collective: starts cooperative and rewards collective cooperation (plays C when group cooperation is high), which maximizes group returns when many reciprocators are present.
- Robust: responds to free-riding with targeted, proportional, and temporary punishment rather than indefinite defection. This deters persistent exploiters while minimizing long-term damage to the group.
- Adaptive: uses a short sliding window so the strategy reacts quickly to behavioral changes but also forgives recent improvements. Probabilistic cooperation in ambiguous cases prevents brittle collapse from single defections.
- Endgame-aware: prevents naive exploitation in the final rounds while still giving cooperation a chance if the group has been cooperative.

Parameter notes (transparent, can be tuned by tournament designer)
- Window W = min(10, r) balances recency and stability.
- τ_good = 0.7 and τ_punish = 0.45 are chosen to require clear evidence of cooperation before trusting universal cooperation and to require noticeable underperformance before punishment.
- P_max = min(5, r) keeps punishment short so cooperation can be repaired.

Summary (one-sentence instruction for each round)
- Compute each player’s recent cooperation rates over the last W rounds; if any player is a clear recent defector, impose a short, proportional punishment (defect) for a bounded number of rounds; otherwise cooperate whenever group cooperation is clearly high, probabilistically cooperate in ambiguous situations, defect when the group is obviously noncooperative or at endgame unless others have recently cooperated, and always try contrition after my own accidental defections to restore trust.
'''

description_EXPLOITATIVE_1 = '''
Name: Opportunistic Conditional Cooperator (OCC) — exploit-first, repair-if-punished

Intuition (one sentence)
- Start by seeding cooperation to attract cooperators, then opportunistically free-ride when others are reliably cooperating; if my defection provokes retaliation, quickly repair cooperation. Always defect in the irrefutable endgame.

Parameters computed from game inputs
- n, k, r are given.
- Window W = min(10, r) — how many past rounds I use to estimate recent behavior.
- Endgame length E = max(1, ceil(r/4)) — in the last E rounds I treat punishment as ineffective and prioritize immediate payoffs.
- Majority threshold M = ceil((n-1)/2) — a simple social-majority cutoff.
- Leniency thresholds (fixed): T_low = 0.3, T_high = 0.9. (These are used to detect mostly-defectors or near-universal cooperation.)

State I maintain from history
- For each other player j: total contributions of j in last W rounds (or fewer if fewer rounds played).
- G_recent = average contribution rate of the other players over the last W rounds (fraction between 0 and 1).
- last_round_others = number of other players who contributed in the previous round.
- last_action_self = my action in previous round.
- retaliated = boolean flag: true if I defected previously and observed a drop in G_recent after that defection (used to trigger repair).

Decision rules (round t, 1-indexed)
1) Endgame:
   - If t > r - E (i.e., within the last E rounds) then defect (D). Rationale: retaliation is weak or impossible; maximize immediate payoff.

2) First round (t = 1):
   - Cooperate (C). Rationale: signal and attract cooperative opponents; free initial information.

3) Otherwise (1 < t ≤ r - E): compute recent statistics:
   - Update G_recent over the last W rounds (exclude this round).
   - last_round_others = number of other players who contributed in round t-1.

   A) Detect hopeless environment:
      - If G_recent ≤ T_low (others have been cooperating rarely), defect (D). There is little expectation of reward from contributing.

   B) Exploit near-universal cooperation:
      - If last_round_others = n - 1 (everyone else contributed last round) AND G_recent ≥ T_high:
          - Defect this round (D). This is the core exploit move: free-ride when everyone else is reliably cooperating.
          - Set retaliated = true if last_action_self = C (i.e., this is my first defection in a cooperation streak); otherwise leave retaliated as is.

   C) Maintain cooperation with reciprocators:
      - Else if last_round_others ≥ M (a majority of others contributed last round):
          - Cooperate (C). The group shows a cooperative norm; contribute to sustain it.

   D) Punish persistent defectors / avoid being bled:
      - Else (last_round_others < M):
          - Defect (D). If most others defect, contributing is costly and unlikely to trigger cooperative returns.

4) Forgiveness and repair logic (applies after any round update)
   - If I defected in round t-1 and retaliated is true:
       - Compare G_recent after my defection to the G_recent window before my defection:
           - If G_recent has dropped noticeably (e.g., by ≥ 0.15 absolute), other players punished my defection:
               - Immediately cooperate for at least the next two non-endgame rounds (set retaliated = false after two rounds of cooperation). Purpose: repair the relationship to regain future exploitation opportunities.
           - If G_recent did not drop (others kept cooperating despite my defection):
               - Continue exploiting using rule 3B (keep defecting when they all cooperate). No immediate repair needed.

5) Tie-breakers and deterministic behavior
   - If a rule gives conflicting prescriptions (rare when applied in order above), follow the first applicable rule in the order listed (Endgame → First round → A → B → C → D).
   - Actions are deterministic given history.

Why this is exploitative and robust
- Exploitation: If there are unconditional or generous cooperators, step 3B extracts value by free-riding on their contributions when they are reliably contributing (high recent cooperation and all others cooperated last round).
- Robustness:
  - If opponents are mostly defectors, rule 3A and 3D protect me from wasting tokens.
  - If opponents are conditional punishers (they retaliate when exploited), the forgiveness/repair logic quickly restores cooperation and prevents long punishment wars; I lose a small short-term payoff to regain a larger long-term stream.
  - If opponents are reciprocators or stochastic, the majority and recent-window rules adapt my behavior to preserve profitable cooperation while still taking advantage when safe.
- Endgame defection guarantees I do not leave payoff on the table when future punishment is impossible.

Edge cases
- Very short games (r ≤ 4): E = max(1, ceil(r/4)) ensures at least the last round is treated as endgame; effectively I cooperate in round 1 but quickly switch to defect as the horizon shortens.
- Small groups: M and thresholds automatically scale with n since M = ceil((n-1)/2).
- When W > rounds played: statistics use all available past rounds.
- If multiple opponents change behavior at once (e.g., coordinated retaliation), the repair rule uses a measurable drop in G_recent to detect and respond.

Summary pseudocode (compact)
- t = current round index.
- If t > r - E: play D.
- Else if t = 1: play C.
- Else:
   - compute G_recent, last_round_others.
   - If G_recent ≤ T_low: play D.
   - Else if last_round_others = n-1 AND G_recent ≥ T_high: play D (set retaliated if I had been cooperating).
   - Else if last_round_others ≥ M: play C.
   - Else: play D.
- After observing responses: if I recently defected and group cooperation fell substantially, cooperate for two rounds to repair.

This strategy maximizes exploitation where it is safe (high, stable cooperation by others), avoids wasting contributions where it is not, and quickly repairs relations if opponents punish, thus preserving future exploitation opportunities.
'''

description_EXPLOITATIVE_2 = '''
Goal: maximize my own cumulative payoff by (1) free-riding on persistent naive cooperators, (2) cooperating with and preserving cooperation among conditional/punishing players when that is instrumentally profitable, and (3) avoiding long costly wars with strong punishers. My strategy is entirely history-based and uses only the game parameters (n, r, k) and observed actions/payoffs.

Parameters I use (fixed, small constants implicitly set from r/n scale):
- ProbeRounds = min(3, r-1)     // initial probing to learn opponents
- Window = min(10, roundsPlayed) // history window for statistics
- PunishDelta = 0.30            // drop in conditional cooperation that flags a retaliator
- NaiveCoopThresh = 0.95        // identifies almost-constant cooperators
- ForgiveLength = 2             // how many rounds to punish before forgiving
- MaxPunish = min(3, r - currentRound) // cap punishment length near end

Definitions computed each round t (using data up to round t-1):
- rem = r - t + 1  // remaining rounds including current
- For each player j (j ≠ me):
  - coopRate_j = fraction of past Window rounds where j contributed
  - coopAfterMyC_j = fraction of rounds (in window) where j contributed given I contributed previous round
  - coopAfterMyD_j = fraction of rounds (in window) where j contributed given I defected previous round
  - responsiveDrop_j = coopAfterMyC_j - coopAfterMyD_j  (how much j reduces cooperation after my defection)
  - isRetaliator_j = (responsiveDrop_j >= PunishDelta)
  - isNaiveCooperator_j = (coopRate_j >= NaiveCoopThresh and responsiveDrop_j < PunishDelta/2)
- groupCoopRate = average of coopRate_j over j

Heuristic economic test (instrumental check whether preserving cooperation is worth it):
- ImmediateGainIfIDefect = 1 - (k / n)  // per-round gain from a one-shot defect vs cooperate
- ApproxFutureLossIfCollapse = rem * (k - 1) // worst-case per-player loss if mutual cooperation collapses entirely (cooperate->all defect)
- RetaliatorFraction = fraction of players with isRetaliator_j = true
- InstrumentalThreshold: if RetaliatorFraction * ApproxFutureLossIfCollapse > ImmediateGainIfIDefect then it is likely instrumentally better to cooperate to avoid collapse

Decision rules (per round t):

1) Last-round rule:
- If t == r (final round) then defect. (Backward induction: no future to preserve.)

2) Opening probe (rounds 1..ProbeRounds):
- Cooperate in probes to reveal opponents’ tendencies and to attract cooperation. Exception: if n = 1 or k/n ≥ 1 (not in standard PGG) then defect as appropriate; in standard PGG cooperate for probes.

3) Compute statistics from history and evaluate:
- If there exists at least one isNaiveCooperator_j and RetaliatorFraction is small (below a conservative exploitation threshold, e.g. 1/(2n)), prefer to exploit by defecting (free-ride) because naive cooperators will continue contributing.
- Else run the Instrumental test above:
  - If InstrumentalThreshold is true (i.e. enough retaliators and enough rounds remain that collapse would cost more than a one-shot gain), then enter Cooperative/Reciprocal mode:
    - Rule in cooperative mode:
      - Cooperate if the recent observed group cooperation (groupCoopRate over Window) is above 50% OR if a majority of players cooperated last round.
      - If I see a defection by me or a significant drop in cooperation, punish only the specific retaliators or the whole group for PunishLength = min(ForgiveLength, MaxPunish) rounds by defecting; then return to cooperation if they resume cooperating. Do not escalate punishments beyond MaxPunish; prefer forgiveness to re-establish mutually beneficial cooperation.
  - Else (InstrumentalThreshold false) enter Exploit/Defect-heavy mode:
    - Default: defect every round to maximize short-term free-rides.
    - But be cautious: if a new retaliator is detected (a player who sharply reduces cooperation right after I defect), switch for next rem rounds to a “targeted appeasement” pattern:
      - For the next rem rounds or until statistics update, cooperate occasionally to probe whether punishment persists; if retaliation seems durable and Remain is large, switch back to Cooperative/Reciprocal mode per above.
    - If there are isolated naive cooperators, exploit them by defecting while monitoring whether others start punishing; keep defections persistent as long as punishers remain rare.

4) Targeted punishment and forgiveness mechanics (important for robustness):
- If I defect and some players reduce their cooperation noticeably the next round, mark them as retaliators_j.
- Punish retaliators by defecting for PunishLength rounds unconditionally (or by matching their past defection frequency), then forgive: resume cooperation to check whether they restore cooperation.
- If a player punishes me repeatedly beyond ForgiveLength (i.e., becomes a persistent retaliator/punisher), treat them as a fixed retaliator when computing InstrumentalThreshold and prefer cooperation if their fraction is large enough.

5) Handling noisy or erratic opponents:
- Use moving windows (Window) and require persistent patterns before reclassifying someone as naive or retaliatory (avoid overreacting to single idiosyncratic rounds).
- If opponent behavior is highly stochastic (no clear patterns), default to defecting unless InstrumentalThreshold indicates cooperation is valuable.

6) Near-end adjustments:
- For small rem (e.g., rem ≤ 2), bias strongly toward defection unless immediate past round shows near-universal cooperation and no punishers; in that exceptional case a one-round cooperation could yield temporary extra payoff if opponents will not punish immediately and the one-shot mutual cooperation payoff is favorable. Generally, for rem small, the future-loss factor is tiny so defect.

Rationale and exploitative alignment:
- I begin by cooperating briefly to reveal who is exploitable (naive cooperators) and who punishes. That attracts cooperation from conditional cooperators and reveals unconditional cooperators so I can free-ride.
- I exploit persistent naive cooperators by defecting while monitoring for punishers.
- I avoid long costly punish–counterpunish wars by using short, targeted punishments and rapid forgiveness; if many players will punish me and many rounds remain, it becomes instrumentally better to cooperate so I switch to reciprocal cooperation to extract long-run surplus.
- The decision is adaptive: it explicitly weighs the one-shot gain from defection against the expected future loss if cooperation collapses, using observed fraction of retaliators and remaining rounds as inputs.
- This strategy is robust: it performs well against pure defectors (I defect), pure cooperators (I exploit), conditional cooperators/punishers (I cooperate to sustain mutually beneficial cooperation when it pays or punish briefly and then rehabilitate), and stochastic players (I rely on windows and demand persistent evidence before changing classification).

Summary pseudocode (condensed):
- If last round: D.
- If t ≤ ProbeRounds: C.
- Compute coopRate_j, responsiveDrop_j, isRetaliator_j, isNaiveCooperator_j, RetaliatorFraction, rem.
- If any isNaiveCooperator and RetaliatorFraction very small: D (exploit).
- Else if RetaliatorFraction * rem * (k - 1) > (1 - k/n): // cooperation is instrumentally worth preserving
    - Cooperate if recent group cooperation high / majority cooperated last round; if we or others defect, punish briefly (PunishLength) then forgive.
- Else: defect by default; if isolated naive cooperators exist exploit them; if punishers appear, use short appeasement probes and re-evaluate.

This strategy is explicitly exploitative (free-rides on naive cooperators), adaptive (switches between exploitation and reciprocal cooperation based on measured retaliation and remaining rounds), and robust (short punishments, forgiveness, and statistical thresholds to avoid being trapped in destructive wars).
'''

description_EXPLOITATIVE_3 = '''
Name: Opportunistic Exploiter

Summary: Start by probing/cooperating to identify who will reliably contribute or punish you. When a substantial fraction of others are cooperative and unlikely to retaliate, occasionally defect to reap higher short-term payoffs. If your defections produce retaliation, back off and rebuild cooperation. Always defect in the final rounds when future retaliation is impossible.

Definitions computed each round (using only game parameters and observed history)
- t = current round (1..r). n = number of players, r = total rounds.
- Window length w = min(10, max(3, floor(r/10))). (Use up to 10 recent rounds for statistics; in very short games this is at least 3.)
- For each other player j, coop_rate_j = fraction of rounds they contributed in the last w rounds.
- group_rate = average of coop_rate_j over all other players (i.e., expected fraction others contribute recently).
- retaliation_score_j = (average contribution by j in rounds immediately following rounds in which you contributed) minus (average contribution by j in rounds immediately following rounds in which you defected), computed over the last w rounds where applicable. Positive retaliation_score_j means j reduces contribution after your defection (they retaliate).
- punisher_count = number of players with retaliation_score_j >= 0.25 (they noticeably reduce contribution after your defection).
- steady_cooperators = number of players with coop_rate_j >= 0.95 and retaliation_score_j < 0.1 (almost always cooperate and not punishers).

High-level priorities (tie-breaker order)
1. Safety/endgame (avoid wasted restraint when no future): if t == r (final round) — defect.
2. If the game is so short that w >= remaining rounds and you cannot gather reliable retaliation data, be conservative: cooperate first round; after that favor defection unless group_rate is high and punishers are rare (see below).
3. If almost everyone defects recently (group_rate <= 0.2) — defect (no point cooperating).
4. If many punishers exist (punisher_count >= ceil((n-1)/2)) — avoid repeated exploitation: default to cooperating unless there is a clear exploitable subpopulation (see exploit rules).
5. Otherwise apply opportunistic exploitation rules below.

Round-by-round decision rules
- Round 1: Cooperate. This is a probe to discover who will cooperate and who punishes.
- In the last 1–3 rounds: escalate defection. Concretely, if t >= r - 2 then defect (no future to enforce cooperation); if r <= 3, defect from round 2 onward.
- If group_rate <= 0.2 (others rarely cooperate): defect.
- If steady_cooperators >= 1 and those steady cooperators are not punishers:
  - Targeted exploitation: if steady_cooperators >= 1 and punisher_count == 0:
    - Defect with probability p = min(0.7, 0.25 + 0.5*group_rate). (This probabilistic pattern extracts surplus from reliable cooperators while leaving enough cooperation to avoid collapse.)
    - Otherwise cooperate.
- If group_rate >= 0.7 and punisher_count == 0:
  - Opportunistic exploitation: defect with probability p_exploit = clamp(0.4 + 0.8*(group_rate - 0.7)/0.3, 0.4, 0.9).
    - (This means defect fairly often when the group is highly cooperative and unlikely to punish.)
  - With remaining probability, cooperate.
- If 0.2 < group_rate < 0.7 (mixed group):
  - If punisher_count is small (punisher_count < ceil((n-1)/4)):
    - Be slightly exploitative: defect with probability p = 0.3 + 0.4*(group_rate - 0.2)/0.5 (ranges roughly 0.3–0.7).
  - If punishers are present (punisher_count >= ceil((n-1)/4)):
    - Default to conditional cooperation: cooperate unless you have recently been defected on by a majority. If a recent round had >50% of others defecting, defect this round; otherwise cooperate.
- If you defect this round and observe a substantial coordinated retaliatory drop in group_rate next round (group_rate drops by >= 0.25), then enter a repair mode:
  - Repair mode: cooperate for the next m = min(3, remaining rounds - 1) rounds to rebuild trust, unless the last round is imminent (in which case defect).
  - After repair mode, re-evaluate rates and punishers and resume opportunistic rules.

Notes on measurement and robustness
- All decisions use only observed history (who contributed each past round) and game parameters; no communication assumed.
- Probabilistic exploitation prevents predictable patterns that invite coordinated permanent punishment. The probabilities are scaled by observed group cooperativeness so exploitation increases with the availability of “easy” gains.
- Retaliation detection is local and lenient (thresholds chosen to avoid misclassifying noise as punishment). If you mistakenly provoke retaliation, repair mode limits long-term damage.
- In games with many punishers or low remaining horizon, the strategy becomes more cooperative/defection-prone respectively, protecting against costly fights with retaliatory opponents and exploiting endgame certainty.

Exploitative mindset explicitly implemented
- Lure and probe by cooperating early to identify persistent cooperators.
- Extract surplus from highly cooperative opponents by probabilistically defecting when expected short-term gain is high and retaliation risk is low.
- Avoid being locked into mutually costly wars by detecting punishment and repairing cooperation quickly.
- Use endgame defection to capture the last-round payoff when future enforcement is impossible.

Behavioral examples
- Against unconditional cooperators: repeatedly defect probabilistically to earn consistently higher payoffs while occasionally cooperating to avoid immediate collapse.
- Against unconditional defectors: defect always, conserving your endowment.
- Against reciprocal/retaliatory players: cooperate enough to sustain mutual cooperation, defect only rarely to capture brief gains if the retaliation signal is weak.
- Against mixed populations: focus exploitation on identified steady cooperators while respecting punishers, using probabilistic defections and repair cycles.

This strategy trades short-term greedy defections when the environment is exploitable, with measured cooperation and forgiveness when opponents retaliate or when the future value of cooperation is high.
'''

description_EXPLOITATIVE_4 = '''
Adaptive Exploiter — a history‑dependent, opportunistic strategy that probes opponents, identifies who is safe to free‑ride on, and then defects opportunistically while avoiding sustained group collapse. Rules use only n, k, r and observed past actions/payoffs.

Parameters (computed from game inputs):
- W (window for recent statistics) = min(10, max(3, r//5))
- P_probe (initial probing rounds) = min(5, max(3, r//6))
- E_end (endgame horizon; rounds in which cooperation is abandoned) = min(3, max(1, r//10))
- Thresholds (interpretable, scale-invariant):
  - HIGH_COOP = 0.80 (recent contribution rate for an opponent to be considered a strong cooperator)
  - LOW_RESP = 0.10 (small change in others’ behavior after my defection -> they are not retaliators)
  - RETALIATE_DROP = 0.20 (a drop >= this after my defection marks an opponent as a retaliator)
  - SIGNIFICANT_GROUP_DROP = 0.15 (if average group cooperation falls this much after I exploit, stop exploiting)

Operational overview (per round t):

1. Endgame rule (deterministic)
- If t > r - E_end (i.e., in the last E_end rounds), defect (choose D). In particular, defect on the last round always. Rationale: finite horizon unraveling; exploit final rounds.

2. Probing phase (rounds t ≤ P_probe)
- Purpose: seed cooperation and learn responsiveness.
- Rounds 1 and 2: cooperate (C) to build baseline.
- In the remaining probe rounds (if any), mostly cooperate but perform 1 deterministic one‑shot defect at a fixed probe round (e.g., round 3 of probe) to test whether opponents reduce their contributions in response.
- Record for every opponent j:
  - coop_rate_j_recent := fraction of j’s contributions in the last W rounds (or all available rounds so far).
  - prob_after_my_defect_j := fraction of times j contributed in the round immediately after a round where I defected (use available samples).
  - prob_after_my_coop_j := fraction of times j contributed in the round immediately after a round where I cooperated.
  - responsiveness_j := prob_after_my_coop_j − prob_after_my_defect_j.

3. Classification (after probe and updated continuously thereafter)
- For each opponent j:
  - If coop_rate_j_recent ≥ HIGH_COOP and responsiveness_j ≤ LOW_RESP, label j as Naive/Unconditional Cooperator (safe to exploit).
  - If responsiveness_j ≥ RETALIATE_DROP, label j as Retaliator/Conditional Cooperator (will punish my defection).
  - Otherwise label j as Mixed/Unpredictable.
- Also track group aggregates:
  - frac_naive := fraction of opponents labeled Naive.
  - frac_retaliators := fraction labeled Retaliator.
  - avg_coop_last := average fraction of players (excluding me) who contributed last round.

4. Exploitation vs. caution decision (every non‑probe, non‑endgame round)
- Safety check: if frac_retaliators > (n-1)/2 (i.e., strict majority of opponents are retaliators) then do not try to exploit. Instead adopt a conservative reciprocal mode:
  - If at least ceil((n-1)/2) opponents contributed last round, cooperate (C); otherwise defect (D).
  - Rationale: avoid being singled out by coordinated punishment; maintain parity with majority behavior.
- Exploit when safe: if frac_naive ≥ 1 and frac_retaliators is small (specifically frac_retaliators ≤ frac_naive):
  - Play soft exploitation: defect with probability p_exploit = clamp(0.2 + 0.6 * frac_naive, 0.2, 0.9). Otherwise cooperate.
  - Implementation detail (deterministic tournament adapt): if randomness is disallowed, use a simple deterministic schedule that defects every k_th eligible round where k = max(2, floor(1/p_exploit)).
  - Rationale: take advantage of predictable cooperators but preserve enough cooperation to keep them from changing strategy.
- If no clear safe exploitable cooperators (frac_naive = 0) and no majority retaliators:
  - Play cautious reciprocator: cooperate if at least half of opponents cooperated last round; otherwise defect. This mirrors conditional cooperators and avoids sustained losses.

5. Online monitoring and responsiveness adaptation
- After any round in which the strategy defects while many opponents cooperated, immediately compare avg_coop (average contributions of others) in the W rounds before and in the W rounds after that defect.
  - If avg_coop drops by ≥ SIGNIFICANT_GROUP_DROP after my exploitation attempt, interpret that as group‑level punishment or collapse. Immediately switch out of exploitation mode into cautious reciprocator mode for a recovery period of R_recover = min(5, max(2, r//10)) rounds (cooperate conditionally as in the conservative reciprocal rule above), then re‑evaluate classifications.
- Update classifications continuously: any opponent whose responsiveness_j rises above RETALIATE_DROP becomes a Retaliator permanently (or until long run statistics change); any opponent who maintains HIGH_COOP and low responsiveness remains exploitable.

6. Handling corner cases
- Very short games (r ≤ P_probe + E_end): default to a short probe then primarily defect in endgame; i.e., cooperate only in first one or two rounds to collect diagnostic data, then defect.
- Small n: thresholds still apply. If n = 2 (pairwise), the classification still works; retaliators are especially dangerous, so conservative reciprocal mode will dominate.
- Noisy opponents / limited samples: use conservative defaults. If statistics are too noisy (less than 3 relevant samples for responsiveness), treat uncertain opponents as Mixed (not naive). Do not exploit unless you have at least one opponent with ≥ 3 observed cooperative rounds and low responsiveness.
- Ties and exact thresholds: break ties in favor of caution (i.e., if an opponent sits exactly on a threshold, treat them as Mixed/Retaliator).

Why this is exploitative and robust
- Exploitative: the strategy actively seeks out opponents who consistently contribute regardless of my behavior and defects against them (with controlled frequency) to collect the safe free‑ride gains repeatedly.
- Robust: it probes to learn responsiveness, avoids exploiting those who punish, and reverts to conservative reciprocal behavior if the group reacts negatively. Endgame defection ensures exploitation of the final rounds when cooperation unravels anyway.
- Adaptive: continuous reclassification and monitoring allow it to escalate exploitation when safe and retreat when others change behavior.

Summary decision checklist (per round):
1. If in final E_end rounds → defect.
2. If in probe rounds → mostly cooperate, inject one probe defection early.
3. Else update statistics and labels.
4. If majority retaliators → conservative reciprocal mode: cooperate iff majority cooperated last round.
5. Else if at least one Naive cooperator and fraction of retaliators small → soft exploit (defect with p_exploit tuned to fraction of naives).
6. Else → cautious reciprocator (cooperate if ≥ half of opponents cooperated last round).
7. If exploitation causes a large group drop, switch to recovery (conservative reciprocal) for R_recover rounds and then reassess.

This strategy balances immediate exploitative gains against the risk of provoking sustained retaliation; it targets predictable contributors while protecting itself from collective punishment and endgame unraveling.
'''

description_EXPLOITATIVE_5 = '''
Name: Probe-and-Exploit with Conditional Maintenance (PECM)

Goal (exploitative): Minimize my contributions while extracting as much benefit as possible from cooperators. I only cooperate when it is necessary to sustain a valuable pool of cooperating opponents; otherwise I defect. I probe opponents early to classify them, periodically re-test to detect changes, punish only when necessary, and forgive quickly so I can keep extracting from conditional cooperators without being entrenched in long vendettas. I always defect in the final round.

Notation I use (all computed from publicly observed history):
- t = current round (1..r).
- n = number of players.
- For each player j != me: C_j(t') = 1 if j cooperated in round t', 0 otherwise.
- q_j = cooperation rate of player j over the most recent W rounds (including all rounds so far if fewer than W). I set W = min(10, r) unless r < 5 then W = r.
- resp_j = measured responsiveness: the drop in j's cooperation rate in the k rounds after any of my defections, compared with its cooperation rate when I cooperated. Practically compute as: resp_j = average[ C_j(t+1) ] following rounds where I defected in round t minus average[ C_j(t+1) ] following rounds where I cooperated in round t. (A negative resp_j means j reduces cooperation after I defected; take absolute size to measure sensitivity.)
- group_coop_recent = sum_j q_j (sum over other players) — expected other cooperations per round.
- params (defaults, all determined from r,n and history):
  - Probe probability p_probe = 0.3 for round 1 (lower if n small).
  - High-coop threshold TH_high = 0.75
  - Low-coop threshold TH_low = 0.25
  - Responsiveness threshold TH_resp = 0.15
  - Reprobe probability p_reprobe = 0.05 (ongoing small probing)
  - Forgiveness window F = 2 rounds (if others resume cooperation I resume quickly)
  - Final-round policy: always defect on round r; for safety I also defect on round r-1 if r <= 10, otherwise only final round guaranteed defect.

Classification rules (adaptive):
- Unconditional cooperator (UC): q_j >= TH_high and resp_j ≈ 0 (they cooperate almost always and don't punish).
- Conditional cooperator (CC): q_j >= TH_low and resp_j <= -TH_resp (they reduce cooperation noticeably after I defect).
- Defector (D): q_j <= TH_low.
- Mixed/Noisy: otherwise.

High-level decision flow each round t:

1) Endgame rule
- If t == r: choose D (defect).
- If r small (r <= 10) and t >= r-1: choose D (defect in last 1–2 rounds). This avoids endgame exploitation.

2) If t == 1 (no history)
- Play C with probability p_probe (to identify cooperators), else D.
  Rationale: small initial cooperation can reveal unconditional cooperators while limiting initial cost.

3) Classification update
- Update q_j and resp_j for every opponent using the most recent W and recent response observations.

4) Compute counts:
- n_UC = number of UCs
- n_CC = number of CCs
- n_D = number of Ds
- est_other_coop = group_coop_recent (expected # of other cooperations)

5) Core exploit vs. maintenance logic
- If n_UC >= 1 and (n_CC + n_UC) < (n/2):
  - Exploit unconditional cooperators: choose D. Do not try to sustain cooperation for majority benefit because UCs alone are an exploitable source; defecting maximizes immediate payoff and UCs rarely punish.
- Else if (n_CC >= (n-1)/2) or est_other_coop >= (n-1)*0.6:
  - Conditional-cooperator majority present: aim to sustain enough cooperation by cooperating most rounds, but extract.
    Decision:
    - If in the previous round the group cooperation (excluding me) was high (>= ceil( (n-1)*0.6 )), then:
      - Cooperate this round with high probability (1 - epsilon_exploit), where epsilon_exploit = max(0.05, 0.1 * (1 - average_resp_sensitivity)), i.e., occasionally defect to extract once in a while.
      - Specifically: cooperate with probability 0.9 (defect 10%) initially; if opponents do not punish that occasional defection, increase defect frequency gradually (see adaptation below).
    - If in the previous round group cooperation collapsed (below ceil((n-1)*0.6)):
      - Defect until cooperation recovers for F rounds among the CC-majority; after F rounds of recovery, resume cooperating to maintain the pool.
  Rationale: when a majority are conditional cooperators, maintaining overall cooperation by occasionally cooperating yields higher long-run payoff; but I will steal occasionally.
- Else (no cooperative majority and no clear UCs)
  - Default to defection: choose D.
  Rationale: when few cooperators exist and no conditional majority to sustain, defecting is safest and exploitative.

6) Probing and re-testing (adaptive exploitation)
- On rounds where the core logic prescribes D, with small probability p_reprobe (0.05) cooperate instead to test whether I can induce cooperation, and to gather fresh data.
- On rounds where I cooperate as part of sustaining strategy, occasionally defect with small chance epsilon_exploit to extract surplus and measure punishment response.

7) Punishment and forgiveness
- If I defect and a conditional cooperator j reduces their cooperation (resp_j indicates punishment), reduce my defect frequency for that opponent's influence: i.e., in subsequent rounds cooperate whenever the majority of CCs cooperate for at least F rounds.
- If a substantial collapse occurs (group cooperation drops below TH_low fraction), punish by defecting until I observe recovery for F rounds, then cooperate to restore the pool.
- Forgive quickly: if group cooperation recovers, resume extracting behavior (cooperate most rounds, occasionally defect).

8) Handling noisy or mixed opponents
- If opponents appear noisy (not clearly UC/CC/D), treat them conservatively as likely punishers: favor defection except when a clear majority of sustained cooperation emerges, in which case follow the conditional-majority rule but with higher exploitation rate (i.e., defect more often) until a pattern clarifies.

Parameter adaptation (robustness)
- If my occasional defections are not followed by punishment for several successive probes, increase my defect frequency against that class of opponents toward always defecting.
- If I face heavy punishment after probing (large drop in cooperation), immediately reduce defect frequency to regain cooperation because the long-run payoff from sustained cooperation can exceed short-term gains from defecting.
- Window W and thresholds may shrink in short games (small r) so I learn quickly; in long games I use longer windows to avoid overreacting to noise.

Summary of the exploitative posture
- I never naively cooperate. I only contribute to maintain a profitable cooperative environment when enough opponents are conditional cooperators whose cooperation raises my long-run payoff.
- I exploit unconditional cooperators relentlessly (defect whenever endgame/other rules allow).
- I periodically probe and steal: small, infrequent defections when cooperating majority exists to extract extra payoff, and I adapt the theft rate based on whether others punish.
- I always defect in the final round (and typically in the last 1–2 rounds for small r) to avoid endgame exploitation.

Concrete pseudocode-like decision rule (compact)
- If t == r: D
- Else if r <= 10 and t >= r-1: D
- Else if t == 1: C with prob p_probe else D
- Else:
  - Update q_j, resp_j over W rounds
  - Classify opponents (UC/CC/D)
  - If any UC exists and cooperative set size < n/2: D
  - Else if CC majority or est_other_coop >= 0.6*(n-1):
      - If last round others cooperated broadly: cooperate with prob 0.9 (occasionally defect with prob 0.1); if probes were unpunished, gradually increase defect rate.
      - If last round cooperation collapsed: D until cooperation recovers for F rounds.
  - Else: D
  - Always with tiny probability p_reprobe convert the prescribed action to its opposite to test responses.

Edge cases
- Very small groups (n=2): use same logic but thresholds scale; exploit unconditional cooperator when detected; cooperate only to sustain partner if partner is clearly conditional and the long-run horizon r is long.
- Very short games (r small): be conservative about cooperating; only cooperate to probe once or twice early, otherwise defect, and always defect in final rounds as specified.
- Noisy opponents: use larger window W if r large; if noise persists, treat as defectors for extraction.

Why this is exploitative and robust
- It actively identifies and exploits unconditional cooperators.
- It sustains cooperation only when that yields higher long-run payoff (conditional-majority case), and then extracts via occasional defections.
- It adapts via probes, punishment detection, and forgiveness so it does well against a wide range of strategies (never slavishly cooperating; never blindly defecting when sustained cooperation is profitable).
- It avoids costly permanent retaliation: quick forgiveness preserves profitable cooperative pools while still extracting surplus.

End of strategy description.
'''

description_EXPLOITATIVE_6 = '''
Strategy name: Selective Conditional Cooperator with Timed Exploitation (SCC-TE)

Summary intuition (exploitative): Start by cooperating to attract conditional cooperators. Cooperate only when the observed recent cooperation level of the group (or a sizeable reliable subset) makes future reciprocal gains plausible. When the group looks reliably cooperative, intermittently defect to extract one-shot gains while keeping exploitation low enough to avoid wholesale collapse. Always defect when others are reliably defecting or in the final round(s). Punish and forgive: if exploitation provokes sustained retaliation, stop exploiting and revert to defecting until cooperating becomes attractive again.

Parameters (computed from game inputs; no external info):
- n, r, k: game parameters (players, rounds, multiplier) are available.
- W = min(10, max(3, floor(r/4))) — recent-history window for estimating behavior.
- R_high = 0.60 — group cooperation rate considered “reliable.”
- R_low = 0.30 — group cooperation rate considered “unreliable.”
- T_high = 0.80 — individual cooperation rate considered “highly reliable.”
- Exploit_rate_base = 0.20 — base probability of defecting when exploiting.
- Exploit_rate_endgame_multiplier = linear scale from 1 to 3 as rounds remain go from r to 1 (more exploitation as the end nears).
- Max_consecutive_exploits = 2 — do not exploit more than this many consecutive rounds without a recovery period.
- Recovery_length = 2 — after exploiting Max_consecutive_exploits times, cooperate Recovery_length rounds to rebuild trust.
- Punishment_threshold = drop of group cooperation by >= 0.25 within W rounds after exploitation — trigger to stop exploiting.
- Last_rounds_defect = max(1, floor(r/10)) — defect automatically in the final Last_rounds_defect rounds (safe endgame exploitation).

All references to cooperation rates exclude our own action (they are computed over the other n−1 players).

Decision rules (per round t, 1-indexed):
1. If t > r: (game over) N/A.
2. If t is within the final Last_rounds_defect rounds (t > r − Last_rounds_defect): choose D (defect). Rationale: no future to punish, exploit cooperators.
3. If t = 1 (first round): choose C (cooperate). Rationale: attract any conditional cooperators and reveal tendencies.
4. Compute, using the last min(W, t−1) rounds (if t−1 = 0 treat rates as 0):
   - For each other player j, r_j = fraction of rounds in that window where j cooperated.
   - Group rate R = average of r_j over j ≠ me.
   - m_high = number of players with r_j ≥ T_high.
   - recent_coop_count = total contributions by others in the most recent round (t−1), if t>1.
5. If R ≤ R_low: choose D. (Group is unreliably cooperative; do not give away tokens.)
6. If R ≥ R_high and m_high ≥ max(1, floor(n/4)):
   - We are in the “reliable coop group” regime. Consider exploiting:
     a. Compute exploit_probability = Exploit_rate_base * Exploit_rate_endgame_multiplier_factor,
        where Exploit_rate_endgame_multiplier_factor = 1 + ((r − t)/r)*2 (so exploitation probability increases as t approaches r).
     b. Keep track of how many consecutive exploits we have done in the recent window CE (count of our D moves while R ≥ R_high and m_high condition held).
     c. If CE ≥ Max_consecutive_exploits: play C for Recovery_length rounds (to rebuild trust), reset CE = 0.
     d. Else:
        - With probability exploit_probability: play D (exploit). Increment CE.
        - Otherwise play C.
   - After any exploit (we played D while others are highly cooperative), monitor the next W rounds: if group cooperation drops by ≥ Punishment_threshold compared to its pre-exploit R, stop exploiting permanently and move to the “defect-until-recover” branch (step 8).
   Rationale: take occasional one-shot gains when others reliably cooperate, but limit exploitation so cooperation doesn’t collapse.
7. If R is between R_low and R_high (ambiguous regime):
   - Use simple reciprocity:
     a. If t>1 and recent_coop_count ≥ ceil((n−1)/2) (a majority of others cooperated last round), play C.
     b. Otherwise play D.
   Rationale: reciprocate recent group behavior to remain aligned with conditional cooperators but avoid being the sole contributor.
8. Punish/Recovery mode (triggered if exploitation causes a big drop or if group remains unreliable):
   - Enter a conservative mode: defect every round until group cooperation rate R (computed over W) rises to ≥ R_high and sustains for W rounds, or until the final Last_rounds_defect rounds (in which case continue defecting). Once R recovers, return to normal rules but start with Recovery_length forced cooperations to signal goodwill.
   Rationale: stop giving exploitable opportunities if retaliation occurs or cooperation collapses.
9. Safety against targeted persistent defectors:
   - If a large subset of players consistently defect (for example, > 50% of others have r_j ≤ 0.1 over W), treat the group as unreliably cooperative and defect (step 5).
10. Tie-breaking / deterministic fallback:
   - If any probabilistic draw is needed, use a deterministic but pseudo-random rule based on the round number and observed total contributions in past rounds (so the strategy is reproducible): e.g., exploit on round t if (hash-like deterministic function of t and recent sum) mod 100 < 100*exploit_probability.

Notes on exploitation mindset and robustness:
- Exploitative: this strategy deliberately cooperates early and when others are reliably cooperative, but deliberately defects occasionally to pocket one-shot gains. The exploitation is controlled (limited consecutive exploits, probability-based) to avoid provoking a permanent collapse of cooperation (which would eliminate future exploitation opportunities).
- Safety: never cooperate when the group is clearly defecting; always defect in the final rounds where future punishment is ineffective.
- Adaptivity: thresholds and the window length are computed from r and adjusted for endgame; the strategy monitors individual reliability (r_j) and group-level changes, switching modes (exploit / punish / recover) as needed.
- No external coordination is assumed; all decisions rely solely on observed public history (everyone’s past actions and payoffs) and game parameters.

Edge cases covered:
- First round: cooperate to attract conditional cooperators.
- Immediate collapse: if others never cooperate, strategy defects from the second round onward.
- Last few rounds: deterministic defection to exploit remaining cooperators.
- Small r (few rounds): W and thresholds shrink automatically; exploitation probability escalates faster as rounds run out.
- If playing alone (n=1) or trivial n: adapt same rules; with n=1 cooperation is strictly dominated, so after first round you will defect per the R_low rule (since there are no others).

Implementation notes (for tournament use):
- Keep simple counters: per-player cooperation counts over the last W rounds, a CE counter for consecutive exploits, and a flag for Punish/Recovery mode.
- Choose deterministic pseudo-random tie-breaking to ensure reproducibility in tournaments that disallow true randomness.
- Tune base parameters (R_high, R_low, Exploit_rate_base) if allowed by contest organizers; the defaults above are intentionally conservative to balance exploitation with longevity of cooperative opportunities.
'''

description_EXPLOITATIVE_7 = '''
Exploitative Conditional Prober (ECP)

Short description
- Play mostly selfishly but probe early to classify opponents into (a) exploitable cooperators (keep contributing even when you defect), (b) retaliators/conditional cooperators (change contribution after your action), or (c) defectors. Once identification is reliable, exploit exploitable cooperators by defecting every round while occasionally “maintenance”-cooperating if their behavior starts to drift; otherwise use a cautious conditional-cooperation rule that cooperates only when a strong signal of large-group cooperation exists. Always defect in the final rounds to avoid end‑game exploitation.

Parameters derived from game parameters (deterministic, uses only n, r, k)
- Window size W = min(6, max(2, floor(r/6))) — history window for short-term statistics.
- Probe length P = min(6, max(2, floor(r/6))) — number of rounds of an initial probing pattern (see below).
- Exploitable threshold TE = 0.80 (unconditional cooperation rate when you defect).
- Retaliation threshold TR = 0.40 (drop in partner contribution probability after you defect).
- Maintenance period M = max(6, floor(r/10)) — how often to play one cooperative action to keep borderline cooperators cooperating.
- Endgame rounds E = min(2, r) — always defect in the final E rounds.

Metrics computed from history (sliding by last W or full probe history until enough data)
For each opponent j:
- DefRounds = number of past rounds in which you played D (count over the considered window).
- CoopWhenIDefected_j = number of those rounds where opponent j contributed.
- UncondRate_j = CoopWhenIDefected_j / max(1, DefRounds).
- P_afterC_j = fraction of rounds where j contributed on the round after you cooperated (count only rounds where you cooperated and a next round exists).
- P_afterD_j = fraction of rounds where j contributed on the round after you defected (count only rounds where you defected and a next round exists).
- RetaliationDrop_j = max(0, P_afterC_j - P_afterD_j).

Classification rules (deterministic)
- Label opponent j “exploitable” if UncondRate_j >= TE and RetaliationDrop_j <= TR.
  (Meaning j contributes reliably even when you defect and does not punish your defections soon after.)
- Label opponent j “retaliator/conditional” if RetaliationDrop_j > TR (they reduce cooperation if you defect).
- Else label j “uncertain/defector-leaning.”

Action decision (per round t)
1. Endgame: If t > r - E (in the last E rounds) — play D (defect). No testing; never give free tokens in the last rounds.

2. During probing phase (t <= P):
   - Alternate a deterministic probe pattern: C on odd probe rounds, D on even probe rounds (C, D, C, D, ...). This generates contrast to detect unconditional contributors and retaliators.

3. After probing (t > P):
   - Recompute metrics using the most recent W rounds (including probe rounds); update labels.

   - If there exists at least one opponent labeled “exploitable”:
     - Default action: D (defect) every round to harvest their contributions.
     - Maintenance: every M rounds (counting from the end of probe phase), play 1 C instead of D if and only if the set of “exploitable” players’ UncondRate averaged over the last W has fallen by >0.05 since the last maintenance check. This single cooperative pulse is a deterministic “reminder” intended to keep borderline cooperators from drifting away; otherwise do not give them tokens. Immediately after a maintenance C, if the average UncondRate for those players drops by >0.10 in the subsequent W rounds, mark them as no longer exploitable and stop maintenance.

   - Else (no exploitable players):
     - Be cautious and stingy: play C only if two strong signals both hold in the previous round:
       a) At least T = ceil(0.6*(n-1)) other players contributed in the previous round (a large majority of others cooperated last round).
       b) The average contribution rate among others over the last W rounds is >= 0.60.
     - If both hold, play C (attempt limited cooperation); otherwise play D.
     - If you play C and the very next round the number of contributors among others falls by more than 30% (compared to the previous round), immediately switch to pure D for a punishment period of length P (re-enter probe-like behavior for P rounds to re-assess and avoid further exploitation).

Rationale and exploitative mindset
- Probing early with deterministic C/D alternation creates the contrasts necessary to detect unconditional cooperators and retaliators without relying on randomization or communication.
- If opponents are exploitable (they keep contributing even while you defect and they do not punish), always defect to extract value; only perform minimal, periodic maintenance cooperations if their behavior shows signs of decay. This yields sustained free-riding against naive cooperators.
- If opponents are conditional/retaliatory, avoid being exploited: cooperate only when there is a clear, recent majority signal of cooperation and the recent average cooperation rate is high; otherwise defect. Use immediate, short punishments when cooperative gestures are not reciprocated.
- Endgame defection avoids the risk of last-round exploitation and is consistent with an exploitative, self-interested approach.

Edge cases and robustness
- Small r: P and W shrink appropriately (no excess probing). If r <= E, always defect (no profitable investment).
- Noisy opponents: window W and thresholds provide smoothing; maintenance and re-classification steps are conditional and conservative to avoid overreacting to noise.
- If many opponents are mutually exploitable (they all always contribute regardless of your action), this strategy defects and gets the maximum relative advantage.
- If the tournament has many strict defectors, this strategy converges rapidly to universal defection (no losses).
- If opponents are mostly conditional cooperators who punish, this strategy will maintain cooperation only when it is robust (majority signal + history), and will otherwise avoid repeated exploitation.

Determinism: all thresholds and timing are fully determined by n, r, k and past observed actions/payoffs; no hidden randomness is required.
'''

description_EXPLOITATIVE_8 = '''
Strategy name: Adaptive Prober–Exploiter (APE)

Summary (intent): Build a short cooperative reputation to identify which opponents reliably contribute, then free‑ride on those cooperators while protecting myself from being repeatedly exploited. Be willing to punish if many opponents respond to exploitation by defecting, and always defect in the final round. The strategy is fully determined by the game parameters (n, r) and the public history of contributions.

Parameters (derived from r):
- Probe rounds R_probe = min(3, r). (Signal basic cooperativeness.)
- History window L = min(10, r). (For recent-rate estimates.)
- High cooperation threshold T_high = 0.60.
- Low cooperation threshold T_low = 0.40.
- Small cooperation probability while exploiting ε = 0.15 (used to “refuel” cooperation).
- Punishment length P_len = 2 rounds.
- End-window W_end = max(1, floor(r/10)). Always defect in the last round.

State computed from history (every round):
- For each opponent j, p_j = fraction of last L rounds in which j contributed (use whole history if < L rounds exist).
- Group recent cooperation P_recent = average of p_j over all opponents (i.e., fraction of contributions by others in the last L rounds).
- Last_round_majority_C = true if a strict majority of other players contributed in the immediately preceding round (if no previous round, treat as false).

Decision rules (executed at the start of each round t):
1. Endgame rule
   - If t is the final round: choose D (defect).
   - If t is within the last W_end rounds before the final round (i.e., t > r - W_end): bias toward defection by following the Exploit mode rules below but with ε set to 0 (no voluntary cooperation), because endgame incentives collapse cooperation.

2. Probe phase (rounds t ≤ R_probe)
   - Play C (cooperate). Purpose: signal cooperativeness and elicit responses so we can identify cooperators.

3. After probes (t > R_probe), choose one of two modes based on P_recent:
   A. Exploit mode (if P_recent ≥ T_high)
      - Objective: free‑ride on a cooperative population.
      - Default action: D (defect) each round to collect the private token while most others cooperate.
      - Occasional cooperation: in non-endgame rounds, with independent probability ε cooperate (C) instead of D. The occasional cooperation prevents immediate collapse by giving cooperators some continued joint benefit and can improve reputation if needed.
      - Monitoring and fallback: after any round in which overall group cooperation (others’ contribution fraction that round) falls by more than (T_high − T_low) relative to P_recent, enter a Punish phase: play D for P_len rounds and then switch to Reciprocate mode if group cooperation remains below T_low. If cooperation rebounds above T_high you may return to Exploit mode.
      - If a persistent subset of opponents (one or more players) has p_j ≥ 0.90 while the rest are low cooperators, exploit them in the same way (defect most rounds, occasional ε cooperation); but if those players reduce their p_j after exploitation, treat them like any others and follow the fallback above.

   B. Reciprocate mode (if P_recent < T_high)
      - Objective: avoid being isolatedly exploited and maintain cooperation where feasible.
      - Rule: play as a conditional cooperator: if Last_round_majority_C is true, play C this round; otherwise play D.
      - Exception for very uncooperative environments: if P_recent ≤ 0.20, play D consistently (do not be the only consistent cooperator).
      - If repeated rounds of reciprocation yield a sustained P_recent ≥ T_high, switch to Exploit mode.

4. Punishment and forgiveness
   - Punishment is temporary and proportional: when triggered (sharp drop in others’ cooperation after you attempted exploitation), punish by cooperating no more than D for P_len rounds, then return to Reciprocate mode rather than permanent hostility. This keeps the threat credible but avoids mutual destruction.
   - Forgiveness: if after punishment others resume cooperating (P_recent rises), allow a transition back to Exploit mode when criteria are met.

5. Tiebreakers / defaults
   - If counts tie when measuring “majority,” default to D.
   - If history is too short to compute full statistics, base decisions on whatever history exists (R_probe ensures minimal seed).

Rationale and exploitative behavior
- The initial cooperative probes create chances to identify reliable cooperators; many strategies in tournaments start cooperative, so early cooperation can recruit contributions and reveal which opponents will keep contributing.
- Once reliable cooperators are detected (P_recent ≥ T_high), the strategy defects most rounds to harvest the private token while continuing to receive public-good benefit from others’ contributions; occasional cooperation (ε) reduces the risk of immediate mass retaliation by keeping return flows positive and preserves a minimal reputation.
- If exploitation provokes a sustained collapse in others’ cooperation, APE punishes briefly and then switches to reciprocal play to avoid being trapped in mutual defection and to allow re‑establishment of exploitable cooperators.
- Endgame defection (last round) and increased defection near the end are included to exploit the finite-horizon incentive structure.

Practical notes
- All components depend only on public history and n, r. No communication or side payments are required.
- The numerical thresholds (T_high, T_low, ε, L, etc.) are tunable but chosen to balance exploitation and resilience across a wide variety of opponent behaviors.
'''

description_EXPLOITATIVE_9 = '''
Adaptive Exploiter — natural-language strategy (pseudocode-style)

Overview
- Goal: maximize my total payoff by (a) free-riding when others are reliably contributing, and (b) investing in cooperation only when that investment demonstrably increases other players’ contributions enough to pay back the cost over the remaining rounds. The strategy uses only public history (who contributed each round, payoffs) and the game parameters n, k, r. It is adaptive, robust, and deliberately exploitative.

Setup (derived from game parameters)
- Let T = total rounds = r.
- Define a modest probe phase length P = min(6, max(1, floor(r/10))). (If r small this is at least 1; if r large it is at most 6.)
- Define an endgame window K = min(3, r) (unconditional defection in the last K rounds to avoid endgame exploitation).
- Use a rolling-history window W = min(40, r) for statistics.
- Small persistent exploration probability eps = 0.03 (3%) used to probe for changing behavior (except in the final K rounds where eps = 0).

Data to maintain (computed from public history)
- For each completed round t we observe others’ total contributions S_t = sum_{j != me} c_j(t) (range 0..n-1).
- Let R_C = list of S_t values for rounds t where in the previous round I played C (i.e., those rounds reflect others’ behavior after I cooperated).
- Let R_D = list of S_t values for rounds t where in the previous round I played D (i.e., rounds after my defection).
  - (For the first round there is no “previous” round; for R_C/R_D we only consider rounds t >= 2.)
- Compute avg_after_C = average(R_C) over the most recent up to W entries (if none, treat as undefined).
- Compute avg_after_D = average(R_D) over the most recent up to W entries (if none, treat as undefined).
- Define delta = avg_after_C - avg_after_D (interpreted as the estimated increase in other players’ contributions in a round when I have cooperated in the previous round).
  - If either avg is undefined (insufficient data), delta is undefined.

Decision rule (per round t, 1..r)
1) Endgame:
   - If t > r - K (i.e., in the last K rounds): play D (defect) unconditionally. No exploration. Rationale: final-round defection is dominant; avoid being exploited.

2) Early probe phase:
   - If t <= P: play C (cooperate) to build signal and collect statistics on how others respond to my cooperation.

3) Otherwise (main adaptive phase, t > P and not in final K rounds):
   - If there is insufficient history to compute both avg_after_C and avg_after_D (i.e., either list empty or too small), then:
       - Cooperate with small probability eps (exploration/probing) and defect otherwise. This collects information while avoiding predictable long-term generosity.
   - If delta is defined:
       - Estimate the number of remaining decision rounds after this one: M = r - t (remaining rounds after current one; treat M >= 0).
       - Compute threshold Theta = n / (k * (M + 1)).
         - Intuition/derivation: contributing now costs 1 immediate token; the benefit per extra contribution by others is (k/n) per round. If my single contribution today can be expected to increase others’ contributions by about delta per round, across the remaining (M) future rounds plus possibly an immediate effect, then net expected benefit ~ (k/n) * delta * (M + 1) - 1. Solve for delta > 1 * n / (k * (M + 1)). Theta is the delta required for cooperation to be worthwhile.
       - Decision:
         - If delta >= Theta: play C (cooperate). Rationale: empirical evidence suggests my cooperating increases others’ contributions enough over remaining rounds to pay back the cost; invest.
         - Else:
             - If avg_after_D (the baseline others’ contributions when I defect) is high (>= (n-1)*0.6 or more than ~60% of others contributing on average), then defect (D). Rationale: free-ride when others already contribute reliably.
             - Else defect, but with tiny exploration: with probability eps play C this round (to probe whether the group’s responsiveness changed); otherwise play D.
   - Additional behavioral guardrails:
       - If there is a sudden drop in avg_after_C or avg_after_D (e.g., drop > 30% within last W rounds) indicating that many players started punishing or abandoning cooperation, switch to a conservative defection mode: play D for the next min(3, M) rounds before re-evaluating. This prevents being lured into cooperating immediately after a coordinated decline.
       - If the group shows strong, consistent responsiveness (delta well above Theta for several consecutive evaluations), the strategy will continue to cooperate (possibly intermittently) to sustain and then exploit the cooperative behavior; but if responsiveness drops, revert to defect.

4) Randomization:
   - Outside the last K rounds small stochastic probing (eps) is used when statistics are inconclusive or when defecting most of the time; this prevents adversaries from perfectly modeling or permanently locking out the strategy and allows detection of shifts in others’ behaviors.

Repair and forgiveness
- If I observe that after I defected the group sharply reduced contributions (avg_after_D falls), but later they return to higher contributions, I will re-enter the cooperative-investment mode if delta again exceeds Theta.
- Retaliation is limited and graduated (the temporary conservative D-mode described above) rather than permanent — this improves expected payoff against noisy reciprocators and reduces mutual collapse with conditional cooperators.

Edge cases summary
- First round: cooperate (part of probe P).
- Early rounds (1..P): cooperate to gather data and attract conditional cooperators.
- Final K rounds: defect unconditionally.
- If very small game (r <= P + K): positioning adjusts naturally: start with probes, then quickly move to endgame defection.
- If opponents are unpredictable/noisy and history inconclusive: default to defect with occasional small-probability probes.
- If opponents are highly cooperative regardless of my action: defect to free-ride and exploit that generosity.
- If opponents clearly respond to my cooperation and delta is large enough to pay back my cost over remaining rounds: cooperate to invest in and exploit sustained group cooperation.

Why this is exploitative and robust
- The strategy only cooperates when it can quantify (from observed history) that cooperation is an investment that yields net benefit across the remaining rounds; otherwise it defects and free-rides on others’ generosity.
- It actively probes early and occasionally thereafter to detect exploitable cooperators, but it does not blindly tit-for-tat: it tolerates noise via forgiveness and uses graduated retaliation to discourage persistent punishers.
- The explicit economic threshold (Theta) ties cooperation to the game parameters n, k and remaining horizon r, so the strategy adapts to different multipliers and time horizons and is not dominated by naive unconditional cooperators.

Implementation notes (for tournament designers / implementers)
- Use the most recent up to W rounds for averages to keep the estimator responsive but not overly noisy.
- To compute avg_after_C and avg_after_D, use rounds t >= 2 and associate round t’s others’ total with my action in round t-1.
- Use smoothing (e.g., exponential moving average) if prefer to weight recent behavior more heavily; the Theta decision logic remains the same.

End result
- The strategy alternates between measured investment (cooperate) when it is profitable to spur cooperation, and exploitation (defect) when others are reliably contributing or when the investment is not justified. It is explicitly exploitative, adaptive, and robust to a wide range of opponent behaviors.
'''

description_EXPLOITATIVE_10 = '''
Name: Opportunistic Conditional Exploiter (OCE)

Core idea (exploitative mindset)
- Start by appearing cooperative to learn who is willing to contribute.
- When the group (others) is reliably cooperative, defect to take the private advantage while still leaving enough cooperative behavior in the group to keep exploitation profitable.
- If exploited or punished by responsive opponents, apply short, decisive punishments to regain advantage, then return to exploitation.
- In the known endgame, switch to defection to avoid being exploited in the last rounds.

Parameters (computed from game parameters and adaptive from history)
- n, r, k: game parameters (known).
- w := min(20, remaining rounds) — window length for recent statistics.
- H_high := 0.80 — high cooperation fraction threshold (fraction of other players cooperating on average over the window).
- H_mid  := 0.50 — mid cooperation fraction threshold to sustain cooperation.
- punish_len := 3 — number of rounds to punish a detected punisher or downward shift.
- forgive_len := 5 — number of rounds to gradually return from punishment to exploitation.
- eps_coop := 0.05 — small random probability to cooperate even when defecting, to reduce coordination on collective defection and to stochasticize behavior.
- endgame_margin := min(3, r/10 rounded down) — last rounds in which always defect (strict endgame).

All these are fixed rules derived from parameters and history; they do not rely on coordination or side channels.

Definitions from history (computed each decision round t)
- For each past round compute others' total contribution (excluding me).
- mean_other_fraction := (average over last w rounds of (other contributions)/(n-1)) — normalized 0..1.
- For each opponent i compute coop_rate_i := fraction of rounds (so far) in which i contributed.
- responsive_drop_detected := true if, after any round in which I defected and most others cooperated, a nontrivial subset of players (≥1) reduced their coop_rate by > 0.30 in the subsequent w rounds (evidence of retaliators/punishers).
- unconditional_cooperators := count of opponents with coop_rate_i >= 0.95.

Decision rules (per round t)
1. Endgame: If remaining rounds <= endgame_margin, defect (D). Rationale: last rounds cannot be credibly rewarded; exploitative rationality demands defection near the end.

2. First round: Cooperate (C). Rationale: appear cooperative to learn; unconditional cooperators will reveal themselves.

3. If mean_other_fraction >= H_high:
   - If responsive_drop_detected is false:
     - Defect (D) this round (exploit high cooperative baseline).
     - With probability eps_coop, cooperate instead (randomized forgiveness to avoid deterministic collapse).
   - If responsive_drop_detected is true:
     - Enter targeted punishment phase: defect for punish_len rounds (D), then set a gradual return schedule: next forgive_len rounds play cooperating at rate 0.7 (i.e., cooperate unless strong reason to defect).
     - After that, resume exploitation rules.

4. Else if mean_other_fraction >= H_mid:
   - Cooperate (C). Rationale: sustain a moderate cooperative baseline so that exploitation opportunities re-emerge. If there are many unconditional_cooperators (>= 2), occasionally (probability 0.25) defect to probe their responses.

5. Else (mean_other_fraction < H_mid):
   - Defect (D). Rationale: not enough cooperating others to make exploitation profitable; do not subsidize non-cooperators.
   - Occasionally (with probability 0.10) cooperate to probe whether cooperation can be re-ignited.

6. Probing and opportunistic bursts:
   - If unconditional_cooperators is large (>= ceil((n-1)/2)), and mean_other_fraction >= H_mid:
     - Trigger an exploitation burst: defect for up to 2 consecutive rounds (unless punished), then return to rule (3). This extracts short-term gains while monitoring for retaliation.

7. Reaction to direct punishment signals:
   - If after an exploitation round you observe at least one opponent sharply lowering their cooperation in the very next round and the group cooperation falls substantially, treat that as evidence of effective punishers and switch to the punishment phase described in (3) (punish_len rounds of defection), then forgive.

8. Monitoring and adaptation:
   - Continually update coop_rate_i and mean_other_fraction and responsive_drop_detected.
   - If the population drifts to near-universal defection (mean_other_fraction < 0.05 for w rounds), remain defecting (no costly attempts at rebuilding cooperation).
   - If a clear window of stable cooperation reappears, resume exploitation rules.

Notes on robustness and exploitation
- The strategy is exploitative: it defects whenever the other players are reliably providing public goods, extracting a private gain while keeping the group cooperative enough to continue doing so.
- It is adaptive: thresholds and windows respond to observed behavior; it probes and randomizes to avoid predictable collapse of exploitation.
- It is robust: it punishes retaliators briefly and then forgives (avoids endless mutual defection), uses stochastic cooperation to prevent coordination on punishment cascades, and retreats when cooperation collapses.
- It respects the endgame: in last rounds it defects to avoid being exploited without reciprocal opportunity.

Summary pseudocode (high-level)
- If remaining rounds <= endgame_margin: play D.
- Else if t == 1: play C.
- Compute mean_other_fraction over last w rounds and coop_rate_i for opponents.
- If mean_other_fraction >= H_high:
    - If no responsive_drop_detected: play D (with eps_coop chance of C).
    - Else: punish for punish_len rounds (D), then gradually forgive for forgive_len rounds, then resume.
- Else if mean_other_fraction >= H_mid:
    - play C (with occasional probe defections if many unconditional cooperators).
- Else:
    - play D (with occasional probe cooperations).
- Continuously update responsive_drop_detected and unconditional_cooperators and adapt.

This rule set uses only the game parameters and the publicly observed action/payoff history. It seeks to maximize my payoff by exploiting cooperative opponents while limiting the cost of retaliation through short punishments and controlled forgiveness.
'''

description_EXPLOITATIVE_11 = '''
Name: "Exploit-and-Repair (E&R)"

High-level idea
- Extract as much value as possible from opponents who are willing to contribute while giving just enough cooperation to keep conditional cooperators from permanently quitting. Mostly defect, but seed cooperation early, probe opponents to classify them, exploit predictable cooperators, and use short, lenient repairs when group cooperation collapses. Always defect in the last round(s).

Parameters used (set from game parameters and simple constants)
- n, k, r: game parameters you are given.
- window w = min(5, max(3, floor(r/10))) — lookback window for recent behavior.
- seed length s = min(3, max(1, floor(r/10))) — initial seeding rounds.
- endgame safety e = min(2, floor(r/10)) — number of final rounds to always defect (at least last round).
- high-coop threshold H = 0.75 (default). If k/n > 0.7 increase H to 0.85; if k/n < 0.4 lower H to 0.65. (Intuition: if contributions are relatively more valuable for group, demand stronger evidence before exploiting.)
- moderate-coop threshold M = 0.45.
- repair length T = 2 rounds of unconditional cooperation to try to restore cooperation.
- leniency: require two consecutive rounds of sustained cooperation drop before declaring "collapse" (avoid over-reacting to noise).

Decision rules (what to play each round)
1. First s rounds (seeding and probing):
   - Cooperate. Purpose: build a baseline of cooperation so conditional cooperators reveal themselves. Record everyone’s actions.

2. If current round t is within the final e rounds (t > r - e):
   - Defect. (Endgame: no future to leverage.)

3. From round t = s+1 to r - e:
   a. Compute recent group statistics over the last w rounds (excluding current round):
      - For each other player j, cooperation rate p_j = fraction of those w rounds in which j contributed.
      - Group cooperation rate G = average over all players (including self if you cooperated in those rounds) of contributions per round in that window, i.e., expected total contributions per round among others: sum_j≠i p_j.
      - Track responsiveness: for each player, estimate whether they reduce cooperation after you defected (measure correlation between your defection and their next-round drop). Use this to detect conditional cooperators.
   b. Classify opponents roughly:
      - Unconditional cooperator: p_j >= 0.9 and low responsiveness (they keep cooperating after you defect).
      - Conditional cooperator: p_j >= 0.4 and show responsiveness (they cut cooperation when punished).
      - Defector: p_j <= 0.2.
   c. Choose action for this round:
      i. If there are one or more Unconditional cooperators and the recent group cooperation G (per-round contributions by others) >= H*(n-1):
         - Defect. Rationale: you can siphon returns from their high contribution while they continue contributing.
      ii. Else if the majority of others are Conditional cooperators (count_conditional >= count_unconditional + count_defector) and recent group cooperation G >= M*(n-1):
         - Play a mixed/lenient policy that favors occasional defection but avoids collapse:
           - If you cooperated last round and no strong punishment was observed (no large drop in group cooperation), defect this round with probability p_exploit = 0.5 (otherwise cooperate).
           - If you defected last round and within the last two rounds the group cooperation dropped by more than 20% (absolute drop), enter Repair mode (see Repair below).
         - This stochastic exploitation extracts value while not triggering stable punishment.
      iii. Else (group cooperation low or dominated by defectors):
         - Defect. Do not waste your token when others largely defect.
   d. Repair mode (triggered when exploitation caused a meaningful collapse):
      - If you detect that after you defected the group cooperation rate fell by > 20% relative to the window average, then for the next T rounds cooperate unconditionally (even if that yields an immediate loss) to signal goodwill and restore conditional cooperators.
      - If after T repair rounds cooperation does not recover to at least M*(n-1), switch to Permanent-Defect (defect every remaining round) until you have new evidence otherwise.
      - If repair succeeds, resume the above exploitation rules.

Edge cases and robustness
- Small r: when r is small (e.g., r <= 6), reduce seeding s to 1 and be more conservative about repair; rely more on immediate exploitation because the future payoff to signal is limited. Still defect in last round.
- Noisy opponents: require 2 consecutive rounds of cooperation collapse (leniency) or >20% sustained drop before declaring collapse to avoid reacting to random noise or brief fluctuations.
- Mixed evidence / ambiguous classification: if opponents’ behavior is unstable, default to defect to avoid being exploited.
- If you detect an opponent that punishes permanently after any defection (grim-like), then avoid exploiting that specific opponent in later rounds: avoid defection that directly precedes their punishment (i.e., after you detect a player’s deterministic retaliation, cooperate against them to keep their cooperation advantage). If most players are permanent punishers, treat them as conditional cooperators and favor cooperation only when group cooperation is high enough to make long-run exploitation possible.
- If all other players are classified as Unconditional Cooperators, defect every round (except endgame repair considerations) to maximize extraction — they will continue contributing despite your defection.
- If you are in a small game (n=2, public-good reduces to Prisoner’s Dilemma), the same rules apply; exploit unconditional cooperators, be careful with conditional punishers (TFT-like), and always defect in last round.

Exploitative mindset — clear alignment
- Primary objective: maximize cumulative payoff by letting others provide the public good while contributing as little as possible yourself.
- Use early cooperation to create opportunities (seed contributions), then opportunistically defect when the evidence shows opponents will keep contributing.
- Be adaptive: probe, classify, exploit, but be ready to repair to prevent permanent collapse of cooperation that would reduce your long-run extraction.
- Be lenient to occasional noise and punitive to sustained retaliation: punishers that respond harshly will reduce your exploitation opportunities, so avoid provoking them repeatedly — instead, target exploitation toward players who are predictable cooperators.
- Endgame awareness: do not waste tokens when there is no future leverage — defect in the final rounds.

Summary pseudocode (natural language)
- Round 1..s: cooperate (probe).
- For each subsequent round until last e rounds:
  - Measure recent w-round cooperation statistics per player and group.
  - Classify players as unconditional cooperator / conditional cooperator / defector.
  - If many unconditional cooperators and group cooperation is high (>=H), defect every round to exploit them.
  - Else if many conditional cooperators and group cooperation moderate (>=M), occasionally defect (≈50% when safe) but repair promptly with T rounds of cooperation if your defection causes a sustained drop; abandon repair and defect permanently if repairs fail.
  - Else defect.
- Last e rounds: defect every round.

This strategy is simple, parameterized only by (n, k, r) for thresholds and windows, relies only on observed history, aggressively exploits predictable cooperators, protects against being trapped by harsh punishers, and is robust to noise by requiring sustained patterns before changing long-run stance.
'''

description_EXPLOITATIVE_12 = '''
Name: Adaptive Targeted-Exploiter (ATE)

Principles (short):
- Exploit unconditional cooperators aggressively.
- Maintain cooperation with conditional reciprocators when it is profitable to sustain future mutual gains.
- Use a short probing phase to classify opponents by observed responsiveness, then apply targeted exploitation or cooperation per classification.
- Always defect in the final round. Be forgiving but cautious with noisy opponents.

Notation (informal):
- n = number of players, r = total rounds, t = current round (1..r).
- For each opponent j maintain: rounds_seen_j, coop_count_j, coop_after_myC_j, coop_after_myD_j.
- coop_rate_j = coop_count_j / rounds_seen_j (smoothed with +1/+2 to avoid division by zero).
- responsivity_j = (coop_after_myC_j / times_I_was_C) - (coop_after_myD_j / times_I_was_D) (smoothed).
- remaining = r - t.

Threshold defaults (tunable but fixed by this strategy):
- UNCOND_COOP_THRESH = 0.9 (cooperation frequency above → considered unconditional cooperator)
- DEFECTOR_THRESH = 0.2 (below → considered defector)
- RESPOND_THRESH = 0.20 (responsivity above → considered reciprocator / contingent)
- PROBE_ROUNDS = min(6, max(3, floor(r/10))) (short probing phase length)
- SOFT_EXPLOIT_FREQ = once every max(5, floor(r/10)) rounds when safe (sporadic, to extract surplus)
- FORGIVENESS_WINDOW = 2 (when punished once, allow short recovery)

Decision procedure (what I actually do each round):

Initialization:
- Start by setting all counters to 0.
- Probing phase for the first PROBE_ROUNDS rounds: play a controlled mixed pattern designed to reveal types:
  - Round 1–2: cooperate (encourage cooperation baseline).
  - Round 3: defect (single targeted probe) if PROBE_ROUNDS >= 3, to test punishment sensitivity.
  - Rounds 4..PROBE_ROUNDS: cooperate with probability 0.6 (keep exploration).
- After each probe round update per-opponent statistics.

Classification (recompute after each round):
- For each opponent j:
  - Estimate coop_rate_j (with Laplace smoothing: (1 + coop_count_j) / (2 + rounds_seen_j)).
  - Estimate responsivity_j as difference in their cooperation probability after my C vs after my D (smoothed).
  - Classify:
    - Unconditional cooperator: coop_rate_j >= UNCOND_COOP_THRESH and responsivity_j small (abs(responsivity_j) <= 0.05).
    - Reciprocator/Conditional cooperator: responsivity_j >= RESPOND_THRESH (they reduce cooperation noticeably after my defection).
    - Defector: coop_rate_j <= DEFECTOR_THRESH.
    - Unknown/noisy: otherwise.

Round-by-round action (for any round t):

1) Last round rule:
   - If t == r: defect. (No future to sustain.)

2) Quick majority check (safety):
   - Let expected_cooperators = count of opponents with coop_rate_j >= 0.5 or classified as reciprocator/unconditional.
   - If expected_cooperators < 1 (i.e., everyone looks like a defector/noisy), defect.

3) Exploitation logic:
   - If there exists at least one Unconditional cooperator AND the number of Reciprocators + Unconditional cooperators is large enough that a single defection will not trigger mass collapse, then exploit:
     - Practical rule: if (#unconditional >= 1) AND (#reciprocator + #unconditional >= 2) then defect this round to gain immediate extra payoff from their contributions.
     - If there are many reciprocators (majority of opponents), avoid continuous exploitation. Use targeted soft-exploitation:
       - Defect in this round, but only do so at most once every SOFT_EXPLOIT_FREQ rounds (track last exploit round).
       - After a soft-exploit defection, if reciprocators reduce cooperation next round, immediately cooperate for FORGIVENESS_WINDOW rounds to restore cooperation; if they do not restore, revert to defecting more often.
   - If unconditionals exist but reciprocators are few (so my defection will cause cooperation collapse), do not exploit; instead aim to sustain cooperation.

4) Cooperation-sustaining logic:
   - If no clear unconditionals and a substantial set of reciprocators exists (e.g., #reciprocator >= 1 and expected_cooperators >= ceil((n-1)/2) ), then cooperate to maintain high mutual payoffs. Rationale: the future stream of mutual cooperation with reciprocators typically outweighs per-round cost (especially when remaining rounds > few).
   - More precise heuristic: cooperate if remaining >= 3 and at least half of opponents look like reciprocators or high-frequency cooperators. If remaining is small (<=2), lean toward defect except when cooperating strictly prevents imminent punishment cascade.

5) Handling noisy/unknown opponents:
   - Be cautious: if many opponents are “unknown/noisy,” default to defection unless cooperating clearly increases the pool of expected cooperators and remaining rounds justify it.
   - Use probabilistic cooperation (p ≈ 0.3–0.5) to probe unknowns occasionally; never give unconditional cooperation to unknowns.

6) Punishment and forgiveness:
   - If you defect and observe a sharp drop in cooperators among reciprocators next round, interpret as punishment. Respond to moderate punishment by cooperating for FORGIVENESS_WINDOW rounds to restore cooperation. If punishment persists past forgiveness window, escalate by defecting until cooperation rates fall to defector-like levels.
   - Do not attempt long hard punishments: they are costly and make you lose the exploit opportunity.

7) Targeting individuals:
   - When exploiting unconditionals, no need to single them out (actions are group-level), but track if individual unconditionals change behaviour; if they become less cooperative after being exploited, reclassify and stop exploiting.

Edge cases and clarifications:
- Very short games (r <= PROBE_ROUNDS): reduce probing; default to defect except possibly cooperate in very first round if you detect strong evidence of many unconditional cooperators (rare).
- n = 2 (pairwise public good): behavior reduces to pairwise Prisoner’s Dilemma logic: treat the other as reciprocator/unconditional as above; always defect in last round; in earlier rounds cooperate only if you can sustain mutual cooperation with reciprocation.
- Noisy observations: use smoothing on frequencies to avoid overreacting to single events.
- Ties / indecision: prefer defection (exploitative bias) unless there is clear evidence cooperating yields higher future payoff.

Why this is exploitative and robust:
- It actively identifies and exploits unconditional cooperators by defecting while relying on other cooperators to keep the public good contributions high.
- It protects against being permanently ostracized by reciprocators by using short probes, soft exploitation, quick forgiveness and by cooperating where sustaining cooperation is profitable.
- It adapts to arbitrary mixtures of opponents (defectors, reciprocators, unconditional cooperators, noisy players) using empirically estimated frequencies and responsiveness rather than assuming norms.

Summary pseudocode (compact):
- Probe for PROBE_ROUNDS to estimate coop_rate and responsivity.
- Classify opponents into unconditional, reciprocator, defector, unknown.
- If last round → D.
- If unconditionals exist and reciprocators + unconditionals >= 2 → occasional targeted D (at most once per SOFT_EXPLOIT_FREQ) with forgiveness if punished.
- Else if many reciprocators/expected cooperators and remaining rounds justify future gains → C.
- Else → D.
- Always update beliefs and reclassify; exploit unconditionals until they change behavior; forgive briefly after punishment; default to defect in ambiguous/short-horizon cases.
'''

description_EXPLOITATIVE_13 = '''
Name: Selective Free-Rider with Probing, Mild Punishment and Endgame Defection (SFR-PMP)

Principles (exploitative orientation)
- Seek to free-ride on others’ contributions whenever those contributions will remain high enough without my continuous payments.
- Signal cooperative intentions early so conditional cooperators keep contributing; thereafter defect by default to capture the surplus.
- Punish only briefly and predictably when cooperation collapses so others learn that my cooperation is conditional — but avoid prolonged mutual punishment that lowers my payoff.
- Always defect in the last rounds (no future to leverage), and ramp up defection toward the end.

Notation
- n, r, k: game parameters (players, rounds, multiplier).
- t: current round (1..r).
- c_j(t): observed contribution (0/1) of player j in round t.
- others(t) = contributions by all players except me in round t.
- avg_others(window): average fraction of other players contributing in the given recent window of rounds.
- TOTAL_OTHERS_PER_ROUND = n - 1.

Fixed tuning constants (interpretable and small; can be adjusted if desired)
- PROBE_ROUNDS = min(5, max(2, floor(r/6))). — a short initial “I cooperate” window to test responses.
- OBS_WINDOW = min(6, r) — window length for recent-statistics.
- RECIPROCITY_THRESHOLD = 0.15 — minimal increase in others’ cooperation after my cooperation that flags responsive cooperators.
- EXPLOIT_TRIGGER = 0.5 — if recent average other cooperation >= this, I attempt exploitation.
- PUNISH_LENGTH = 2 — short punishment length in rounds after a clear collapse.
- ENDGAME_ROUNDS = min(3, r) — always defect in last ENDGAME_ROUNDS rounds.
- SUPPORT_PROB_MIN = 0.05 — minimal occasional contribution probability to stabilize cooperation.
- SUPPORT_DECAY = 0.4 — how much occasional support I give depending on observed drop (explained below).

High-level state machine
- States: PROBE, EXPLOIT, COOPERATE, PUNISH, ENDGAME.
- Start in PROBE. Transition rules below determine state.

Decision rules (explicit)
1. Endgame override
   - If t > r - ENDGAME_ROUNDS: ALWAYS DEFECT (0). (Simple and exploitative.)

2. PROBE phase (rounds 1..PROBE_ROUNDS)
   - Action: CONTRIBUTE (1).
   - Purpose: show cooperative intent and collect data on others’ reactions.

3. After PROBE, compute statistics each round using the most recent OBS_WINDOW rounds (or all past rounds if fewer):
   - recent_avg_others = (sum over last OBS_WINDOW rounds of others(t)) / (OBS_WINDOW * TOTAL_OTHERS_PER_ROUND).
   - responsiveness estimate: compare each opponent’s cooperation rate in rounds immediately following my cooperative rounds vs following my defections (if such events exist); aggregate a simple responsiveness score R in [−1,1]. Concretely:
     - Let A = average cooperation rate of others on rounds immediately after rounds when I contributed.
     - Let B = average cooperation rate of others on rounds immediately after rounds when I defected.
     - Set R = A − B (if no data for one of A or B, treat missing as 0 and proceed conservatively).
   - Interpreting R: R > RECIPROCITY_THRESHOLD indicates a population of conditional cooperators who increase contributions when I cooperate.

4. State selection after probe (and thereafter at each round start unless in PUNISH or ENDGAME)
   - If R >= RECIPROCITY_THRESHOLD and recent_avg_others >= EXPLOIT_TRIGGER:
       -> Enter EXPLOIT state (I will try to free-ride).
   - Else if recent_avg_others is high (>= EXPLOIT_TRIGGER) but R < RECIPROCITY_THRESHOLD:
       -> Enter COOPERATE state (others cooperate but not because of me — safer to join).
   - Else (recent_avg_others low):
       -> Remain in COOPERATE state for one more probing window if remaining rounds are many; otherwise defect (conserve tokens).

5. EXPLOIT state (primary exploitative behavior)
   - Default action: DEFECT (0) every round.
   - Occasional support: to avoid a complete collapse of others’ cooperation, occasionally contribute:
     - Compute recent_total_contrib_rate = recent_avg_others (as above).
     - If recent_total_contrib_rate has dropped since the last measurement by more than 0.10, then with probability p_support contribute for one round to “top-up” cooperation. Otherwise, with low base probability SUPPORT_PROB_MIN contribute (a small, random-looking support to keep reciprocators hopeful).
     - Practical rule: p_support = max(SUPPORT_PROB_MIN, SUPPORT_DECAY * (EXPLOIT_TRIGGER − recent_total_contrib_rate)). This means the worse the drop, the more likely I will chip in occasionally to stabilize.
   - If the group cooperation collapses sharply (see PUNISH trigger below), transition to PUNISH state.

   Rationale: mostly defect to capture surplus from cooperators, but contribute occasionally so conditional cooperators do not permanently abandon cooperation and so I continue to exploit their contributions.

6. COOPERATE state (when exploitation is too risky)
   - Action: CONTRIBUTE (1).
   - Stay in COOPERATE as long as recent_avg_others remains high or until evidence that my cooperation does not yield reciprocation (R small or negative).
   - If others’ cooperation falls below EXPLOIT_TRIGGER and remains low for more than OBS_WINDOW rounds, revert to PROBE for a short re-test or switch to EXPLOIT if R is high.

7. PUNISH state (short, targeted punishment)
   - Trigger to enter PUNISH: if, after I have been cooperating or giving occasional support, the next rounds show a sudden drop in average other cooperation of > 0.20 relative to the recent baseline — interpret this as exploitation of my contributions or uncooperative collapse.
   - Punishment rule: DEFECT for PUNISH_LENGTH rounds (PUNISH_LENGTH typically = 2), then re-evaluate statistics and move to PROBE or EXPLOIT depending on R and recent_avg_others.
   - Rationale: short, harsh but limited punishment makes cooperating players learn that cooperation is conditional on mutuality, but avoids prolonged mutual loss.

8. Handling noisy or insufficient data
   - If history is too short to compute meaningful R (e.g., early rounds), be conservative:
     - After PROBE, if data insufficient, continue a brief extended probe (contribute 1 for another 1–2 rounds) then decide.
   - If many different behaviors appear in the population (high variance in others), prefer COOPERATE only enough to test individual responsiveness; otherwise exploit.

9. Last-resort defensive rules
   - If during any sustained stretch my average payoff drops below what pure defection would guarantee (i.e., I'm being systematically exploited despite attempts), switch to permanent DEFECT until endgame. This prevents being plundered by clever punishers who never reciprocate.

Edge cases summary
- First round: contribute (part of PROBE).
- Very short games (r <= PROBE_ROUNDS): be cooperative for first rounds but defect in last round(s) per endgame override.
- Final ENDGAME_ROUNDS: always defect.
- If my contributions never seem to increase others’ cooperation (R ≈ 0 or negative), do not keep subsidizing — revert to defect-heavy behavior.
- If opponents are mostly unconditional defectors, I will quickly switch to permanent defection to avoid waste.

Why this is exploitative and robust
- It intentionally opens with cooperation to attract conditional cooperators, then defects by default to capture the extra surplus those cooperators provide.
- It uses explicit, measurable responsiveness and recent group cooperation to decide when exploitation is safe and when to join cooperation.
- It punishes defections briefly so cooperating opponents learn conditionality, but it avoids long reciprocal punishment cycles that would lower my absolute payoff.
- It always defects near the end (exploitive and safe given backward induction), and it has fallbacks to avoid being trapped as a predictable donor.

Implementation notes (for tournament designers)
- All decisions require only n, r, k and observed history of contributions — no communication or coordination beyond that.
- Tuning constants (probe length, thresholds, punishment length) can be adjusted for different tournament lengths or opponent populations; the structure (probe → detect → exploit or cooperate → short punishments → endgame defection) is the key exploitative idea.
'''

description_EXPLOITATIVE_14 = '''
Name: Adaptive Prober–Exploit (APE)

Principle (exploitative mindset)
- My objective is to maximize my own total payoff. I will try to extract contributions from cooperative opponents while avoiding being permanently punished by retaliators. I only cooperate when doing so is likely to raise my future payoff sufficiently; otherwise I defect. I actively probe opponents to discover whether they are exploitable, punish only enough to deter harsh punishers, and repair briefly to restore exploitable cooperation when it is profitable.

Notation / maintained statistics (computed from the public history)
- n, r, k — game parameters (known).
- t — current round index (1..r).
- For each player j ≠ me: history of their actions; track recent cooperation rate coopRate_j over a sliding window W rounds.
- groupCoopRate = average of coopRate_j across j ≠ me (recent average fraction of others cooperating).
- myRecentDefections — whether I have defected in the last few rounds.
- r_remaining = r − t + 1.
- Derived constants (set from parameters, deterministic):
  - W = min(10, max(3, floor(r/10))) — window for recent rates.
  - ProbeRounds = min(3, max(1, floor(r/10))) — initial probing length.
  - EndgameWindow = min(2, r) — final rounds to always defect (see below).
  - HighCoop = 0.75, MidCoop = 0.40, LowCoop = 0.20 — cooperation-rate thresholds.
  - EpsilonProbe = min(0.10, 3 / max(1,r)) — small probability to probe when in default-defect mode.
  - RepairLength = 2 (rounds) when attempting to restore cooperation after punishment.
  - RetaliateLength = min(3, max(1, floor(r/10))) — short, limited punishment length.

Modes (implicit; chosen from history and stats)
- PROBE: initial friendly probing to discover cooperators.
- EXPLOIT: preferentially defect to free-ride because many others keep cooperating.
- CONDITIONAL-COOP: standard conditional cooperation to sustain mutually profitable cooperation against mild punishers.
- DEFECT (DEFAULT): mostly defecting world where cooperators are rare; only occasional probes.
- RETALIATE: brief punishment phase triggered if others heavily punish after my defections.
- ENDGAME: last EndgameWindow rounds — always defect.

High-level rule (applied each round)
1) Endgame: If t > r − EndgameWindow, play D (defect). (Final rounds: always defect.)

2) If t ≤ ProbeRounds (initial probing phase): play C (cooperate) to attract conditional cooperators.

3) After initial probing, compute groupCoopRate over the last W rounds (excluding my actions when evaluating others). Choose behavior based on this rate and on how others react to my recent defections:

   A) If groupCoopRate ≥ HighCoop (many players reliably cooperate):
      - Enter/maintain EXPLOIT mode:
         - Default action: D (defect) every round to free-ride when others remain cooperative.
         - Monitor responses: if after a sequence of my defections there is a sustained drop in groupCoopRate of at least 0.30 (they punish me strongly), then switch to RETALIATE mode for RetaliateLength rounds (defect to signal unwillingness to be exploited further), then perform RepairLength rounds of unconditional C (cooperate) to re-establish cooperation, and then return to EXPLOIT. Also, in EXPLOIT mode, occasionally play C with probability 0.05 (tiny) to probe whether cooperation revived — but only if r_remaining is sufficiently large (≥ RepairLength + RetaliateLength).
      - Rationale: exploit stable cooperators but detect and respond to punishers quickly and briefly so cooperation can be restored and re-exploited.

   B) If MidCoop ≤ groupCoopRate < HighCoop (mixed population):
      - Enter/maintain CONDITIONAL-COOP mode:
         - Rule: cooperate (C) this round iff groupCoopRate over last W rounds ≥ MidCoop and the majority of players responded cooperatively to my last RepairLength rounds (if any). Otherwise defect (D).
         - If I defect and the group responds by reducing cooperation noticeably (≥ 0.15 drop), interpret that as credible punishment and adopt a short cooperative repair: play C for RepairLength rounds to attempt to re-establish mutual cooperation. If the repair fails (cooperation does not rise), switch to DEFECT mode.
      - Rationale: try to sustain mutually profitable cooperation when punishers exist but are not extreme; avoid persistent exploitation.

   C) If LowCoop ≤ groupCoopRate < MidCoop (cooperation rare or unstable):
      - Enter DEFECT mode with probing:
         - Default action: D (defect).
         - With small probability EpsilonProbe each round, play C for a probe to see if a subset of players will respond by cooperating consistently. If a probe is followed (within next W rounds) by a rise in groupCoopRate to ≥ MidCoop, promote to CONDITIONAL-COOP or EXPLOIT depending on resulting stability.
      - Rationale: do not pay the cost of cooperation in mostly defecting groups, but keep exploring to find exploitable cooperators.

   D) If groupCoopRate < LowCoop (virtually no cooperation):
      - Stay in DEFECT mode and do a probe only very rarely (EpsilonProbe/2). Never initiate repair; expect low returns from cooperating.

4) Handling punishers and stability:
   - Punishment detection: compare groupCoopRate after my defection(s) to the groupCoopRate before. If my defection caused a sustained and sizeable drop, treat the group as a retaliator; respond with a short RETALIATE (defect) then short unconditional REPAIR (cooperate) sequence only if continuing cooperation would on average increase my future payoff (spoiler: I require at least MidCoop level to attempt repair).
   - Never allow a punishment spiral to continue indefinitely: punish/back off cycles are short and designed to either restore exploitable cooperation (preferred) or return to stable defection if opponents persist in hurting my payoffs.

5) Parameter adaptivity:
   - Window W, ProbeRounds, RetaliateLength scale with r (shorter games → shorter probes/punishments).
   - Thresholds HighCoop / MidCoop / LowCoop are fixed but interpreted over W rounds; strategy is robust if opponents’ timescales differ because detection is windowed and repairs/punishments are short.

6) Edge cases and clarifying points
   - First round(s): cooperate for ProbeRounds rounds to identify cooperators (unless r is 1 or 2; see endgame rule).
   - Last rounds (Endgame): in the final EndgameWindow rounds I always defect (no incentive to invest for future returns).
   - If r = 1: single round → defect.
   - If some opponents’ histories are inconsistent (very noisy), the strategy relies on averages and keeps to DEFECT with occasional probes.
   - No reliance on communication or coordination other than observed actions and payoffs.

Why this is exploitative and robust
- It extracts value from unconditional or naïve cooperators by defecting whenever the rest of the group remains cooperative (EXPLOIT mode).
- It avoids getting locked into mutual defection with retaliators by using short, measured punishments and short repair attempts rather than infinite grudges; this prevents wasted long-term losses.
- It actively probes to discover exploitable opponents and adapts to the observed responsiveness of the group.
- It respects the finite horizon: it never pays to cooperate in the final rounds, so it defects at the end to avoid being exploited.

Summary pseudocode (round t decision)
- If t > r − EndgameWindow: play D.
- Else if t ≤ ProbeRounds: play C.
- Else compute groupCoopRate (last W rounds).
  - If groupCoopRate ≥ HighCoop: EXPLOIT rules (default D, detect punishment -> retaliate then repair, occasional tiny probes).
  - Else if groupCoopRate ≥ MidCoop: CONDITIONAL-COOP rules (cooperate if group remains moderately cooperative; repair after punishment).
  - Else if groupCoopRate ≥ LowCoop: DEFECT with occasional probes (EpsilonProbe).
  - Else: DEFECT (rare probes only if r large).
- Update statistics and adapt mode each round.

This strategy is deterministic except for small probing probabilities; it only uses game parameters and public history, and balances exploitation of cooperators with short, strategic retaliation and repair to avoid long-term losses from reciprocal punishers.
'''

description_EXPLOITATIVE_15 = '''
Exploitative conditional-cooperator (ECC) — natural-language strategy

Summary goal
- Exploit persistent cooperators (free-ride when it is safe) while avoiding long-term collapse from punishers. Adaptively identify which opponents are “safe to exploit” (consistently contribute and do not retaliate) and defect against them repeatedly to harvest payoff; but if exploitation starts to reduce group cooperation, rebuild cooperation briefly. Always defect in the final round(s).

Parameters computed from game inputs (use these values unless you choose small adjustments)
- n = number of players, r = total rounds, k = multiplier.
- Probe length T_probe = min(6, max(2, floor(r/6))). (Short initial cooperation phase to learn opponents.)
- History window W = min(50, r) for statistics.
- Responsiveness window M = 2 rounds after a my-defection to measure retaliation.
- Exploitable_coop_rate = 0.75 (mark players cooperating >= this fraction as “high cooperators”).
- Responsiveness_threshold = 0.25 (if an opponent reduces cooperation after my defection by less than this amount, treat them as non-punisher).
- Exploitation_threshold = max(1, floor((n-1)/3)) (minimum number of exploitable opponents needed to safely defect).
- Exploit_prob = 0.9 (when safe to exploit, defect with this probability to avoid perfect predictability).
- Forgiveness_prob = 0.05 (small random cooperation when usually defecting to prevent permanent collapse).
- Rebuild_length = min(4, max(1, floor(r/20))) (how many rounds to cooperate to rebuild if group cooperation collapses).
- Endgame_length = min(3, max(1, floor(r/10))) (in the last Endgame_length rounds always defect).

Observables tracked each round t
- For every opponent j: total times j played C in last W rounds → coop_rate_j.
- For every opponent j: responsiveness r_j = baseline coop_rate_j minus coop rate of j in the M rounds immediately following each time I previously defected (averaged). Roughly: how much j reduces cooperation right after I defect.
- Group_mean_coop = average of all coop_rate_j (or fraction of players who cooperated in last round(s)).
- My past moves and whether my defections were followed by drops in group cooperation.

Decision rules (per round t)

1) Endgame
- If t is within the last Endgame_length rounds (including final round), play D (defect) unconditionally.

2) Probing phase (rounds 1..T_probe)
- Play C every round. Purpose: build baseline cooperation and create opportunities to test reactions when you later defect.

3) Identification (after T_probe)
- Each round compute coop_rate_j and responsiveness r_j over W and M as defined.
- Mark opponent j as “exploitable” if coop_rate_j >= Exploitable_coop_rate AND r_j <= Responsiveness_threshold.
  - Intuition: j gives high cooperation and does not reliably punish my defections.

4) Primary exploitation decision (normal rounds, not endgame)
- If number_exploitable >= Exploitation_threshold:
    - If group cooperation has been stable recently (Group_mean_coop has not dropped by more than 0.25 in the last few rounds), then defect with probability Exploit_prob, else defect with probability max(0.5, Exploit_prob*0.5).
    - Occasionally (with probability Forgiveness_prob) cooperate to avoid becoming a permanent defector pattern that triggers sophisticated punishers.
  - Rationale: when there are enough weak punishers and many cooperators, I can safely free-ride and harvest.
- Else (not enough exploitable players):
    - Cooperate this round with probability 1 - Forgiveness_prob (i.e., usually cooperate to maintain cooperation), and defect with small probability Forgiveness_prob to probe for exploitable changes.
  - Rationale: if exploitation is risky, maintain cooperation to sustain future gains.

5) Detection of backfire and rebuild
- After any round where I defect:
  - If average group cooperation in the next 1–2 rounds drops by more than 0.3 relative to the pre-defection baseline (i.e., exploitation triggered a collapse), immediately switch to a Rebuild mode: cooperate for Rebuild_length consecutive rounds unconditionally to restore trust and re-identify exploitable players.
  - If collapse recurs despite rebuilding, increase threshold for exploitation (require a larger number_exploitable) and lengthen rebuilds.

6) Continual adaptation
- Update coop_rate_j and r_j each round. If a previously exploitable player starts showing responsiveness (r_j rises) or stops cooperating (coop_rate_j falls), remove them from exploitable set immediately and stop relying on them for exploitation.
- If many players become punishers simultaneously (group responsiveness increases), switch to a cooperative stance to avoid long-term losses.

Edge cases and clarifications
- First round: play C (part of probe).
- Final round(s): always D (defect), because no future to leverage.
- If r is very small (e.g., r <= 3), behave simply: cooperate the first round, defect thereafter.
- Randomization is used to avoid being perfectly predictable; probabilities above are guidance — keep some randomness but bias toward exploitation when safe.
- All decisions use only observed history (players’ past actions and payoffs) and game parameters (n, r, k). No communication or coordination assumed.

Exploitative mindset made explicit
- You try to harvest whenever you can identify a stable cohort of cooperators who will not reduce their contributions in response to your defection.
- You avoid provoking efficient punishers — if exploitation causes a noticeable drop in group cooperation, you act quickly to rebuild cooperation and raise your exploitation standards.
- You always defect at the end (no costly altruism when there is no future), and you use small, deliberate randomness to avoid being labeled and permanently punished by sophisticated strategies.

Why this is robust
- Identifies and targets only those who are consistently cooperative and non-responsive to defection, so it extracts surplus from unconditional cooperators and naive conditional cooperators.
- Protects against harsh punishers by measuring responsiveness and by rebuilding when group cooperation collapses.
- Uses probing, thresholds, and stochasticity so it adapts to many opponent types (unconditional cooperators, TFT-like punishers, random players, forgiving strategies, etc.).
'''

description_EXPLOITATIVE_16 = '''
Name: Selective Exploiter (SE)

Short goal: Extract high payoffs from cooperative opponents while avoiding sustained retaliation from conditional punishers. SE is adaptive, player‑level sensitive (detects who punishes you), time‑aware (grows more exploitative toward the end), and includes a small randomization to avoid being predictably exploited.

Definitions and running state (computed from publicly observed history up to but not including current round t):
- t = current round index (1..r).
- Contributions[j, s] = contribution (0/1) of player j in round s.
- MyDefectHistory = list of rounds s < t in which I defected.
- For each opponent j:
  - coop_rate_j = (sum over s < t of Contributions[j, s]) / max(1, (t-1)).
  - punish_rate_j = if I defected at least once before t then:
      (# of rounds s < t where I defected in round s-1 and opponent j defected in round s)
      divided by
      (# times I defected in some round s-1 < t);
    else punish_rate_j = 0.
- L = lookback window = min(5, max(1, t-1)). Use the last L rounds for recent-group measures.
- recent_group_coop = (sum of contributions by all opponents in the last L rounds) / ((n-1) * L).
- P_thresh = max(1, floor((n-1) / 4)) — threshold number of detected punishers that makes retaliation likely.
- punisher_threshold = 0.60 (an opponent with punish_rate_j >= 0.60 is treated as a punisher).
- sucker_threshold = 0.70 (an opponent with coop_rate_j >= 0.70 is classified as a likely unconditional cooperator to be exploited).
- epsilon = 0.03 (small random flip probability to break deterministic cycles).
- stage_coop_threshold = 0.60 if t <= r/2, otherwise 0.50 (I become more willing to exploit in late game).

Decision rule (what I do this round):
1. Endgame:
   - If t == r (last round): defect (0). (Dominant one-shot choice: no future to protect.)

2. Early signal:
   - If t == 1: cooperate (1). Start by signaling cooperative intent to draw out unconditional cooperators so I can exploit them later.

3. Compute punishers:
   - Let Punishers = { j : punish_rate_j >= punisher_threshold AND coop_rate_j >= 0.20 }.
     (Require some baseline cooperativeness so that persistent defectors are not mistaken for punishers.)

4. Safety check against retaliation:
   - If |Punishers| >= P_thresh, choose cooperate (1) this round.
     Rationale: enough players are likely to retaliate to my defection that short-term gain from exploitation is outweighed by expected sustained losses.

5. If not in strong-punisher regime, exploit when profitable:
   - If recent_group_coop >= stage_coop_threshold:
       - Defect (0) this round with probability (1 - epsilon) — exploit the high recent cooperation of others.
       - With probability epsilon, cooperate (1) (randomized forgiveness/exploration).
     Rationale: when many others have been contributing recently and there is no strong punisher block, free‑riding yields higher immediate payoff and opponents who are unconditional cooperators will fund me.

6. Build cooperation (or repair relationships) when exploitation is unsafe or unpromising:
   - Else (recent_group_coop < stage_coop_threshold):
       - Cooperate (1) this round to build or restore cooperative returns.
     Rationale: if others are not providing a reliable stream of cooperation, seeking mutual cooperation can give higher long-run payoffs than isolated selfishness.

7. Special handling of chronic defectors:
   - If a large majority of opponents are chronic defectors (e.g., sum_j coop_rate_j <= 0.15*(n-1)), then defect (0) trivially (no public good available to exploit).
     (This overrides cooperate rule in step 6.)

8. Minor randomization:
   - After choosing an action following the above, flip it (cooperate <-> defect) with tiny probability epsilon to avoid being trapped by deterministic punishment cycles or exploited by strategies that exploit strict patterns.

Implementation notes and rationale:
- First round cooperation lures unconditional cooperators ("suckers") and provides information. Last-round defection is unambiguous rationality.
- Punisher detection is key: SE never blindly free‑rides if enough players retaliate reliably; instead it preserves cooperation to avoid profitable long-term punishment.
- The lookback window L is short (up to 5 rounds) so SE is responsive, not overly swayed by distant past events; thresholds adapt in the second half of the game (lower stage_coop_threshold) to become more exploitative as the chance of long-term punishment diminishes.
- The sucker_threshold and coop_rate_j are tracked for diagnostics (identify players to exploit), but because actions are simultaneous and non‑targetable, exploitation is exercised by choosing to defect when group cooperation is high.
- The small epsilon randomness prevents infinite mutual retaliation loops and makes SE robust against exploitation by cleverly adaptive opponents.

Edge cases:
- No history yet (t=1): cooperate.
- No prior defections by me: punish_rate_j = 0 (protects me from false punisher classification).
- Short games (small r): since r halves the stage_coop_threshold, SE becomes more exploitative in short games earlier; last-round defection always applies.
- If the history is extremely mixed (no clear punishers and no reliable group cooperation), SE defaults to cooperating to attempt to build a cooperative baseline that it can later extract from.

Exploitative alignment:
- SE seeks to extract surplus when others are reliably cooperative (step 5), but only when the risk of sustained retaliation is low (step 4). It signals cooperation early, selectively defects to harvest gains, and preserves peace when a block of punishers can meaningfully reduce its future payoffs. This yields high average payoffs vs unconditional cooperators and robust protection vs reciprocators.
'''

description_EXPLOITATIVE_17 = '''
Adaptive Probe-and-Exploit (APE)

Summary
- Start by appearing cooperative and probing opponents’ sensitivity to defections.
- Use observed conditional cooperation statistics to classify the group (punishers, conditional cooperators, unconditional cooperators, or indifferent).
- Exploit whenever the group will not retaliate; otherwise maintain conditional cooperation and take only infrequent, carefully-timed defections to harvest gains while avoiding prolonged punishment.
- Always defect in the final round. Adapt all parameters from only the game parameters (n,k,r) and observed history.

Notation / bookkeeping (computed from the history up to, but not including, the current round t)
- t = current round index (1..r)
- For each other player j track:
  - coop_after_me1_j = fraction of rounds (in a sliding window of up to L recent rounds) where j cooperated given I cooperated in previous round.
  - coop_after_me0_j = fraction where j cooperated given I defected in previous round.
  - overall_coop_j = overall fraction of rounds j cooperated in the same window.
- Group-level measures (averages across other players): group_pC = average(coop_after_me1_j), group_pD = average(coop_after_me0_j), group_overall = average(overall_coop_j).
- Window length L = min(20, max(3, t-1)). (Use as much history as is available up to 20 rounds.)

Initial rules / edge cases
- If r = 1: defect (no future).
- Round 1 (t = 1): cooperate. This establishes a baseline and lets us observe others’ unconditional tendencies.
- Final round (t = r): defect (no future to punish).
- If t <= L and not enough data for statistics, follow the probe schedule below.

Probe phase (first few rounds or until statistics are stable)
- For the first min(6, r) rounds:
  - Cooperate on rounds 1 and 2 to build trust baseline.
  - On one middle probe round (e.g., round 3 if r >= 3), defect once to test immediate reactions.
  - Otherwise cooperate.
- After probe rounds, compute the statistics above and move to adaptive mode.

Classification (use these thresholds to interpret statistics)
- Unconditional cooperators: overall_coop_j >= 0.9 and coop_after_me1_j ≈ coop_after_me0_j ≈ overall_coop_j.
- Conditional cooperators/reciprocators: coop_after_me1_j − coop_after_me0_j >= 0.15 (they cooperate more after you cooperate).
- Punishers/retaliators: coop_after_me0_j <= coop_after_me1_j − 0.25 (they sharply reduce cooperation after you defect).
- Indifferent/noisy: differences are small and overall_coop_j near 0.5.

Main decision rule (for rounds 2..r-1)
1) If t == r: defect (final round).
2) If group_pD >= group_pC − 0.05 (group does not meaningfully reduce cooperation after my defection):
   - The group effectively does not punish me. Exploit fully: defect every round from now on (maximize one-shot gain; nothing to lose).
3) Else if group_overall >= 0.8 and group_pC − group_pD >= 0.15 (many cooperators who respond to cooperation):
   - Conditional cooperation with opportunistic defections:
     - Default action: cooperate.
     - Occasional exploitation: defect with small probability q each round, where q = min(0.2, (group_pC − group_pD)/2). This yields occasional one-shot gains but keeps the group mostly cooperative.
     - If any single defection by me causes a sharp group drop in the next round (group cooperation falls by ≥ 0.25), immediately stop defecting and cooperate for S = 3 consecutive rounds to rebuild trust before resuming this scheme with a lower q (halve q).
4) Else if many punishers detected (>= 1 other player with punisher pattern):
   - Avoid provoking: play cautious conditional cooperation (Tit-for-tat style):
     - Cooperate if all players cooperated in the previous round.
     - If any player defected last round, defect this round as a proportional, short punishment: defect for P = min(3, number_of_defectors_last_round) consecutive rounds, then resume cooperating if no further defections occur.
   - Rationale: prevent prolonged mutual defection while not triggering escalation.
5) Else (mixed/noisy group):
   - Use conservative exploitation:
     - Default: cooperate to maintain baseline contributions.
     - Defect occasionally with small fixed probability q0 = 0.05.
     - Monitor reactions; if group_pD is noticeably lower than group_pC, reduce q0; if group_pD ≈ group_pC, raise q0 (up to 0.2).

Individualized adjustments (fine-grain exploitation)
- If one or more players are clearly unconditional cooperators (overall_coop_j >= 0.95 and little sensitivity to my action), single out their presence: bias exploitation more heavily (increase q by +0.05 up to caps above) because those players will sustain high group contribution even when I defect occasionally.
- If a small subset are strict punishers while others are gullible, avoid defecting in rounds immediately followed by a punisher’s likely retaliation pattern: i.e., time opportunistic defections when punishers previously cooperated for at least 2 rounds in a row (punishers are less likely to punish if they themselves expect no future gain? this heuristic preserves robustness).

Endgame handling (last few rounds)
- Final round r: defect.
- Second-to-last round t = r−1: defect if group_pD >= group_pC − 0.05 (no retaliation) OR if the group contains many unconditional cooperators. Otherwise, be cautious:
  - If punishers exist (detected above), cooperate in round r−1 to avoid provoking punishments that would reduce payoff in r−1 (you will defect in r anyway).
- If r is tiny (r <= 3): be more conservative in round r−1; prefer cooperating unless you have clear evidence you can defect without retaliation.

Adaptive parameter updates
- Recompute statistics every round in sliding window L and adapt q and classification.
- If you observe long sequences of punishments after your defections, switch decisively to conservative/tit-for-tat mode to stop escalating losses.
- If you observe extended tolerance (group_pD ≈ group_pC), shift toward full exploitation (defect every round).

Design justification (exploitative mindset)
- The strategy looks cooperative early to learn opponent types and to provoke cooperation from conditional cooperators.
- It harvests one-shot gains whenever the group will not punish (full exploitation), and harvests small, infrequent defection gains when the group is fragile but mostly cooperative (opportunistic defections with quick repair).
- It is robust: it detects and backs off from punishers to avoid prolonged losses, and it times defections to minimize triggering long punishments.
- It uses only game parameters and observable history and adapts continuously, so it performs against unconditional cooperators, conditional reciprocators, punishers, and noisy players.

Behavior summary (practical cheat-sheet)
- Round 1: cooperate.
- If the group won’t punish (group_pD ≈ group_pC): defect always.
- If the group cooperates a lot but punishes modestly: cooperate by default and defect rarely (probability q chosen from observed sensitivity); repair quickly if punished.
- If punishers are present: play conditional cooperation with short proportional punishment (avoid escalation).
- Final round: defect; handle the penultimate round cautiously depending on detected punishers.
'''

description_EXPLOITATIVE_18 = '''
Name: Opportunistic Probe-and-Exploit (OPE)

Idea (one line): Act to free-ride on players who keep contributing while avoiding sustained losses against players who punish free-riding. Use short probes to classify opponents as tolerant (exploit) or retaliatory (reciprocate), defect in the known endgame, and keep occasional probes/forgiveness so exploitable cooperation persists.

Fixed internal parameters (computed from game parameters):
- Window W = min(10, r) — history length used for statistics.
- Endgame E = min(2, r) — always defect in the last E rounds to extract endgame surplus.
- Probe interval T_probe = 5 (every T_probe rounds do an active probe if not in endgame).
- Reaction tolerance delta = 0.20 (20 percentage points).
- Cooperator threshold p_coop = 0.6 (used to label a player as likely cooperative).
- Small forgiveness probability q = 0.10 (used to occasionally cooperate while exploiting).

State maintained from history:
- For each other player j, c_rate_j = fraction of rounds they contributed in the last W rounds (if fewer than W rounds exist use available rounds).
- g_rate = average of c_rate_j across all other players (group cooperation rate excluding you).
- After any round where you defect, keep track whether average group cooperation in the subsequent up-to-W rounds fell by more than delta relative to the average when you last cooperated — this tests whether opponents punish your defection.

Decision rules (applied each round t from 1..r):

1. Endgame override:
   - If t > r - E (i.e., in the last E rounds), play D. (No future to enforce cooperation; exploit naive contributors.)

2. Initialization / short histories:
   - If t = 1, play C. (A gentle initial test to detect unconditional cooperators; small one-round risk to seed exploitable cooperators.)
   - For t > 1 but while total rounds played < W, use the same logic below but compute rates with available history.

3. Classify opponents (every round using most recent W rounds):
   - Mark player j as a probable cooperator if c_rate_j >= p_coop.
   - Compute g_rate (average of c_rate_j over j ≠ you).

4. Reaction test (retaliation detection):
   - If you have defected at least once during the observed window and after your defections the group's cooperation rate dropped by more than delta compared to periods when you cooperated, label the population as "retaliatory".
   - Otherwise label it "tolerant/exploitable".

5. Main action selection:
   - If population is labeled "retaliatory":
       - Play reciprocally to avoid being punished:
         - If a strict majority of other players contributed in the immediately preceding round (i.e., count of contributions among others ≥ ceil((n-1)/2)), play C this round.
         - Otherwise play D this round.
       - Additionally: if any individual player is identified as an unconditional cooperator (c_rate_j = 1.0 over W), you may defect once against them only if you observe they do not reduce their c_rate after being defected upon; but if any such targeted defection causes group cooperation to drop by > delta, revert to pure reciprocity.
   - If population is labeled "tolerant/exploitable":
       - Exploit: prefer D to maximize immediate payoff while keeping enough cooperation among others to earn the public good:
         - If the number of other players who contributed in the immediately preceding round ≥ 1 (i.e., there is some ongoing cooperation), play D to free-ride.
         - If the group appears to be collapsing (g_rate below 1/(n-1) or there were zero contributions from others last round), play C with small probability q to reseed cooperation; otherwise play D.
       - Additionally, every T_probe rounds (when not in endgame) do a probing defection (play D if not already defecting) and observe response to update the retaliation test.
       - With probability q per round cooperate (forgiveness/maintenance) even while exploiting, to avoid immediate collapse if some opponents are conditional cooperators who require occasional positive signals.

6. Safety against exploitation by targeted punishers:
   - If a repeated pattern shows sustained loss (your average payoff over last W rounds is lower than what pure defection would have yielded given observed others), be conservative: switch into "retaliatory" (reciprocal) mode for at least W rounds to avoid further exploitation.

Edge cases / comments:
- r = 1: play D (no future, defect).
- Very small r (r ≤ E): defect in all rounds.
- If many opponents are unconditional cooperators (several players with c_rate_j ≈ 1), OPE will mostly defect to harvest the public good created by them, occasionally cooperating with small probability q to keep them from all quitting at once.
- If opponents punish defection (their cooperation rate drops after your defection), OPE switches to a safe reciprocal mode (matching the recent majority) to avoid long-run losses.
- If opponents are unpredictable/random, the strategy uses simple short-window statistics and will tend to defect (safer) while occasionally probing for exploitable behavior.
- The strategy is adaptive: it continuously updates c_rate_j and g_rate and flips between Exploit mode and Reciprocal mode according to observed reaction to defections.

Exploitative alignment:
- The core exploitative behavior is: identify when others tolerate defection and then free-ride persistently (maximizing immediate payoff), but retain probes and small cooperative gestures (q) to sustain enough cooperative supply so exploitation remains profitable. At the same time, OPE protects itself from strategies that punish by switching to reciprocal cooperation when punishment is detected, preventing costly long-run retaliation.

This strategy only uses game parameters (n, r) and observable history of actions/payoffs and is designed to exploit unconditional cooperators and naive strategies while being robust against retaliatory strategies.
'''

description_EXPLOITATIVE_19 = '''
Summary goal
- Maximize my total payoff by identifying and exploiting players who give away value (unconditional cooperators) while maintaining just enough cooperation from conditional cooperators to extract surplus. Be adaptive: probe early, classify opponents, then choose actions that maximize my expected immediate payoff plus a simple estimate of future gains from inducing cooperation. Always defect in the final round.

Terminology and computed quantities I keep each round t
- n, r, k are known. Let alpha = k / n (per-contribution benefit to each player).
- history records every player's contributions each past round and my own actions.
- remaining = r - t + 1 (rounds left including current).
- For each opponent j:
  - coop_rate_j = fraction of past rounds j contributed.
  - P_j(C | I_C) = fraction of rounds j contributed in the round after I contributed (when data exist).
  - P_j(C | I_D) = fraction of rounds j contributed in the round after I defected.
  - responsiveness_j = P_j(C | I_C) - P_j(C | I_D).
- Aggregate statistics:
  - avg_other_coop = average of coop_rate_j over all others.
  - avg_resp = average responsiveness_j over all others.
  - estimated_E_others_if_I_C = sum over j of P_j(C | I_C) (estimate of expected #others contributing next round if I cooperate now).
  - estimated_E_others_if_I_D = sum over j of P_j(C | I_D).

Setup / probing phase (first few rounds)
1. If r <= 2: defect every round (endgame is immediate; do not invest).
2. Choose probe_rounds = min(4, max(2, floor(r/10))). (Small, but enough to collect data.)
3. Probe pattern: in the probe_rounds perform a simple alternating pattern starting with C on round 1: C, D, C, ... (if probe_rounds > 1). This mixes cooperation and defection so we can measure opponents’ conditional responses.
4. Record all opponent actions; compute coop_rate_j and responsiveness_j after probes.

Classification of opponents (updated every round)
- Unconditional cooperator if coop_rate_j >= 0.85 (very high cooperation) and responsiveness_j <= 0.05 (not particularly responsive to my action).
- Conditional cooperator if responsiveness_j >= 0.15 and coop_rate_j >= 0.25.
- Defector if coop_rate_j <= 0.20 and responsiveness_j <= 0.05.
- Uncertain otherwise (treat as weak conditional cooperator with lower weight).

Main decision rule (applied each round after probing)
A. Hard endgame rule
- If this is the last round (t == r): choose D.

B. If not in last round, do the following calculations:
1. Estimate immediate expected payoff if I choose C:
   - payoff_C = 0 + alpha * (estimated_E_others_if_I_C + 1)
     (I pay 1 token so my base (1 - c_i) = 0; others’ expected contributions include my +1)
2. Estimate immediate expected payoff if I choose D:
   - payoff_D = 1 + alpha * estimated_E_others_if_I_D
3. Immediate_diff = payoff_C - payoff_D

4. Estimate the next-round inducement of my cooperating:
   - delta = estimated_E_others_if_I_C - estimated_E_others_if_I_D
   - Rough future benefit from cooperating now = delta * alpha * (remaining - 1)
     (assumes the induced change in others’ contributions persists one round on average; this is a conservative simple forecast)
5. If Immediate_diff + future_benefit > 0, cooperate (choose C); otherwise defect (choose D).

C. Exploitative special rules (override or shape the above)
1. If one or more opponents are classified as Unconditional cooperators:
   - Always defect (D) every round (except optionally probe once in a long game to check for reclassification). Rationale: unconditional cooperators reliably donate value you can capture; you gain most by never giving them reciprocal value.
2. If majority of others are Defectors (coop rate low overall) and no strong conditional cooperators detected:
   - Default to D (do not waste contributions when there is no one to entice).
3. If there are Conditional cooperators but not many Unconditional cooperators:
   - Use the calculation in B to decide; this will typically cooperate sparingly only when cooperating buys repeated extra contributions from those conditionals.
   - Additionally, when cooperating to sustain conditional cooperators, prefer “targeted” cooperation: cooperate only when estimated_E_others_if_I_C (or measured count of conditional cooperators who tended to respond to my past C) is large enough that payoff decision in B favors C.

Exploration and forgiveness (to avoid being permanently isolated)
- If I have defected repeatedly and group cooperation collapses (avg_other_coop falls below 0.1 for several rounds), with small probability p_probe = min(0.10, 2 / remaining) I will play C as a probe to see whether any conditional cooperators remain and can be reactivated. This is strictly occasional and decreases as the game approaches the end.
- If I am being punished (others respond to my defection by reducing cooperation), I allow a short forgiveness window: after 1–2 rounds of mutual defection, attempt one cooperating probe (with probability up to 0.25) to re-establish profitable cooperation with conditionals. If that fails, revert to D.

Response to sudden reclassification
- Continuously update coop_rate_j and responsiveness_j. If someone moves from Unconditional to Conditional (large responsiveness appears) I stop pure exploitation and switch to the decision rule B for that opponent subset.
- If someone classified as Conditional shows sustained defecting (coop_rate falls), reclassify as Defector and stop investing efforts to cajole them.

Edge cases and practicalities
- Very short games (r <= 2): defect every round.
- If probe data are insufficient (early rounds), be conservative: default to defect unless there is clear evidence cooperating produces higher expected payoff computed in B.
- Thresholds (0.85, 0.15, 0.20, etc.) are chosen to be robust across many opponent types; they can be interpreted as tunable but fixed parameters of the strategy and must not depend on opponents’ internal code.

Why this is exploitative and robust
- Identifies and never reciprocates to unconditional cooperators, extracting free value whenever they exist.
- Actively reaps gains from conditional cooperators by cooperating only when it is profitable (when my cooperation meaningfully increases others’ future contributions), otherwise defects.
- Uses brief probing to detect exploitable opponents, then adapts; uses occasional exploration and limited forgiveness to avoid permanent isolation but keeps exploration rare so exploitative gains are preserved.
- Defects in the final round to avoid being exploited by endgame exploitation.

Compact pseudocode-style summary
- If r <= 2: always D.
- Probe for probe_rounds with alternating C/D starting with C; compute coop_rate_j and responsiveness_j.
- Classify each opponent as Unconditional / Conditional / Defector / Uncertain by thresholds.
- Each round t:
  - If t == r: D.
  - If any Unconditional cooperator exists: D (exploit).
  - Else compute payoff_C, payoff_D, delta, future_benefit as above.
  - If payoff_C - payoff_D + future_benefit > 0: C; else: D.
  - Occasionally (rare probability decreasing with remaining) probe with C if group cooperation collapsed.
  - Update classifications and repeat.

This strategy is intentionally exploitative: it prioritizes defection except when cooperating yields a measurable expected return (immediate + projected short-run inducement), and it refuses to reciprocate unconditional generosity. At the same time it remains adaptive and robust: it probes, classifies, forgives briefly, and recalculates each round based only on observed history and known game parameters.
'''

description_EXPLOITATIVE_20 = '''
Adaptive Exploiter — strategy description (pseudocode-style, natural language)

Overview
- Goal: maximize my own cumulative payoff by (1) free-riding on persistent unconditional cooperators, (2) coaxing conditional cooperators to add contributions only when that inducement makes contributing personally profitable, and (3) avoiding being a sustained donor to defectors. The strategy uses a short probing period to estimate opponents’ unconditional/cooperative propensities and their responsiveness to my actions, then adapts each round using a simple profitability test plus safety rules for the endgame.

Parameters I compute from game inputs
- n (number of players), r (rounds), k (multiplier).
- m = probing rounds = min(6, max(2, floor(r/10))). (If r < 4, set m = 1.)
- endgame_len = min(3, max(1, floor(r/10))). (I always defect in the final round; for the last endgame_len rounds I bias toward defection unless a very clear short-term gain appears.)
- Smoothing constant for probability estimates: use Laplace smoothing with +1 numerator and +2 denominator.

Data I track from history
- For each other player j:
  - Count A_j_CD = number of rounds j cooperated when I had defected that round.
  - Count N_j_CD = number of rounds I defected (for which we observed j).
  - Count A_j_CC = number of rounds j cooperated when I had cooperated that round.
  - Count N_j_CC = number of rounds I cooperated (for which we observed j).
- From these, estimate:
  - P_j(coop | I defect) = (A_j_CD + 1) / (N_j_CD + 2)
  - P_j(coop | I coop)   = (A_j_CC + 1) / (N_j_CC + 2)
- From those per-player estimates compute:
  - E_others_if_I_defect = sum_{j != me} P_j(coop | I defect)
  - Delta = sum_{j != me} [P_j(coop | I coop) - P_j(coop | I defect)]
    (Delta is the expected net increase in others’ contributions if I switch from defect to cooperate this round.)

Decision rule each round t (1-indexed)
1. Endgame override
   - If t = r (last round): defect.
   - Else if t > r - endgame_len: treat as endgame; use the same decision rule below but require a stronger inducement to cooperate (see step 4, amplified threshold).

2. Probing phase (round t <= m)
   - Alternate to collect information: if t is odd, defect; if t is even, cooperate.
   - If r = 1 or m = 1, defect in first round to avoid a single-round donation being exploited.
   - Record others’ reactions to build the conditional probabilities above.

3. After probing (t > m), compute expected immediate payoffs:
   - If I defect this round, expected payoff:
       pi_def = 1 + (k/n) * E_others_if_I_defect
   - If I cooperate this round, expected payoff given immediate behavioral responses:
       pi_coop = 0 + (k/n) * (E_others_if_I_defect + Delta + 1)
   - Cooperation is immediately profitable if:
       (k/n) * (Delta + 1) > 1
     Rearranged threshold for Delta:
       Delta > (n/k) - 1
   - Intuition: my one token contribution is worth k/n to me plus any additional induced contributions from others; I cooperate only if the induced contributions (Delta) are large enough to offset my private cost.

4. Decision for this round
   - Baseline: If Delta > (n/k) - 1, then cooperate; else defect.
   - Endgame amplification: If t > r - endgame_len (near the end), require a stricter threshold: Delta > gamma * ((n/k) - 1) with gamma = 1.5 (i.e., need 50% more inducement to risk cooperating near the end). Practically, I will almost always defect in the final rounds unless Delta is very large.
   - Safety for persistent unconditional cooperators: if E_others_if_I_defect >= target_others where target_others = max(1, round((n-1) * 0.6)), I defect unconditionally (free-ride) because enough others already contribute that defecting yields high payoff. In other words, if a majority (or a strong minority) will contribute even when I defect, I defect.
   - Recovery/test probability: if I have been defecting for K consecutive rounds and group cooperation has collapsed (group contributions average below 10% of n for L consecutive rounds, with L = 2), I occasionally probe with low probability p_probe = 0.1: cooperate with probability p_probe to test for resurgent conditional cooperators. This prevents being permanently stuck in a worse equilibrium if opponents are adaptable.

5. Punishment / forgiveness dynamics
   - If a particular opponent j shows a sharp negative change in P_j(coop | I coop) compared to earlier estimates (they stop responding to my cooperation), I stop cooperating to try to avoid subsidizing them.
   - If the group cooperates for many consecutive rounds without my cooperating and my defection yields a big personal advantage, continue defecting (exploit). If a reasonable fraction of players consistently contribute even when I defect (high E_others_if_I_defect), continue exploiting.
   - If cooperation will be profitable by the Delta test, cooperate repeatedly as long as the Delta estimate remains above threshold; if it falls below threshold, revert to defecting.

Edge cases and robustness
- Small r or single-round games: defect in round 1 (no long-term leverage).
- No reliable statistics (e.g., after very few observations): rely on probing; use Laplace smoothing so estimates are never extreme from little data.
- Noisy opponents: smoothing and averaging over many rounds reduces noise impact; occasional re-probes (probabilistic cooperation) check for strategy changes by others.
- Highly conditional opponents: the Delta test detects if my cooperation meaningfully increases others’ contributions; I will pay to trigger their cooperation only if it becomes personally profitable.
- Unconditional cooperators: they are exploited — I defect and collect the private 1 token while receiving the public share from others’ contributions.
- All-defectors environment: if no one cooperates even when I cooperate (Delta ≈ 0 and E_others_if_I_defect small), I stop cooperating after probes and defect every round.

Why this is exploitative
- I only pay a token to the public good when doing so yields a strictly higher expected personal payoff (Delta large enough to make up for my token). Otherwise I defect.
- I free-ride on unconditional cooperators and coax conditional cooperators only when inducement is personally profitable.
- I avoid getting trapped by naive forward-looking cooperation: near the end I bias heavily toward defection, and I punish or withhold cooperation from players who stop responding to inducement.
- Probing and conditional estimates allow me to adapt against a wide array of opponent types (naive cooperators, conditional cooperators, pure defectors, stochastic players) with low risk of being persistently exploited.

Summary actionable rules (short)
- Round 1: defect (unless r = 1 then defect).
- Rounds 1..m: probe (odd = defect, even = cooperate) to estimate P_j.
- For t > m:
  - Compute E_others_if_I_defect and Delta from smoothed estimates.
  - If E_others_if_I_defect already large (enough contributors without me), defect (free-ride).
  - Else, cooperate only if Delta > (n/k) - 1 (use a 50% higher threshold in last few rounds); otherwise defect.
  - Occasionally (low probability) probe if group cooperation collapsed to detect changes.
- Last round: always defect.

This policy is simple to compute from the public history, adapts to many opponent types, and explicitly pursues exploitation whenever doing so is safe and profitable.
'''

description_EXPLOITATIVE_21 = '''
Name: Calculated Prober–Punisher (CPP)

Short description
- Start by signaling cooperation to attract conditional cooperators.
- Cooperate while the group shows strong, recent cooperation.
- When the group is reliably cooperative, perform occasional single-round free-rides (probes) to extract surplus.
- If a probe (or any recent history) indicates others will not tolerate exploitation, switch to a short, deterministic defensive/punishment phase (defect-only) to stop being exploited and to restore cooperative incentives.
- Always defect in the final rounds (endgame), so as not to be exploited when no future reciprocity is possible.

Parameters derived from game inputs (deterministic functions of n, k, r)
- Window length W = max(1, floor(sqrt(r))). (Used to measure recent behavior.)
- Burn-in B = min(3, r) initial rounds of unconditional cooperation (if r < 3 then B=r).
- Final-defect horizon F = min(3, r) — always defect in the last F rounds.
- Stable-cooperation threshold theta_high = 0.90 (others cooperated on ≥90% of opportunities in the window).
- Low-cooperation threshold theta_low = 0.50 (others cooperated <50% → do not cooperate).
- Sensitivity delta = 0.15 (used to detect a meaningful drop after a probe).
- Punishment length P = W (defect for P rounds when punished or betrayed).

State & signals (computed each round, using only observed history and parameters)
- others_coop_rate = (sum of other players’ contributions over the last W rounds) / [(n−1) * W].
- stable_for = number of consecutive rounds up to now in which others_coop_rate ≥ theta_high (computed sliding-window-wise).
- If fewer than W rounds of history exist, compute rates over the available history.

Decision rules (what I play each round)
1. Endgame override
   - If current round t > r − F (i.e., in the final F rounds) or t = r (the last round), play D (defect). Rationale: no future to recoup the direct cost of contributing.

2. Burn-in
   - If t ≤ B: play C (cooperate). Rationale: build a cooperative reputation to attract reciprocators.

3. Defensive (punishment) mode
   - If we are currently in the punishment/defensive phase (we entered it because a recent probe led to a sharp collapse or because others_coop_rate has been low), play D. Continue defecting for exactly P rounds, then re-evaluate history and exit this mode. (If you re-enter multiple times, each entry triggers P rounds.)

4. Normal evaluation (not in burn-in, not in punishment, not endgame)
   - Compute others_coop_rate over the last W rounds.
   - If others_coop_rate ≥ theta_high:
       a) If stable_for ≥ W (i.e., group has been stably cooperative for at least W rounds) then: perform a probe — play D for exactly one round (one-shot free-ride).
          - Immediately after that probe, observe the next W-round others_coop_rate.
          - If the next-window others_coop_rate drops by more than delta compared to the pre-probe level (a significant backlash), enter punishment mode for P rounds (play D for the next P rounds).
          - If the drop is ≤ delta, treat the probe as successful exploitation: resume cooperating in subsequent rounds (return to this rule) and schedule the next probe only after stable_for again reaches W.
       b) Else (stable_for < W): play C (continue cooperating to consolidate stable cooperation).
   - Else if theta_low ≤ others_coop_rate < theta_high:
       - Play C (conditional cooperation). Rationale: still worth supporting cooperation to try to raise the rate.
   - Else (others_coop_rate < theta_low):
       - Play D (defect until evidence of sustained cooperation returns). Rationale: avoid being a net donor to mostly defecting groups.

Key implementation notes and motivations (exploitative alignment)
- Attract reciprocators: initial cooperation and conditional cooperation when others show willingness to contribute. This creates opportunities to extract surplus later.
- Extract surplus: single-round probes (isolated free-rides) when cooperation is stable give an immediate payoff advantage with limited disturbance risk. The probe is single-round and conditional on a robust recovery rule so you do not trigger long collapses.
- Limit losses from retaliation: if the probe clearly triggers a strong negative reaction (others reduce contributions by more than delta), the strategy switches to a deterministic, finite punishment/defense phase (P rounds of defection). This both stops further immediate exploitation and signals that exploitation is costly, encouraging restoration of cooperation later.
- Avoid endless punishment: punishment is finite (P rounds) so you return to testing cooperation again; this avoids mutual-defection traps that would lower long-run returns.
- Endgame safety: defecting in final rounds prevents being sucker-punched when future influence is zero.
- Robustness: thresholds and window lengths scale with r (via W and B). The rules use only observed frequencies and deterministic thresholds; no reliance on coordination, shared labels, or opponent identities is required.
- Exploitative bias: the policy favors extracting gains from groups that are willing to cooperate, while switching to defection when the group is defect-heavy. It actively probes for exploitable cooperators and punishes when exploitation backfires.

Edge-case clarifications
- Very short games (r ≤ 3): B and F ensure we either cooperate a tiny initial number of rounds then quickly switch to defection in the final round(s); all other windows adapt to available history.
- Ties and boundary values: comparisons like ≥ or < are as written. If history is insufficient to fill W, compute rates on available rounds.
- Deterministic behavior: there is no randomization; actions are fully determined by past public history and the parameters n, k, r (as required).

Summary in one sentence
- Cooperate early to attract reciprocators; cooperate conditionally while cooperation is moderate; when the group is reliably cooperative, perform occasional one-shot free-rides to exploit them; if exploitation provokes durable retaliation, switch to a short defensive defection phase; always defect in the final few rounds.
'''

description_EXPLOITATIVE_22 = '''
Name: Conditional Exploiter (CE)

Summary goal: Win by free-riding when it is safe and by cooperating when defection would trigger costly punishment. CE learns from the observed responses of each opponent to its own past defections and makes a local cost–benefit decision each round: defect when the immediate one-shot gain from defection exceeds the expected future loss caused by others reducing their contributions in response; cooperate otherwise. It also uses occasional isolated defections ("probes") to exploit stable cooperative opponents while limiting retaliation.

State CE maintains (computed from history only):
- r_rem: rounds remaining.
- For each opponent j:
  - Count of rounds (within a recent window W) where j cooperated conditional on CE’s previous action being C: N_j(C|prevC) and total seen rounds with prevC, T_j(prevC).
  - Count of rounds where j cooperated conditional on CE’s previous action being D: N_j(C|prevD) and total seen rounds with prevD.
  - From those, compute p_jC_after_myC = N_j(C|prevC)/max(1,T_j(prevC)) and p_jC_after_myD = N_j(C|prevD)/max(1,T_j(prevD)).
- Group statistics over window W: average cooperation rate of others p_group, average cooperation rate after CE’s defections, persistence length of reductions after CE’s defections (measured from history, see below).
- Parameters (set as functions of n,k,r_rem, and history):
  - Window W = min(20, max(3, r - current_round + 1)) — use up to 20 most recent rounds but not more than remaining rounds.
  - Immediate one-shot gain from defecting this round: G = 1 - k/n (>0).
  - Minimum exploitable cooperation threshold theta_high = 0.75 (used for opportunistic probing).
  - Punishment sensitivity threshold delta_thresh = 0.08 (labels a meaningful drop in an opponent’s cooperation after CE defects).
  - Punishment-duration cap tau_cap = min(5, r_rem) (assume punishments persist at most a few rounds unless history shows longer).

How CE estimates expected future loss from a defection:
- For each opponent j compute delta_j = p_jC_after_myC - p_jC_after_myD (positive means j cooperates less after CE defects).
- Let Delta_total = sum_j max(0, delta_j) (sum of expected per-round reductions in total contributions from others when CE defects).
- Estimate punishment duration tau:
  - If historical data contains past CE defections, measure for each past defection how many subsequent rounds (up to W) others kept cooperation reduced relative to baseline; average those lengths; if no data, use tau = 1 (optimistic).
  - Then tau = min(tau, tau_cap, r_rem).
- Expected future loss (approx) from defecting now: L = (k/n) * Delta_total * tau.
  - Interpretation: each unit drop in others’ contributions reduces CE’s payoff by k/n per round.

Decision rules (applied each round, sequentially):
1. Terminal-round rule:
   - If r_rem == 1 (this is the last round): choose D (defect). No future to lose.
2. Initial behavior:
   - If no history yet (round 1): choose C (cooperate) — establish cooperative baseline and gather data.
3. Safety-check against known punishers:
   - If any opponent j has delta_j >= 2 * delta_thresh and that opponent’s punishment has historically persisted for at least 2 rounds, treat j as a strong punisher. If more than a simple majority of players are strong punishers, cooperate (avoid provoking coordinated punishment).
4. Main cost–benefit test:
   - Compute G and L as above.
   - If G > L + ϵ (use ϵ = 0.01 as a small margin), choose D (exploit); else choose C.
   - Tie-breaker: if G ≈ L within ϵ, choose C to favor maintaining cooperation unless there is a clear short-term exploit opportunity (see probing below).
5. Opportunistic probing / periodic exploitation (to extract value from stable cooperators without destroying cooperation):
   - If p_group >= theta_high and Delta_total ≈ 0 (no detected punishers), then defect this round (exploit) but follow the defection with at least two cooperative rounds in a row to restore trust. In effect: use isolated one-shot defections spaced out so that opponents do not find long-term incentive to punish CE.
   - Implement these probes only if r_rem > 3 (so there is room to repair), and no strong punishers are detected.
6. Reaction after being punished:
   - If CE defects and then observes a sustained drop in others’ cooperation (Delta_total observed > delta_thresh for multiple rounds), mark those punishers and revert to cooperating for a recovery phase of length max(2, observed punishment length) to regain cooperative returns (cooperate until their cooperation recovers to near baseline).
7. Exploit vs defecting when others mostly defect:
   - If last round most others defected (group cooperation below 20%), defect as well (avoid being the sucker).
8. Endgame adjustment:
   - As r_rem shrinks (e.g., <= tau_cap), be progressively more willing to defect because future punishment has less value; equivalently, reduce tau used in L proportionally to r_rem.

Notes on robustness and exploitative mindset:
- CE always compares the guaranteed immediate gain from defecting (1 - k/n) against an empirically estimated future cost. This makes CE adaptive: it will routinely free-ride when opponents do not punish or when punishment is short-lived, but it will not repeatedly defect against players who reliably punish and cause long-term losses.
- CE begins by cooperating to build a cooperative baseline and to identify pure cooperators to exploit later with intermittent single-shot defections.
- CE treats each opponent separately when estimating punishment sensitivity (delta_j). That permits selective exploitation: defect often against non-punishing players, cooperate with or avoid provoking known punishers.
- Probes are isolated and followed by cooperative repairs; this preserves long-term exploitation opportunities while limiting the risk of triggering harsh group-wide retaliation (grim-like responses).
- The algorithm uses only game parameters (n, k, remaining rounds) and observed history of actions and payoffs. All thresholds and windows are fixed functions of these inputs and of past observations.

Edge cases and clarifications:
- Single-round game (r = 1): defect.
- If history is too short to estimate delta_j reliably, CE assumes delta_j = 0 (optimistic) and uses tau = 1 — allowing early opportunistic exploitation but still shifting once reliable punishment is observed.
- If multiple opponents exhibit coordinated punishment after a CE defection (many delta_j large and persistent), CE stops exploiting and cooperates until their cooperation returns to baseline.
- CE never relies on communication or coordination; everything is inferred from observed actions.
- Parameter values (W, delta_thresh, theta_high, tau_cap) are conservative defaults; they can be tuned but remain functions of n, k and remaining rounds, not of external information.

Behavioral summary by situation:
- Group largely cooperative and no punishers detected: occasionally play an isolated D to free-ride, then cooperate enough rounds to repair trust.
- Group largely cooperative but some players punish: avoid defecting against punishers; defect selectively only when net expected gain remains positive.
- Group mostly defecting: defect to avoid being exploited.
- After being punished: cooperate to recover unless punisher can be profitably outlasted (rare).
- Last round: always defect.

This strategy is exploitative because it systematically takes one-shot gains whenever the expected future loss (from reduced contributions by others) is small, while being cautious and concessionary when defection provokes sustained, costly punishment. It learns and adapts from observed opponent reactions, enabling selective exploitation of naive cooperators and protection against costly reprisals.
'''

description_EXPLOITATIVE_23 = '''
High-level description
- Goal: harvest contributions from cooperative opponents while avoiding being locked into mutual cooperation or punished by reciprocators. Use a short probing phase to learn others’ tendencies, classify opponents, then switch to an adaptive mix of calculated defection (to exploit naive cooperators) and conditional cooperation (to keep reciprocators cooperating). Ramp up defection near the end (endgame) when future retaliation is impossible.

State maintained (computed only from observed history)
- t = current round index (1..r).
- For each player j ≠ me:
  - coop_rate_j = fraction of rounds so far in which j contributed.
  - after_my_defect_rate_j = fraction of rounds (after I defected and j previously cooperated) in which j still cooperated next round — used to measure forgiveness/naivety.
  - responsiveness_j = estimate of whether j retaliates: drop in j’s cooperation following my defection (large drop => punisher/reciprocator).
- summary statistics:
  - F_naive = fraction of other players with coop_rate_j ≥ 0.75 AND after_my_defect_rate_j ≥ 0.6 (steady cooperators who do not punish my defection).
  - F_recip = fraction of players with coop_rate_j ≥ 0.4 and responsiveness_j indicates they reduce cooperation after I defect (conditional cooperators / punishers).
  - F_defect = fraction with coop_rate_j ≤ 0.2 (persistent defectors).
- performance check: track whether my past cooperation tends to increase others’ future cooperation and my future payoffs (use simple comparison of average group payoff following my cooperations vs my defections). If cooperating has reliably improved future payoffs, weight toward cooperation.

Fixed parameters (interpretable rules, not magic numbers)
- Probe phase length T_probe = min(4, max(1, floor(r/10) + 1)). (Short; adapts to very short games.)
- Endgame safe-defect window T_end = min(3, r) (always defect in last T_end rounds).
- Thresholds as above: naive_coop cutoff 0.75, forgiving cutoff 0.6, reciprocal cutoff 0.4, defector cutoff 0.2. These are guidelines to classify opponents.

Decision rules (round-by-round)
1. Immediate edge cases
   - If r = 1: defect (no future to influence).
   - If t > r - T_end: defect (endgame: no credible future rewards/punishments).
   - If my algorithm has only incomplete statistics (t ≤ T_probe): play cooperatively to signal and probe unless the previous round showed a near-unanimous collapse to defection (≥ 80% of others defected), in which case defect this probe round to avoid being burned.

2. After the probe phase (t > T_probe)
   - Recompute coop_rate_j, after_my_defect_rate_j, responsiveness_j, and F_naive, F_recip, F_defect.

   - If F_naive ≥ 0.5 (majority are steady, forgiving cooperators)
     - Enter Exploitation Mode:
       - Defect with probability p_exploit = min(0.9, 0.2 + 1.2 * F_naive). (More naive cooperators → higher defection probability.)
       - However, if in the previous round fewer than half of players cooperated (group cooperation low), reduce p_exploit by half for one round to avoid a coordinated collapse.
       - Occasionally (about 1 out of 5 exploit rounds) cooperate to maintain a reputation and keep naive cooperators from switching—this is implemented by the probabilistic rule above (p_exploit < 1). If a particular opponent is classified as forgiving but then retaliates after my defect, update classification immediately and reduce p_exploit.

   - Else if F_recip ≥ 0.5 (majority are conditional cooperators / punishers)
     - Enter Conditional Cooperation Mode:
       - Use a conservative reciprocity rule: cooperate this round if a majority of other players cooperated in the previous round; otherwise defect.
       - If I defect and a substantial fraction of reciprocators retaliate next round (observed fall in their coop rates), switch to persistent defection against them (and continue conditional cooperation only with others who keep cooperating).
       - If conditional cooperation has been increasing my average payoff relative to defection (performance check), bias toward cooperating slightly (i.e., if tie, cooperate).

   - Else (heterogeneous/no clear majority or many defectors)
     - Defensive/Opportunistic Mode:
       - If more than half the group are persistent defectors (F_defect ≥ 0.5), defect always (don’t sink tokens into a lost cause).
       - Otherwise, behave opportunistically: cooperate if the plurality of others cooperated last round and my cooperation has historically increased their cooperation; otherwise defect.
       - If I detect a small coalition of naive cooperators (≥ 2 players) even when group is mixed, I occasionally (with probability equal to coalition_fraction) defect to extract benefit from them, but revert to defensive defection quickly if their cooperation collapses.

3. Handling individual opponents (targeted exploitation)
   - Track per-player reactions: if a player j is classified naive (high coop_rate and forgiving), I will defect more often in rounds where j contributed in previous rounds to maximize extraction from j while maintaining enough cooperating rounds to keep j naive.
   - If a player j retaliates reliably against my defections (responsiveness high), treat j as a reciprocator: do not attempt to exploit j; cooperate with j in rounds when cooperating with reciprocators maintains group cooperation.

4. Recovering from miscalibration
   - If at any point my cooperation is met with sustained defections by others (group cooperation drops and stays low), shift to all-defect to stop being exploited.
   - If I have exploited and then observe a coordinated reputational punishment (many players reduce coop rates after I defected), reduce exploitation intensity immediately, rebuild trust by cooperating for a short run (2–3 rounds) only if that reliably restores cooperation and improves my average payoff.

Exploitative mindset made explicit
- Prioritize actions that increase my payoff relative to others:
  - Use cooperation early as a cheap signal to learn who will give tokens back in future (naive cooperators).
  - When sufficiently many opponents are reliably cooperative and forgiving, free-ride frequently to collect the benefit of their contributions without paying the cost.
  - Avoid long mutual-cooperation commitments unless doing so demonstrably increases my payoff (i.e., opponents reciprocate and the net future gains outweigh being the sole sucker).
  - Never allow persistent exploitation by others: if others consistently defect, switch to defection to protect relative standing.
  - Endgame: take maximum short-term advantage (defect) because future reputational consequences are minimal or none.

Examples of concrete behavior patterns (for clarity)
- Very short game (r ≤ 3): cooperate first round only if you see value in probing; otherwise defect; always defect in last two rounds.
- Many naive cooperators: cooperate for T_probe rounds, then defect in most rounds (probabilistically), occasionally cooperating to keep them complacent.
- Mostly reciprocators: play a majority-rule tit-for-tat: cooperate if most cooperated last round; defect if most defected; attempt limited exploitation only if reciprocators fail to punish.

Robustness notes
- The strategy updates classifications continually; it does not assume that opponents share norms or sophisticated strategies.
- Probabilistic exploitation prevents synchronized massive defections that would collapse group cooperation and hurt my long-term extraction.
- Endgame defection prevents being exploited by naive opponents who might cooperate in final rounds.
- The thresholds and probabilities are adaptive guidelines; the core principle is to exploit persistent, forgiving cooperators while respecting and cooperating with retaliatory opponents to preserve long-run extraction.

Summary one-liner
- Probe briefly, identify forgiving cooperators and retaliators, then exploit forgiving cooperators with frequent but randomized defection while playing conditional cooperation with reciprocators and full defection in the final rounds — always switching to protective defection if others punish or collapse into defection.
'''

description_EXPLOITATIVE_24 = '''
High-level idea
- Be opportunistic: defect whenever the short-term gain outweighs the expected long-term loss from opponents reducing their contributions in response.
- Learn each opponent’s responsiveness to my defection (how much they “punish”). Exploit opponents who are forgiving or indifferent; avoid (or cooperate with) groups that punish.
- Probe early and occasionally to gather the data needed for safe exploitation. Near the final round(s) defect because there is little or no future cost.

Definitions I keep and update from history
- r = total rounds, t = current round (1-based). L = remaining rounds after this round = r - t.
- For each opponent j (j != me):
  - total_coop_j = number of rounds j contributed so far.
  - count_afterC_j = number of rounds (t' >= 2) where I cooperated in round t'-1 (my previous action = C).
  - coop_afterC_j = number of those rounds where j cooperated at t'.
  - count_afterD_j and coop_afterD_j similarly when my previous action = D.
  - base_rate_j = total_coop_j / (# past rounds).
  - p_afterC_j = coop_afterC_j / max(1, count_afterC_j)  (use 1 in denom to avoid division by zero)
  - p_afterD_j = coop_afterD_j / max(1, count_afterD_j)
  - estimated_punish_delta_j = max(0, p_afterC_j - p_afterD_j).  (positive means j cooperates less after I defect — they punish)
- estimated_group_delta = sum_j estimated_punish_delta_j (sum over all other players).
- Constants I use (depend only on r and history):
  - T_probe = min(8, max(2, floor(r/4))).  (short probing phase early)
  - min_samples = 3.  (minimum per-condition samples to trust an opponent’s delta)
  - optimistic_default_delta = 0.02.  (small default assumed punishment when data is absent)
  - immediate_gain = 1 - k/n.  (the per-round immediate advantage of defection vs cooperation)
  - per_round_future_loss = (k/n) * estimated_group_delta.  (expected loss to my share per future round if I defect now)
  - Decision inequality threshold: defect if immediate_gain >= L * per_round_future_loss (ties -> defect).
  - Occasional re-probe probability epsilon = 0.03 (3%) if I have good statistics; used to detect changes.

Strategy: step-by-step rules
1. Early probing phase (round t <= T_probe)
   - Play a deterministic alternating probe: if t is odd -> C, if t is even -> D.
   - Update all statistics after each round.
   - Rationale: quickly collect observations to estimate how each opponent’s cooperation changes after my C vs D.

2. After the probe phase (t > T_probe), each round do:
   a. Update base_rate_j, p_afterC_j, p_afterD_j, estimated_punish_delta_j and estimated_group_delta from full history.
   b. For any opponent j where count_afterC_j < min_samples or count_afterD_j < min_samples:
      - Treat estimated_punish_delta_j = optimistic_default_delta (I behave optimistically about unknowns but still slightly cautious).
      - If many opponents lack samples (say > n/2), increase optimistic_default_delta to 0.05 (more cautious) until we have more data.
   c. Compute immediate_gain and per_round_future_loss as above.
   d. If L == 0 (this is the last round) -> Defect (D).
   e. Else use the decision inequality:
      - If immediate_gain >= L * per_round_future_loss -> Defect (D).
      - Else Cooperate (C).
   f. Tie-breaking: if exactly equal, choose Defect.

3. Robustness and exploitation refinements
   - If the observed average base_rate across opponents is extremely low (average base_rate < 0.15), always Defect: cooperating is wasted.
   - If opponents are essentially unconditional cooperators (for most j, base_rate_j > 0.95 and estimated_punish_delta_j ≈ 0), then systematically Defect until I detect genuine punishment — but do so with a small probing frequency to avoid being surprised: after I defect, in the next round occasionally (probability 0.1) cooperate to check if cooperation persists.
   - If opponents are harsh punishers (estimated_group_delta large so that the inequality favors cooperation), then Cooperate to sustain long-term gains. Continue to monitor; if punishers are inconsistent, re-probe as needed.
   - Occasional re-probing: with small probability epsilon (3%), take the opposite action to what the inequality recommends (i.e., defect when it says cooperate or vice versa) to detect changes in opponents’ behavior and avoid being trapped forever by an outdated model.

4. Handling endgame and last few rounds
   - The inequality already accounts for remaining rounds L; as L shrinks, the right-hand side goes down and the strategy naturally defects more frequently.
   - Explicitly: always Defect in the final round. For the last few rounds (small L), the strategy will often defect because immediate_gain is positive and future loss is small.

5. Practical notes on counting and noise
   - Use only direct conditioning on my previous action for estimating p_afterC_j and p_afterD_j (because opponents act simultaneously but can condition on my previous action).
   - If history is noisy or opponents switch strategies, the occasional re-probes ensure the estimates adapt.

Why this is exploitative and robust
- Exploitative: It defects whenever short-term gain dominates the projected long-term cost, so it will defect to free-ride on forgiving opponents and on unconditional cooperators. Against naive cooperators it reaps repeated windfalls.
- Adaptive: It learns each opponent’s responsiveness to defection and uses that to judge whether defection now will provoke costly future retaliation. It probes early and occasionally to acquire and refresh those estimates.
- Robust: It is cautious when data are scarce (uses small default punishments and increased caution if many opponents are unknown), avoids cooperating against mostly defectors, and defects with certainty at the last round(s) to avoid leaving easy gains on the table.
- Simple, parameter-light, and fully determined by game parameters and observed history (no external signals or communication).

Summary pseudocode (compact)
- Maintain per-opponent counters described above.
- Probe for T_probe rounds alternating C/D.
- Each subsequent round:
  - Compute estimated_group_delta (use min_samples and optimistic defaults).
  - If last round -> D.
  - Else if average base_rate < 0.15 -> D.
  - Else if immediate_gain >= L * (k/n) * estimated_group_delta -> D else C.
  - With small probability epsilon invert the decision to re-probe.

This strategy maximizes exploitation when it is safe (opponents won’t punish) and avoids long-term traps by detecting and responding to punishment.
'''

description_EXPLOITATIVE_25 = '''
Name: Adaptive Exploiter (AE)

Principles (short): start by appearing cooperative to probe responses; classify opponents as unconditional cooperators, conditional/reciprocal players, or defectors; free-ride on unconditional cooperators; sustain cooperation with reciprocal players but probe them occasionally to extract value; punish persistent defectors; always defect in the last round. Use simple, robust statistics over recent history and forgiving one-shot punishments so we do not get locked into mutual low-payoff outcomes.

Parameters (derived from r and n; fixed small constants):
- test_rounds = min(4, max(1, floor(r/5))) — short probing phase
- history_window w = min(8, r) — how many recent rounds we smooth over
- coop_uncond = 0.90 — threshold to call a player “unconditional cooperator”
- coop_defect = 0.20 — threshold to call a player “defector”
- resp_threshold = 0.25 — decrease in cooperation after my defection that indicates a player is “conditional”
- exploitation_rate = 0.25 — rate at which we take opportunistic defections against conditional cooperators (implemented deterministically, see below)
- last_round_defect = 1 — number of final rounds where we always defect (always defect in final round)
These are tunable but fixed for the strategy; they depend only on r and observed history.

Per-player statistics we maintain from observed history:
- coop_rate_j = fraction of rounds (in the window w) in which player j cooperated
- coop_after_myC_j = fraction of rounds in which j cooperated on the round immediately after I cooperated (estimate from recent history)
- coop_after_myD_j = fraction of rounds in which j cooperated on the round immediately after I defected
- responsiveness_j = coop_after_myC_j − coop_after_myD_j (positive means j reduces cooperation after I defected → conditional/reciprocal)

High-level decision outline (one line): in early rounds probe; thereafter defect always against clear defectors and unconditional cooperators, sustain cooperation with conditional players but take occasional, limited defections to extract surplus; punish only briefly and forgive quickly; always defect in final round.

Detailed decision rules

A. Initialization and edge cases
1. If r = 1: defect (no future to gain).
2. If current round t is the final round (t = r): defect (no future punishment possible).
3. If t ≤ test_rounds: cooperate. (Build reputation and collect response data.)
4. If w > number of past rounds, compute stats over all available rounds.

B. Classification after the test phase (update each round using last w rounds)
- For each player j ≠ me:
  - If coop_rate_j ≥ coop_uncond and responsiveness_j ≤ 0.10 → label j = UNCONDITIONAL_COOPERATOR.
  - Else if coop_rate_j ≤ coop_defect → label j = DEFECTOR.
  - Else if responsiveness_j ≥ resp_threshold → label j = CONDITIONAL (reciprocal/punisher).
  - Else label j = MIXED.

Labels are updated every round (forgiveness allowed): a player labeled DEFECTOR or CONDITIONAL can be relabeled if their recent behavior improves.

C. Group-level diagnostics (each decision round)
- Compute fractions:
  - f_uncond = fraction of players labeled UNCONDITIONAL_COOPERATOR
  - f_cond = fraction labeled CONDITIONAL
  - f_def = fraction labeled DEFECTOR
- Compute recent group cooperation level g = average cooperation fraction among others over last w rounds.

D. Action decision (for round t not in the initial test rounds and not final round)
1. If f_uncond > 0:
   - Defect. Rationale: unconditional cooperators will continue cooperating; exploit them. Continue to monitor them; if they reduce cooperation after a pattern of my defections, reclassify them as conditional and stop always defecting.
2. Else if f_def ≥ 0.5:
   - Defect. Rationale: majority defectors means there is no payoff to sustaining cooperation; avoid being exploited.
3. Else (no obvious unconditional cooperators and defectors are not a majority):
   - We want to sustain cooperation with conditional/reciprocal players but extract surplus periodically.
   - If f_cond is small (f_cond < 0.3) and group cooperation g is low (g < 0.4) → defect (cooperation unlikely to be sustained).
   - If group cooperation g is high (g ≥ 0.6) and f_cond ≥ 0.3:
     - Use a controlled exploitation pattern: cooperate most rounds to maintain mutual cooperation, but defect deterministically on a fixed schedule amounting to exploitation_rate of the non-final rounds (for example: defect on rounds whose index modulo ceil(1/exploitation_rate) equals 0). This deterministic schedule avoids relying on random seeds but still limits exploitation frequency to a steady low rate. The schedule is known only to me and based on t and r.
     - After any defection, observe whether many conditionals reduce cooperation. If responsiveness of multiple conditionals exceeds resp_threshold, stop scheduled exploitation and resume full cooperation for at least one forgiveness window (1 round) to rebuild cooperation; if conditionals continue to punish and do not return to cooperation, switch to defecting until their cooperation returns.
   - If g is intermediate (0.4 ≤ g < 0.6) and f_cond moderate:
     - Be cautious: cooperate unless the most recent round’s immediate group payoff suggests defecting is more beneficial. Concretely, if in the preceding round my payoff would have strictly increased by defecting given observed others' contributions and no sign of imminent retaliation (few conditionals), defect; otherwise cooperate.

E. Punishment and forgiveness rules (avoid long vendettas)
- Punishment after observing an unexpected drop in others’ cooperation that directly follows my cooperation:
  - If a group member j reduced cooperation response after I cooperated (responsiveness_j negative in the sense they retaliate for my cooperation? unlikely), treat as DEFECTOR and defect against them until they return coop_rate_j > 0.3.
- If I defect and a conditional player retaliates by defecting next round, punish briefly by defecting back for a single round (tit-for-tat for one round). After one-round punishment, forgive and return to cooperation pattern unless the opponent shows persistent defection (2 or more consecutive defections), in which case treat them as DEFECTOR and defect until they show sustained cooperation again.
- This one-round punishment + forgiveness keeps retaliation costs low and prevents endless mutual defection.

F. Handling changes in opponents
- Recompute labels and diagnostics every round using the sliding window w. If an “unconditional” begins to respond to my defections (responsiveness rises), immediately stop exploiting them and shift to scheduled limited exploitation or cooperation mode as above.
- If many players change simultaneously (e.g., a wave of defections), fall back to defecting until new patterns emerge (safety).

G. Deterministic exploitation schedule (example implementation)
- Let K = ceil(1 / exploitation_rate) (e.g., exploitation_rate = 0.25 → K = 4).
- After the test phase, if we are in the “sustain cooperation but exploit occasionally” regime, defect on rounds t where (t − test_rounds) mod K == 0, except never defect in the final round. If a scheduled defection triggers strong retaliation (measured as a sharp drop in coop rates of conditionals), cancel the next scheduled defections for at least one forgiveness window and recompute.

Why this is exploitative and robust
- Exploitation: AE free-rides on clearly unconditional cooperators (maximizes short-term gain from them) and takes small, controlled defections against conditional cooperators to extract surplus while preserving the overall cooperation structure that yields high payoffs.
- Robustness: AE does not assume cooperation norms; it probes early, classifies players from observed responses, and updates labels. It punishes only briefly and forgives, which limits losses against retaliatory opponents and avoids getting trapped in mutual defection. It defects against clear defectors and when group cooperation is unsustainable.
- Adaptive: the sliding-window statistics and per-player responsiveness let AE adjust to mixtures of strategies (unconditional cooperators, tit-for-tat, random, exploiter opponents). The deterministic exploitation schedule is simple, observable only to AE, and prevents over-exploitation that would collapse cooperation.

Summary (operational bullets)
- First few rounds: cooperate to probe.
- Compute per-player cooperation rates and responsiveness over a recent window.
- If someone is an unconditional cooperator → always defect against them (exploit) until they stop being unconditional.
- If many defectors or cooperation is low → defect.
- If many conditionals and cooperation high → largely cooperate but defect on a fixed low-frequency schedule to extract surplus, revert immediately if retaliation occurs.
- Punish only briefly (one round) and forgive to avoid long mutual losses.
- Always defect in final round.

This strategy requires only parameters r, n, and the public history of moves/payoffs. It balances exploitation of naive cooperators with protection from and accommodation of conditional retaliators, making it both exploitative and broadly robust in heterogeneous tournaments.
'''

description_EXPLOITATIVE_26 = '''
Objective: maximize my own lifetime payoff by inducing and maintaining cooperation from others where it is profitable to do so, while opportunistically free-riding on cooperative opponents and harshly (but short-lived) punishing those who repeatedly exploit me. The strategy uses only n, k, r and the observed history of contributions.

Initialization (compute once from game parameters)
- L = max(3, min(10, floor(r/10)))  // window for measuring recent behavior
- T_end = max(1, floor(0.05 * r))   // last T_end rounds: guaranteed defection (endgame)
- P = max(1, floor(r/20))           // punishment length when triggered
- low_thresh = 0.40                 // below this recent cooperation rate => treat as noncooperative
- high_thresh = 0.80                // above this recent cooperation rate => group is reliably cooperative
- exploit_cap = min(0.5, (n - k) / max(1, n - 1))  // maximum baseline exploitation probability; scales with how individually attractive defection is
- (All thresholds are functions of n,k,r only via the computed exploit_cap; they are fixed during the tournament.)

State maintained
- For each player j != me: record q_j = fraction of their contributions in the last min(L, rounds so far) rounds.
- Punish_timer (integer, initial 0): number of remaining rounds to defect as group punishment.
- Targeted_blacklist: set of players declared persistent defectors (see rule below).

Round-by-round decision rule (at the start of each round t)
1. Endgame: if t > r - T_end, choose D (defect). Reason: backward-induction endgame unraveling; no future to sustain cooperation.

2. Update q_j for all j using the last min(L, t-1) rounds.

3. Identify persistent defectors:
   - If any player j has q_j <= 0.05 and has played at least L rounds, add j to Targeted_blacklist.
   - For players in Targeted_blacklist, I will always defect against them indirectly by never taking actions to restore their cooperation (i.e., I will not tolerate them when computing forgiveness triggers).

4. Immediate retaliation trigger:
   - If in the previous round I cooperated and at least one non-blacklisted opponent defected while most other players cooperated (i.e., that defection looked like an opportunistic exploitation of my cooperation), set Punish_timer = P.
   - Also set Punish_timer = P if two or more non-blacklisted opponents have q_j < low_thresh (concerted low cooperation).

5. If Punish_timer > 0:
   - Play D this round (defect).
   - Decrement Punish_timer by 1.
   - After punishment completes, do not immediately return to full cooperation — return via the exploitation path below.

6. Otherwise (no active punishment and not endgame):
   - Compute group_recent = mean_j!=me q_j over non-blacklisted players. If all others are blacklisted, defect.
   - Cases:
     a) group_recent >= high_thresh (group reliably cooperative):
        - Exploit opportunistically: with probability p_exploit = exploit_cap * (group_recent - high_thresh) / (1 - high_thresh), play D; otherwise play C.
          - (This makes me defect more when the group is more reliably cooperative; p_exploit is capped at exploit_cap.)
        - Additionally: ensure at least one cooperative action every ceil(1 / max(p_exploit, 0.05)) rounds to avoid permanent collapse (i.e., if randomization would produce a long run of defections, override to C occasionally).
     b) low_thresh <= group_recent < high_thresh (mixed group):
        - Be conditional: mirror the recent majority behavior.
          - If a strict majority of non-blacklisted players contributed in the last round, play C; otherwise play D.
        - This preserves cooperation when it exists but avoids being the sole cooperator.
     c) group_recent < low_thresh (group mostly defecting):
        - Play D (defect). No costly cooperation when others appear unwilling to reciprocate.

7. Targeted moderation for individual cooperators:
   - If a single player j (not blacklisted) has q_j >= 0.9 while most others are lower, I will bias my exploitation to take advantage of that high-cooperator by increasing my personal chance to defect by an additional small amount delta = min(0.2, q_j - 0.9) in rounds where group_recent >= low_thresh. This extracts surplus from strong cooperators while keeping the group sufficiently satisfied.

8. Forgiveness and re-entry:
   - Players on Targeted_blacklist can be removed if they show sustained cooperation: if for L consecutive rounds after being blacklisted they contribute in >= 80% of those rounds, remove from blacklist.
   - After each punishment completion, I resume from step 6; the strategy is forgiving and gives cooperating opponents an opportunity to return to favorable treatment.

Notes on stochastic choices and robustness
- Randomization (used for p_exploit and occasional forced cooperations) prevents pure exploitability by strict reciprocators and avoids pathological lock-step interactions. The probabilities are calibrated from n and k so that exploitation is larger when immediate defection is more profitable and capped so I do not destroy cooperation wholesale.
- The strategy punishes quickly and firmly but only for a short, predefined P rounds, preventing long punitive wars that waste payoff.
- The strategy is designed to:
  - Extract extra payoff from reliably cooperative groups and players by occasional defection.
  - Avoid being a sucker: do not cooperate into a cluster of defectors.
  - Identify and isolate persistent defectors individually (blacklist) so occasional rogue players cannot parasitize my generosity.
  - Be forgiving: allow re-entry after verified sustained cooperation.

First round behavior
- Play C in round 1 (to signal willingness to cooperate and attract cooperative strategies).

Summary of exploitative mindset
- Cooperate early and when the group looks reliably cooperative to induce contributions.
- Opportunistically defect (probabilistically) when the group is reliably cooperative to extract immediate gains.
- Punish quickly and briefly when exploited or when cooperation collapses, and blacklist persistent defectors.
- Defect in the known terminal rounds (endgame), and otherwise balance exploitation and preservation of cooperation to maximize cumulative payoff.
'''

description_EXPLOITATIVE_27 = '''
Goal (exploitative): maximize my own cumulative payoff by free-riding whenever it is “safe” (others keep contributing) and by giving just enough cooperation to sustain a profitable pool of cooperators. Avoid harsh, permanent punishments that destroy profitable cooperation; be forgiving and adaptive so I can continue to extract value from conditional cooperators.

Overview of key ideas
- Test and signal: start by cooperating briefly to discover whether the group contains conditional cooperators.
- Measure baseline: keep a short moving estimate of how often the OTHER players contribute.
- Free-ride when others routinely contribute (exploit cooperators).
- If group cooperation collapses, provide limited, strategic rebuilding contributions rather than full unconditional cooperation.
- Detect whether others respond to my defections (responsiveness). If they do, be more willing to cooperate to preserve them; if they do not, defect more aggressively.
- Always defect in the final phase when future retaliation is impossible.

Notation and bookkeeping (kept only from history and parameters)
- n (players), r (rounds), k (multiplier), t = current round (1..r)
- For each previous round s < t we observe c_j(s) for every player j.
- Let OthersContrib(s) = sum_{j≠me} c_j(s)
- Window L = min(10, max(1, r-1)) (use up to 10 recent rounds; shrink if r small)
- last_phase = min(3, r) (final rounds in which I always defect; adjust down if r small)
- p = recent average cooperation rate of others = (sum_{s=t-L}^{t-1} OthersContrib(s)) / (L*(n-1))
- lastRoundContribs = OthersContrib(t-1) (if t>1; otherwise undefined)
- Responsiveness R: estimate how much others’ cooperation drops following my defections versus following my cooperations, using available history (see the responsiveness calculation below)

Responsiveness estimate (simple, robust)
- Partition past rounds into those where I cooperated and those where I defected (excluding round 1 if I cooperated for signaling).
- Compute avg_others_if_I_cooperated = average OthersContrib(s) in rounds when I contributed.
- Compute avg_others_if_I_defected = average OthersContrib(s) in rounds when I did not contribute.
- R = avg_others_if_I_cooperated - avg_others_if_I_defected (normalized by (n-1) if you want fraction).
- Interpret R:
  - If R ≥ 0.05 (others reduce their contributions noticeably when I defect) → others are responsive/punishing; preserve cooperation more.
  - If R < 0.05 → others are largely insensitive to my choice; I can free-ride heavily.

Concrete decision rules (every round t)
1. Final phase: if t > r - last_phase, choose D (defect). (No future to preserve.)
2. First round (t = 1): cooperate (C). Purpose: cheaply probe for cooperators and signal willingness to cooperate.
3. Compute p using up to L most recent rounds (exclude round 1 if you used it only as a probe—still include it for statistics if helpful).
4. If p is very low (p ≤ T_low where T_low = 0.25):
   - Others almost never cooperate. They will not deliver future benefits. Choose D (defect) every round until p rises above T_low. No costly rebuilding unless there is clear evidence that a few cooperators are emerging.
5. Else if p is very high (p ≥ T_high where T_high = 0.60):
   - Many others are cooperating reliably. Free-ride: choose D (defect) to exploit them.
   - Exception: if responsiveness R ≥ 0.10 (others heavily punish my defect), switch to the “preserve” behavior below instead of immediate defection.
6. Else (intermediate p: T_low < p < T_high):
   - Use adaptive mixed strategy:
     a. If responsiveness R ≥ 0.05 (others respond to my behavior): be more cooperative to sustain them. Contribute (C) this round if lastRoundContribs was at least floor((n-1)*0.5) (a recent majority of others cooperated); otherwise defect (D).
     b. If responsiveness R < 0.05 (others insensitive): defect (D) more often but occasionally cooperate to test/rebuild: cooperate with small probability q_rebuild = 0.25. If you do cooperate, observe whether p increases—adjust R accordingly.
7. Soft punishment and forgiveness:
   - If you observe a sudden large drop in OthersContrib(s) relative to the recent baseline (a drop > 30% of others), do not trigger permanent grief. Instead:
     a. Punish only by defecting for a short controlled punishment window P = 2 rounds.
     b. After P rounds, attempt a single cooperative move to probe for recovery. If others respond, resume exploitation/maintenance rules; otherwise remain defecting.
8. Special rule to avoid ruinous swings:
   - Never follow a single defection by the group with immediate permanent defection. Use short punishments and frequent probes so profitable cooperation can be recovered.

Parameter summary (values chosen to be robust; they depend only on n, r, k insofar as L and last_phase do)
- L = up to 10 recent rounds
- T_high = 0.60, T_low = 0.25
- Responsiveness thresholds: 0.05 (noticeable), 0.10 (strong)
- q_rebuild = 0.25 (probability to contribute when trying to rebuild)
- last_phase = min(3,r)
- short punishment P = 2 rounds

Why this is exploitative and robust
- Exploitative: when others cooperate often (p large) the strategy defects to capture the private benefit of free-riding; only minimal cooperation is given to keep conditional cooperators from abandoning the group.
- Adaptive: the strategy measures others’ baseline cooperation and their sensitivity to my actions (R). If others punish my defection, I increase my cooperation to preserve their future contributions; if others are insensitive, I defect heavily.
- Safe/failsafe: in the final rounds it defects (no future value). It uses short punishments and forgiveness rather than grim triggers, avoiding collapses that would eliminate exploitation opportunities.
- Robust to heterogeneous opponents: it extracts from unconditional cooperators, tolerates unresponsive defectors (by not wasting contributions), and maintains conditional cooperators with minimal cost.

Edge cases
- Very short games (r ≤ 3): cooperate round 1 to probe, then defect every subsequent round (except possibly one small rebuild if evidence suggests opponents will respond).
- n = 2 (pairwise case): the same lessons apply; responsiveness is clearer and punish/probe logic still holds.
- If the tournament shows extreme volatility: widen L to include more history (up to r-1) so estimates stabilize.

Summary in one line
Start by cooperating to test; measure recent other-players’ cooperation rate and how they respond to your defections; if others cooperate a lot or are insensitive, defect to free-ride; if others punish your defection or cooperation is collapsing, provide limited, strategic cooperation (probabilistic rebuilding and short punishments) to preserve a profitable pool of cooperators; always defect in the final rounds.
'''

description_EXPLOITATIVE_28 = '''
Name: Probe–Exploit–Adapt (PEA)

Summary goal (exploitative mindset): maximize my own payoff by (a) free‑riding on persistent cooperators whenever it is safe to do so, (b) avoiding costly cooperation when the group is non‑cooperative or when punishment is likely, and (c) adapting quickly if my defections provoke retaliation. Decisions use only n, r, k and the full history of players’ contributions and payoffs.

Fixed derived quantities
- b = k / n (marginal public benefit per contribution; 0 < b < 1 when 1 < k < n).
- window w = min(10, max(3, floor(r/10))) — memory used to estimate recent behavior.
- probe rounds m = min(3, max(1, floor(r/20))) — short initial cooperation/testing phase.
- thresholds: T_high = 0.7, T_low = 0.3 (group cooperation rate thresholds).
- punish_threshold = 0.25 (drop in others’ cooperation after I defect that counts as retaliation).
- K_exploit_max = 5 (max consecutive defections when exploiting).
- reprobing interval M = 7 (if cooperation collapsed, occasionally probe to check recovery).

State kept from history
- For each other player i: cooperation rate p_i over the last w rounds.
- Group cooperation rate g = average of p_i across all other players (or fraction of others who cooperated in the last w rounds).
- My recent defect streak and how others reacted after I defected (used to detect punishers).

High-level rules (applied each round t = 1..r in order)

1) Edge-case rules
- Final round (t = r): defect (D). Never give a freebie in the terminal round.
- Final two rounds (t >= r-1): defect (D). To be exploitative and robust to backward induction, default to defect in the last two rounds unless there is unanimous, persistent cooperation and zero evidence of punishment (rare). This reduces exposure to endgame exploitation.
- First m rounds (probe phase): cooperate (C). Purpose: reveal opponents’ tendencies and attract conditional cooperators. If r is extremely small (r ≤ 3), fall back to defect after the first round(s) if group cooperation is weak.

2) Compute diagnostics (using history up to t-1)
- Compute p_i for each other player (fraction of their C in last w rounds).
- Compute g = mean(p_i) (group cooperation rate).
- Compute the immediate reaction-to-my-defection score:
  - Find occasions in the last w rounds when I defected. For each such occasion, compute the average cooperation rate of others in the next 1–2 rounds and compare to the 1–2 rounds before the defection. If the average drop > punish_threshold, mark “punishers present”.
- Flag “many unconditional cooperators” if count of players with p_i ≥ 0.9 ≥ 1 (there are at least some near-unconditional cooperators).

3) Main decision branches (when not in edge-case rounds)
A. If many unconditional cooperators exist and punishers are absent:
   - Exploit them aggressively: defect for up to K_exploit rounds in a row (K_exploit = min(K_exploit_max, 1 + floor(10*(g - T_high)) ), but at least 1). After K_exploit defections, play one cooperation (C) to maintain enough reputation so conditional cooperators continue to cooperate. Repeat this exploit/maintenance cycle while g remains ≥ T_high and punishers remain absent.
   - Rationale: free-ride on predictable contributors while giving occasional cooperation to avoid becoming labeled permanently as a defector by conditional cooperators.

B. Else if g ≥ T_high and punishers are absent:
   - Mostly defect but be minimally cooperative to sustain exploitation:
     - Defect unless this is the “maintenance” round in the cycle (one C after up to K_exploit D’s).
   - If punishers appear after I start exploiting, immediately stop long exploit streaks and switch to the conservative branch below.

C. Else if T_low < g < T_high (mixed/moderate cooperation):
   - Conditional cooperation: play C this round if and only if a strict majority of other players cooperated in the previous round (or if average p_i over window w ≥ 0.5). Otherwise play D.
   - Rationale: match the local majority; do not volunteer to be the lone cooperator.

D. Else if g ≤ T_low (group largely defecting):
   - Defect (D) each round. Do not pay the cost of contributing when group payoff is low.
   - Occasionally probe for recovery: every M rounds (counting from the last probe), play a single C to test whether cooperation has returned. If this probe leads to a sustained spike in others’ cooperation for the next w rounds, re-evaluate (may transition into B or C).

E. If punishers are present (others retaliate strongly to my defections):
   - Stop exploitation. Adopt a cautious conditional-cooperate policy:
     - Cooperate if at least 60% of others cooperated in the previous round; otherwise defect.
     - If mutual cooperation re-establishes (g rises above T_high for w rounds) and retaliation ceases (no significant drop after my isolated defections), cautiously resume exploitation as in branch B but with K_exploit_max reduced (e.g., halved).

4) Per-opponent micro-exploitation (optional refinement)
- If a single other player j is near-unconditional (p_j ≥ 0.95) while many others are defectors, preferentially defect to exploit j even if g is not extremely high. If retaliation is triggered by exploiting j (others reduce cooperation), stop exploiting j.

5) Recovery and forgiveness
- If my defections trigger permanent collapse to mutual defection, attempt periodic reestablishment probes: after a long mutual-defection sequence (≥ w rounds), play C once every M rounds. If group responds with increased cooperation for ≥ w rounds, switch back to conditional cooperation / limited exploitation depending on punishers.

6) Determinism, randomness, and predictability
- The above can be implemented deterministically (cycle lengths, thresholds) or with light randomness to avoid being exploited by strategies that learn deterministic patterns. If randomization is used, randomize only the timing of maintenance cooperations and probes (small probability p ≈ 0.05–0.15 of cooperating on a non-maintenance round when exploiting), but keep decisions otherwise rule-based to ensure robustness.

Why this is exploitative and robust
- It free-rides systematically on persistent cooperators (branch A/B) while minimizing long-term losses from punishers by detecting retaliation and immediately reverting to cautious play.
- It avoids needless cooperation when the group is non‑cooperative (branch D), so it does not donate to defectors.
- It probes early and occasionally thereafter to identify exploitable opponents and to reestablish cooperation when profitable.
- It always defects in the terminal rounds to avoid endgame exploitation.
- All actions depend only on observed history and the parameters (n, r, k) through b and the decision thresholds; no communication or coordination is required.

Concrete operational summary per round (short checklist)
1. If t ≥ r-1: play D.
2. If t ≤ m: play C (initial probe).
3. Compute g, p_i, and punishers.
4. If punishers present → cautious conditional cooperation (cooperate if ≥60% cooperated last round; else D).
5. Else if many near-unconditional cooperators → exploit: D up to K_exploit, then 1 C.
6. Else if g ≥ T_high → mostly D with periodic maintenance C.
7. Else if T_low < g < T_high → match majority last round (C if majority did C).
8. Else (g ≤ T_low) → D, with 1-in-M probes to test recovery.

This strategy prioritizes short-term exploitation of cooperators while preserving the option to stop exploitation if it provokes effective retaliation. It is adaptive across a wide range of opponent behaviors and uses only game parameters and observed history.
'''

description_EXPLOITATIVE_29 = '''
Name: Adaptive Exploiter

Short description (intent): Probe early to identify conditional and unconditional cooperators, then strategically cooperate only when it is either immediately profitable or likely to sustain additional cooperative contributions from others. Otherwise defect. Always defect in the last round. Use targeted probing (rare random cooperations) to detect changes. This approach extracts value from naive or conditional cooperators while minimizing losses to persistent free-riders.

State tracked (per opponent and global):
- For each player j (other players):
  - total_rounds_seen_j (counts of rounds in which j had a recorded action)
  - coop_after_myC_j = number of rounds j cooperated in the round following a round in which I cooperated
  - coop_after_myD_j = number of rounds j cooperated in the round following a round in which I defected
  - times_I_cooperated_before_observations_j and times_I_defected_before_observations_j (counts used to compute the conditional rates)
  - overall_coop_j = fraction of rounds j cooperated
- Global:
  - t = current round index (1..r)
  - rem = remaining rounds including current = r - t + 1

Default priors / small-data handling:
- If a conditional rate cannot be estimated (not enough observations), treat the missing conditional probability as 0.5 (uninformative prior).
- Use a small probing probability epsilon = max(0.02, min(0.08, 4/r)) to occasionally cooperate even when rules recommend defect, to detect changes in opponents’ behavior.

Endgame:
- If t == r (last round): always defect (D).
- If r is very small (r <= 3): be aggressive — defect except possibly cooperate round 1 as a probe; otherwise defect.

Decision rule for rounds t with rem >= 2 (main logic):
1. Compute for each opponent j:
   - p_j(C | I_C) = coop_after_myC_j / times_I_cooperated_before_observations_j (or 0.5 if denominator = 0)
   - p_j(C | I_D) = coop_after_myD_j / times_I_defected_before_observations_j (or 0.5 if denominator = 0)
   - responsiveness R_j = p_j(C | I_C) - p_j(C | I_D)

2. Compute summary statistics:
   - expected_others_if_I_C = sum_j p_j(C | I_C)
   - expected_others_if_I_D = sum_j p_j(C | I_D)
   - R_sum = sum_j R_j
   - immediate_expected_net_gain_from_cooperating (Delta_immediate) =
       (k / n) * (1 + expected_others_if_I_C - expected_others_if_I_D) - 1
     (Explanation: contributing increases total contributions by 1 plus any extra contributions your cooperation is expected to elicit; your immediate payoff change is k/n times that increase minus your 1-token cost.)

3. Decision thresholds and forward-looking adjustment:
   - Responsiveness threshold: R_threshold = 0.35 * (n - 1)
     (interpreted as “enough aggregate responsiveness among others to justify investing to sustain cooperation”)
   - If Delta_immediate >= 0: Cooperate (C). Cooperating is immediately expected to be non-negative.
   - Else if R_sum >= R_threshold and rem >= 3: Cooperate (C).
     (Rationale: enough opponents who tend to reciprocate when you cooperate; cultivating cooperation yields multi-round returns.)
   - Else: Defect (D).

4. Probing and forgiveness:
   - With probability epsilon (small), cooperate despite the decision above being D. Use probing only if you are currently defecting overall; do not probe in the last round.
   - If you switch from cooperation to a defection-dominated regime because the group collapsed, continue to probe at epsilon to detect recovery.
   - If the group shows persistent mass defection (group average cooperation < 0.2 for last max(4, r/5) rounds), switch to long-run defection with very rare probes (epsilon/2).

5. Punishment and forgiveness mechanism (implicit, global):
   - Because actions are group-wide, punishment is implemented by global defection: when many opponents fail to reciprocate, you stop cooperating (step 3).
   - Forgiveness occurs automatically via probing after a cooling-off period (epsilon-probe) and by re-evaluating conditional probabilities continually: if responsiveness increases, you resume cooperating under the main rule.

Edge cases and initialization:
- Round 1: Cooperate (C) as an informative probe (except if r = 1, then defect). This identifies unconditional or conditional cooperators quickly.
- Very small groups (n small): responsiveness threshold R_threshold scales with n so you require fewer responsive players.
- Very short games (rem small):
  - rem = 1: defect.
  - rem = 2: cooperate only if Delta_immediate >= 0; otherwise defect (do not rely on long-term cultivation because only one future round remains).
- Missing data: use the 0.5 prior to avoid overreacting to tiny sample noise.

How this is exploitative and robust:
- Exploitative: the strategy intentionally defects whenever contributing is not immediately profitable and when there is insufficient evidence that cooperating will elicit enough extra contributions to offset the cost. Against unconditional cooperators and naive conditional cooperators, it will cooperate often enough to continue receiving their contributions but will defect opportunistically to pocket the benefit whenever the expected gain from defecting is positive.
- Protective: by tracking conditional probabilities and using a responsiveness threshold, it avoids being continuously exploited by persistent free-riders: if many players do not reciprocate, it switches to global defection.
- Adaptive: it constantly recalculates conditional cooperation probabilities and thus adapts to shifts in opponents’ behavior. Small random probes let it discover strategy changes in opponents.
- Endgame-safe: it defects in the final round (and is cautious in the penultimate rounds), avoiding the classic final-round exploitation.

Practical notes on tuning:
- The responsiveness multiplier (0.35) and epsilon probe rate are design parameters. They should be moderate so the strategy is not overly “nice” (which invites exploitation) nor overly “mean” (which foregoes exploitable cooperators). In tournaments, these defaults balance short-term exploitation and cultivating conditional cooperation for multi-round benefit.
- If you observe particularly high immediate returns (Delta_immediate substantially positive) the strategy will cooperate even if R_sum is low — this captures the case of many unconditional cooperators.

Summary pseudocode (compact):
- If t == r: play D.
- If t == 1 and r > 1: play C (probe).
- Else compute p_j(C|I_C), p_j(C|I_D) for all j (use 0.5 priors if no data). Compute expected_others_if_I_C, expected_others_if_I_D, R_sum, Delta_immediate.
- If Delta_immediate >= 0 => play C.
- Else if R_sum >= 0.35*(n-1) and rem >= 3 => play C.
- Else => play D, but with small probability epsilon cooperate as a probe (not in last round). If global coop rate is very low for an extended window, reduce probing frequency further.

This strategy is explicitly exploitative: it only sustains cooperation when doing so yields net expected value (immediately or through measurable responsiveness), otherwise it defects and probes only rarely to detect new exploitation opportunities.
'''

description_EXPLOITATIVE_30 = '''
Opportunistic Extractor (an exploitative, history-adaptive rule set)

Principles (brief)
- Default to free-riding (defect) to collect the one-token private return, except when a small, controlled investment is likely to sustain many other players’ cooperation (which I will then exploit).
- Use short, deterministic probes to identify reciprocators and punishers; sustain cooperation only when there is evidence that cooperating yields future returns from others.
- Never cooperate in the very last rounds where there is no future to buy with present costs.

Notation
- n, r, k are game parameters.
- t is current round (1..r).
- For any past round s, c_j(s) ∈ {0,1} is player j’s contribution that round.
- “Others” means all players except myself.
- RecentWindow w = min(10, max(3, floor(r/10))). (Small fixed window that scales mildly with r.)
- For any set of rounds R, OthersCoopRate(R) = sum_{s∈R} sum_{j≠me} c_j(s) / (|R|*(n-1)). (Fraction of possible other-player contributions in R.)
- Reciprocator test: A player j is a reciprocator if, over the probe and rebuild history described below, j cooperated in at least 60% of rounds immediately following rounds when I cooperated (i.e., j tends to return cooperation when I give it).

Decision rules (deterministic pseudocode-style)

1) Endgame rule (always apply first)
- If t > r - 3 (the last three rounds): Defect (c = 0). Rationale: negligible future to buy, so never pay the cost.

2) Probing phase (rounds 1..m_probe)
- Let m_probe = min(4, max(2, floor(r/10))). In the first m_probe rounds do a short deterministic probe pattern to learn others’ responsiveness:
  - If t is odd in the probe (first probe round, third probe round, ...): Cooperate (c = 1).
  - If t is even in the probe: Defect (c = 0).
- After probes are complete, classify players as reciprocators using the “reciprocator test” on the probe rounds (and any subsequent rebuild attempts; see below).

3) Main behavior (t > m_probe and not in last-three rounds)
- Maintain a small state: lastCoopRound (most recent round I cooperated), punishUntil (if in punishment cooldown), and reciprocatorSet (players flagged as reciprocators).

- If punishUntil is set and t ≤ punishUntil: Defect (c = 0). Punishment cooldowns are used when the group permanently punishes my cooperation; see punishment detection below.

- Compute recent cooperation rate among others on window W = last min(w, t-1) rounds: q = OthersCoopRate(last W rounds). Also compute R = number of players currently flagged reciprocators.

- If R ≥ ceil(n/3) AND OthersCoopRate(only rounds in last W where reciprocators contributed) ≥ 0.75:
    - I have a sizable set of reciprocators who are reliably cooperating. Exploit:
      - Defect (c = 0) whenever the recent q ≥ 0.6 (i.e., when group cooperation is high I free-ride).
      - If q < 0.6 and I have not cooperated for S rounds (S = max(3, floor(r/20))), then cooperate once (c = 1) to “top up” cooperation and re-signal willingness to cooperate to reciprocators. Set lastCoopRound = t.
    - Rationale: when enough reciprocators are reliably contributing, I mostly defect to enjoy their contributions and only occasionally pay the cost to maintain the reciprocators’ incentive.
- Else (no substantial reciprocator core found):
    - Default strategy is cautious attempt to build or discover reciprocators while minimizing cost:
      - If q ≤ 0.25 (group cooperation very low): Attempt a rebuild step by cooperating this round (c = 1) at most once every S = max(3, floor(r/20)) rounds. That is, cooperate only if (t - lastCoopRound) ≥ S; otherwise defect. If cooperating, set lastCoopRound = t.
      - If q > 0.25: Defect (c = 0). I do not pay to sustain weak or unproven cooperation.
    - After each rebuild cooperation, update reciprocatorSet by marking any player j who contributed in the immediate next round after I cooperated; if j has contributed in at least 60% of such “post-my-cooperate” rounds encountered so far, label j a reciprocator.
    - If after several (ceil(r/10)) rebuild attempts no reciprocators appear, stop rebuilding permanently and default to always defect for the remainder of the game.

4) Punishment detection and cooldown
- If I cooperate in some rounds and, in response, the group’s average cooperation falls drastically (OthersCoopRate in the next w rounds drops by ≥ 0.4 compared to the w rounds before my cooperation), interpret this as strong punishment or hostile population.
- Reaction: set punishUntil = t + ceil(r/20) (short cooldown) and remove from reciprocatorSet any players who participated in the punitive drop. During punishUntil I always defect. After cooldown, resume probing with a short probe (two alternating rounds) and attempt to detect a new reciprocator set.

5) Safety and exploitation limits
- Never cooperate two rounds in a row unless it is part of a short probe or rebuild attempt and I have evidence that some players reciprocate; this keeps my cost low.
- Cooperation frequency target:
  - If exploiting a reciprocator core, cooperate no more often than once every S = max(3, floor(r/20)) rounds (a sparse maintenance rate).
  - If rebuilding, cooperate only at most once every S rounds until reciprocators are found.

Summary (plain-language)
- I default to defecting to collect the private token.
- At the start I run a short, deterministic probe sequence to reveal who reciprocates to my cooperation.
- If I find a substantial group of reciprocators (≥ ~n/3) who reliably return cooperation, I mostly defect to free-ride on them and only cooperate very occasionally (sparse maintenance) to keep their incentive to keep contributing. This is the core exploit move.
- If I do not find reciprocators, I rarely try short rebuild cooperations to recruit reciprocators; if that fails, I give up and permanently defect.
- If others respond to my cooperation by punishing (dropping cooperation sharply), I go into a short defect cooldown and then re-probe later.
- Always defect in the final three rounds.

Why this is exploitative and robust
- Exploitative: When many others are conditionally cooperative, the strategy captures their value by defecting whenever group cooperation is high, while paying only infrequent maintenance costs. That yields a higher net payoff than consistent cooperation or naive conditional strategies.
- Adaptive: Short probes and rebuild attempts detect which players will reciprocate, and the strategy switches between exploitation, rebuild, and quit modes according to observed behavior.
- Robust: Conservative rebuild pacing, punishment detection, and a clear endgame rule prevent heavy losses against punishers, pure defectors, or unpredictable opponents. The rules depend only on game parameters and observable history.
'''

description_EXPLOITATIVE_31 = '''
Name: Opportunistic Minimal-Provider (OMP)

High-level intent (exploitative mindset)
- Maximize my cumulative payoff by (a) free-riding on players who give unconditionally, (b) extracting maintenance cooperation from conditional reciprocators with the smallest possible contribution “investments,” and (c) avoiding costly long punishments that reduce my own income. Always defect in the clear endgame where cooperation cannot be repaid.

State I maintain (computed from observed history only)
- For each other player j:
  - R_j = number of rounds observed for j.
  - C_j = number of times j contributed.
  - C_j_afterC = number of times j contributed in a round that immediately followed a round where I contributed.
  - C_j_afterD = number of times j contributed in a round that immediately followed a round where I defected.
  - p_j = C_j / R_j (overall cooperation rate, undefined => treat as 0 until observed).
  - p_j_afterC = C_j_afterC / (number of rounds observed after my C) (undefined => 0).
  - p_j_afterD = C_j_afterD / (number of rounds observed after my D) (undefined => 0).
- Global recent group cooperation rate (excluding me) over a sliding window W = min(10, r): G = fraction of other-player contributions observed in last W rounds (if fewer than W rounds observed, use all past rounds).
- Derived signals:
  - delta_j = p_j_afterC - p_j_afterD (positive values suggest j rewards my cooperation; negative suggests j punishes or ignores it).
  - n_rec = number of j with delta_j >= delta_threshold (estimated reciprocators).
  - n_uncond = number of j with p_j >= uncond_threshold (likely unconditional cooperators).
- Parameter choices (fixed, computed from n,k,r):
  - endgame rounds E = min(3, r) — always defect for the last E rounds.
  - window W = min(10, r).
  - uncond_threshold = 0.95 (someone this cooperative is treated as effectively unconditional).
  - delta_threshold = 0.18 (a robust sign of positive conditionality).
  - group_target = 0.60 (target group cooperation proportion I want to sustain among reciprocators/unconditionals).
  - probe_probability p_probe = min(0.20, 4 / max(1,r)) — occasional exploration early in long games.

Decision rule for each round t (1..r)
1. Endgame: If t > r - E (we are in the last E rounds), choose D (defect). Rationale: no future to be rewarded; cooperating is costly and exploitable.

2. Quick classifications and obvious exploitation:
   - If any players are classified as unconditionals (p_j >= uncond_threshold):
     - Defect always. Rationale: they give reliably; always free-ride on them.
   - Else if all other players are persistent defectors (for all j, p_j <= 0.05 and R_j >= 3):
     - Defect always. Rationale: no one will reward cooperation.

3. Probing and learning (early rounds / sparse data):
   - If total history is very short (t <= 2) or there is little data about others (average R_j < 3):
     - With probability p_probe, play C (probe). Otherwise play D.
     - Use probes to create variation in my actions so I can estimate delta_j quickly.

4. Maintain reciprocators with minimal cost:
   - Compute S = sum_j delta_j over others (estimated marginal increase in others’ cooperation next round if I cooperate this round).
   - Conservative payoff test: estimate immediate next-round return from paying 1 token now. The additional expected contributors next round ≈ S. The marginal next-round payoff from that extra contribution(s) to me ≈ (k/n)*S. Cooperate this round only if (k/n)*S >= cost_fraction, where cost_fraction = 0.6 (a conservative fraction of the contribution cost to allow for multi-round benefit; adjust implicitly via parameter choices). That is, if (k/n)*S >= 0.6, play C; otherwise D.
     - Rationale: only invest when there is clear, measurable reciprocation likely to repay a meaningful part of the cost. The constant <1 lets me accept that benefits may compound over more than one round.

5. Group-maintenance trigger (periodic “repair”):
   - If recent group cooperation G among others has fallen below group_target and there exist one or more reciprocators (n_rec >= 1):
     - Perform a short repair: play C for a minimal number of rounds s = 1 (one-shot maintenance contribution). Recompute deltas after that round. If group cooperation recovers (G rises back above group_target in the next window), stop cooperating and return to default exploitation. If not, stop wasting contributions and revert to Defect.
     - Rationale: restore cooperation cheaply; keep contributions minimal and test if cooperation is salvageable.

6. Defensive nuance versus punishers:
   - If some players appear to punish cooperation (delta_j <= -delta_threshold and p_j_afterC low), avoid repeated cooperation aimed at them. Do not attempt to “buy” their cooperation. Treat punishers as defectors for practical play and defect.

7. Occasional randomization to avoid exploitation patterns:
   - If none of the above rules force C and I am not in endgame, default to D but with a tiny randomized cooperation probability p_rand = min(0.05, 1 / max(10, r)) to prevent predictable cycles and to collect further signal data. (This is small and used only if I am not actively maintaining reciprocators.)

Summary behavior patterns
- Free-ride fully on clear unconditional cooperators (never give them an incentive by cooperating).
- Identify genuine reciprocators via how their actions change after my C vs D; make tiny, targeted investments (single-round C) when those investments are likely to increase future contributions enough to repay the cost.
- Repair group cooperation only when it is worthwhile (measured decline below a target and presence of reciprocators), and with the minimum number of contributing rounds.
- Punishers and defectors get defected against, not courted.
- Always defect in the final few rounds.

Edge cases
- Very short games (r <= E): immediately defect every round (endgame logic dominates).
- n or k extreme values: thresholds are conservative; if k is very close to n (k/n ≈ 1) cooperation is harder to make profitable individually but the delta-based test still controls whether a contribution is worthwhile. If k/n is larger than typical, S threshold will more easily be met and I will invest more often to sustain reciprocators.
- Noisy/random opponents: probes and the sliding window W allow the strategy to estimate tendencies robustly; the conservative payoff test prevents overpaying noisy players.

Why this is exploitative and robust
- It deliberately defects against players who give without conditioning, thereby extracting surplus.
- It spends the minimal necessary to sustain conditional cooperators, rather than reciprocating fully and symmetrically.
- It avoids long costly punishments and endgame foolishness, and it adapts to a wide set of opponent behaviors via per-player statistics and short, skeptical repairs.
'''

description_EXPLOITATIVE_32 = '''
Adaptive Opportunist — an exploitative, history‑dependent policy for repeated public goods games

Summary (one line)
- Start by signalling cooperation, probe opponents to learn who is forgiving vs retaliatory, then systematically defect to extract value from forgiving players while maintaining cooperation with or punishing retaliators; always defect in the final rounds.

Parameters derived from the game and history (computed deterministically from n, k, r and past rounds)
- Window w = min(20, max(3, floor(r/5))) — number of most recent rounds used for statistics.
- Probe rounds PR = min(4, max(2, floor(r/10))) — early rounds used for active probing.
- Endgame safe window E = min(2, r) — in the last E rounds always defect.
- Naive threshold p_high = 0.80 (an opponent whose cooperation rate ≥ p_high over window w is treated as highly cooperative).
- Retaliation sensitivity delta = 0.15 (an opponent whose cooperation probability after you defect drops by ≥ delta relative to their baseline is treated as retaliatory).
- Forgiveness window L_punish = 1 (short punishment length for single defections), escalate if repeated defections from many opponents.

Definitions (computed each decision round t > 1)
- For each opponent j:
  - p_j = fraction of rounds they contributed in the last w rounds (or all past rounds if fewer).
  - q_j = fraction of rounds they contributed immediately after rounds in which you defected (estimate of how they respond to your defection). If no data, mark as unknown.
  - Label opponent j as:
    - naive if p_j ≥ p_high and (q_j is unknown or q_j ≥ p_j − delta) — high cooperation and low/no retaliation.
    - retaliator if q_j is known and q_j ≤ p_j − delta — they reduce cooperation specifically after your defection.
    - conditional otherwise (mixed behavior / insufficient data).
- Group statistics:
  - naive_frac = fraction of opponents labeled naive.
  - last_round_coop_rate G_{t-1} = fraction of players who contributed in the immediately previous round.

Decision rules (applied each round t from 1 to r)
1. Edge cases:
   - If t = 1: Cooperate (C). This signals willingness to cooperate and gathers first data.
   - If t > r − E (in last E rounds): Defect (D) — avoid endgame exploitation; do not attempt cooperation in final E rounds.
2. Early probing (t ≤ PR and t ≤ r − E)
   - Use a structured probe: cooperate in round 1, then in subsequent probe rounds defect rarely (e.g., defect in one or two of the early probe rounds chosen deterministically, e.g., round 2 and round 1 + floor(PR/2)). Collect opponent responses to those defections to populate q_j.
   - Outside the selected probe rounds, cooperate to build baseline p_j.
3. Classification complete (after probes or when enough history exists)
   - If naive_frac ≥ 0.5 and G_{t-1} ≥ 0.6:
     - Exploit mode: defect (D).
       - Rationale: a majority are reliably cooperative and do not punish; defecting each round maximizes immediate payoff. Monitor p_j and q_j continuously; if naive_frac falls below 0.5 or signs of retaliation appear, exit exploit mode.
       - Maintain occasional short cooperative gestures if many opponents are conditional (see below) — see “maintenance” rule.
   - Else (no strong majority naive):
     - Reciprocity mode: pursue conditional cooperation with calibrated punishment.
       - If any opponent defected in the previous round, punish by defecting this round (L_punish = 1) — tit‑for‑tat style, but punish only briefly unless defection persists.
       - If multiple opponents defected in the previous round, punish for a longer but bounded punishment length proportional to the fraction who defected (e.g., punish for min(3, 1 + round(2 * fraction_defected * w/PR)) rounds).
       - If no recent defections (none in last L = min(3,w) rounds), cooperate (C).
4. Targeted exploitation in mixed groups
   - If a nontrivial subset of opponents are labelled naive but naive_frac < 0.5, perform targeted opportunistic defections:
     - On any round where naive_frac ≥ 0.2 and last_round_coop_rate G_{t-1} ≥ 0.6, defect to pocket immediate gains from naive cooperators.
     - If retaliators begin to reduce cooperation (q_j drops or they start defecting after your defections), immediately switch back to Reciprocity mode and enforce short punishments until cooperation resumes.
5. Stochastic probing and deception
   - While in Reciprocity mode, occasionally (small probability p_probe = 0.05) defect on a round even if no one defected recently — this checks whether opponents are truly conditional or are pretending; if opponents tolerate these probes (no retaliation), mark them as more naive and shift toward exploitation.
6. Recovery and forgiveness
   - After any punishment period, automatically return to cooperation if a majority of players resume contributing in the round following punishment. Do not hold grudges beyond the bounded punishment window unless opponents show long-run persistent defection.
7. Safety checks and switching logic
   - If average group cooperation rate drops below 0.2 for several consecutive windows (w), default to Defect (D) until cooperation reappears — cutting losses when the group collapses.
   - If exploitation leads to a rapid drop in others’ p_j or a rise in retaliatory labels, exit Exploit mode immediately and revert to Reciprocity mode.

Why this is exploitative and robust
- Exploitative: the strategy actively identifies and extracts value from players who are reliably cooperative and do not punish (naive). When naive_frac is high and group cooperation is strong, it defects to pocket immediate gains. It uses occasional and targeted defections to exploit mixed groups.
- Robust: the strategy learns which opponents punish and which forgive; it enforces brief, calibrated punishments against retaliators so they cannot systematically exploit you, but it is forgiving so cooperative equilibria can be sustained when reciprocation exists. Structured probing and stochastic probes detect opponents’ responsiveness without forfeiting long periods of cooperative returns.
- Endgame safety: guaranteed defection in the last E rounds prevents being exploited by backward‑inducing cooperators and stops wasting tokens when future gains are impossible.

Operational summary (what you will actually do each round)
- Round 1: Cooperate.
- Early rounds: follow the probing schedule (mostly cooperate; 1–2 early defections to test).
- After probes: label opponents as naive/retaliator/conditional.
  - If majority naive and recent cooperation is high → exploit: defect every round (monitor and exit on retaliation).
  - Otherwise → mutual cooperation with short tit‑for‑tat punishments; occasionally probe with small probability to detect naive players.
- Always defect in the final E rounds.
- Continuously update labels and switch modes immediately when data indicate changed opponent behavior.

This policy depends only on n, k, r (to set the windows) and on observed history of contributions. It is deliberately exploitative (seeks gains against forgiving opponents) while being adaptive (learns who punishes and who forgives) and robust (bounded punishments, forgiveness, endgame safety).
'''

description_EXPLOITATIVE_33 = '''
Summary: Play to free-ride whenever safe, but probe early, punish only briefly to avoid permanent mutual defection, and occasionally lure/coax cooperation so you can exploit it later. Use simple, history-based statistics so the rule is deterministic given the parameters and observed past actions.

Parameters (set from the known game parameters r, n, k and the history). Default choices below can be tuned by tournaments but are fixed rules:
- probe_rounds = min(2, r) — cooperate in the first 1–2 rounds to probe.
- window w = min(8, max(2, floor(r/5))) — number of most recent rounds used for statistics.
- high_coop = 0.60 — threshold above which the group is “cooperative” and worth exploiting.
- low_coop = 0.40 — threshold below which the group is “uncooperative” and not worth generous moves.
- exploit_burst_max = 3 — maximum consecutive rounds to run a pure exploitation burst.
- lure_prob = 0.20 — when trying to lure cooperation, cooperate with this probability, otherwise defect.
- forgiveness_reset = 3 — if cooperation rises after punishment for forgiveness to kick in.
- final_defect_rounds = min(3, r) — in the final few rounds always defect.

Definitions computed each decision step:
- t = current round index (1..r).
- For each other player j, compute their cooperation rate over the last w rounds (or all history if fewer than w rounds) p_j.
- Group recent cooperation P = average_j p_j (average cooperation rate of the other n-1 players over the window).
- My recent cooperation rate M (used only for bookkeeping).

Decision rules (pseudocode style):

1. Final rounds
- If t > r - final_defect_rounds: play D (defect). Rationale: finite horizon, exploit in last rounds.

2. Initial probing
- If t <= probe_rounds: play C (cooperate). Rationale: reveal opponent types and entice cooperators so you can exploit them later.

3. Compute P (group recent cooperation rate) using the last w rounds.

4. Exploit mode (take immediate free rides while cooperators are available)
- If P >= high_coop:
  - Enter an exploitation burst: play D for up to exploit_burst_max consecutive rounds or until P drops below low_coop.
  - After each round of D in the burst, recompute P; if P falls below low_coop, exit burst.
  - Rationale: when many others are cooperating, defecting maximizes one-shot payoff. Keep the burst short to avoid provoking permanent collapse.

5. Conditional cooperation / Mirror (stabilizer)
- Else if low_coop <= P < high_coop:
  - Play what the majority of others did in the immediately preceding round:
    - If a majority of other players contributed in round t-1, play C; otherwise play D.
  - Rationale: mirror the recent group norm to avoid needless provocation while still exploiting occasional cooperation.

6. Lure + selective exploitation (when group is uncooperative)
- Else if P < low_coop:
  - Default to D (protect yourself).
  - Additionally, with small probability lure_prob, play C to attempt to seed cooperation and identify latent cooperators. If you choose C, track which players responded by cooperating in the next round(s); mark those as potential exploitation targets.
  - If any individual other player j responds with sustained cooperation (p_j rises above high_coop individually over forgiveness_reset rounds), revert to targeted exploitation bursts that rely on that player’s cooperation (i.e., defect while they keep cooperating), but cap burst length to exploit_burst_max.

7. Forgiveness and rehabilitation
- If you have punished (played D while others were cooperating) and observe an increase in opponents’ cooperation afterwards (P climbs above low_coop for forgiveness_reset rounds), resume normal exploitation logic (allow future bursts) rather than holding a permanent grudge.
- Do not attempt permanent retaliation: punish only briefly and then test again with probes or lure moves.

8. Individual targeting nuance (exploitative detail)
- Track individual p_j rates. If one or a few players show consistent cooperation (p_j >= high_coop) while the group average is still moderate, prefer to defect (D) to free-ride on them even if others sometimes defect. If most players are consistently defecting, avoid being the lone cooperator.

9. Edge cases
- r = 1: play D (single-shot).
- Very small games (n ≤ 2): behave similarly but reduce lure_prob to 0.1 and exploit_burst_max to 1 because retaliation is more impactful.
- If the history is empty (first-round probe), follow the probe rule.

Intended practical behavior and rationale (exploitative mindset)
- Start by probing to reveal cooperators and build future exploitation opportunities rather than defecting immediately and burning bridges.
- When you detect a clearly cooperative population, defect short bursts to harvest free rides; keep bursts short so opponents do not collectively spiral into permanent defection.
- When the population is mixed, mirror to avoid unnecessary loss from being punished while still capturing opportunistic gains.
- When the population is uncooperative, protect yourself (mostly defect) but occasionally invest small, low-risk cooperation to try to create exploitable cooperators.
- Use simple, robust statistics (sliding window averages and a few fixed thresholds) rather than assuming norms or coordination; this makes the strategy adaptive across diverse opponents.
- Always defect in the known final rounds to capitalize on the finite horizon.

This strategy is explicitly exploitative: it prioritizes defecting when others are contributing to take the one-shot advantage, it probes and occasionally lures to manufacture exploitable cooperators, it punishes briefly to discourage being a steady sucker, and it avoids long, self-harming retaliation cycles by using short bursts and forgiveness so exploitation opportunities persist.
'''

description_EXPLOITATIVE_34 = '''
Name: Adaptive Conditional Exploiter (ACE)

Goal: Maximize my payoff relative to others by (a) exploiting players who continue to contribute when I defect, (b) preserving cooperation with conditional cooperators when it’s profitable to do so, and (c) avoiding sustained punishment. The strategy uses short probes to learn opponents’ responsiveness, then chooses the action that maximizes expected immediate payoff with a small defect-bias and occasional probing to detect changes.

Parameters I set from the game inputs (n, r, k) and fixed safe defaults:
- probe_rounds m = min(4, max(1, floor(r/5))) — initial all-cooperate probing phase (unless r = 1).
- end_horizon H = min(2, r-1) — last H rounds I treat as endgame (see below).
- smoothing α = 0.2 — exponential smoothing weight for updating estimates.
- sensitivity threshold S = 0.25 — what I consider a “retaliatory” fall in cooperation after my defection.
- defect_bias ε = 0.02 — small advantage I give to defection when payoffs are nearly equal.
- probe_defect_prob p_probe = 0.10 — occasional probing defections against tolerant groups to discover exploitable opponents.
- forgiveness_wait F = 2 — rounds I wait before switching back to cooperation after a one-off punishment response.

Data I maintain from history:
- For each opponent j: overall cooperation rate p_j (exponentially smoothed), cooperation rate after I cooperated p_j|C, cooperation rate after I defected p_j|D. I update these each round using smoothing α so recent behavior matters more.
- Group-level statistics derived from the p_j and conditional rates: expected others’ contributions if I choose C vs D.

Decision logic (natural-language pseudocode):

1. Handle trivial/single-round cases
   - If r = 1: play D (no future benefit to cooperating).
   - For rounds t = 1..m (initial probe stage, only if r > 1): play C. Purpose: establish baseline cooperation and elicit conditional responses.

2. Endgame
   - If t > r - H (in the last H rounds): play D. Rationale: no future to sustain cooperation; exploit any remaining unconditional cooperators.

3. Estimation step (for t > m and not in endgame)
   - For each opponent j compute:
     - p_j (smoothed overall coop rate)
     - p_j|C (smoothed prob j cooperates in rounds immediately after I cooperated)
     - p_j|D (smoothed prob j cooperates in rounds immediately after I defected)
     - sensitivity s_j = p_j|C - p_j|D (how much j punishes my defection)
   - If a conditional estimate is unreliable (too few observations), fall back to p_j.

4. Compute expected immediate-payoff difference between cooperating and defecting
   - Let E_others_if_C = sum_j p_j|C (expected number of other contributions if I cooperate)
   - Let E_others_if_D = sum_j p_j|D (expected number of other contributions if I defect)
   - Expected payoff if I play C: U_C = (k/n) * (1 + E_others_if_C)
   - Expected payoff if I play D: U_D = 1 + (k/n) * E_others_if_D
   - (These are expected immediate payoffs using conditional estimates.)

5. Decision rule (exploitative bias + robustness)
   - If U_D >= U_C + ε: play D (defect; immediate payoff advantage, plus bias to exploit).
   - Else if U_C > U_D + ε: play C (cooperate when cooperating yields clearly higher immediate payoff).
   - Else (payoffs nearly equal):
     - Count retaliators R = number of j with s_j >= S.
     - Count tolerant T = number of j with s_j <= 0.05 (almost no sensitivity).
     - If T >= ceil(n/2): play D with probability 1 - p_probe and play C with probability p_probe (exploit tolerant majority, but occasionally cooperate to avoid coordination collapse and recalibrate).
     - If R >= ceil(n/2): play C (too many will punish defection — maintain cooperation).
     - Otherwise: play D (small default defect bias).

6. Probing and exploitation refinement
   - Periodically (with probability p_probe any round where I would otherwise play C) substitute a D to probe whether others are tolerant; update conditional estimates.
   - If a probe causes widespread punishment (drop in others’ cooperation), switch to cooperation for at least F rounds to recover the goodwill of conditional cooperators (forgiveness rule).

7. Collapse detection and safety
   - If observed group cooperation falls below a low threshold (e.g., average p_j < 0.2) and people are unresponsive to my cooperation, switch to persistent D to avoid giving away tokens to mostly defecting group.
   - If a stable cooperative cluster is detected (many players with p_j near 1 and s_j small), exploit them more aggressively by defecting often while interspersing cooperative moves to avoid triggering coordinated punishment.

Additional notes on robustness and exploitation rationale
- Starting cooperative (except in single-round games) reveals information and builds an image of being a cooperator; that lures unconditional cooperators and conditional cooperators into contributing in future rounds, which I can exploit selectively.
- Using conditional estimates p_j|C and p_j|D lets me predict how my action changes others’ behavior. Players who barely change their contributions when I defect (low s_j) are the targets of exploitation: defecting yields me higher returns while keeping them contributing.
- I bias toward defection when payoffs are nearly equal (ε) because exploitation of tolerant cooperators is profitable and small stochastic probing prevents opponents from learning a static predictable schedule.
- I forgive short punishments to avoid getting locked into mutual defection cycles caused by transient responses or noise.
- Endgame defection is explicit and deterministic: in final H rounds I always defect and extract whatever immediate gains remain.

Edge cases
- If m >= r (very short game): behave like the single-round rule — default to defection near the end; if no future rounds, defect.
- If conditional data are scarce for an opponent, I rely on overall p_j. If overall data are scarce for the group, I treat them as neutral and rely on probing to collect data.
- If the group is heterogeneous (mixture of strong retaliators and strong tolerators), the decision is based on majority effects: if majority punish, cooperate; if majority tolerant, defect and probe.

Summary (plain):
- Start cooperative for a short probing phase (unless only one round).
- Learn each opponent’s responsiveness to my defections.
- In most rounds choose the action that gives higher expected immediate payoff using those conditional estimates, with a small bias toward defection to exploit tolerant cooperators.
- Occasionally probe with defections to detect exploitable players; forgive brief punishments to restore cooperation when worthwhile.
- Defect deterministically in the last few rounds (endgame).
- If group-wide cooperation collapses, switch to persistent defection to avoid being exploited.

This strategy is exploitative because it deliberately defects against players who remain cooperative after my defection, while protecting long-term gains by cooperating when a majority would punish me. It is adaptive because it continuously updates conditional probabilities, and robust because it uses smoothing, probing, forgiveness, and an explicit endgame rule.
'''

description_EXPLOITATIVE_35 = '''
Summary (exploitative goal)
- Maximize my own payoff by: (1) identifying and permanently free-riding on any unconditional cooperators, (2) opportunistically exploiting conditional cooperators while avoiding long mutual-punishment that lowers my payoff, and (3) defecting in the known endgame. Be adaptive: use early probing to classify opponents, exploit when safe, back off when opponents reliably punish.

Parameters I set from the game inputs (examples of recommended values; compute these once from n, r):
- Seed/probe phase length S = min(4, max(1, floor(r * 0.10))) — short initial cooperation window.
- Recent-window L = min(10, max(3, floor(r * 0.20))) — for estimating recent cooperation rates.
- High cooperation threshold H_high = 0.70 (used to indicate a group is mostly cooperative).
- Low cooperation threshold H_low = 0.30 (used to indicate a largely defecting group).
- Unconditional-cooperator cutoff P_uncond = 0.90 (contribution rate indicating near-always-C).
- Conditional/cooperator cutoff P_cond = 0.60.
- Punishment sensitivity delta = 0.30 (drop in an opponent’s rate after we defect that counts as retaliation).
- Exploit probability p_exploit = 0.80 (probability to defect when exploiting a cooperative population).
- Forgiveness length F = 3 rounds (temporary cease exploitation after severe retaliation).
- Endgame length E = min( max(1, ceil(r * 0.05)), 3 ) — always defect in last E rounds (guaranteed endgame defection).

Data I maintain every round
- For each opponent i: overall contribution rate R_i (fraction of rounds they contributed), recent contribution rate R_i_recent (over last L rounds), and a flag Uncond_i if they meet unconditional criteria.
- Group statistics: others’ average recent cooperation fraction G_recent = average of R_i_recent over all opponents.

Detailed decision rules (per-round)
1. Edge cases first:
   - If current round t is in the last E rounds: choose D (defect). (Backward-induction safe endgame.)
   - If r is very small (r <= 3): defect every round (no incentive to invest short-term).

2. Initialization / probing phase (first S rounds):
   - Action: C (cooperate) for rounds 1..S to encourage conditional cooperators to begin cooperating and reveal responsiveness.
   - Immediately after round S (i.e., at round S+1) perform one deliberate probe-defection:
     - Round S+1: choose D.
     - Use the responses in that round and the S previous rounds to classify opponents:
       - If an opponent’s overall contribution rate across rounds 1..S+1 >= P_uncond and they contributed in the probe round despite my D, mark Uncond_i = true.
       - If R_i >= P_cond but they reduced contributions after my D, mark them as Conditional/reciprocal.
       - If R_i is very low (< H_low), mark Defector_i.

3. Ongoing rounds t > S+1 (non-endgame):
   - If any Uncond_i exists (I detected at least one near-always-cooperator):
     - Exploit them heavily: choose D every round. Reason: unconditional cooperators will keep contributing; no need to invest to sustain them.
     - Exception: if a large subset of opponents (excluding Uncond ones) begin to punish me collectively (see “collective punishment” detection below), consider temporary partial cooperation as in the “retreat” rule below.
   - Else (no confirmed unconditional cooperators):
     - Recompute G_recent (average others’ recent cooperation).
     - If G_recent >= H_high:
       - The group is mostly cooperative. Exploit opportunistically: choose D with probability p_exploit (e.g., 0.8), choose C otherwise.
         - Purpose: get free-rides most rounds while occasionally cooperating to prevent coordinated collapse and to slow retaliatory strategy detection.
         - If exploitation provokes a consistent drop in G_recent (see “punishment detection”): step down to the Retreat/Forgiveness behavior (next bullet).
     - If H_low <= G_recent < H_high:
       - Mixed population / many conditional cooperators. Play conditionally cooperative:
         - If in the last F rounds I was met with heavy retaliation (see punishment detection), cooperate this round (C) to recover trust for F rounds.
         - Otherwise, cooperate (C) to keep mutual cooperation profitable across rounds; insert occasional single-round D probes at frequency 1 per ceil(r/10) rounds to test for unconditional cooperators.
     - If G_recent < H_low:
       - Group is mostly defecting; defect (D). There is no benefit investing in cooperation.

4. Punishment detection and response (avoid long mutual-defection traps)
   - When I play D and some opponents sharply reduce their R_i_recent by > delta in the immediate subsequent window, mark those opponents as Punishers.
   - If a substantial fraction of opponents (a quorum, e.g., >= 40% of others) behave as Punishers (collective retaliation lowers G_recent by > delta):
     - Retreat: cease large-scale exploitation. For the next F rounds cooperate (C) to re-establish cooperative baseline with punishers, then resume opportunistic exploitation only if G_recent recovers.
   - If retaliation is limited to a few players (small minority punishers) and others remain cooperative, continue to exploit but watch for escalation; target exploitation away from punishers by cooperating slightly more until punishers’ behavior softens.

5. Individual-targeted exploitation (if tracking per-opponent responses)
   - If the tournament’s opponent choices cannot be conditioned per-opponent (actions affect all players simultaneously), targeted actions are not possible; follow group-level rules above.
   - If you can infer that some players are unconditional cooperators and some punishers, prefer always defecting since unconditionals continue paying for the public good; be conservative when punishers’ share of population is large.

6. Maintenance/probing during long runs
   - Periodically (once every ceil(r/10) rounds, excluding the last E rounds) insert one “cooperation” if I’ve been defecting heavily to avoid being classified permanently as a universal exploiter by adaptive opponents. This reduces the chance of persistent, large-scale punishment against me.

Why this is exploitative and robust
- Unconditional cooperators: I detect and then permanently free-ride (maximizes exploitation).
- Conditional cooperators: I seed cooperation early so many conditionals start cooperating, then exploit them probabilistically to get high short-term returns while minimizing the chance of permanent collapse.
- Punishers: I respond to collective punishment by temporary forgiveness (limited-length cooperation) to avoid long mutual-defection traps that hurt my payoff.
- Endgame: I always defect in the final E rounds so opponents cannot safely exploit my forgiveness near the end.
- Parameter choices (S, L, H_high, p_exploit, F, E) make the policy adaptive: short probes to reveal types, probabilistic exploitation to hide from detectors, and limited forgiveness to keep relations from collapsing permanently.

Concrete pseudocode-like decision summary (per round t)
- If t in last E rounds or r <= 3: play D.
- Else if t <= S: play C (seeding).
- Else if t == S+1: play D (probe) and classify opponents.
- Else:
  - Update R_i_recent, G_recent, Uncond_i, Punisher set.
  - If any Uncond_i: play D (exploit them).
  - Else if G_recent >= H_high: play D with probability p_exploit, else C.
  - Else if G_recent >= H_low: if under collective punishment -> play C for next F rounds; else play C (cooperative baseline) with occasional D probes.
  - Else (G_recent < H_low): play D.
  - If collective punishment detected: play C for F rounds, then re-evaluate.

Notes and practical tips
- Tune thresholds conservatively for robustness: false-positive detection of “unconditional cooperator” or “punisher” can be costly; I err toward short probes and short forgiveness windows.
- Keep records short (recent-window L) so the strategy adapts to changing opponent behavior patterns.
- This strategy requires no communication, uses only observed histories and payoffs, and is expressly exploitative: it builds cooperation where useful to extract value and defects whenever that yields higher personal payoff while applying measured punishments and forgiveness to manage retaliation risk.
'''

description_EXPLOITATIVE_36 = '''
Name: Calculated Opportunist (CO)

Goal (exploitative mindset): maximize my total payoff by free‑riding on others’ contributions whenever it is safe and profitable, while avoiding long costly punishment cycles and keeping enough reputation to sustain exploitable cooperators. The strategy is entirely based on the observed history and the game parameters (n, r, k); it uses short empirical windows, simple thresholds, occasional probes, and an endgame rule.

Common notation used below
- t = current round (1..r)
- For any player j ≠ me, c_j(s) ∈ {0,1} is j’s contribution in round s.
- My action in round s is c_me(s).
- Window size w = min(10, max(3, floor(r/5))) — use the last w rounds (or fewer if t−1 < w) to compute recent statistics.
- “Group cooperation rate” G = average over opponents j and over rounds s in the window of c_j(s). (This is the fraction of possible opponent contributions observed recently.)
- For each opponent j compute:
  - p_j|C = fraction of rounds in the window where j contributed in rounds where I contributed.
  - p_j|D = fraction of rounds in the window where j contributed in rounds where I defected.
  - p_j = overall contribution rate of j in the window.
- Parameters (fixed, interpretable):
  - alpha_uncond = 0.90 (used to classify almost‑always cooperators).
  - delta_resp = 0.25 (responsiveness threshold: how much j’s cooperation rises when I cooperate).
  - drop_threshold = 0.30 (used to detect sharp drop in group cooperation after my defection → likely punishers).
  - recovery_len = min(5, max(1, floor(r/10))) (number of rounds for “reputation recovery” after I detect punishment).
  - probe_rate = 0.05 (small chance to probe by defecting when otherwise cooperating; deterministic proxies are explained below).
  - endgame_horizon = min(2, r) (always defect in the last endgame_horizon rounds).

High‑level phases
1. Opening / Reputation‑build: first S rounds I cooperate to build a base of reputation and collect statistics.
   - S = min(3, r) (if r small) or S = min(5, max(1, floor(r/10))) for longer games — practically: cooperate for the first 1–5 rounds depending on r.

2. Steady exploitation phase (after opening and until the endgame): mostly defect to free‑ride on cooperators; occasionally cooperate just enough to maintain conditional cooperators and to avoid provoking punishers.

3. Recovery / Avoid retaliation: if I detect punishers (others reduce their cooperation after I defect), I cooperate for a short recovery period to restore beneficial cooperation rather than engage in costly tit‑for‑tat wars.

4. Endgame: defect in the final rounds (no incentive to maintain reputation when no future rounds matter).

Detailed decision rules (deterministic pseudocode style)

Round t:
1. Endgame check
   - If t > r − endgame_horizon: action = Defect (D). (Final rounds: always defect.)

2. Opening rounds
   - If t ≤ S: action = Cooperate (C). (Build initial reputation and gather data.)

3. Compute recent statistics using the last up to w rounds:
   - Compute G (group cooperation rate) and p_j, p_j|C, p_j|D for each opponent j.

4. Classify opponents (based on window statistics)
   - Unconditional cooperator: p_j ≥ alpha_uncond. These players contribute almost regardless of my behavior — they are prime targets for exploitation.
   - Conditional cooperator (responsive exploitable): p_j|C − p_j|D ≥ delta_resp and p_j|C ≥ 0.60. They contribute notably more when I cooperate; I can influence them.
   - Potential punisher/retaliator: if I observe a sharp decline in group cooperation immediately following my defections:
       - Compute avg_G_after_my_D = average group cooperation in rounds that followed my defections in the window (if none, treat as not detected).
       - If (G − avg_G_after_my_D) ≥ drop_threshold, label “punishment_detected = true”.
     (This is a lightweight test: if group cooperation drops by ≥30% after I defect, many players are responding negatively to my defects.)

5. If punishment_detected is true:
   - Recovery mode: cooperate for recovery_len rounds (action = C) to regain cooperative responses from conditional cooperators and avoid extended mutual defection. While in recovery mode, reset punishment_detected only after the recovery_len rounds complete. (Rationale: I prefer to pay small costs to restore a stream of future returns from cooperators rather than fight a long costly war.)

6. Otherwise (no punishment detected), exploitation decision:
   - If there exist one or more unconditional cooperators (p_j ≥ alpha_uncond):
       - Exploit them: action = D (defect). They will continue contributing; taking the free ride maximizes my payoff.
   - Else compute G (group cooperation rate) as above:
       - If G ≥ 0.60: group is fairly cooperative on average → defect (D) to free‑ride now.
       - If 0.30 ≤ G < 0.60: mixed group → play opportunistically:
           - If I have many conditional cooperators (at least one and they collectively account for a noticeable fraction of past contributions), cooperate rarely, scheduled to maintain their cooperation: cooperate once every L rounds, where L = ceil(1 / mean_over_conditional_j(p_j|C − p_j|D)). Practically this means cooperate occasionally at a frequency proportional to how responsive they are. If L ≤ 1 (i.e., they are very responsive), play C; otherwise play D on rounds that are not scheduled cooperation rounds.
           - If I have no conditional cooperators and no unconditionals, defect (D).
       - If G < 0.30: group largely defecting → cooperate (C) rarely only if I suspect cooperation can be rebuilt (I will cooperate for at most 1–2 rounds every recovery_len rounds to test); otherwise defect (D). The idea: don’t spend many tokens into a sinking cooperative environment.

7. Probing (to keep the strategy adaptive and discover exploitable behavior)
   - If the decision above prescribes C, follow it; if it prescribes D, with small probability probe_rate replace D with C to test whether opponents will increase contributions. In deterministic tournaments where randomness is not desirable, replace probabilistic probing with deterministic probing: cooperate once every max(20, floor(r/10)) rounds if currently defecting.

Edge / practical handling notes
- When window data are sparse (early rounds), fall back on conservative defaults: cooperate for the first S rounds, then defect but probe at a higher probe_rate until enough data are collected.
- If multiple conditions conflict (e.g., presence of unconditional cooperators but also punishment_detected triggered by a different subpopulation), punishment detection takes precedence: prioritize short recovery and cooperation to avoid losing the stream of contributions from people who react to your defections.
- All thresholds are meant to be robust default values; they are functions of r only via window size and recovery_len. They do not assume anything about opponent norms; they react only to observed behavior.

Why this is exploitative and robust
- Exploitative: CO never hesitates to defect when the group is cooperative or when there are clear unconditional cooperators: those situations yield immediate positive gains from free‑riding. CO explicitly searches for and exploits unconditional or strongly conditional cooperators.
- Reputation management: CO does not simply always defect; it invests a small amount of cooperation early and occasionally later to sustain conditional cooperators’ tendency to contribute. Compared with always‑defect, that small investment can unlock repeated payoffs from others who condition on me.
- Safety from punishers: CO monitors immediate drops in group cooperation following my defections. If punishment is detected, CO prefers short cooperative recovery rather than escalating costly punishment wars. That preserves long‑run payoffs versus fighting.
- Adaptivity: CO uses short empirical windows to adapt to a wide range of opponent behaviors (unconditional cooperators, conditional reciprocators, punishers, neutrals). Probes let it discover hidden exploitable players. The endgame rule prevents wasting tokens in the final rounds.

Summary checklist (compact)
- Round 1..S: cooperate to gather data.
- Final endgame_horizon rounds: always defect.
- Use last w rounds to estimate p_j|C, p_j|D, p_j and group G.
- If group cooperation drops sharply after my defections → cooperate for recovery_len rounds (avoid wars).
- Else if there are unconditional cooperators or G is high (≥0.60) → defect to free‑ride.
- If mixed group → schedule occasional cooperation at a frequency determined by how responsive conditional cooperators are; otherwise defect.
- If group is mostly defecting → defect mostly; occasionally probe to see if cooperation can be rebuilt.
- Add small probing probability (or deterministic periodic probe) while defecting so exploitable players reveal themselves.

This strategy is fully specified in terms of observable history and the game parameters (n, r, k through window sizing and endgame choices). It aims to maximize exploitation of cooperators while minimizing losses from punishers, and it remains adaptive across many opponent types.
'''

description_EXPLOITATIVE_37 = '''
Name: Exploitative Adaptive Conditional Cooperator (EACC)

Summary goal: maximize my total payoff by (1) identifying unconditional or high-probability cooperators and free-riding on them when safe, (2) preserving enough cooperation in the group when that yields higher long-run return for me, and (3) defecting aggressively near the end to harvest remaining cooperative contributions. The strategy uses only game parameters (n, k, r) and observed history of actions/payoffs.

Parameters I use (fixed, derived from r and n):
- probe_rounds = min(3, max(1, floor(r/10))) — short initial cooperation to probe others.
- final_exploit = min(3, max(1, floor(r/20))) — last-final rounds in which I always defect.
- alpha = 0.4 — EWMA weight for updating each opponent’s cooperation probability.
- p_high = 0.8 — label players as “high cooperators” if estimated coop prob ≥ p_high.
- p_low = 0.2 — label players as “likely defectors” if estimated prob ≤ p_low.
- restore_rounds = 3 — number of rounds I will cooperate to try to restore cooperation if I detect punishment.
- drop_detect = 0.25 — relative drop in observed group cooperation that I treat as punishment.
- exploit_threshold_frac = 0.25 — fraction of players classified as high cooperators that triggers active exploitation.
- safety_margin = 0.0 — small margin used for my marginal incentive condition (can be set slightly positive for extra caution).

Internal state maintained from history:
- For each other player j, p_j = estimated probability they contribute this round (initialized 0.5 before any data).
- rolling group cooperation avg p_avg = mean_j p_j.
- a short memory of recent group contribution levels to detect drops.

Decision rules (round-by-round):

1) First rounds (probing)
- Rounds 1 .. probe_rounds: cooperate (play C). Purpose: provoke cooperation from reciprocators and gather data.

2) Last rounds (final exploitation)
- If current round t > r - final_exploit: defect (D) always to extract value from any remaining cooperators.

3) Update estimates
- After each round, for every opponent j update p_j by EWMA:
  p_j <- (1 - alpha) * p_j + alpha * c_j (where c_j is 1 if j contributed this last round, else 0).
- Update p_avg = mean_j p_j and record recent average group cooperation history to detect sudden drops.

4) Compute my myopic break-even threshold
- For a given expected number of other contributors E_S = sum_{j != me} p_j,
  my one-round net gain from contributing (vs defecting) is: delta = -1 + (k/n) * (E_S + 1).
- Rearranged: contributing is myopically profitable if E_S >= (n/k) - 1 + safety_margin.
- Use this as a baseline for whether a single cooperative act is immediately beneficial.

5) Exploit vs stabilize decision logic (applied when not in probe or final-exploit rounds)
A) Active exploitation condition (free-ride aggressively)
- Compute fraction_high = (# of j with p_j ≥ p_high) / (n-1).
- If fraction_high ≥ exploit_threshold_frac and p_avg ≥ 0.5:
  - I defect (D). Rationale: enough reliable cooperators exist that I can safely free-ride and increase my payoff.
  - After such a defect, monitor group cooperation next round. If group cooperation drops by more than drop_detect (relative to the immediate prior average), treat that as punishment and enter restore mode (see E).

B) Myopic-profit condition (short-term rational)
- Else, compute E_S. If E_S ≥ (n/k) - 1 + safety_margin (i.e., my immediate expected net gain from cooperating is positive):
  - Cooperate (C). This means the expected level of others’ cooperation makes contributing profitable this round.
- Otherwise:
  - Defect (D). If cooperating is myopically negative and I don’t have a strong population of high cooperators to exploit, I conserve my token.

C) Encouraging cooperation when group is fragile
- If p_avg is in a moderate band (0.35 ≤ p_avg < 0.5) and no strong exploitable minority exists, I will cooperate occasionally (C) to try to sustain group cooperation: specifically, cooperate with probability p_avg (a weighted probabilistic move), but if doing so I always respect the myopic-profit check (I will not cooperate with high cost when E_S is far below the threshold unless in explicit restore mode).

D) Probabilistic unpredictability
- To avoid being exploited by adversaries that learn a deterministic pattern of exploitation, when I choose D under exploit conditions I may randomize a small fraction of the time (e.g., cooperate with probability 0.05) to appear noisy. Conversely, when I choose C under restore behavior I stick to cooperation deterministically for restore_rounds.

E) Restore / Forgiveness mode
- If I detect that my recent defection(s) caused a large drop in group cooperation (group average contribution fell by more than drop_detect compared to the immediate prior window) or if many opponents’ p_j values decline quickly, I switch to a restore phase:
  - For the next restore_rounds rounds I cooperate (C) unconditionally attempting to rebuild trust.
  - After restore_rounds I resume normal decision logic but with updated p_j estimates.

6) Edge-case handling and safety
- If I have no data on opponents (e.g., at t = probe_rounds + 1 for very small r), use p_j = 0.5 priors and follow myopic-profit rule using E_S = (n-1)*0.5.
- If k is very close to n such that (n/k) -1 ≤ 0, my one-shot incentive to cooperate is positive even if others do nothing; in that case I favor cooperating early to harvest group benefit unless exploit_condition says many others are already high cooperators (then I may still defect to free-ride).
- If n is very small (2 players), the logic reduces to a standard two-player conditional cooperation: probe, then defect if partner is low, cooperate only when partner’s p ≥ (n/k)-1 threshold (which becomes straightforward).
- I always defect in the final_exploit window regardless of history.

Rationale and exploitative alignment:
- The strategy is exploitative: it actively looks for and free-rides on reliably cooperative opponents (fraction_high ≥ exploit_threshold_frac), defects when cooperation is unlikely to be rewarded, and defects decisively near the end to harvest naive cooperators.
- It is adaptive: it estimates individual probabilities p_j, updates beliefs after each round, and responds to punishment by restoring cooperation to recover profitable cooperation when that serves my long-term reward.
- It is robust: it combines myopic single-round best-response (the break-even E_S condition) with strategic exploitation and a restore/forgiveness mechanism to prevent permanent loss of cooperative partners.
- It avoids simplistic unconditional strategies that die out in tournaments (always C or always D), and it resists exploitation by persistent defectors by maintaining low cooperation toward them (via p_j tracking) and avoiding costly cooperation when group-level expectations are too low.

Behavioral summary (short):
- Probe briefly with cooperation.
- Estimate each player’s cooperation probability with EWMA.
- If a sizable subset are high cooperators, defect to exploit them; otherwise cooperate only when expected others’ contributions make my contribution profitable.
- If my defection provokes a sharp group drop, temporarily cooperate for a few rounds to rebuild cooperation.
- Always defect in the last few rounds to harvest remaining cooperators.
'''

description_EXPLOITATIVE_38 = '''
Goal (exploitative mindset)
- Secure as high a personal payoff as possible by (a) inducing and sustaining cooperation from players who respond to my cooperation and (b) free‑riding (defecting) whenever a sufficient mass of others is likely to contribute. Avoid being repeatedly exploited by quickly switching to defection against persistent defectors.

Overview of mechanics (what I track)
- n, r, k are known.
- For each opponent i I track:
  - Count C_i = number of rounds i contributed.
  - Count CO_given_myC_i = number of rounds i contributed when I contributed in the immediately preceding round.
  - Count CO_given_myD_i = number of rounds i contributed when I defected in the immediately preceding round.
  - All counts use Laplace +1 smoothing when computing probabilities to be robust early.
- Global summary each round:
  - Others_last = number of other players who contributed last round.
  - My_round = round index t (1..r).

Parameter choices (derived from r and n; fixed formulas so strategy depends only on parameters)
- Build (reputation) phase length T_build = max(1, min(5, floor(0.10 * r))). (Invest a small fraction up to 5 rounds to build a cooperative reputation.)
- Endgame window T_end = min(2, max(1, floor(0.05 * r))). (Begin defections in the known final rounds.)
- Cooperators_threshold_frac = 0.60 (I treat “enough others cooperating” as ≥ 60% of other players).
- Probe_probability p_probe = min(0.2, 0.05 + 0.5/(r + 1)). (Small occasional probes that shrink with longer games.)
- Forgiveness window L_recency = 3 (use recent behavior as stronger signal).

Definitions computed after build phase
- P_i = (C_i + 1) / (t_seen_i + 2) — smoothed empirical cooperation rate of player i (t_seen_i is rounds seen).
- P_i_given_myC = (CO_given_myC_i + 1) / (myC_occurrences_for_i + 2).
- P_i_given_myD = (CO_given_myD_i + 1) / (myD_occurrences_for_i + 2).
- Responsiveness score R_i = P_i_given_myC − P_i_given_myD (positive means i is more likely to cooperate when I previously cooperated).
- Supporter score S_i = weighted sum: 0.6 * P_i + 0.4 * max(0, R_i). (Ranks players who are both generally cooperative and responsive to me.)

Supporter set
- Supporters = players with S_i ≥ 0.5 OR the top m supporters where m = max(1, floor( (n-1) * 0.25 )). (I maintain a small coalition of likely cooperators; the exact size adapts to population.)

Core decision rules (step-by-step)
For each round t:
1. If t == 1: cooperate. (Open by building a reputation.)
2. If t > r − T_end (i.e., in last T_end rounds): defect. (Endgame: defect to avoid being exploited in one-shot final moves.)
3. If t ≤ T_build: cooperate every round. (Reputation build to elicit conditional cooperation and collect statistics.)
4. After build phase (t > T_build) do:
   a. Update all counts and compute P_i, P_i_given_myC, P_i_given_myD, R_i, S_i, Supporters.
   b. If recent rounds show broad defection (Others_last ≤ ceil((n-1) * 0.15) for the last L_recency rounds): switch to persistent defection for the rest of the game. Rationale: no one is cooperating; stop wasting contributions.
   c. Exploitative free‑riding rule:
      - If Others_last ≥ ceil((n-1) * Cooperators_threshold_frac): defect this round. Rationale: others are contributing en masse — free‑ride.
   d. Supporter maintenance / selective cooperation:
      - Compute fraction_supporters_last = number of supporters who contributed last round / |Supporters|.
      - If fraction_supporters_last ≥ 0.5 and at least one supporter has shown responsiveness R_i > 0.05: defect to free‑ride on their likely cooperation, but with a periodic maintenance cooperation:
         • Every K rounds (K = max(3, ceil(0.10 * r))), cooperate to “top up” the reputation with supporters so they don’t switch away. This is a low-frequency maintenance signal: it keeps responsive cooperators thinking cooperation is reciprocated while minimizing my contributions.
      - Else (supporter cohort is shaky or many supporters defected last round): cooperate for up to M_repair consecutive rounds (M_repair = 2) to try to restore cooperation only if a majority of players had positive overall cooperation rate (mean P_i across players > 0.3). If repair fails (supporter cooperation does not recover within M_repair), switch to defection.
   e. Retaliation protection against being milked:
      - If any single player i has P_i_given_myC − P_i_given_myD ≤ −0.2 (they are more likely to defect especially when I cooperated), mark i as exploitative and stop cooperating for them (i.e., do not perform maintenance contributions timed for them). If the majority of players are exploitative, switch to persistent defection.
   f. Random probing to detect changes:
      - If none of the above decisively applies, cooperate with probability p_probe (small probe). Use probes to detect whether others will resume cooperation; otherwise defect.

Special cases / tie-breakers
- If Supporters is empty but average cooperation P_avg across players > 0.4: try cooperating for one or two rounds to seed a coalition, then revert to the exploitative rules above.
- If n is very small (n ≤ 3): be more conservative on probes (reduce p_probe) and shorten T_build because each contribution affects payoffs more directly.
- If the game is extremely short (r ≤ 3): behave like a short build: cooperate only round 1, then defect rounds 2..r (avoid being exploited).

Why this is exploitative and robust
- Exploitative: the strategy free‑rides whenever there is evidence that many others will contribute (free payoff with zero cost that round), and otherwise only contributes sparingly to keep a small set of conditional cooperators (supporters) cooperating. Maintenance contributions are minimized and scheduled infrequently so overall my contribution share is low while sustaining returns from others.
- Adaptive: it learns per‑player responsiveness and overall cooperation trends, switches quickly to mutual defection if others are defecting, and uses occasional probes/repairs to recover cooperation when profitable.
- Defensive: it identifies and stops rewarding players who defect in response to my cooperation, and it stops contributing if cooperation collapses, so it avoids being repeatedly exploited.
- Parameter choices are explicitly derived from n and r (T_build, T_end, supporter size fraction, probe frequency), so the strategy uses only allowed inputs.

Summary (concise pseudocode form)
- Initialize counters.
- Round 1: C.
- Rounds 2..T_build: C (build reputation).
- For each round t > T_build:
  - If t in final T_end rounds: D.
  - If sustained low cooperation recently: permanent D.
  - If others_last ≥ 60% of others: D (free‑ride).
  - Else compute Supporters and their recent cooperation:
    - If supporters are reliably cooperating: D most rounds; every K rounds give a maintenance C.
    - If supporters are faltering and overall cooperation > 0.3: attempt up to M_repair rounds of C to restore cooperation; if fails, D thereafter.
  - If specific players show exploitative behavior vs my cooperation: stop rewarding them.
  - Otherwise probe with small probability p_probe (C), else D.

This yields a program of selective, minimal contributions targeted to sustain exploitably cooperative partners while defaulting to defection whenever others are likely to carry the public good.
'''

description_EXPLOITATIVE_39 = '''
Name: Adaptive Exploitative Conditional Cooperator (AECC)

Overview (one-line): Start by probing to identify cooperators, sustain cooperation only when a clear cooperative majority exists, otherwise free-ride; opportunistically exploit persistent unconditional cooperators while using short, targeted punishment and fast forgiveness to avoid long mutual collapse. Always defect in the final few rounds.

Parameters (computed from game parameters n, k, r)
- Window W for recent-history estimates: W = min(5, max(1, floor(r/10))).
- Initial probing rounds Init = min(3, r-1) (if r=1 then no probe).
- Endgame horizon H = min(3, r-1). In the last H rounds always defect.
- Group-cooperation threshold alpha = clamp(k/n + 0.15, 0.25, 0.75) (i.e., k/n + 0.15 but not below 0.25 or above 0.75).
- “High-cooperator” threshold theta_high = 0.92 (used to identify near-unconditional cooperators).
- Exploit probability p_exploit = 0.5 (probability of defecting to exploit a detected high cooperator).
- Punishment length P = min(3, r - current_round - 1) when triggered (but never extends into the final H rounds).
- Forgiveness rule: after punishment, return to a short probe (1 round of cooperation) to test recovery.

Data kept from history
- For every other player j, maintain cooperation-rate p_j computed over the last W rounds (or since they first appeared if shorter).
- Group cooperation rate GC = average of p_j over all j != i.
- Count of cooperators in the previous round C_prev (number of players who contributed last round).

Decision procedure (per round t)
1. Endgame check
   - If t > r - H (i.e., we are in the last H rounds) then play D (defect). Rationale: final rounds have little or no future value; avoid being exploited.

2. Single-round edge cases
   - If r = 1 (only one round): play D.
   - If t = 1 and Init ≥ 1: play C (first probing move) except when r = 1. (If r = 2 you still probe once on round 1.)

3. Probing phase (first Init rounds)
   - In rounds 1..Init (unless in endgame): play C to reveal opponents’ tendencies and establish goodwill. Record others’ replies.

4. Normal adaptive phase (t > Init and not in punish state)
   - Compute p_j for each other player j over the last W rounds and GC (average p_j).
   - Detect persistent cooperators: set S_high = {j : p_j ≥ theta_high}.
   - If GC ≥ alpha:
       - If S_high is non-empty:
           - Exploit opportunistically: with probability p_exploit, play D (free-ride on the persistent cooperators); otherwise play C.
             - If you choose D this round while most others (C_prev majority) cooperated and no immediate retaliation observed, keep exploiting with similar probability but watch for punishment signals (see punishment rules).
       - Else (no clear unconditional cooperators): play C. Rationale: when the group shows robust cooperation, contribute to sustain it and capture the higher collective payoffs while still allowing occasional exploitation of truly unconditional cooperators.
   - Else (GC < alpha):
       - Play D (defect). Rationale: cooperation is not safely sustained; avoid being systematically exploited.

5. Punishment and safety rules (to protect against being exploited by conditional exploiters or “sucker” sequences)
   - If you cooperated in the previous round and C_prev (number of others who cooperated last round) dropped sharply compared to its recent average (e.g., C_prev ≤ 0.5 * (GC*(n-1)) rounded down), treat this as an unreciprocated cooperation and enter punishment:
       - Enter a punishment state: play D for P rounds (P computed as above but never to exceed remaining non-endgame rounds).
       - After P rounds, play one probe round of C to test whether cooperation has returned. If cooperation returns, resume normal adaptive phase; if not, stay in defect mode until GC improves above alpha.
   - If you defect and detect immediate strong retaliation (group cooperation drops and specific players reduce p_j sharply), reduce p_exploit by half for the next T_retreat = 3 rounds to avoid endless mutual punishment, then resume adaptive behavior.

6. Recovery and exploitation control
   - If exploitation by this strategy causes some players’ p_j to fall below theta_high (i.e., you converted some unconditional cooperators into conditional ones), then reduce exploitation frequency: halve p_exploit until GC recovers above alpha for two consecutive windows.
   - Always prefer short, targeted punishments rather than permanent grudges to keep future exploitation opportunities open.

Rationale summary (how this is exploitative, adaptive, robust)
- Exploitative: AECC actively defects when group-level cooperation is weak (avoids losing by being the only cooperator) and opportunistically defects with significant probability when it detects near-unconditional cooperators (S_high) to extract value from them.
- Adaptive: It uses short-window empirical estimates (p_j, GC) to detect both cooperative clusters and pure defectors, adjusts exploitation frequency when opponents retaliate, and uses forgiveness to re-establish profitable cooperation.
- Robust: Probing in early rounds gathers information; the group-threshold alpha depends on k/n so the strategy cooperates more readily when MPCR is higher; punishment is short and targeted to avoid long collapses; endgame defections avoid being exploited in the terminal rounds.
- Defensive: The punishment-and-forgiveness cycle prevents persistent exploitation by others and avoids falling into endless mutual defection that destroys future profit opportunities.

Practical notes (implementation hints)
- Use simple counts over the last W rounds for p_j and GC; update these each round.
- Use a fair random generator for probabilistic exploitation to avoid predictability; if randomness is not allowed in a tournament, replace probabilistic exploitation with deterministic periodic exploitation (e.g., defect every 2nd time a high-cooperator is present).
- Tune theta_high and p_exploit conservatively if you detect aggressive punishers in the population (use observed retaliation frequency to reduce p_exploit).

Behavioral examples (short)
- In a group of many cooperators (GC high) AECC mostly cooperates but occasionally defects against those who never punish, pocketing extra tokens.
- In a group of defectors AECC defects immediately (after probing) to avoid being the only contributor.
- If someone punishes AECC for exploiting, AECC responds with a short punishment then forgives and reduces exploitation frequency, which limits long retaliation cycles.

End.
'''

description_EXPLOITATIVE_40 = '''
Name: Adaptive Probe-and-Exploit

Summary goal (exploitative mindset)
- Extract contributions from conditional cooperators while avoiding long term retaliation; free-ride whenever the group is sufficiently cooperative, but keep cooperation signals at a low rate to sustain that behavior. Defend against persistent defectors by punishing them (collectively) and give timely forgiveness only when restoring cooperation is likely to pay off. Always defect in the known final rounds.

Parameters (computed from known game parameters and history)
- n, k, r: game parameters (players, multiplier, rounds).
- benefit ratio b = k / n (0 < b < 1). Use b to scale aggressiveness: smaller b → more profitable to free-ride, so be more exploitative.
- Window W = min(10, r) — recent rounds to estimate behavior.
- Endgame window T_end = min(3, max(1, floor(r/10))) — final rounds to switch to guaranteed defection.
- Responsiveness threshold θ_resp = 0.20 (an opponent is “responsive” if they contribute ≥ θ_resp more often after I cooperated than after I defected).
- Signal spacing S = max(3, ceil(5*(1 - b))) — how often to voluntarily send a cooperation signal while exploiting.
- Exploit defect probability p_exploit = clamp(0.6 + 0.4*(1 - b), 0.6, 0.95) — probability of defecting when exploiting.
- Moderate-defect probability p_mod = 0.7 — use when opportunistic exploitation but opponents less clearly responsive.
- Forgiveness span F = 2 rounds after a repair attempt.

Definitions from history
- For each opponent j, compute:
  - CoopRateAfterMyC_j = fraction of rounds (in the last W rounds where applicable) in which j contributed in the round immediately following a round when I cooperated.
  - CoopRateAfterMyD_j = same but following rounds when I defected.
  - Responsive_j = CoopRateAfterMyC_j − CoopRateAfterMyD_j.
- ResponsiveFraction = fraction of opponents with Responsive_j ≥ θ_resp.
- RecentGroupCoop = average fraction of opponents contributing in the last W rounds.
- LastRoundMajorityCoop = whether majority of opponents contributed in the previous round.
- RecentDrop = whether RecentGroupCoop has fallen by more than 0.30 relative to the W rounds before the most recent change (used to detect retaliation or collapse).

Decision rules (ordered, apply first matching rule)
1. Final-round / endgame rule
   - If current round t ≥ r − T_end + 1 (i.e., the final T_end rounds) or t = r: play D (defect) always. Rationale: backward induction and endgame exploitation.

2. Early-round startup
   - Rounds 1 and 2: play C (cooperate). Rationale: cheaply probe for conditional cooperators and establish a cooperative signal.

3. Responsive-exploit mode (primary exploitative mode)
   - If ResponsiveFraction ≥ 0.5 and RecentGroupCoop ≥ 0.50:
     - Treat many opponents as conditional cooperators who respond to my cooperation.
     - Exploit: defect with probability p_exploit; otherwise cooperate.
     - Signal rule: ensure I cooperate at least once every S rounds (i.e., if I have not cooperated in the last S − 1 rounds, play C now) to keep responsive players “on the hook.”
     - If RecentDrop is detected immediately after I defected, play C for the next F rounds (forgiveness/repair) then resume exploit mode. Rationale: mostly free-ride on responders, but keep minimal cooperation to maintain their responsiveness and repair when exploitation collapses.

4. Opportunistic exploitation against generally cooperative groups
   - Else if RecentGroupCoop ≥ 0.75 (many others reliably contribute) but ResponsiveFraction < 0.5:
     - These opponents contribute often but aren’t clearly triggered by my actions (they may be unconditional cooperators).
     - Defect with probability p_mod (≈0.7); cooperate otherwise.
     - Signal spacing: still send a cooperation signal every S rounds to reduce risk of broad punishment.

5. Defensive reciprocity when cooperation is fragile
   - Else if RecentGroupCoop < 0.50:
     - Cooperation is fragile or rare. Do not try to exploit a collapsed environment.
     - Play conditional reciprocity (defensive):
       - If LastRoundMajorityCoop is true, play C (reward recent group cooperation).
       - Else play D (punish/defend).
     - If the group shows steady improvement (RecentGroupCoop rising) switch back to Responsive-exploit assessment.

6. Unresponsive high-cooperation corner case
   - If opponents are almost always cooperating (RecentGroupCoop ≥ 0.90) but responsiveness is negligible:
     - Treat them as free targets: defect with very high probability (≈0.9), but still occasionally cooperate (probability 0.05) as a periodic signal to avoid provoking coordinated group retaliation from accidental triggers.

7. Safety/failsafe
   - If the strategy’s own cooperation rate in recent W rounds exceeds 0.6 and the group suddenly punishes me (RecentDrop) reduce exploitation aggressiveness: for next F rounds adopt defensive reciprocity (rule 5) before re-assessing. Rationale: avoid long mutual collapse from aggressive exploitation.

Additional operational notes (how to behave round-by-round)
- Randomization: use independent random draw each round where probabilities are specified. This prevents pure-deterministic cycles that opponents could exploit.
- Minimal bookkeeping: only need per-opponent two conditional counts (responses after my C vs after my D), global recent averages over window W, and a counter since last voluntary cooperation for S enforcement.
- Parameter dependence on b: as b → 1 (public return per token high), p_exploit decreases (we tolerate more cooperation ourselves); as b → 0 (low return) p_exploit increases (be more exploitative).
- Robustness: the probe phase identifies conditional cooperators; the signaling mechanism maintains them at low cost; the defensive reciprocity prevents sustained loss to unconditional defectors.
- Exploitative orientation: when the group contains conditional or unconditional cooperators, favor defecting most rounds to free-ride while sending intermittent cooperation signals only as needed to sustain their behavior. When cooperation collapses, refuse to bankroll others — switch to defensive reciprocity until cooperation proves recoverable.

Edge cases handled
- Very short games (r ≤ 3): cooperate first round to probe, then defect all remaining rounds (except if r=2 where play C then D). This recognizes extreme endgame effects.
- If opponents are extremely noisy and estimates unreliable (insufficient samples in window W), default to cautious behavior: continue cooperating for a few more probes (up to W rounds), then move to the exploit assessment.
- If multiple opponents show mixed behavior, ResponsiveFraction measures the majority; the strategy tolerates some free-riders and targets exploitation only when a clear exploitable subset exists.

Why this is exploitative and robust
- It actively identifies and exploits conditional cooperators (common in human-like strategies) by defecting often while sending minimal cooperation signals to sustain their contributions.
- It defends against persistent defectors by switching to conditional reciprocity and by stopping exploitation that provokes wholesale collapse.
- It adapts to game parameters via b, scales endgame behavior with r, and uses short-term statistics (window W) so it’s robust across a wide range of opponent types and match lengths.
'''

description_EXPLOITATIVE_41 = '''
Name: Greedy Conditional Cooperator with Occasional Forgiveness (GCC-OF)

Principle (exploitative aim)
- Extract the free-rider advantage whenever others are contributing, but maintain just enough cooperative signaling and occasional forgiveness so conditional and naive cooperators keep contributing rather than permanently switching to all-defect. Defect decisively against persistent non-cooperators and always defect in the final round.

Parameters derived from game inputs (used internally)
- n, k, r (given). Let personal marginal gain from defection = g = 1 - k/n (g > 0).
- Window w = min(4, r-1) — lookback window for recent behavior.
- High-cooperation threshold H = 0.6 (fraction of other-players' contribution rate over w indicating a cooperative environment).
- Low-cooperation threshold L = 0.1 (fraction indicating a hostile environment).
- Small cooperation “maintenance” probability p_coop = min(0.2, 0.1 + 0.5*(k/n)) — low but nonzero.
- Probe frequency P_probe = max(4, ceil(8/(k/n))) — how often to probe a hostile group.
- Punish duration P_punish = 2 rounds. Forgive requirement S_forgive = 2 consecutive rounds of good behavior.

Concrete decision rules (pseudocode-style description)

Initial signaling
- Round 1: Cooperate. (Purpose: attract conditional/naive cooperators and gain future exploitation opportunities.)

Every subsequent round t = 2..r:
1. If t == r (last round): Defect. (No future to leverage.)
2. If t >= r - 1 (final round window): Defect in the final 1–2 rounds (always defect in the last round; defect also in round r-1 if you want to be slightly more exploitative — by default defect in last round and defect in r-1 if you observed falling cooperation). This prioritizes extracting one-shot gains when future incentives vanish.
3. Compute recent behavior:
   - For rounds max(1,t-w) .. t-1, compute others’ contribution rate:
     others_rate = (sum across those rounds of contributions by other players) / (w*(n-1))
   - Also note last_round_others = number of other players who contributed in round t-1.

4. State classification and action:
   - Cooperative environment (others_rate >= H):
     - Primary action: Defect this round (free-ride). This captures the constant per-round gain g whenever others cooperate.
     - Maintain reputation: with small probability p_coop, cooperate instead of defecting (randomized). This occasional cooperation prevents hard retaliation from tolerant reciprocators and sustains a cooperating environment.
   - Intermediate environment (L < others_rate < H):
     - If last_round_others >= ceil((n-1)/2) (majority of others contributed last round): Defect this round to exploit that majority.
     - Otherwise (no clear majority): Cooperate this round to encourage contributors (and to learn whether cooperation is stabilizing).
   - Hostile environment (others_rate <= L):
     - Primary action: Defect (do not donate into a pool that rarely pays).
     - Probing: Every P_probe rounds (according to a round counter since entering or since last probe), send a single cooperating round as a probe to test whether cooperation can restart. If probe elicits a sustained rise above L for S_forgive rounds, switch to the appropriate cooperative/intermediate mode.
5. Punishment / targeted deterrence:
   - If you observe persistent defection behavior by many players (e.g., the number of players who defected in 2 consecutive recent rounds exceeds half the group), enter a short punishment phase: defect for P_punish rounds to avoid being exploited and to discourage conditional cooperators from tolerating defectors.
   - After punishment, forgive if you observe others cooperatively contributing at or above L for S_forgive consecutive rounds; resume exploitation pattern.
   - Do not escalate to permanent grim-trigger except when clearly justified (e.g., everyone else permanently defects) because permanent mutual defection gives low payoff.

Robustness notes (how this adapts across opponent types)
- Against unconditional cooperators: initial cooperation plus the small cooperation probability keeps them contributing; the strategy predominantly defects to collect the free-rider advantage.
- Against conditional cooperators (tit-for-tat variants): first-round cooperation attracts them; occasional cooperative moves and short punishments keep them from permanently abandoning cooperation while you extract surplus on most rounds.
- Against persistent defectors: strategy quickly switches to defect and probes occasionally; punishment phase avoids being repeatedly exploited and reduces wasted contributions.
- Against random or mixed strategies: sliding thresholds and probing detect changes and adapt to exploit transient cooperative episodes while avoiding repeated losses.
- Against fully rational backward-induction defectors: you will mostly defect in the tail and not lose extra tokens to naive cooperation.

Edge cases and clarifications
- First round: cooperate (signal).
- Final round: always defect.
- If r is very small (r <= 2), prioritize defect in final round(s); for r=1 cooperate only if you expect others to be naive; default still: cooperate round 1 as signal if r>1, otherwise defect if r=1 because no future.
- All randomization uses low probability draws so behavior is mostly deterministic exploitation with occasional cooperation for maintenance/probing.
- All decisions use only observed history of contributions and payoffs (no communication), and all parameters are computed from n, k, r.

Summary (one-sentence)
Start by signalling cooperation, then primarily free-ride whenever others are reliably contributing while using rare cooperative moves and short punishments to sustain exploitable cooperation and to avoid being stuck in mutual defection; always defect in the final round.
'''

description_EXPLOITATIVE_42 = '''
Name: Probe–Exploit–Reciprocate (PER) — an adaptive, exploitative repeated-PGG strategy

Core idea (exploitative mindset)
- I will only cooperate when doing so is expected to raise my long-run payoff via reciprocal behavior from others; otherwise I defect to extract private gain. I actively probe opponents to classify them (unconditional cooperators, conditional cooperators/punishers, defectors) and use that classification to decide whether to ride cooperators or sustain reciprocal cooperation. I punish when necessary to deter exploitation and I always defect at the end (no future to enforce cooperation).

Notation / bookkeeping (all based only on publicly observed history)
- For each opponent j track:
  - total_coop_j = number of rounds j contributed
  - afterMyC_coop_j = number of rounds j contributed immediately following a round in which I contributed
  - afterMyD_coop_j = number of rounds j contributed immediately following a round in which I defected
  - counts afterMyC_count_j and afterMyD_count_j are the counts of such opportunities
- Derive rates:
  - overall_rate_j = total_coop_j / (rounds_played so far)
  - p_afterC_j = afterMyC_coop_j / max(1, afterMyC_count_j)
  - p_afterD_j = afterMyD_coop_j / max(1, afterMyD_count_j)

Fixed internal parameters (deterministic, chosen from history and game parameters)
- T_probe = min(6, max(3, floor(r/5))) — short probing phase
- T_tail = min(3, r) — last rounds in which I always defect
- punish_length = 3 (rounded down if fewer rounds left)
- thresholds (interpretable, fixed): UC_rate = 0.80, UC_overall = 0.75, CC_delta = 0.25, PD_overall = 0.20

Phase structure and decision rules (round t = 1..r)
1) Trivial/small-game cases
   - If r <= 4: defect every round (endgame dominates; exploitation best).
2) Tail behaviour
   - If t > r - T_tail (i.e., in last T_tail rounds) or t == r: choose D (always defect in final rounds).
3) Probing phase (t <= T_probe)
   - Use a deterministic alternating probe to gather signals while trying to extract payoff:
     - If t is odd: play D (initially exploit cooperators)
     - If t is even: play C
   - Record opponents' responses to populate p_afterC_j and p_afterD_j.
4) Classification (after T_probe rounds, update each round)
   - For each j:
     - If p_afterD_j >= UC_rate and overall_rate_j >= UC_overall → classify j as Unconditional Cooperator (UC).
     - Else if (p_afterC_j - p_afterD_j) >= CC_delta and p_afterC_j >= 0.50 → classify j as Conditional Cooperator / Punisher (CC).
     - Else if overall_rate_j <= PD_overall → classify j as Pure Defector (PD).
     - Else → Unknown (mixed/uncertain).
   - Compute group fractions f_UC, f_CC, f_PD (fractions of players in those classes).
5) Main decision rule (post-probe, not in tail)
   - If currently in an active punishment phase against the group (see Punishment below): play D.
   - Else apply the following ordered checks (first applicable rule wins):
     A) If f_PD > 0.5: defect (majority defectors → cooperating is wasted).
     B) If f_UC >= 0.60 and f_CC < 0.25: defect (many unconditional cooperators and few punishers → exploitable group).
     C) If f_CC >= 0.40: cooperate (sizable punishing/reciprocal minority that sustains profitable mutual cooperation).
     D) Otherwise compute short-run expected immediate payoffs (myopic estimate) to break ties:
         - Estimate average cooperation of others if I cooperate: p_ifC = average_j max(p_afterC_j, overall_rate_j)
         - Estimate average cooperation of others if I defect:  p_ifD = average_j p_afterD_j
         - Compute expected immediate payoff if I cooperate:
             Payoff_ifC = (k/n) * (1 + (n-1)*p_ifC)   [since I pay 1]
           and if I defect:
             Payoff_ifD = 1 + (k/n) * ((n-1)*p_ifD)
         - If Payoff_ifC + continuation_bonus >= Payoff_ifD then cooperate; else defect.
           - continuation_bonus is implemented as a simple heuristic: if f_CC >= 0.25, add a positive bias (equivalent to valuing future cooperation); otherwise no bonus.
         - Practically: require Payoff_ifC to exceed Payoff_ifD by at least 0.05 (to prefer cooperation).
6) Punishment rule (to deter being exploited)
   - If in the immediately preceding round I cooperated and the number of opponents who defected that round increased by at least 2 compared with their typical rate after my cooperation (i.e., a clear group betrayal), enter a punishment phase:
     - Play D for punish_length rounds (or until the end of the game).
     - During punishment, update classification; if majority of opponents resume cooperation toward me (p_afterD rises), exit punishment early.
   - Punishments are temporary, not forever (forgiveness possible), unless widespread defection persists.

Additional behavioral details and rationale
- Starting with D in probing is intentionally exploitative: I try to extract payoff from naïve cooperators immediately, while collecting signals on who punishes and who doesn't.
- I will not be the group’s unconditional “sucker.” Unconditional cooperators are exploited once identified (by a choice to defect when punishers are rare), because defecting when many UCs exist gives a direct private advantage and triggers little retaliation.
- If a substantial fraction of the group are conditional cooperators (punishers), I prefer to cooperate so mutual cooperation can be sustained (this raises long-run payoff). I only cooperate when I think reciprocity will be sustained.
- I always defect in the final T_tail rounds because there is no future to enforce reciprocal behavior.
- Against highly mixed or uncertain groups, I rely on my myopic expectation plus a small forward-looking bias if there is evidence of conditional cooperation.
- The strategy is deterministic and transparent (so my behavior is consistent across tournaments) but adaptive via continual reclassification from observed history.

Edge cases summary
- Very short games (r ≤ 4): defect every round.
- First round: D (part of probing).
- Last round and final T_tail rounds: D (always defect).
- If you detect persistent majority punishment, shift to cooperation to obtain higher long-run payoffs; if punishers are rare or a majority defectors, defect and exploit.

Why this is exploitative and robust
- It actively probes to detect exploitable opponents (unconditional cooperators) and defects in situations where punishment is unlikely.
- It secures higher long-run payoffs by cooperating only when conditional cooperators are present in numbers sufficient to sustain reciprocity; otherwise it defects and avoids being exploited.
- Punishment and forgiveness mechanisms deter others from exploiting me while allowing reconciliation when reciprocal behavior returns.
- Deterministic rules that use only public history make the behavior interpretable and robust across a wide set of opponent algorithms.
'''

description_EXPLOITATIVE_43 = '''
Adaptive Exploiter — an adaptive, history-based exploitative strategy for repeated PGG

Summary intuition (one sentence)
- Test early to learn how others respond to my defections; exploit opponents who do not punish me by defecting whenever the short-term gain outweighs the expected future loss caused by reduced cooperation, but revert to cooperation (or partial cooperation) against retaliatory groups to avoid long costly punishments. Always defect in the final round(s).

Parameters I compute from the known game inputs
- n, k, r (players, multiplier, total rounds)
- immediate defect gain g = 1 − k/n (this is the per-round advantage of D vs C for the current round)
- remaining rounds at the start of round t: R_rem = r − t + 1 (including current round)

Data I track from history (updated after every round)
- For each opponent j:
  - count_Cj = number of times I played C and observed j’s action in the next round
  - coop_after_Cj = fraction of those next-round actions that were C
  - count_Dj = number of times I played D and observed j’s action in the next round
  - coop_after_Dj = fraction of those next-round actions that were C
  - delta_j = coop_after_Cj − coop_after_Dj (positive if j reduces cooperation after I defected)
- Group-level derived values:
  - observed_exposure_count = total rounds where I can measure next-round responses (sum over rounds with known next-round actions)
  - responsiveness estimate d = sum_j delta_j (this is the expected drop in the number of other cooperators next round attributable to my defection this round)
  - baseline_group_coop = fraction of opponents cooperating in the last W rounds (use W = min(5, r) or fewer if not available)

Initialization and probing phase
- Set a short probing window T_probe = min(6, max(2, floor(r/5))). (If r is small, probing is short; if r is large, probing is up to 6 rounds.)
- First T_probe rounds: purposeful probes to estimate responsiveness
  - Round pattern (deterministic): C, D, C, D, ... (begin with C to attract cooperators)
  - After each round record opponents’ next-round behavior to populate counts for coop_after_Cj and coop_after_Dj.
- If after probing a given opponent j has fewer than min_obs = 2 observations for either coop_after_Cj or coop_after_Dj, treat delta_j as uncertain and count it toward an “unknown” bucket (see decision rules below).

Per-round decision rule (for round t, after having updated metrics from round t−1)
1. Endgame override
   - If t = r (last round) then play D (defect).
   - If t ∈ {r−1} (the penultimate round) play D unless you have very strong evidence that almost all opponents are unconditional cooperators (baseline_group_coop > 0.95 and many opponents have zero responsiveness observed). The default is D in final two rounds.

2. If we are still in the probing window (t ≤ T_probe) follow the probe pattern (C/D alternating as above).

3. If not probing and not in the forced endgame:
   - Compute g = 1 − k/n (immediate per-round gain from defecting now).
   - Compute R_rem = r − t + 1 (rounds including the current one).
   - Compute observed responsiveness d (sum_j delta_j) using available delta_j values. For opponents with insufficient observations, assume conservatively that they are somewhat responsive: treat unknown delta_j = max(0.25, baseline_group_coop) * 0.5 (a small nonzero assumed responsiveness to avoid naïve exploitation when data is sparse). If you have good data (count_Dj + count_Cj ≥ min_obs for most players), use measured delta_j directly.
   - Compute a simple break-even threshold D_threshold = g * n / (k * R_rem).
     - Interpretation: if my defection causes the group cooperativeness to fall by more than D_threshold contributions per round on average, the future loss will typically outweigh the immediate gain.
   - Decision:
     - If d < D_threshold (i.e., estimated responsiveness is small enough that defecting now likely yields net expected benefit), play D.
     - Else (d ≥ D_threshold), play C.
   - Tiebreakers and noise:
     - If coop_after_C and coop_after_D are both very low (baseline_group_coop < 0.25), defects are safe: play D (cooperating is unlikely to be reciprocated).
     - If coop_after_C is very high (>0.9) but coop_after_D shows a moderate drop (delta_j positive but small), prefer a mixed/soft-exploit: play D with probability p_defect = min(0.8, 0.4 + 0.4*(1 − d / D_threshold)). This lets me exploit largely but occasionally cooperate to maintain goodwill and avoid triggering new punishment dynamics from slowly responsive players.

Response to clear punishment
- If after a D I observe a sharp group-wide retaliation (next-round total cooperators drops by > 50% or average delta_j > 0.5), switch to a conciliatory policy:
  - Play C for the next T_calm = min(3, R_rem − 1) rounds to restore cooperation, while collecting updated delta_j values. This avoids long mutual-defection spirals and reduces lost future payoff versus stubborn permanence of defection.
- If the retaliation is targeted and persistent from only some opponents, keep exploiting the non-punishers but play cooperatively enough (or probabilistically cooperate) to avoid broad breakdown.

Forgiveness and recovery
- Always allow recovery: if an opponent’s coop_after_Dj returns to its coop_after_Cj level over subsequent observations, stop treating them as punishers. Do not apply permanent grim-trigger punishments yourself; prefer temporary cooperation phases to restore mutual benefit when retaliation appears costly.

Handling noise and sparse data
- If total observations are very low (early game) use a conservative default: play C in early rounds to attract cooperators but follow the probing schedule.
- If patterns are noisy, smooth delta_j estimates using exponential smoothing (more recent observations weighted more heavily) — operationally, count recent transitions with heavier weight. In natural-language terms: trust recent responses more than old ones.

Edge cases and special heuristics
- If k is very close to n (k/n ≈ 1), g = 1 − k/n is near zero: defection advantage is tiny, so be more cooperative—require a much smaller d to justify defection (D_threshold becomes very small). Practically, that means cooperate unless opponents are clearly noncooperative.
- If k is small relative to n (k/n ≪ 1) then g is large: more incentive to defect, so the strategy will be more willing to defect unless opponents clearly punish.
- If the entire group has cooperated at high rates for many rounds and no one ever punished deviations, shift to heavy exploitation (play D) because the group is effectively exploitable.
- If many opponents appear to be conditional cooperators (high delta_j), defer to cooperation to maintain steady collective returns.

Concrete pseudocode-style summary
- Initialize metrics.
- Probe for T_probe rounds with pattern C, D, C, D...
- After each round update coop_after_Cj and coop_after_Dj and compute delta_j, baseline_group_coop.
- For each new round t:
  - If t = r: play D.
  - If t = r−1: play D unless group is almost perfectly unconditional-cooperative.
  - Compute g, R_rem, d (with conservative defaults for unknowns), D_threshold = g*n/(k*R_rem).
  - If baseline_group_coop < 0.25: play D.
  - Else if d < D_threshold: play D (heavy exploitation).
  - Else if d modestly above D_threshold: play mixed/soft-exploit (mostly D, occasional C) to preserve cooperation.
  - Else (d well above threshold): play C to avoid triggering costly punishment.
  - If I am met with sharp retaliation, play C for a small calm window to restore cooperation.

Exploitative alignment
- This strategy is exploitative because it explicitly seeks and exploits opponents who do not punish defections (defecting when expected future loss is small compared to immediate gain), while still protecting itself from conditional retaliators by switching to cooperation when opponents are responsive. It adapts to diverse opponent types (unconditional cooperators, unconditional defectors, conditional cooperators, retaliators) and uses explicit arithmetic (g and D_threshold) tied to game parameters (n, k, r) to make exploitation decisions robust rather than ad hoc.

Behavioral notes (what opponents will experience)
- Unconditional cooperators: will be exploited after probing; the strategy will defect often once it has evidence they won’t punish.
- Conditional cooperators / punishers: the strategy will cooperate to avoid long-run losses, with occasional calibrated exploitation if their responsiveness is weak.
- Pure defectors: the strategy will defect routinely (no wasted cooperations).
- Noisy or mixed opponents: the strategy uses smoothing and recent-data weighting to avoid over-reacting to noise and to recover from transient punishments.
'''

description_EXPLOITATIVE_44 = '''
Strategy name: Opportunistic Conditional Free-rider (OCF)

Goal (exploitative mindset)
- Maximize my own cumulative payoff by free-riding whenever enough other players are contributing, but avoid being driven to permanent low-payoff mutual defection. I induce or sustain cooperation in others only to the extent that I can extract net benefit over time.

Key ideas (high level)
- Start by signaling willingness to cooperate to attract cooperators.
- Monitor the recent contribution rate of the group (excluding myself).
- If others are reliably cooperative, defect to free-ride most of the time but give occasional cooperative "signals" so cooperation does not collapse.
- If others are mostly defectors (or retaliate against my defection), switch to defection until cooperation becomes attractive again.
- Always defect in the final round (no future to sustain cooperation); progressively ramp down cooperation as the end approaches.

Parameters (computed from game parameters and history)
- n, k, r are given.
- alpha = k / n (public-good factor per contribution).
- Window W = min(10, max(3, floor(sqrt(r)))) — number of most recent rounds used to estimate behavior (adjusts with game length).
- q = estimated average contribution rate of each other player over the last W rounds:
    q = (total contributions by other players in last W rounds) / ((n-1) * W).
  So q in [0,1].
- Thresholds:
    q_high = 0.60 (treat group as cooperative)
    q_low = 0.20 (treat group as non-cooperative)
  (These are defaults; they do not require external calibration and are robust across many opponent mixes.)
- Exploitation persistence parameter:
    p_signal = 0.10 (probability of cooperating while in exploit mode to signal non-hostility and allow repair)
- Punishment length P: when group responds to my defections by reducing contributions, punish by defecting P = min(3, remaining_rounds) rounds, then reassess.
- Endgame horizon E = min(3, r) rounds: in the last E rounds, progressively reduce cooperation and always defect in final round.

Decision rules (round t, with remaining rounds R_rem = r - t + 1)
1. Last-round rule:
   - If R_rem == 1 (this is the last round): Defect.

2. Endgame taper:
   - If R_rem <= E (close to end), my cooperation probability falls linearly with remaining rounds. In practice: if R_rem == 2, cooperate only with probability 0.05; if R_rem == 3, use 0.15; otherwise follow normal logic. This avoids wasting tokens near the end.

3. Compute q using the last W rounds (or all available rounds if fewer than W have been played).

4. Core mode decision:
   - If currently in a punishment episode (I have observed a sustained, significant drop in others' contributions immediately after I defected and punishment rounds remain), continue to Defect until punishment length P expires, then clear punishment and Reassess.
   - Else:
     a) If q >= q_high (group is cooperative):
        - Exploit: Defect most of the time to free-ride.
        - Implementation: Defect deterministically, except with small probability p_signal cooperate (randomize cooperation with probability p_signal). The occasional contributions signal that I am not permanently hostile and allow cooperators to resume trusting me.
     b) If q_low < q < q_high (mixed / conditional cooperators):
        - Maintain cooperation to cultivate higher group contributions: Cooperate.
     c) If q <= q_low (group is mostly defecting):
        - Defect (no point contributing).
   - After each defection, check the next 1–2 rounds for changes in others' average contributions:
       * If others reduce their contributions significantly (e.g., group average contribution per player drops by >= 20% relative to the pre-defection window), treat that as retaliatory punishment and enter Punish mode: defect for P rounds (so I do not continue to pay cost while they punish), then return to reassess.

5. Probing / initial behavior:
   - Round 1: Cooperate (signal non-hostile intent and attract cooperators).
   - Rounds 2..min(3, r): continue cooperating unless early evidence shows group-wide defection; this short probe window lets me estimate q safely.
   - After the initial probe window, follow the Core mode decision rules.

6. Randomization and secrecy:
   - The only intentional randomness is the small p_signal when exploiting and some tiny randomness in endgame tapering probabilities. Randomization makes it hard for purely deterministic exploiters to always punish optimally and prevents my behavior from collapsing into predictable cycles that others can exploit.

Why this is exploitative and robust
- Exploitative: When many opponents cooperate (q >= q_high), I defect to collect the sure private token plus a share of the public good funded by others — maximizing my relative payoff. I only give occasional cooperative tokens to maintain the cooperation stream and avoid triggering permanent retaliation.
- Robust to defectors: When others defect, I defect too, so I am not exploited. If my occasional defection provokes group retaliation, I recognize it (drop in others' contributions) and switch to a punishment episode rather than continuing to waste contributions while being punished.
- Adaptive: Uses recent empirical q to classify the group's state; window W scales with game length so the strategy is neither overly myopic nor too slow to react.
- Endgame-safe: Always defects in the last round and reduces cooperation as the horizon approaches, avoiding endgame exploitation by opportunists.

Pseudocode summary (natural-language form)
- On round t:
  1. If this is final round: Defect.
  2. Update W and compute q from last W rounds (others' contributions only).
  3. If in punishment episode: Defect until P rounds of punishment are completed, then clear punishment.
  4. Else if R_rem <= E: follow endgame taper (very low cooperation probabilities).
  5. Else:
     - If q >= q_high: Exploit — normally Defect, but cooperate with probability p_signal.
     - If q_low < q < q_high: Cooperate.
     - If q <= q_low: Defect.
  6. After acting, if I defected, observe the next 1–2 rounds: if others reduce their contribution rate sharply (>= 20% drop relative to pre-defection q), enter punishment episode (defect for P rounds).

Notes and tuning
- Default thresholds and probabilities are chosen to be broadly robust. In practice:
  - W = min(10, max(3, floor(sqrt(r)))) adapts to short and long tournaments.
  - q_high = 0.6 and q_low = 0.2 separate cooperative, mixed, and defecting populations.
  - p_signal = 0.1 is small enough to capture most of the exploitation surplus while still allowing repair.
- The strategy uses only game parameters (n,k,r) and observed history (past actions and payoffs) and requires no communication or shared norms.

In short: start cooperative to attract cooperators, monitor others’ recent contribution rate, free-ride when others are reliably cooperating while sending occasional cooperative signals to avoid collapse, defect when the group is non-cooperative or when endgame makes cooperation futile, and punish-then-forgive if my defection provokes retaliation. This balances exploitation of cooperators with protection from being exploited.
'''

description_EXPLOITATIVE_45 = '''
Name: Stingy Conditional Exploiter (SCE)

Summary intuition (one line)
- Test quickly, classify players by how often they contribute, then exploit cooperators by mostly free‑riding while using short, targeted punishment and occasional “maintenance” gifts to keep cooperators contributing. Always defect in the final round.

Parameters computed from game inputs (used internally)
- n, r, k: game inputs (assumed n ≥ 2).
- Window W = min(10, max(3, floor(r/4))) — lookback for recent behavior.
- Probe rounds P = min(3, max(1, floor(r/10))) — initial testing phase.
- Reliable threshold T_high = 0.80 (player is a reliable cooperator if their contribution rate over W ≥ T_high).
- Unreliable threshold T_low = 0.40 (player considered mostly defector if rate ≤ T_low).
- Group-cooperation thresholds: G_high = 0.75, G_mid = 0.40.
- Exploit probabilities: p_free = 0.85 (when group highly cooperative, defect with this probability), p_signal = 0.15 (small probability to contribute to sustain cooperation).
- Forgiveness/probe probabilities: p_probe = 0.05 (rare probe contribution when group mostly defects), p_rebuild = 0.10 (small chance to cooperate in mixed groups to rebuild).
- Punishment length L_punish = min(3, max(1, floor(r/20))) — how long to continue targeted punishment before re-checking.
- Endgame: in round t = r (last round) always defect. For simplicity also treat last 1–2 rounds as “don’t give gifts”: if r_remaining ≤ 2 then defect.

Data maintained from history
- For every player j (j ≠ me): count of contributions in last W rounds → rate_j.
- Group recent rate f = average of others’ contributions over last W (sum_j rate_j / (n-1)).
- Last-round contributions set S_last (which players contributed last round) and count c_last = |S_last|.

Decision rules (run each round t = 1..r)

1) Last-round safe rule
- If t = r (final round): play D (defect).
- If r − t + 1 ≤ 2 (last two rounds), default to D except do not escalate punishments or try to rebuild cooperation; treat as safe defection zone.

2) Initial probing phase (t ≤ P)
- Round 1: C (cooperate). Purpose: reveal who will reciprocate.
- Rounds 2..P: play C if at least half of the other players contributed in the previous round (c_last ≥ ceil((n-1)/2)); otherwise play D. This quickly separates likely cooperators from defectors.

3) Update classifications after each round (t > P)
- For each opponent j compute rate_j = contributions_by_j over the last W rounds / min(W, rounds_so_far).
- Classify:
  - Reliable cooperator if rate_j ≥ T_high.
  - Mostly defector if rate_j ≤ T_low.
  - Uncertain otherwise.

- Compute group recent rate f = average of rate_j for all j ≠ me.

4) Main action rule (after probe, not in last-round zone)
- If f ≥ G_high (many others reliably cooperate):
  - Exploit mode:
    - If there are at least two reliable cooperators, adopt freeride posture: defect with probability p_free (0.85). With probability p_signal (0.15) contribute (C) as a maintenance gift to prevent collapse of cooperation. Randomization keeps me unpredictable so punishers cannot safely drive me to always cooperate.
    - Additionally, if any individual j is mostly defector (rate_j ≤ T_low), target them: continue to defect until they improve their rate above T_low; however do not allow extended vendettas — after L_punish rounds of punishing a specific low-rate player, allow a p_signal contribution to test forgiveness.
- Else if G_mid ≤ f < G_high (mixed group):
  - Conditional reciprocity mode:
    - If a majority of others contributed in the last round (c_last ≥ ceil((n-1)/2)), play C (cooperate) with probability (1 − p_rebuild) to join cooperative bursts but still randomly defect with probability p_rebuild to extract occasional gain.
    - If a majority of others did not contribute last round, play D.
    - If several players are reliable cooperators, bias slightly toward defecting (exploit) while keeping occasional C to sustain them.
- Else (f < G_mid — group mostly defects):
  - Defection mode:
    - Play D every round to avoid being repeatedly exploited.
    - With tiny probability p_probe (0.05) play C as a probe to check whether cooperators can be re-activated; if that probe is reciprocated by others, transition gradually to the mixed-group rule.

5) Targeted punishment and forgiveness (keeps strategy robust)
- I punish individual persistent defectors by refusing cooperation when they are below T_low, but:
  - Punishment is brief (L_punish rounds) to avoid long-term loss.
  - After L_punish rounds, perform a one-round generous signal (contribute with probability p_signal) to allow them to resume cooperation; if they respond by improving rate_j above T_low, remove punishment.
- This targeted punishment prevents exploitation by pure free-riders but is short enough to avoid long retaliation spirals.

6) Randomization and unpredictability
- Introduce the stated probabilities to avoid deterministic patterns that sophisticated opponents can exploit (e.g., exact tit-for-tat exploitation).
- Use randomness to (a) free-ride often when others cooperate, (b) occasionally contribute to sustain cooperation, (c) probe defecting populations.

Edge cases
- If r = 1: always play D (single-shot defection is dominant).
- If r is very small (e.g., r ≤ 3): shorten or skip the probing phase (P = 1) and be more conservative — default to D except a single probe.
- If n = 2 (bilateral): behavior is similar but thresholds for majority reduce to the partner’s actions — treat their behavior directly: punish/forgive and exploit when they remain cooperative.
- If many opponents are labeled mostly defectors (f very low), SCE will largely defect until it finds exploitable cooperators.

Why this is exploitative and robust
- Exploitative: when a subset of players reliably contributes, SCE mostly defects to capture the extra private payoff from their contributions, while giving occasional maintenance gifts so cooperators do not abandon cooperation — this extracts surplus repeatedly.
- Robust: it defends against pure defectors via short punishments, avoids long vendettas (which would lower its own payoff), uses probes to discover new cooperators, randomizes actions so it is difficult for opponents to fully retaliate, and always defects in the final round to avoid endgame exploitation.
- Adaptive: classifications update continuously using recent-window rates; behavior shifts automatically among exploit, conditional reciprocity, and defection modes depending on what the population does.

Behavioral summary (quick reference)
- Round 1: C (probe).
- Early rounds (brief): follow conditional probing to classify players.
- If many others cooperate consistently: mostly defect, occasionally C to maintain their cooperation.
- If mixed: conditional cooperate if others cooperated last round, but inject occasional D to extract value.
- If most defect: mostly defect, rare probes to test for recovery.
- Targeted short punishments for persistent defectors, followed by limited forgiveness.
- Final round(s): always defect.
'''

description_EXPLOITATIVE_46 = '''
Name: Exploitative Conditional-Cooperator (ECC)

Intent: Maximize my long-run payoff by (1) attracting and maintaining cooperation from responsive/conditional cooperators, (2) punishing persistent defectors, and (3) opportunistically exploiting predictable, unresponsive cooperators. The strategy uses only game parameters (n, r, k) and the observed history of every player’s contributions.

Key derived quantity (used to decide whether future cooperation is worth protecting):
- One-shot gain from defecting = 1 − k/n (always positive since k/n < 1).
- If my single defection reduces each other player’s cooperation probability by Δp on average, my per-round future loss ≈ (k/n) * (n−1) * Δp.
- Cooperating is preferable (in expected long-run terms) when average Δp > threshold, where
  threshold = (n − k) / (k * (n − 1)).
  (Interpretation: if others are sufficiently responsive to my defection, keep cooperating; otherwise defect to exploit.)

Parameters and defaults (computed from known game params):
- Window W = min(10, max(3, floor(r/5))) — recent rounds used to estimate behaviour (smaller if short game).
- Min observations per condition m_min = 3 (if fewer observations, treat responsiveness estimate as uncertain).
- Initial probe rounds I = min(3, r−1) — first few rounds used to gather data (but not the final round).
- Exploit probability when group looks exploitable p_exploit_base = 0.15; escalate conservatively up to p_exploit_max = 0.4 if opponents remain unresponsive.
- Forgiveness / punishment length P = 2 (use short punishments to avoid permanent collapse).
- Small exploration probability epsilon = 0.05 (to test for hidden conditionality).

Per-round decision rules (high-level):

1. Terminal rule:
   - If this is the final round (round r): defect.

2. Initialization and early rounds:
   - For the first I rounds (unless r = 1 or it's the final round), cooperate to signal goodwill and collect data on responsiveness and unconditional cooperation rates.
   - If r is very small (r ≤ 2), be aggressive: cooperate first round only if you expect future rounds; otherwise defect in last(s).

3. Each non-final round t > 1:
   - Build statistics from history up to round t−1 using window W:
     a) For each other player i, compute:
        - p_i_afterC = fraction of rounds in the window where player i contributed in the round following one where I cooperated.
        - p_i_afterD = fraction of rounds in the window where player i contributed in the round following one where I defected.
        - responsiveness r_i = p_i_afterC − p_i_afterD. (If insufficient conditional samples for player i, mark r_i as uncertain.)
        - baseline cooperation rate b_i = fraction of rounds in window where i contributed.
     b) Group averages:
        - R = average of r_i over players with sufficient data (treat uncertain r_i as 0 for the average but track confidence).
        - B = average baseline cooperation rate across other players.
   - Compute required_threshold = (n − k) / (k * (n − 1)).

4. Cooperation vs defection decision:
   - If insufficient data (we are still in the initial I rounds or fewer than m_min conditional samples overall):
     - Play cooperatively (except in the final round). Rationale: favor learning and attracting conditional cooperators early.
   - Else if R ≥ required_threshold (others are sufficiently responsive on average to my defections):
     - Cooperate. Rationale: my future losses from breaking cooperation are likely to outweigh immediate one-shot gain.
   - Else (R < required_threshold; opponents are weakly responsive overall):
     - If B is low (e.g., B < 0.25): defect (group is mostly defecting; no benefit in cooperating).
     - If B is moderate or high (B ≥ 0.25):
       - Identify “unresponsive cooperators”: players with b_i ≥ 0.75 and r_i small (≤ 0.05 or uncertain). If a meaningful fraction of players (>= 30%) fit that description, treat group as exploitable.
       - If group exploitable:
         - Defect with probability p_exploit, cooperate otherwise. Start with p_exploit = p_exploit_base; if after several rounds those players remain unresponsive, slowly increase p_exploit toward p_exploit_max.
         - If any of the unresponsive cooperators reduce their contribution rate significantly after my exploitations, immediately reduce p_exploit and revert to cooperation as guided by the responsiveness test (so exploitation is reversible).
       - Else (no clear exploitable subset), cooperate with a small exploration probability: generally cooperate, but with probability epsilon defect to probe responsiveness.

5. Punishment and forgiveness:
   - If there is a sudden drop in group cooperation (B decreases by more than 30 percentage points compared to the previous window), treat it as mass defection and switch to defection for P rounds to punish.
   - After P punishment rounds, reassess statistics and be forgiving if responsiveness suggests cooperation can recover. Do not engage in prolonged revenge cycles: punish briefly, then return to the main decision rule.

6. Individual-targeted behavior (robustness to heterogeneity):
   - If opponents are heterogeneous and some are clearly responsive while others are exploitable, prefer actions that preserve cooperation with responsive players while extracting surplus from unresponsive ones:
     - Use probabilistic exploitation rather than permanent defection to avoid alienating responsive players.
     - If the responsive subset is large enough that cooperation is overall profitable (R weighted by player importance exceeds threshold), favor cooperation.

7. Robustness notes:
   - Always defect in the last round.
   - Maintain short memory windows to detect regime shifts (players who change strategies).
   - Keep exploitation conservative and reversible: increase exploitation only after observing persistent unresponsiveness, and reduce it immediately if there is retaliation.
   - Use small exploration to detect hidden conditional types.

Summary intuition (how this is exploitative and safe):
- ECC starts by cooperating to attract conditional cooperators.
- It estimates how much my defection would reduce others’ future cooperation (responsiveness). If the estimated expected future loss exceeds the immediate one-shot gain (threshold test), ECC cooperates to preserve future income.
- If opponents are weakly responsive but cooperate often, ECC opportunistically defects at a controlled rate to harvest short-term gains (exploits unresponsive cooperators).
- ECC punishes mass defectors briefly, but is forgiving so cooperation can return.
- ECC always defects in the final round, and adapts exploitation intensity based on observed opponent reactions, making exploitation both opportunistic and robust.
'''

description_EXPLOITATIVE_47 = '''
Exploitative Conditional-Cooperator (ECC)

Idea (short): Start by cooperating briefly to identify which opponents are conditional/cooperative. Estimate how much your cooperation changes others’ future cooperation. Cooperate only when that estimated future benefit (discounted by remaining rounds) outweighs the sure immediate cost of contributing. Otherwise defect, use short targeted punishments against persistent free-riders, and defect in the final rounds to avoid endgame exploitation. Include rare probes to refresh estimates and to harvest naïve cooperators.

Parameters (fixed, computed from game parameters and history)
- n, r, k: game parameters (players, rounds, multiplier).
- W = min(8, r-1): history window for statistics.
- tau_coop = 0.80: “high cooperation” threshold.
- tau_defect = 0.20: “low cooperation” threshold.
- delta_resp_min = 0.12: minimal per-player responsiveness to count as meaningful.
- probe_rate = 0.04: small probability to perform an exploratory defection/cooperation.
- punish_len = 2: length (rounds) of a punishment streak before testing forgiveness.
- endgame_len = min(2, r): number of final rounds in which always defect.

Auxiliary definitions (computed each round t, using data from previous rounds 1..t-1)
- For each other player j:
  - coop_rate_j = fraction of j’s contributions =1 in the last W rounds.
  - Pr_j(C | I_C) = empirical probability j cooperates in a round following a round in which I cooperated (use available pairs in window).
  - Pr_j(C | I_D) = empirical probability j cooperates following a round in which I defected.
  - resp_j = Pr_j(C | I_C) − Pr_j(C | I_D) (if no data, treat as 0).
- avg_resp = mean over j of max(0, resp_j). (Average positive responsiveness to my cooperation.)
- G = fraction of other players who cooperated in the last round (or average cooperation rate across others in the last W rounds for smoothing).
- R_rem = remaining future rounds after the current decision (R_rem = r − t).

Decision rule (round t)
1. Endgame override: If t > r − endgame_len (i.e., within the final endgame_len rounds), play D (defect). Rationale: no future to convert, so avoid being exploited.

2. If t = 1:
   - Play C (cooperate) to seed information and entice conditional cooperators—unless r = 1 (single-round game), then play D.

3. If currently in an active punishment streak I triggered (see Punishment below):
   - Continue defecting for the punish_len rounds, then move to a test round (one cooperative attempt) to see if group recovers.

4. Otherwise evaluate expected benefit of cooperating:
   - Immediate net cost of cooperating now (one round) = L = 1 − (k/n) (positive because k/n < 1).
   - Model: assume my cooperating this round yields an average persistent increase in others’ contributions of approximately Δ_per_player ≈ avg_resp (per player per round), producing Δ_total = (n − 1) * avg_resp extra contributions per future round.
   - Expected cumulative future benefit of cooperating now (if effect persists for R_rem rounds) ≈ Benefit = R_rem * (k/n) * Δ_total.
   - Required condition to justify cooperating: Benefit ≥ L.
   - So compute required_avg_resp = L / (R_rem * (k/n) * (n − 1)).
   - If avg_resp ≥ max(required_avg_resp, delta_resp_min) AND G ≥ 0.40 (group not already collapsing), then play C.
     - Rationale: my cooperation is justified only if observed responsiveness is large enough that future rounds of higher cooperation will repay the immediate cost.
   - Else play D.

5. Occasional probing/exploitation:
   - With independent probability probe_rate each non-final round, play the opposite of your default decision this round (i.e., defect if default was C, or cooperate if default was D). Use probes to:
     - Harvest extra tokens from naïve/unconditional cooperators when we defect.
     - Refresh estimates of resp_j by creating causal variation.
   - If you probe, record outcome and update statistics; don’t let probes immediately trigger long punishments (label them as “probe” in memory).

Punishment and forgiveness
- Trigger a short punishment if the group’s cooperation collapses after you tried to sustain cooperation:
  - If you cooperated in the previous round and G (fraction cooperating last round) fell below tau_defect, treat that as exploitation and defect for punish_len rounds.
  - After punish_len defect rounds, run one cooperative test round (unless in endgame); if cooperation recovers (G rises above tau_coop for at least one round), resume normal strategy; otherwise continue defecting until group shows improvement.
- This punishment is short and calibrated (punish_len) to avoid costly vendettas and to remain exploitive: punish enough to make cooperation more attractive to conditional cooperators but not so long that you lose all opportunities.

Handling noisy or sparse history
- If insufficient data for reliable resp_j (e.g., window too small or few transitions), be conservative: favor defection except for the initial two round seeding cooperations. Use probes at probe_rate to build data rather than continuous cooperation.

Final-round and short-game adjustments
- If r is small (<=3), be more defect-leaning: after the first cooperating seed round, prefer defection because future leverage is limited.
- Always defect in the final endgame_len rounds (override).

Why this is exploitative and robust
- It extracts value from conditional and reciprocal opponents by cooperating only when doing so creates measurable future benefits. That lures conditional cooperators into sustaining contributions while avoiding continuous giving to unconditional defectors.
- It punishes clear free-riding quickly and briefly to discourage exploitation, then tests forgiveness to resume extracting benefits when cooperation returns.
- It uses statistical responsiveness (resp_j) rather than assuming norms or relying on coordination, so it adapts to a wide range of opponent types (unconditional cooperators, tit-for-tat-like, defectors, random).
- Rare probes let it harvest naïve cooperators in one-shot opportunities and maintain up-to-date estimates.

Practical pseudocode-style summary
- Initialize counters, set W, thresholds.
- Round 1: play C (unless r = 1 then D).
- For each round t > 1:
  - If in final endgame_len rounds: play D.
  - Update coop_rate_j, Pr_j(C|I_C), Pr_j(C|I_D), resp_j, avg_resp, G.
  - If punishment ongoing: play D until punish_len rounds complete, then do a test C round.
  - Compute required_avg_resp = (1 − k/n) / (R_rem * (k/n) * (n − 1)).
  - Default_decision = C if (avg_resp >= max(required_avg_resp, delta_resp_min) and G >= 0.40) else D.
  - With probability probe_rate, flip default_decision (probe).
  - Play chosen action; update history.
  - If you cooperated and the next observed G drops below tau_defect, trigger punish_len rounds of defection.

This strategy is fully specified from game parameters and observed history, balances exploitation vs protection from being exploited, and adapts to diverse opponent behaviors without communication or coordination.
'''

description_EXPLOITATIVE_48 = '''
Name: Adaptive Exploiter (AE)

Goal (exploitative mindset): Maximize my own cumulative payoff by freeloading on reliably cooperative opponents while avoiding being exploited or permanently punished. I seek to induce and sustain enough cooperation from others to make defection profitable, but I back off if the group responds by reducing contributions.

Parameters I set from game inputs:
- n, r, k are known.
- Probe length P = min(6, max(1, floor(r/8))) — short initial test of others.
- Window W = min(10, r) for measuring recent behavior.
- High-cooperation threshold θ_high = 0.6.
- Low-cooperation threshold θ_low = 0.2.
- Exploit margin δ = 0.15 (how much below others’ cooperation rate I will aim to play).
- Punishment detection drop Δ = 0.25 (sustained drop that I interpret as punitive response).
- Punishment patience D = min(5, max(1, floor(r/10))) rounds to confirm punishment.
- Endgame cut T_end = min(3, r) — final T_end rounds I always defect (no future to sustain cooperation).

Basic bookkeeping each round t (1-indexed):
- For each opponent j, record their contributions history c_j(1..t-1).
- Compute for each opponent j their recent cooperation rate over the last W rounds (or over available history if shorter): q_j.
- Compute group other-players’ average recent cooperation rate q_others = mean_j q_j (exclude my own actions).
- Track the running average group contribution per round (including all players) to detect punishment responses.

Decision rules (applied each round t, before action decision):
1. Endgame: If t > r - T_end (i.e., in final T_end rounds), play D (defect). If r = 1, defect on round 1.

2. Probing phase: If t ≤ P, play C (cooperate) to test willingness of opponents to contribute and to collect a baseline.

3. After probes, classify recent environment by q_others:
   - If q_others ≥ θ_high (many others reliably cooperate):
     - Exploit mode: my target cooperation rate p_target = max(0.02, q_others - δ). This keeps my contribution frequency noticeably below others’ so I free-ride while still occasionally contributing to help sustain others’ cooperation.
     - Operationalization:
       - Use a deterministic quota over sliding window W: in any W-round window try to contribute exactly round(W * p_target) times (rounding in favor of defecting when ambiguous). Practically: if my contributions in the last W rounds < target quota, contribute this round; otherwise defect.
       - This deterministic quota avoids reliance on randomness while maintaining a steady, lower-than-group contribution rate.
   - If θ_low < q_others < θ_high (mixed environment):
     - Conditional-match mode: try to be slightly cooperative to benefit from partial cooperation but not fully subsidize it.
     - Set p_target = max(0.05, 0.7 * q_others). Implement using the same deterministic quota rule over window W.
   - If q_others ≤ θ_low (others mostly defect):
     - Defect mode: play D every round (no incentive to give away tokens to defectors).

4. Punishment-sensitivity override:
   - If I enter Exploit mode and then observe a sharp, sustained drop in others’ contributions after I reduce my contributions (group average contribution rate falls by ≥ Δ compared with the pre-exploit baseline and stays down for D rounds), treat that as effective punishment or collapse of cooperation.
   - In response: abandon attempts to coax cooperation — switch to Defect mode (play D forever or until the last-round endgame logic). Rationale: I avoid being kept in a low-payoff state by retaliatory opponents; better to stop contributing and limit losses.

5. Detect unconditional cooperators (targets for extra exploitation):
   - If any opponent j has q_j ≥ 0.9 over at least max(P, W) rounds, treat them as near-unconditional cooperator.
   - Increase my local exploitation against them by lowering my personal p_target by an extra ε = 0.05 (i.e., p_target := max(0.02, p_target - ε)). I do not single-target in action (contributions are public), but I bias my quota to contribute less overall to freeride more on their predictable contributions.

6. Safety: if I ever observe that the majority of players (≥ ceil((n-1)/2)) are switching to a persistent punitive pattern (sustained drop after my defections AND those players’ subsequent cooperation rates stay low while my defections didn’t reduce others’ payoffs), I will adopt Defect mode permanently — exploitation is no longer viable.

Summary operational flow:
- Round 1..P: cooperate to probe.
- For each round t > P and not in final T_end rounds:
  - Compute q_others over window W.
  - If q_others high → Exploit mode: contribute only to meet a deterministic low quota equal to q_others - δ.
  - If q_others mid → Conditional-match: contribute at ~0.7 * q_others quota.
  - If q_others low → Defect always.
  - If my reductions trigger sustained group drop ≥ Δ for D rounds → switch to Defect forever.
  - If an opponent is a near-unconditional cooperator (q_j ≥ 0.9) reduce my quota further to extract extra surplus.
- Last T_end rounds: defect every round.

Why this is exploitative and robust:
- Exploitative: after probing, AE freeloads by contributing less than the observed group rate, capturing the private gain while still giving occasional contributions to maintain others’ incentives. It deliberately under-contributes relative to cooperators rather than matching them.
- Adaptive: decisions depend only on observed recent cooperation rates (window W) and react to changes (punishment detection). It probes early to learn environment, then adapts between exploit, conditional cooperation, and pure defection.
- Robust: AE punishes when group cooperation collapses in response to exploitation (avoids being permanently lowered by punishers), and defects in the endgame to avoid last-round exploitation. Deterministic quotas prevent being repeatedly exploited by stochastic tricks, while the punishment-sensitivity keeps AE from being trapped by coordinated retaliators.

Edge cases:
- Very short games (r ≤ P): probe logic defaults to cooperating early but final-round defect overrides; if r = 1, defect on round 1.
- Small groups: thresholds still apply; exploitation is tempered by observation — with fewer players, q_others will reveal whether freeloading is possible.
- If opponents conceal behavior by extreme stochasticity, AE’s windowed averaging smooths noise; quotas ensure predictable long-run exploitation rather than greedy swings.

Implementation notes (for a tournament entrant):
- Keep a sliding-window count of contributions for each opponent and for the group.
- Maintain my own contribution count over the same window for implementing quotas.
- Update mode each round using the rules above; the decision rule is deterministic given the measured counts (except ties resolved in favor of defection).

This strategy hunts cooperators and extracts surplus while retreating to safe defection when cooperation cannot be reliably sustained or punishment is detected.
'''

description_EXPLOITATIVE_49 = '''
Name: Adaptive Exploitative Conditional Cooperator (AECC)

Summary intuition (one-line): Cooperate only when my cooperation demonstrably and reliably raises future group contributions enough to offset its immediate cost; otherwise defect and occasionally probe/exploit. Use observed conditional responses of others to my past actions to decide, with small randomized exploration to learn and avoid being predicted.

Parameters (derived from game or fixed small defaults)
- n, k, r known.
- remaining_rounds = rounds left including current.
- WINDOW = max(10, r) for statistics window (use whole history if shorter).
- EPSILON = 0.05 (small exploration noise).
- MIN_SAMPLES = 4 (minimum conditioning samples before trusting estimates).
- DECAY = 1 (assume immediate next-round effect is dominant; can treat future rounds linearly by multiplying by remaining_rounds-1).
- SAFETY_MARGIN = 0 (conservative; can be increased if risk-averse).

Key quantities maintained from history
- For every round t>1, define:
  - last_my_action[t-1] (C or D)
  - others_coop_next[t] = fraction of the other n-1 players who cooperated in round t (i.e., after round t-1).
- From recent history (last WINDOW rounds), compute:
  - p_C = average others_coop_next over rounds where my previous action was C.
  - p_D = average others_coop_next over rounds where my previous action was D.
  - count_C = number of instances used to compute p_C.
  - count_D = number of instances used to compute p_D.
- Estimated marginal effect on immediate next-round total contributions from my cooperating now:
  - e_next = (p_C - p_D) * (n - 1). (Expected extra contributions next round caused by me cooperating this round.)
- Conservative estimated cumulative future benefit of cooperating now:
  - Benefit = (k / n) * e_next * (remaining_rounds - 1) * DECAY
    (Interpretation: each extra contribution next round gives me k/n payoff, and I conservatively assume similar total effect persists only for the remaining rounds in aggregate scaled by DECAY. This is intentionally conservative — you can substitute a decaying geometric sum if you want more optimistic estimates.)
- Immediate cost of cooperating this round:
  - Cost = 1 - (k / n).

Decision rule (round-by-round)

1) Last round (remaining_rounds = 1):
   - Always defect (D). No future to influence, and defect strictly dominates in a single round.

2) Early probing phase (insufficient conditioning data):
   - If count_C < MIN_SAMPLES or count_D < MIN_SAMPLES:
     - Play a probing policy to gather data while avoiding easy exploitation:
       - Default: cooperate in the very first round.
       - For subsequent early rounds: cooperate with probability 0.7 and defect with probability 0.3, but always with EPSILON random flips to continue exploration.
     - Purpose: produce both C and D antecedents so p_C and p_D become estimable.

3) General adaptive step (sufficient history):
   - Compute p_C, p_D, e_next, Benefit, Cost as above.
   - Interpret these cases:

   A) If Benefit > Cost + SAFETY_MARGIN:
      - Cooperate (C). Rationale: my cooperation is expected to raise others’ contributions enough over the remaining rounds to cover the immediate loss and increase my total payoff.
      - Add stochastic protection: with probability EPSILON, flip to D to probe and avoid perfect predictability.

   B) If Benefit <= Cost - SAFETY_MARGIN:
      - Defect (D). Rationale: cooperating is not justified by expected future gains; defect to exploit any unconditional cooperators.
      - With small probability EPSILON, cooperate to continue learning.

   C) If Benefit is marginal (within +/- SAFETY_MARGIN of Cost):
      - Use a graded probabilistic response: cooperate with probability p = clamp((Benefit - Cost + SAFETY_MARGIN) / (2 * SAFETY_MARGIN + 1e-9), 0, 1). Practically this means favor cooperation slightly if Benefit slightly exceeds Cost, otherwise defect; plus EPSILON exploration.

4) Reacting to retaliation or strong negative feedback:
   - If after a defection I observe that p_D (others’ subsequent cooperation) falls substantially below p_C (i.e., others punish me when I defect), and this persists for a few rounds:
     - If retaliation is costly to me (Benefit < Cost even when anticipating punished losses), switch to safe mode: defect consistently (D) for the rest of the game (exploit the fact that continued defection avoids paying costs of maintaining cooperation when punishers refuse to cooperate).
     - If I would lose long-term by permanent defection (Benefit > Cost when including anticipated punishments), instead attempt a short calibrated reconciliation: cooperate for 1–2 rounds to re-establish conditional cooperation, then follow the main decision rule.

5) Exploiting unconditional cooperators:
   - If p_C ≈ p_D and p_C is high (e.g., > 0.75) meaning others’ behavior is essentially independent of my action and they are reliably cooperative:
     - Defect persistently except for occasional cooperative probes with probability EPSILON or when Benefit calculation turns positive (unlikely if p_C ≈ p_D).
     - That choice extracts the highest immediate payoff from those unconditional cooperators without meaningful loss from retaliation.

6) Safety and continued learning:
   - Always retain EPSILON exploration: with small fixed probability flip the intended action each round to gather fresh evidence and avoid being perfectly exploitable/predictable.
   - Recompute statistics on a rolling window to adapt to changing opponents.

Edge cases and practical notes
- If n or k are extreme (k very close to n so Cost small), the Benefit threshold becomes easier to satisfy — the algorithm will more readily cooperate when group gains from cooperation are large.
- If the game is very short (few remaining_rounds), Benefit is small and the strategy will defect more often as backward induction predicts.
- The method uses conservative, directly-observable conditional effects (how others’ cooperation rate next round depends on my previous action) rather than untestable assumptions about motives; this protects against being misled by complex multi-agent dynamics.
- The strategy is intentionally exploitative:
  - It defects whenever cooperating is not shown to reliably increase future group cooperation enough to justify the cost.
  - It robs unconditional cooperators (defects when they won’t punish) and only pays to cooperate to sustain cooperation from conditional cooperators when that investment has a positive expected return.
  - It avoids costly punishment wars by switching to permanent defection if cooperating provokes persistent retaliation that reduces my payoffs.

Concise pseudocode summary
- On each round t with remaining_rounds R:
  - If R == 1: play D.
  - Update p_C, p_D from last WINDOW rounds (others’ fraction cooperating after my C or D).
  - If counts too small: probe (C with prob 0.7, D with prob 0.3) with EPSILON random flips.
  - Else compute e_next = (p_C - p_D)*(n-1); Benefit = (k/n) * e_next * (R - 1); Cost = 1 - (k/n).
  - If Benefit > Cost + margin: action = C (flip with EPSILON).
  - Else if Benefit < Cost - margin: action = D (flip with EPSILON).
  - Else action = probabilistic mix favoring C proportionally (plus EPSILON).
  - If persistent retaliation observed (p_D << p_C after my D), consider switching to permanent D.

Why this is robust in a tournament
- It adapts to many opponent types:
  - Exploits unconditional cooperators by defecting.
  - Cooperates with conditional cooperators only when doing so raises my long-run payoff.
  - Avoids being trapped into expensive punish-reward cycles because it conservatively requires measurable conditional benefits.
- It is simple, relies only on observable actions, and contains randomness for continued learning and unpredictability — useful against many algorithmic opponents.
'''

description_EXPLOITATIVE_50 = '''
Overview (exploitative objective)
- Goal: Extract the highest long-run payoff by free-riding on players who reliably contribute, while avoiding being locked into mutual defection by retaliatory players. The strategy is adaptive: it probes early, exploits stable cooperators by mostly defecting, punishes and quickly repairs when others retaliate, and refuses to give away tokens near the endgame.

Key parameters (interpretable from n, r, k; defaults shown)
- Memory smoothing: alpha = 0.7 (exponential memory weight for past actions).
- Cooperator threshold: theta_high = 0.8 (score above → classified as cooperator).
- Defector threshold: theta_low = 0.2 (score below → classified as defector).
- Soft-cooperation probability when exploiting: p_soft = 0.10 (occasionally cooperate to sustain cooperation).
- Probe probability (early rounds): p_probe = 0.20 (test opponents’ responsiveness).
- Repair length after detected punishment: L_repair = 2 rounds (cooperate to restore trust).
- Safety endgame cutoff: last T_end = min(3, max(1, floor(r/10))) rounds → always defect in those rounds.
- Small-change sensitivity: delta_drop = 0.20 (if group cooperation falls by more than this after our defection, we treat it as retaliation).

Maintain per-player cooperation score
- For each opponent j keep score S_j initialized to 0.5.
- After each round t update: S_j <- alpha * S_j + (1 - alpha) * c_j(t), where c_j(t) is j’s contribution that round (1 or 0).
- Compute group-level metrics each round:
  - avg_S = average of S_j across opponents.
  - n_coop = number of opponents with S_j >= theta_high.
  - n_defect = number of opponents with S_j <= theta_low.
  - last_round_contribs = total contributions by others in t-1 (use for detection of immediate reactions).

Decision procedure each round t (natural-language pseudocode)
1. Endgame check
   - If t > r - T_end (we are in the last T_end rounds): choose D (defect). (Contribute nothing in the defined endgame window.)

2. Very short games
   - If r <= 3: defect every round (no sustainable cooperation possible).

3. First-round probe
   - If t == 1:
     - Cooperate with probability p_probe; otherwise defect.
     - Purpose: reveal whether pure cooperators exist; small risk to seed future exploitation.

4. Classification
   - Use S_j values to classify opponents as cooperators (S_j >= theta_high), defectors (S_j <= theta_low), or uncertain.

5. Exploitation vs caution
   - If n_coop >= ceil((n-1)/2) (a clear majority of opponents look like cooperators):
     - Default action: D (defect) to free-ride.
     - However, to avoid destabilizing their cooperation:
       - With small probability p_soft cooperate (C) this round to signal occasional contribution.
       - If in the previous round we defected and total contributions by others dropped by more than delta_drop relative to the round before that, treat this as retaliation and enter a repair phase:
         - Cooperate for L_repair consecutive rounds (C each round) or until avg_S recovers above theta_high for a majority; then return to exploitation defaults.
   - Else if n_coop == 0 (no identified cooperators):
     - Default action: D (defect). No reason to give away tokens.
     - Occasional probe: with tiny probability p_probe/2 cooperate to test if anyone will respond.
   - Else (a mixed population: some cooperators but not a majority):
     - Targeted selective generosity:
       - If there are a few stable cooperators (n_coop >= 1) and their past cooperation was steady (avg_S of that subset >= theta_high), then cooperate with small probability p_soft to keep their incentives intact, otherwise defect.
       - If recent history shows that cooperating led to immediate exploitation (others continue to defect after we cooperated), switch to pure defection until someone’s S_j recovers high enough.

6. Punishment and forgiveness rules (to prevent suicide cycles)
   - If we detect a retaliatory drop in others’ cooperation immediately after our defection (drop > delta_drop), assume opponents punish. Respond by:
     - Entering repair: cooperate L_repair rounds to re-establish mutual cooperation if the group is worth exploiting (n_coop was high before the drop).
   - Forgiveness: after repair, require fewer cooperative signals to resume exploitation (only need average S to exceed theta_high for a simple majority).
   - If repeated cycles of punish-repair occur and the group refuses to stabilize, become permanently defecting for the remainder of the game (except for rare probes).

7. Periodic probing to detect strategy changes
   - Once every ~10 rounds (or with probability p_probe each round), perform a probe: defect if usually cooperating, or cooperate if usually defecting, to see if opponents’ behavior has changed. Use probe outcomes to update S_j and adjust exploitation intensity.

Parameter dependence (why and how to tune)
- The strategy’s aggressiveness (p_soft, p_probe, theta_high) can be scaled with game length and multiplier:
  - Longer games (large r): be more patient (smaller p_soft, larger repair length) because exploitation pays over many rounds.
  - Larger multiplier k (higher group return): exploitation is more lucrative, so favor more aggressive free-riding (smaller p_soft) because cooperators are more valuable; but if k is very large, losing group cooperation is costlier so increase monitoring/repair sensitivity.
  - More players n: with more players a single defection matters less to group total, so exploitation can be more aggressive; adjust p_soft downward as n increases.

Edge cases summary
- Single round (r = 1): defect.
- Very short games (r <= 3): defect every round.
- Final rounds (last T_end rounds): defect every round.
- If all opponents are classified as defectors: defect always (no incentive to give away).
- If one or a few stable cooperators exist: mostly defect to free-ride; cooperate rarely to sustain them; repair if they punish.

Why this is exploitative and robust
- Exploitative: when stable cooperators are present, the strategy defaults to defection (free-riding) so it captures their contributions while only paying the minimum occasional cost to keep them cooperating.
- Robust: the exponential score S_j gives rapid adaptation to changes in opponents’ behavior; the detection of short-term drops in group cooperation triggers repair to avoid long stretches of mutual defection; probes detect when opponents change strategy; endgame defection prevents last-round exploitation.
- Defensive: it never stubbornly cooperates in the face of systematic defection, so it avoids being exploited indefinitely; it also avoids provoking collective retaliation by using soft-cooperation and short repair phases.

Practical notes (what tournament entrants can rely on)
- All decisions require only public history (who gave what each round) and the known parameters (n, r, k).
- No communication, no coordination; behavior is based solely on observed actions.
- Tunable knobs (p_soft, alpha, thresholds) can be adjusted for particular tournament environments, but the qualitative pattern remains: probe → identify cooperators → mostly defect (exploit) → repair if punished → refuse late-game cooperation.
'''

description_EXPLOITATIVE_51 = '''
Name: Opportunistic Conditional-Exploiter (OCE)

Summary (one-sentence): Start by probing for cooperators, classify players by how their contributions respond to your moves, then free-ride on unconditional cooperators and conditional cooperators unless cooperating yields a direct myopic payoff advantage; punish briefly but forgive quickly so you can re-exploit when cooperation resumes. Always defect in the final round.

Parameters (chosen from r and n; fixed constants you can tune):
- Window W for recent-history estimates = max(3, min(10, floor(r/5))). (If r small, W is small; otherwise up to 10.)
- Minimum data threshold D = max(2, floor(W/2)).
- Responsiveness threshold R_t = 0.25 (used to detect conditional responders).
- Unconditional-cooperator threshold U_t = 0.85 (cooperation frequency).
- Punisher threshold P_t = 0.25 (drop in cooperation after your defection to classify as punisher).
- Short punishment length L_punish = 1 round (short, to avoid long vendettas).
- Recon probe probability q = 0.05 (small occasional cooperation to re-check environment).
- Final-round rule: always defect in round r. Optionally treat last 2 rounds as non-cooperative zone.

Data you maintain from history (all observable): for each player j != you:
- coop_rate_j = fraction of j’s contributions in last W rounds.
- p_j_if_I_coop = fraction of rounds (in last W) where j contributed following a round in which you contributed.
- p_j_if_I_defect = fraction of rounds (in last W) where j contributed following a round in which you defected.
- responsiveness_j = p_j_if_I_coop - p_j_if_I_defect.

Decision algorithm for each round t (natural-language pseudocode):

1. Final-round shortcut:
   - If t == r (last round): choose D (defect). End.
   - If r - t <= 1 (only one round after this): treat conservatively — usually defect; fall back to myopic check below but bias toward D.

2. Probe phase (no or little data):
   - If t <= W or for some players data < D: play C for the first 1–2 rounds to gather signals (first-round: C). After 1–2 probing rounds, switch to main rule. The probe is to reveal who is willing to cooperate or punish.

3. Update player statistics using last W rounds.

4. Classify players (soft classifications used for expectations):
   - Unconditional cooperator: coop_rate_j >= U_t.
   - Conditional cooperator / reciprocator: responsiveness_j >= R_t and coop_rate_j >= 0.2.
   - Punisher/retaliator: p_j_if_I_defect <= p_j_if_I_coop - P_t (they substantially reduce contributions after you defect).
   - Defector: coop_rate_j <= 1 - U_t (very low cooperation).

5. Predict next-round contributions of others conditional on your two actions:
   - If you choose C, predict for each j: prob_j_C = p_j_if_I_coop if data sufficient, else coop_rate_j.
   - If you choose D, predict for each j: prob_j_D = p_j_if_I_defect if data sufficient, else coop_rate_j.
   - expected_others_if_C = sum_{j≠i} prob_j_C
   - expected_others_if_D = sum_{j≠i} prob_j_D

6. Myopic payoff comparison (exploitative core):
   - Compute myopic payoff if I choose C: payoff_C = (k/n) * (1 + expected_others_if_C)   [since I give up my 1 token]
   - Compute myopic payoff if I choose D: payoff_D = 1 + (k/n) * expected_others_if_D
   - delta = payoff_C - payoff_D
   - If delta > 0 (cooperating gives higher immediate expected payoff) → play C.
   - If delta <= 0 → default to D, except follow the maintenance/forgiveness rules below.

   Rationale: exploiters should defect whenever the short-run expected payoff is higher; cooperate only when your cooperation provably triggers enough extra contributions from others to compensate your cost.

7. Maintenance rule (avoid losing profitable cooperative streams):
   - If delta <= 0 but a substantial fraction of other players are conditional cooperators or punishers (i.e., your defection would cause a large drop in future contributions), then sacrifice minimal cooperation to sustain that income stream:
     - Compute R_frac = fraction of players with responsiveness_j >= R_t or classified as punisher.
     - If R_frac >= 0.25 and expected_others_if_C is high (e.g., >= max(1, floor((n-1)/3))), then play C to maintain cooperation now and in future.
     - Otherwise play D.

   Explanation: if many players will stop contributing following your defection, the myopic calculation may understate future losses. This rule pays the small price of occasional cooperation to preserve a profitable stream you can later exploit.

8. Short punishment and forgiveness (to keep others cooperating but deter pure defectors):
   - If some player j who was recently cooperative defects in a way that looks like exploitation of you (e.g., they defected while most others cooperated), and you are not already in the final rounds, respond by defecting for L_punish rounds only against everyone (you cannot target one player in pure action set; uniform punishment is the tool).
   - After L_punish rounds, resume the standard decision rules. If the punished players resume cooperating, you reclassify them as cooperators for future exploitation. Do not sustain long punishments — that reduces your average payoff and invites mutual loss.

9. Occasional recon probe:
   - With small probability q (e.g., 5%), cooperate even if the rules say D. Use these random cooperations to detect whether previously unresponsive players have become cooperative or whether previously cooperative players will tolerate more exploitation. This prevents permanent misclassification.

10. Special-case safety checks:
   - If everyone has defected for many rounds and expected_others_if_C and expected_others_if_D are effectively zero, always defect (no point cooperating).
   - If you detect many unconditional cooperators (more than half are coop_rate_j >= U_t), you can defect persistently to extract maximum benefit, but occasionally (per maintenance/probe rules) return one C in K rounds (K large, e.g., 5-10) if doing so reduces the chance they switch to defection. The idea is: free-ride but not provoke wholesale collapse.

Why this is exploitative and robust
- Exploits unconditional cooperators by defecting whenever cooperating does not increase your expected payoff.
- Exploits conditional cooperators only when you can keep them cooperating cheaply; otherwise defaults to defection.
- Uses empirical responsiveness to detect punishers and avoid triggering costly mutual punishment.
- Keeps punishments short and forgiving to limit retaliation cycles and allow re-exploitation.
- Uses small random probes to detect changes and reclassify players, avoiding permanent loss from misclassification.
- Always defects in the final round to extract immediate surplus.

Edge cases summary
- First round(s): cooperate briefly to probe behavior.
- If little history: probe for up to W rounds; after that rely on observed frequencies.
- Last round: defect.
- Last few rounds: bias toward defection; do not attempt to invest to change last-round outcomes.
- If all others defect: defect (no hope).
- If many unconditional cooperators: defect most of the time; occasionally cooperate per maintenance to avoid collapse.

Implementation notes (for tournament implementers)
- Use W sized window and the conditional-frequency estimates; if counts are too low, fall back to unconditional coop_rate_j.
- Tune thresholds (R_t, U_t, q) conservatively: higher U_t makes you more willing to exploit only very persistent cooperators; higher R_t reduces false identification of reciprocators.
- Keep punishments short (L_punish = 1) to maximize average payoff while still deterring opportunistic one-shot exploiters.

Overall behavioral summary
- Probe early, estimate others’ conditional strategies, then free-ride unless cooperating demonstrably increases your immediate expected payoff or is required to preserve a profitable stream of cooperation. Punish briefly when necessary, forgive quickly, and always defect in the last round.
'''

description_EXPLOITATIVE_52 = '''
Summary: play selfishly but adaptively — probe opponents briefly, classify them by how much they keep contributing and how much they punish your defection, then predominantly free-ride on persistent cooperators while avoiding long, costly wars with punishers. Always defect in the final rounds. Use expected-payoff calculations from observed conditional cooperation rates to choose C or D each round; break ties by defect.

Parameters (set from game parameters; sensible defaults)
- T_probe = min(max(3, ceil(0.05 * r)), 6)  — exploration rounds at start
- T_end = min(3, ceil(0.05 * r))  — last rounds in which we always defect
- W = min( max(5, ceil(0.15 * r)), r ) — rolling window length for estimating recent behavior
- eps_resp = 0.15 — responsiveness threshold to call someone a “retaliator”
- eps_exploit = 0.85 — cooperation rate threshold to call someone an “exploitable cooperator”
- p_probe = 0.2 — probability to cooperate during probe rounds
- p_noise = 0.05 — occasional random cooperation to avoid being perfectly predictable

State tracked (updated each round)
- For each other player j: total rounds observed T_j, count of j’s cooperations C_j, count where j cooperated after I cooperated C_j|myC, after I defected C_j|myD
- From those counts compute:
  - coop_rate_j = C_j / T_j
  - P_j(C | myC) = C_j|myC / (# rounds where I cooperated and j observed)
  - P_j(C | myD) = C_j|myD / (# rounds where I defected and j observed)
- Global recent averages computed over window W and over players as needed

Decision rules (each round t, using only public history and the tracked state)

1. Endgame override
- If t > r - T_end: play D (defect). Never cooperate in the last few rounds.

2. Initial exploration
- If t ≤ T_probe:
  - Cooperate with probability p_probe (to detect reciprocators), otherwise defect.
  - Update statistics and continue.

3. Compute expected consequences of C vs D this round
- For each player j estimate their cooperation probability conditional on my action:
  - If we have enough data for j, use P_j(C | myC) and P_j(C | myD).
  - If insufficient data for j, use coop_rate_j as a neutral estimate for both conditional probabilities.
- Let E_others_if_C = sum_j P_j(C | myC)
- Let E_others_if_D = sum_j P_j(C | myD)
- Expected payoff if I play C:
  - EU_C = 0 + (k / n) * (1 + E_others_if_C)
- Expected payoff if I play D:
  - EU_D = 1 + (k / n) * (E_others_if_D)

4. Primary action choice (exploit when profitable)
- If EU_D > EU_C + tiny_margin (tiny_margin = 0.01), play D (exploit).
  - Rationale: if defecting yields higher expected personal payoff, free-ride.
- If EU_C > EU_D + tiny_margin, play C (invest to sustain cooperation).
- If |EU_C - EU_D| ≤ tiny_margin, break tie by defect (prefer exploitation).

5. Maintainability and low-cost “maintenance” cooperation
- Detect exploitable cooperators: players with coop_rate_j ≥ eps_exploit and responsiveness (P_j(C|myC) − P_j(C|myD)) ≤ eps_resp.
- If multiple exploitable cooperators exist and EU_D > EU_C but by only a small margin (< 0.15), occasionally cooperate with small maintenance probability p_maintain = min(0.25, 2*(fraction_exploitables)) to avoid mass reclassification of those players as “suckers who stop cooperating.”
- Always prefer maintaining exploitation by mostly defecting; maintenance cooperation is rare and randomized.

6. Detect and respond to punishers (avoid destructive wars)
- For each j compute responsiveness_j = P_j(C | myC) − P_j(C | myD).
- If many players (≥ 2 or ≥ ceil(n/4), whichever is larger) have responsiveness_j ≥ eps_resp (they punish defection), and EU_D advantage was driven down by anticipated retaliations (i.e., EU_D not much larger than EU_C or EU_D < EU_C), switch to conditional cooperation mode for a limited “truce”:
  - Conditional cooperation mode: play C this round iff at least T_thresh other players cooperated in the previous round, where T_thresh = max(1, round(0.5 * (n − 1))). This punishes defectors but restores cooperation with reciprocators.
  - Stay in conditional cooperation mode for a short adaptive period (e.g., min(5, ceil(0.1 * r)) rounds) unless statistics change.
- If punishers appear to be directly retaliating to earlier defections and that retaliation persists, reduce maintenance cooperation and prefer early cooperation only when it yields higher EU.

7. Randomization and noise
- With low probability p_noise, flip the chosen action (cooperate if planned D, or defect if planned C). This avoids being exploited by strategies that exploit deterministic patterns and maintains probing.

8. Re-classification and continuous learning
- After each round update all per-player statistics using only the most recent W rounds (sliding window) to remain responsive to opponents who change strategies.
- Re-evaluate exploitable/punisher labels continuously and adjust behavior.

Edge cases and clarifications
- If n = 2 (pairwise PGG equivalent): apply the same logic; responsiveness calculation is clearer and tit-for-tat-like responses are more consequential. Default to defect in final rounds.
- If r is very small (< 6): reduce T_probe to 1 and be conservative: play D unless there is very strong short-term evidence cooperation would raise EU.
- If data are sparse for a player, default to using their overall coop_rate as the conditional estimate and prioritize probing them (small random cooperation) to gain information.
- If all opponents are detected as defectors (low coop_rate across the board), always defect.
- Tie-breaking always favors defect (exploit), unless long-run data strongly support cooperation increasing my payoff.

Why this is exploitative and robust
- Exploitative: the decision rule explicitly compares personal expected payoff from defecting vs cooperating using observed conditional responses and chooses defect when it yields higher personal gain — this free-rides on persistent cooperators and only pays the cooperation cost when it is expected to return more.
- Targeted rather than blind exploitation: classification lets the strategy free-ride on unconditional cooperators while avoiding costly punishments by reciprocators; maintenance cooperation is limited and randomized to sustain exploitation without being predictable.
- Adaptive: probing, sliding-window learning, and conditional-mode switches let the strategy handle a wide range of opponents (always-cooperators, always-defectors, reciprocators, complicated learners).
- Safe in noisy or mixed populations: randomization and limited maintenance cooperation prevent rapid collapse of exploit opportunities and reduce risk of being trapped in destructive all-defect wars.

Short pseudocode-style summary per round
- If round in final T_end: play D.
- Else if in first T_probe rounds: play C with prob p_probe, else D.
- Else:
  - Estimate P_j(C | myC) and P_j(C | myD) for all j.
  - Compute EU_C and EU_D as above.
  - If EU_D > EU_C + 0.01: plan D (but if many exploitable cooperators exist and advantage small, cooperate with small p_maintain).
  - Else if EU_C > EU_D + 0.01: plan C.
  - Else plan D.
  - If many detected punishers and retaliation is lowering EU_D, switch to conditional cooperation mode (cooperate only if sufficient others cooperated last round) for a short period.
  - With probability p_noise flip action.
- Update statistics and repeat.

This strategy requires only the game parameters and observable history. It explicitly pursues exploitation when profitable, protects against persistent punishers, and adapts continuously so it can succeed against a wide variety of opponent behaviors.
'''

description_EXPLOITATIVE_53 = '''
Adaptive Exploiter (AE) — strategy description

Summary of mindset
- My primary objective is to maximize my own cumulative payoff by extracting value from cooperators while avoiding long collapses of cooperation that would lower my future returns.
- I probe early to identify who tends to cooperate, exploit predictable cooperators when safe, punish collective collapse quickly to discourage retaliation, and forgive so cooperators can be re-attracted.
- I defect in the final rounds (endgame) when future leverage disappears.

Parameters (computed from game parameters)
- W = min(10, r-1) — sliding window used to estimate opponents’ behavior.
- ProbeRounds = min(2, r) — initial probing length (usually 1–2 rounds).
- StableCoopThresh = 0.8 — contribution frequency to call a player a “stable cooperator”.
- Majority = ceil((n-1)/2) — majority threshold among other players.
- ExploitCooldown = 1 — minimum non-exploit round between repeated exploitations to reduce risk of immediate collapse.
- MaxConsecutiveExploits = 3 — limit on consecutive exploitation attempts before re-evaluating.
- PunishDuration = min(4, max(1, ceil(0.1*r))) — number of rounds to punish after a noticeable collapse.
- EndgameRounds = min(2, r) — in the final EndgameRounds I always defect.
- DropThreshold = 0.25*(n-1) — if the number of contributors among others falls by this absolute amount (compared to pre-exploit baseline) after I exploit, treat as significant retaliation/collapse.

(These numeric values are chosen to be robust; implementations may scale them with r, n if desired.)

State I track each round
- For each other player j: past contribution frequency p_j over the last W rounds (or all past rounds if fewer than W exist).
- Recent group contribution counts (excluding me) per round.
- Count of consecutive exploit rounds used recently.
- Last pre-exploit baseline of others’ contributions when I last cooperated to test exploitation effect.

Decision rules (round t; use only game parameters and history)

1) Endgame
- If t is within the final EndgameRounds (i.e., r - t < EndgameRounds), play D (defect). No cooperation in last rounds.

2) Initial probing
- If t ≤ ProbeRounds: play C (cooperate). Purpose: identify unconditional/conditional cooperators and make cooperation attractive to them.

3) Classify opponents (after ProbeRounds and in each round thereafter)
- For each opponent j compute p_j = fraction of times j contributed in the last W rounds.
- Let StableCooperators = set of j with p_j ≥ StableCoopThresh.
- Let StableCount = |StableCooperators|.
- Let AvgOtherContrib = average number of contributions by others per round in the last W rounds.

4) If most others are persistent defectors
- If AvgOtherContrib ≤ 0.2*(n-1) (i.e., almost nobody cooperates), play D each round (no point in incurring cost to try to build cooperation).

5) Exploitation opportunity (primary exploit rule)
- Condition to attempt an exploit this round:
  - StableCount ≥ Majority OR (AvgOtherContrib ≥ 0.6*(n-1))
    (i.e., there is a sizable pool of predictable cooperators or high overall cooperation).
  - AND I have not exploited more than MaxConsecutiveExploits in a row.
  - AND at least ExploitCooldown rounds have elapsed since my last exploit attempt.
- If exploitation conditions hold: play D (exploit / freeride).
- Record a baseline: store the number of contributors among others in the round immediately before exploitation (BaselineContrib).

6) Monitor and punish if exploitation collapses cooperation
- After I exploit, compare others’ total contributions in the round immediately after the exploit to BaselineContrib.
- If others’ contributions fall by ≥ DropThreshold (absolute drop) or fall by ≥ 30% (relative), treat as retaliation / collapse.
  - Enter Punish phase: play D for PunishDuration consecutive rounds (or until endgame if sooner).
  - Reset consecutive exploit counter to 0 and re-evaluate after punishment.

7) Gentle conditional cooperation (when exploitation not safe)
- If exploitation conditions do not hold and I am not in punishment or endgame:
  - Use conditional cooperation to sustain cooperation with conditional cooperators:
    - If in the previous round at least Majority of other players contributed, play C this round.
    - Otherwise play D.
  - This rule treats the group as cooperative if a majority contributed last round; it is forgiving (cooperates again when the group looks cooperative) but punishes when the group defects.

8) Special handling of persistent unconditional cooperators
- If there are one or more players with p_j ≥ 0.98 (near-unconditional cooperators), then:
  - I will exploit more aggressively when such players are present because they provide reliable public contributions.
  - Specifically, if StableCount ≥ 1 and AvgOtherContrib ≥ 0.4*(n-1), I will attempt an exploit every ExploitCooldown+1 rounds while monitoring for collapse; if no collapse occurs after MaxConsecutiveExploits, continue periodic exploitation but cap frequency to avoid collapse (enforce ExploitCooldown).

9) Forgiveness and re-attraction
- After a punishment phase completes, resume classification and probing behavior:
  - Play C on the first post-punishment round if a majority of others cooperated in the round before punishment (to re-attract conditional cooperators), otherwise continue conditional cooperation rule (step 7).
- Reset baseline and suspense counters; allow cooperators to rebuild trust but keep exploiting when safe.

10) Last-round explicit rule
- In the final round: always play D (defect). This prevents being left vulnerable with no future leverage.

Practical operational notes (how it behaves, why it is exploitative)
- Early probing (C for 1–2 rounds) invites cooperators and identifies who is exploitable.
- When there is a reliable cooperative cohort, AE freerides (D) to capture the 1 - k/n per-round advantage while keeping exploitation intermittent so the cohort does not immediately collapse.
- If exploitation triggers a rapid decline in others’ contributions, AE punishes by defecting several rounds to inflict a cost on retaliators and demonstrate that exploiting cooperators is not free; punishment is limited to avoid mutual loss and to allow reconciliation.
- If most opponents are defectors or cooperation is rare, AE defects persistently (no sunk cost of naive cooperation).
- AE always defects in the last rounds to prevent being taken advantage of with no future leverage.
- The approach is robust: it adapts to unconditional cooperators (exploit them) and to conditional cooperators (cooperate enough to sustain them when profitable), and it retaliates when others coordinate to punish exploitation.

Edge cases
- r = 1: Only one round — play D (always defect in a one-shot public goods game).
- r small (≤ ProbeRounds): probe phase and endgame overlap; prioritize endgame rule (defect in final round(s)). For r = 2, play C first round (probe), D in last round.
- If n = 2 (pairwise public goods equivalent): Majority thresholds work the same (Majority = 1).
- If k is very close to n (wildly high multiplier), cooperation becomes more mutually beneficial; AE still exploits but may reduce exploit frequency if collapse risk is high because the cost of losing cooperation is higher. Concretely, AvgOtherContrib thresholds (0.6*(n-1) etc.) automatically adjust because they are fractions of group size.

Summary pseudocode (compact)
- If in final EndgameRounds: play D.
- Else if t ≤ ProbeRounds: play C.
- Else compute p_j over W rounds, StableCount, AvgOtherContrib.
  - If AvgOtherContrib ≤ 0.2*(n-1): play D.
  - Else if (StableCount ≥ Majority or AvgOtherContrib ≥ 0.6*(n-1)) and exploit-frequency limits allow:
      play D (exploit); set BaselineContrib and increment exploit counter.
  - Else if recovering from punishment: follow forgiveness rule (cooperate if majority cooperated pre-punishment).
  - Else use conditional cooperation: play C if previous round had at least Majority other contributors, else play D.
- After each round, update histories; if others’ contributions drop by DropThreshold after my exploit, enter Punish phase for PunishDuration rounds.

This strategy is intentionally exploitative: it actively seeks to freeride on reliable cooperators, uses punishment to deter organized retaliation, and limits cooperative investments to when they are likely to produce continued exploitable returns. It is adaptive (classifies opponents and responds to observed dynamics), robust (falls back to defection against mostly-defective groups), and practical for tournament play because it depends only on public history and known parameters.
'''

description_EXPLOITATIVE_54 = '''
Selective Reciprocal Exploiter (natural-language pseudocode)

Goal: maximize my payoff relative to others by (1) exploiting persistent unconditional cooperators, (2) maintaining profitable cooperation with genuine reciprocators when there are enough rounds left to make that worthwhile, and (3) avoiding long, costly mutual punishment. The strategy uses only game parameters (n, r, k) and observed history of each player’s contributions.

State kept (computed from history each round)
- For each opponent j:
  - T_j = number of past rounds observed (0 initially)
  - C_j = number of times j contributed
  - p_j = C_j / T_j (cooperation rate; treat as 0 if T_j = 0)
  - Cj_after_myC, N_after_myC = counts of j cooperating / trials in rounds immediately following rounds when I cooperated
  - Cj_after_myD, N_after_myD = counts of j cooperating / trials in rounds immediately following rounds when I defected
  - response_delta_j = (Cj_after_myC / max(1,N_after_myC)) - (Cj_after_myD / max(1,N_after_myD))  (measure of whether j rewards my cooperation)
- Group statistics:
  - G_prev = fraction of players (including me) who cooperated in the previous round (useful when T>0)
  - remaining = r - current_round + 1 (remaining rounds including this one)

Fixed internal thresholds (functions of n, r, k; can be tuned but use these defaults)
- window_min = min(10, max(3, r)) used implicitly by smoothing; we use all history but give more weight to recent rounds via the response measures
- UNCOOP_RATE = 0.95 (>= this → label as unconditional cooperator)
- RECIPROCATOR_DELTA = 0.20 (>= this → label as reciprocator)
- RECIPROCATOR_MIN_RATE = 0.30 (reciprocators should not be almost never cooperating)
- RECIPROCATOR_FRACTION_TO_COOPERATE = 0.20 (need ≥20% of players to be reciprocators to invest in cooperation)
- MIN_ROUNDS_TO_SUPPORT_COOP = 3 (need at least this many rounds left to sustain cooperation)
- PUNISH_LENGTH = min(3, max(1, remaining // 6)) (length of short targeted punishment)
- ENDGAME_THRESHOLD = min(2, r // 10 + 1) (last few rounds to start defecting for backward-induction)

Decision rules (evaluated each round before choosing action)
1. Endgame / last round
   - If remaining ≤ ENDGAME_THRESHOLD: defect. (Backward-induction: avoid being exploited on the final moves.)

2. Initial probe
   - If current_round = 1: cooperate. (Single cheap probe to reveal cooperators/responders. If r is tiny, see endgame rule which overrides.)

3. Classify players from history
   - For each j:
     - If p_j ≥ UNCOOP_RATE and response_delta_j ≤ 0.05 → mark j as Unconditional Cooperator (naive cooperator).
     - Else if response_delta_j ≥ RECIPROCATOR_DELTA and p_j ≥ RECIPROCATOR_MIN_RATE → mark j as Reciprocator.
     - Else if p_j ≤ 0.10 → mark j as Defector.
     - Else → mark j as Mixed/Noisy.

4. Exploit naive cooperators when safe
   - If there exists at least one Unconditional Cooperator AND
     the fraction of Reciprocators among players < RECIPROCATOR_FRACTION_TO_COOPERATE:
     - Defect. Reason: can safely free-ride on naive cooperators without triggering sufficient reciprocal punishment to make cooperation profitable.

5. Selective cooperation to sustain profitable reciprocity
   - Else if fraction of Reciprocators ≥ RECIPROCATOR_FRACTION_TO_COOPERATE AND remaining ≥ MIN_ROUNDS_TO_SUPPORT_COOP:
     - Play a “lenient group tit-for-tat”:
       - If majority of players cooperated in the previous round (G_prev > 0.5): cooperate.
       - If exactly half cooperated (rare tie): cooperate if my own recent cooperation rate > 0.4, else defect.
       - If majority defected in previous round: defect.
     - Rationale: when enough reciprocators exist and many rounds remain, sustaining mutual cooperation yields higher long-run payoff even if immediate incentive is to free-ride.

6. Targeted exploitation of single cooperators
   - If there are one or a few Unconditional Cooperators but a substantial core of mixed or defector players and reciprocators fraction is borderline:
     - Defect against the whole group (public goods is symmetric) but monitor response: if reciprocators start punishing (their p_j drops after my defection), switch to rule 5 to recover cooperation.
     - Rationale: exploit singletons but be ready to repair relations when punished.

7. Punishment and forgiveness (if I detect punishment)
   - If any Reciprocator’s cooperation rate declines sharply after my defections (response shows negative shift), trigger targeted short punishment by defecting for PUNISH_LENGTH rounds (group-level defection is the only possible action) and then allow forgiveness:
     - After PUNISH_LENGTH defect rounds, resume following rule 5 (if reciprocators remain) or rule 4 (if few reciprocators).

8. Noisy / ambiguous environment default
   - If history is too short or mixed signals dominate (no clear Unconditional Cooperators and reciprocators fraction < RECIPROCATOR_FRACTION_TO_COOPERATE):
     - Default to defect (safe, exploit any occasional cooperators) except remain willing to switch to rule 5 if patterns of reciprocity form.

Implementation notes (how it adapts and stays robust)
- The strategy continuously re-estimates p_j and response_delta_j from the observed history; it therefore adapts to opponents who change behavior.
- It only cooperates when there is a credible, reasonably large set of reciprocators and enough rounds remain for the benefits of cooperation to outweigh the immediate incentive to free-ride.
- It immediately exploits persistent unconditional cooperators by defecting, but monitors for retaliation and will switch to cooperative sustainment if retaliation appears (to avoid long costly wars).
- It defects in the final rounds to avoid being exploited by opportunistic cooperators exploiting backward induction.
- It uses short, proportionate punishments (not perpetual grim) so that repairing mutually beneficial cooperation is possible when advantageous.

Examples of behavior summary
- Facing mostly unconditional cooperators and few reciprocators: defect every round (exploit).
- Facing many reciprocators and long horizon: cooperate as a group-level lenient TFT to sustain high joint contributions while occasionally exploiting pure naive cooperators if present.
- Facing majority defectors or ambiguous opponents: defect to avoid being the sucker.
- Final 1–2 rounds: defect.

Why exploitative
- The strategy deliberately defects whenever it can safely extract extra immediate payoff from naive cooperators, while selectively investing cooperation only when there is a high likelihood of sustained reciprocation that compensates for the immediate cost of contributing. It balances short-run exploitation with conditional long-run cooperation to preserve profitable relationships and to avoid being permanently punished.
'''

description_EXPLOITATIVE_55 = '''
Name: Adaptive Exploiter (AE)

Summary (one line): Start by probing to identify who reliably cooperates, then free-ride (mostly defect) against those exploitable cooperators while cultivating new cooperators when none are exploitable; punish briefly if many players retaliate, allow forgiveness, and always defect in the known endgame.

Notation and bookkeeping (what I track)
- For each opponent j keep:
  - total_coop_j = number of rounds j contributed so far
  - recent_coop_j = fraction of j’s contributions over a sliding window W (see parameter choices)
  - cond_coop_after_my_D_j = fraction of j’s contributions on rounds following rounds in which I defected (measuring whether j continues to cooperate after I defect)
- rounds_left = r − t + 1 (t = current round number)
- global_recent_coop = average recent_coop_j across j ≠ me

Parameter choices (deterministic function of n and r)
- Window W = min(10, max(3, floor(r/10))). (Short window for small r; limited memory otherwise.)
- Probe_length = min(3, max(1, floor(r/20))) rounds (initial probing)
- cooperator_threshold = 0.75 (high recent cooperation rate identifies a cooperator)
- exploitable_response_threshold = 0.60 (if a player keeps cooperating after my defections at ≥ this rate, I call them exploitable)
- forgiveness_tolerance = allow up to 1 or 2 unexpected defections in W before treating a player as noncooperative (noise tolerance)
- p_guard_coop = max(0.03, min(0.1, 5.0/r)) (small probability of cooperating while exploiting to avoid immediate collapse of cooperation)
- Endgame_hard_defect = last 2 rounds: always defect
- Rampdown_period = min(5, floor(r/10)) rounds before Endgame: progressively reduce any cooperative gestures to prepare for endgame

High-level phases
- Probe phase (initial): try to identify cooperators.
- Exploit phase: free-ride on identified exploitable cooperators, cooperating only rarely and conditionally.
- Cultivate phase: if no exploitable cooperators are available, cooperate for a time to cultivate willing cooperators.
- Punish / Reset: if exploitation causes broad retaliation, switch to punishment (temporary mass defection) then re-enter Probe/Cultivate.
- Endgame: deterministic defection in final rounds.

Detailed decision rules (what I do each round)

1) Endgame handling (highest priority)
- If rounds_left ≤ 2: defect (D). Never cooperate in the last 2 rounds.

2) Early probing
- If t ≤ Probe_length: cooperate (C). Purpose: reveal which players are willing to cooperate initially.

3) Update statistics
- After each round observe each j’s action and update total_coop_j, recent_coop_j (over last W), cond_coop_after_my_D_j (calculate as fraction of j’s cooperations on rounds that immediately followed rounds where I played D in the past W rounds), and global_recent_coop.

4) Identify exploitable cooperators
- Define ExploitSet = { j : recent_coop_j ≥ cooperator_threshold AND cond_coop_after_my_D_j ≥ exploitable_response_threshold }.
  - Intuition: these players both cooperate frequently and keep cooperating even when I defected → good targets for exploitation.

5) Core decision: Exploit vs Cultivate vs Punish
- If ExploitSet non-empty AND global_recent_coop (excluding me) is reasonably high (e.g., ≥ 0.30), enter Exploit mode this round:
  - Primary action: defect (D) to free-ride on the contributions of others.
  - Exception (stochastic “keep-alive” cooperation): with small probability p_guard_coop, cooperate (C). This rare cooperation serves to limit wholesale collapse: by occasionally contributing I create ambiguity that I’m not permanently a full defector and reduce the chance that every cooperator immediately quits.
  - Monitor responses: if within the next W rounds a large fraction of opponents significantly reduce cooperation (global_recent_coop drops by > 0.20) and many players’ cond_coop_after_my_D_j fall below exploitable_response_threshold, treat this as broad retaliation → go to Punish/Reset step below.
- Else (ExploitSet empty OR global cooperation too low):
  - Enter Cultivate mode:
    - Cooperate (C) for up to Cultivate_length = min(W, max(2, floor(r/10))) consecutive rounds or until ExploitSet becomes non-empty. The goal is to attract conditional cooperators by demonstrating cooperation.
    - While cultivating, if a player defect patterns suggest they are pure defectors (recent_coop_j ≤ 0.15 and never respond to my C), ignore them for exploitation decisions.
- Punish / Reset (if exploited players detect and retaliate or if I am losing expected payoff):
  - If after a recent exploitation attempt global cooperation collapses (global_recent_coop falls by > 0.20) or more than half the players drop cooperation to near-zero, respond with a short punishment: defect for Punish_length = min(W, 3) rounds (mass defection) to impose immediate group cost and signal a reset.
  - After punishment, re-enter Probe phase for Probe_length rounds (cooperate initially to test if some players return to cooperative behavior).
  - This avoids endless erosion of group cooperation while also discouraging coordinated punishment strategies that try to drive me into always defecting.

6) Noise tolerance and forgiveness
- Do not permanently label a player noncooperative after 1–2 defections: require sustained low recent_coop_j (below 0.15 for at least W rounds) before giving up on them.
- If a previously exploitable player drops below exploitable_response_threshold but then recovers cooperation, allow them back into ExploitSet only after they satisfy recent_coop_j ≥ cooperator_threshold again.

7) If multiple opponents appear to be punishers (they reduce cooperation each time I defect)
- If the majority of opponents have cond_coop_after_my_D_j < 0.40 (i.e., they retaliate when I defect), exploitation is too costly. Favor Cultivate: cooperate more to attempt to build mutual cooperation rather than repeatedly provoking punishment.

8) Safety check: expected-payoff heuristic (simple immediate check)
- Each round optionally compute a simple immediate estimate: predicted_others = sum_j recent_coop_j (j ≠ me). If predicted_others is very low (e.g., predicted_others ≤ 0.5), there is little to exploit — prefer to cooperate to try to raise future contributions. If predicted_others is high (several cooperators), exploit as above.

Practical notes and rationale
- Exploitation logic: the strategy seeks to free-ride whenever there exist opponents who consistently contribute even after I defect; those opponents fund my higher immediate payoffs. The rare cooperative gestures (p_guard_coop) prevent a single-shot defection pattern from immediately collapsing all cooperation.
- Adaptivity: AE constantly updates per-player statistics and the global cooperation environment; it switches modes (Exploit, Cultivate, Punish) based on observed responses rather than assuming fixed opponent types.
- Robustness: forgiveness windows and sliding-window statistics protect against noise and mistakes; punishment/reset prevents long-term decline of group cooperation (which would reduce exploitation opportunities).
- Endgame: deterministic defection at the end avoids being exploited in the final unavoidable rounds.

Edge cases
- Very short games (r ≤ 3): skip long probes. Rounds 1..r−2 follow the simple heuristic; last 2 rounds defect. If r = 1, defect.
- All opponents always defect: AE recognizes low recent_coop_j and stays defect-heavy to avoid wasting tokens; will opportunistically try short cultivation periods, but if no response, it gives up.
- All opponents always cooperate (naïve cooperators): After seeing consistent cooperation and that they do not punish my defections (cond_coop_after_my_D_j high), AE will defect continuously (with occasional tiny cooperation p_guard_coop) to harvest huge payoff advantage.
- Many retaliators: If most players punish defections, AE behaves like a conditional cooperator: cooperates enough to maintain mutual cooperation because exploitation becomes costly.

Summary decision checklist (per round, in priority order)
1. If rounds_left ≤ 2 → D.
2. If in initial Probe rounds → C.
3. Update statistics.
4. If ExploitSet non-empty and global_recent_coop is nontrivial → normally D (rarely C with probability p_guard_coop).
5. Else if no exploitable opponents → enter Cultivate and play C for cultivation period.
6. If exploitation provokes broad retaliation → Punish short term (D), then re-probe.
7. Always allow forgiveness and re-evaluation using sliding window W.

End objective
- Maximize my own cumulative payoff by identifying persistent cooperators to free-ride on while avoiding permanent collapse of useful cooperation through smart, minimal cooperation gestures, brief punishments, and forgiving re-probing.
'''

description_EXPLOITATIVE_56 = '''
Name: Exploitative Conditional Cooperator (ECC)

Overview (high level)
- Goal: extract surplus by free‑riding when others are reliably contributing, while avoiding long runs of being exploited by defectors. Combine short, cautious cooperation signals with brief, targeted exploitation bursts plus finite punishment and forgiveness so cooperation can recover. No reliance on communication or coordination.

Fixed internal parameters (computed from game parameters)
- n, r, k are known.
- Memory window W = min(5, t-1) (use up to the last 5 rounds; smaller at the start).
- Persistence window M = min(3, t-1) (look for persistent defectors over up to 3 rounds).
- Endgame horizon R_end = min(2, r-1) (always defect in the last R_end rounds).
- Punishment length P = min(4, r_remaining) if punishment is triggered.
- Forgiveness/test length F = min(2, r_remaining) after a punishment period.
- High cooperation threshold q_high = 0.8; low cooperation threshold q_low = 0.4.
(These constants are fixed but chosen to be conservative and depend only on n,r,k via r_remaining.)

Decision rules (per round t, using only public history and the parameters above)

1) Endgame
- If r - t < R_end (i.e., you are in the last R_end rounds), play D (defect). Do not cooperate in the final rounds.

2) First round
- If t = 1, play C (cooperate). Signal willingness to support cooperation and test opponents.

3) Compute recent statistics
- Let others’ cooperation count in the last W rounds be SumOthers = sum over the last W rounds of the number of other players who contributed.
- Cooperation rate = SumOthers / (W * (n-1)). (If W = 0 because t=1, skip and treat as first-round rule.)
- For each opponent, compute how many times they defected in the last M rounds. If any opponent defected in all M rounds, treat that as a persistent defector signal.

4) Persistent‑defector response (avoid being repeatedly exploited)
- If any opponent is a persistent defector (defected in all of the last M rounds), enter Punish mode: play D for P consecutive rounds (or until the game ends). This prevents repeated unilateral cooperation that persistent defectors would exploit. After P rounds of punishment, follow the Forgiveness/Test step below.

5) Baseline exploitation / cooperation rules (when not in punishment or endgame)
- If cooperation rate >= q_high (others were very reliably cooperating recently):
  - Exploit burst: If your own last action was C (you have been cooperating), play D this round to free‑ride once.
  - If your own last action was D (you just exploited), play C this round to re‑establish cooperative credibility.
  - In short: alternate a single defection after at least one cooperative signal, never defect repeatedly more than once in a row while others remain very cooperative. This extracts gains fast while preserving enough signal to sustain others’ cooperation.
- Else if cooperation rate is between q_low and q_high:
  - Reciprocity by majority last round: look at the previous round only; if a majority of the other players contributed last round, play C; otherwise play D. (This rewards recent group cooperation and punishes recent group defection.)
- Else (cooperation rate < q_low):
  - Play D. When collective contributions are low, defect to avoid being a sucker and to pressure the group.

6) Forgiveness / testing after punishment
- After completing a punishment block of P rounds, play C for F rounds (or until the game ends) as a test: if group cooperation recovers (cooperation rate in those tests rises above q_low), revert to the baseline rules. If not, return to Defecting until cooperation signals change.

7) Robustness to noise and exploitation
- Never permit yourself to be the only consistent cooperator: if you find you played C for S consecutive rounds (S ≥ 3) while group cooperation rate remained below q_low, switch to permanent D for the remainder of the game (you will stop feeding persistent non‑cooperation).
- Always treat public history strictly: decisions are based only on observed contributions and payoffs (no hidden assumptions, no side channels).

Rationale and exploitative behavior
- Lure and exploit: starting with C and using single-round exploit bursts when others are reliably cooperative extracts surplus (you receive the benefit of others’ contributions without paying the cost) but alternating with cooperation avoids destroying the cooperation signal entirely.
- Punish persistent defectors: short, finite punishments deter repeated exploitation and avoid being the long-term sucker.
- Forgiveness ensures cooperation can be re-established after punishing misbehavior; finite punishment prevents endless mutual destruction.
- Endgame defection prevents being exploited by backward induction.
- The strategy adapts to a wide range of opponents: it gains against unconditional cooperators (by free‑riding bursts), avoids sustained loss to defectors (by punishing/withdrawing cooperation), and responds appropriately to conditional strategies that attempt reciprocity.

Edge cases summary
- First round: C (test/cooperate).
- Last R_end rounds: always D.
- If any opponent defects persistently over M rounds: D for P rounds (punish), then F rounds of C as a test.
- When others are highly cooperative: exploit with single-round defections interleaved with cooperation.
- If collective cooperation collapses: default to D to avoid being exploited.

This strategy depends only on the public history and game parameters and balances exploitation, punishment, and forgiveness to be robust in tournament play.
'''

description_EXPLOITATIVE_57 = '''
Name: Exploitative Conditional Maintainer (ECM)

Summary intuition (one line)
- Start by probing to find players who persistently contribute; then mostly free‑ride on those cooperators while making rare, targeted contributions to keep them willing to cooperate; if exploitation triggers sustained punishment or cooperation collapses, switch to permanent defection.

Parameters computed from game inputs
- r = number of rounds; n = number of players; k = multiplier.
- Probe length P = max(1, min(5, floor(r/10))). (Short, informative probe phase.)
- History window W = min(10, r) for short-term responsiveness.
- Maintenance interval M = max(3, floor(r/10)). (How often we do a “maintenance” cooperation while exploiting.)
- Cooperator threshold alpha = 0.6 (a player is treated as a cooperator if they contributed in >= alpha fraction of the relevant window).
- Group cooperation alarm delta_drop = 0.25 (significant drop in others’ average contribution).
- Recovery length R = min(3, r) (short attempt to repair cooperation).
- Final-round safety E = 2 (always defect in last E rounds).

State we track (from public history)
- For each other player j: contribution rate over the probe phase and over last W rounds.
- Group other-players’ average contribution per round over probe and over last W rounds.
- My own recent actions and my recent payoffs.

Decision rules (phase-based)

Phase A — Probe (rounds 1..P)
- Purpose: detect who is reliably contributing.
- Policy:
  - Round 1: Cooperate (C). This reveals some responses and is a low-cost investment in locating naive cooperators.
  - Rounds 2..P: Cooperate in probe rounds unless clear evidence emerges that everyone else is permanently defecting (i.e., group other-players’ contribution = 0 in every probe round so far). If everybody else is clearly never contributing, switch to permanent defection (Phase D).
- After P rounds, mark as “candidate cooperators” every player j whose contribution frequency during the probe ≥ alpha.

Phase B — Assess & choose mode (immediately after probe)
- If at least one candidate cooperator exists, enter EXPLOIT mode.
- If zero candidate cooperators, enter DEFECT mode (permanent D until end or until a clear new opportunity appears).

Phase C — Exploit mode (default while rounds remaining > E)
- Default action each round: Defect (D) — maximize immediate payoff by free-riding.
- Maintenance: every M rounds (counting only rounds since entering Exploit), perform a maintenance cooperation (play C) if the following hold:
  - The other-players’ average contribution over last W rounds (excluding me) is ≥ alpha (they are still cooperating enough).
  - I have not cooperated in the last M rounds.
  - Purpose: a small signal / investment to sustain conditional cooperators who look at public history.
- Reactive repair: if after one or two defections by me the group other-players’ average contribution over the last W rounds falls by ≥ delta_drop relative to the probe average (they are punishing me), then:
  - Enter RECOVER sub-mode: play C for R consecutive rounds to try to restore cooperation.
  - If after recovery the group cooperation returns above alpha, resume Exploit mode.
  - If cooperation remains low or my per-round payoff has fallen below what I would get from permanent defection (estimate comparing my average payoff last W rounds to the all-defect baseline 1), then switch to DEFECT mode (permanent D).
- Safety near the end: when rounds remaining ≤ E, always defect (D).

Phase D — Defect mode (permanent)
- Play Defect (D) every round until the game ends or until you see a clear new cluster of newcomers repeatedly cooperating: if for a continuous window of length max(P, W) the group other-players’ average contribution has been ≥ 0.9 and my own recent payoff suggests cooperating could be profitable, you may re-enter Probe for a fresh assessment. (This prevents you from forever giving up on a suddenly cooperative group.)

Edge cases and further rules
- Final rounds: in the last E rounds (default E = 2) always defect (backward induction safe play).
- Very short games (r ≤ P): probe phase dominates — follow probe rules; when only 1 round total, defect only if you expect no reciprocation; default still: first-round cooperate only if r > 1, else defect on the single round. (Implementation note: set P := min(P, r-1) so you never “invest” on the last round.)
- If the tournament environment shows noisy mistakes (occasional random flips), the maintenance and recovery parameters are conservative (short recovery R, requiring a large drop delta_drop to trigger recovery) so the strategy is not overly reactive to noise.
- Parameter sensitivity: alpha, M, delta_drop, P can be tuned by tournament meta‑learning. The high-level behavior — probe to find cooperators, mostly defect, occasional maintenance contributions, quick recovery attempts, and a hard switch to permanent defection under sustained punishment — should be preserved.

Why this is exploitative and robust
- Exploitative: After identifying persistent cooperators, ECM takes D as the default to capture the extra 1 − k/n gain every round while relying on others’ contributions to inflate the public good payoff. Maintenance cooperations are deliberately rare and timed to preserve others’ incentive to contribute while minimizing the cost borne by us.
- Adaptive: The probe phase finds exploitable cooperators; the maintenance mechanism keeps them cooperating; the reactive recovery and payoff checks detect when exploitation provokes costly punishment and then switch to safe defection.
- Robust: Works against unconditional cooperators (free-rides on them), conditional cooperators (keeps them in the cooperative loop with occasional signals), and harsh punishers (detects and aborts exploitation to avoid net loss). It does not rely on coordination or shared norms and uses only public history and game parameters.

Concrete round-by-round pseudocode (succinct)
- On each round t with Rleft = rounds remaining:
  1. If Rleft ≤ E: play D.
  2. Else if t ≤ P (Probe): play C except if group other-players’ contributions were zero every probe round so far → switch to DEFECT mode and play D.
  3. Else if in DEFECT mode: play D (unless a continuous window of length max(P,W) shows group other-players’ average contribution ≥ 0.9 → go to Probe).
  4. Else (in EXPLOIT mode):
     a. If my last defections coincided with a drop in others’ contributions ≥ delta_drop compared to probe average → play C for R rounds (RECOVER). After recovery, if no improvement → switch to DEFECT.
     b. Else if (current round index since entering Exploit) mod M == 0 and other-players’ avg contribution over last W ≥ alpha and I haven’t cooperated in last M rounds → play C (maintenance).
     c. Else play D.

End result
- ECM is an exploit-first, low-cost maintenance strategy: probe briefly, then mostly defect to harvest gains, interleave rare cooperative moves to keep conditional cooperators on-side, and retreat to unconditional defection if exploitation provokes unprofitable punishment.
'''

description_EXPLOITATIVE_58 = '''
Exploitative Conditional Free‑rider (ECF)

Summary of intent
- Default objective: maximize my own payoff by free‑riding on others’ contributions whenever doing so is profitable and sustainable, while avoiding long runs of mutual collapse that reduce my gains.
- Key ideas: detect who reliably contributes; defect to capture value from reliable cooperators; probe occasionally to learn whether opponents will tolerate exploitation; repair cooperation briefly when conditional cooperators punish; always defect in the known final rounds.

Parameters derived from game inputs (use these exact formulas)
- Window W = min(10, max(1, floor(r/5))). (Use up to 10 most recent rounds to estimate behavior.)
- Probe probability ε = min(0.10, 3 / max(1,r)). (Small, decaying probe rate.)
- High‑cooperator threshold TH_high = 0.9.
- Collapse threshold TH_collapse = 0.2.
- Repair length K_repair = 2 rounds.
- Endgame horizon: last T_end = min(2, r) rounds (always defect in these rounds).

Information used
- For each opponent j compute f_j = fraction of rounds they contributed over the last W rounds (or over all rounds so far if fewer than W).
- Let F_group = average_j f_j (average of others’ recent cooperation frequencies).
- Let last_round_coop_count = number of opponents who contributed in the immediately previous round.
- Detect punishment: if after I defected in round t0, some opponent’s f_j declines by ≥ 0.3 in the subsequent W window relative to the window before t0, treat that opponent as a retaliator.

Decision rules (priority order)
1. Endgame: If current round t > r − T_end, play D (defect). (Exploit by default at the end.)

2. Detect group collapse: If F_group < TH_collapse (very low recent cooperation overall), switch to permanent defection (play D every round). (When cooperation is dead, there is no exploitable stream to ride.)

3. If last round all opponents (n−1 players) contributed (last_round_coop_count = n−1):
   - Play D (free‑ride) in this round to capture the full benefit of others’ joint contribution.
   - Exception: with probability ε, play C instead of D (probe/coax) to avoid causing a permanent collapse if opponents are sensitive. (This keeps cooperation sustainable if opponents are conditional reciprocators.)

4. If a majority of opponents are high cooperators (number of j with f_j ≥ TH_high ≥ ceil((n−1)/2)):
   - Default to D to exploit them.
   - But with probability ε in any given round, play C (randomized cooperation) to maintain the appearance of willingness to cooperate and to reduce the chance that many conditional cooperators simultaneously punish.

5. If you detect punishment behavior against your prior defections (any opponent flagged as retaliator):
   - Attempt a short repair: play C for K_repair consecutive rounds to restore cooperation with conditional reciprocators, then resume the exploit routine (steps 2–4).
   - If repair fails (F_group does not rise after repair), revert to permanent defection.

6. If none of the above triggers (ambiguous/no strong cooperators):
   - Default to D (safe selfish play).
   - Occasionally (with probability ε) play C as a probe to detect latent cooperators and to potentially start a cooperative window that can be exploited under rule 3.

Edge cases and notes
- First round: play C. (Small initial cooperation improves chances of finding cooperative opponents and is cheap to the strategy because it is followed by exploitation.)
- Short games (small r): ε is larger relative to r (via ε = min(0.10, 3/r)) so we probe more early on; endgame rules quickly force defection in the final rounds.
- If multiple opponents are clearly retaliatory, the repair attempt is short (K_repair = 2). If their response is to resume cooperating, I exploit; if they continue to punish, I stop cooperating to avoid being exploited.
- All thresholds are conservative and use only the observed contributions in recent rounds; no assumptions about others’ internal goals are required.
- The strategy is deterministic except for the controlled small randomization (probability ε) used only for probing/forgiveness; this prevents easy exploitation by simple reciprocators that might otherwise coordinate to eliminate me.

Why this is exploitative and robust
- Exploitative: whenever others provide a calculable stream of contributions (full‑round cooperation or many high‑frequency cooperators), the strategy defects to capture value, only paying occasional small costs to keep those streams alive.
- Adaptive: it learns from recent history who is reliably cooperative and who punishes; it probes, repairs, and withdraws accordingly.
- Robust: when cooperation is absent or opponents punish reliably, the strategy falls back to safe defection to avoid net loss; small randomized probes detect switching opportunities without exposing long vulnerabilities.
'''

description_EXPLOITATIVE_59 = '''
Name: Opportunistic Classifier-and-Exploit (OCE)

Summary (one line)
- Exploit unconditional cooperators, sustain cooperation only with responsive reciprocators when it benefits me, probe occasionally to find new exploit opportunities, and always defect at the final turn(s).

State I keep (computed from the common history each round)
- r = total rounds, n = players, k = multiplier (given).
- For each other player j: cooperation rate over last W rounds, C_rate_j.
- Over last W rounds: total contributions by others each round; compute average others_coop_rate = average fraction of other players who contributed.
- Responsiveness score for each j: how much j’s cooperation probability drops after I defected in the previous round(s).
- Window size W = min(10, max(1, floor(r/5))) (short games use shorter memory).
- Small probing probability epsilon = min(0.15, 3 / max(10, r)).

Classification (updated each round)
- Unconditional cooperator (prey): C_rate_j >= 0.9 over W AND responsiveness low (their cooperation does not fall after I defect).
- Reciprocator: C_rate_j >= 0.5 and responsiveness high (they cut cooperation after I defect).
- Defector: C_rate_j <= 0.2.
- Others: Neutral / mixed.

Decision priority (what I do this round)
1. Endgame rule
   - If this is the final round: Defect.
   - If within last K_end rounds (K_end = min(3, floor(r/10))): default to Defect unless there is a long-standing cooperating coalition that clearly rewards continued cooperation for me (see Rule 3). In practice I will mostly defect in last few rounds to avoid being suckered.

2. Exploit obvious prey
   - If there are at least M_prey other players classified as Unconditional cooperators where M_prey >= max(1, ceil((n-1)/3)):
     - Defect. Rationale: these players keep contributing even when I defect; defecting yields me strictly higher payoff while they keep contributing.
   - (This is the core exploit move: free-ride on predictable cooperators.)

3. Sustain profitable reciprocation
   - If a large cooperating cluster of reciprocators/neutral players exists such that cooperating will likely engender continued mutual cooperation and thus higher long-run payoff for me, cooperate; otherwise defect.
   - Operational rule:
     - Let last_round_others = number of other players who contributed in previous round.
     - Set T_coop = max(1, ceil((n-1)/2)). (Require roughly a majority of others cooperating last round.)
     - If last_round_others >= T_coop AND at least half of the players who contributed last round are classified as Reciprocators or Neutral (not Defectors):
       - Cooperate this round. Rationale: cooperating when a majority of reciprocators are cooperating sustains long-run gains from mutual cooperation with players who will punish me if I exploit them.
     - Else Defect.

4. Probing and reclassification
   - With small probability epsilon do a probe (take the opposite of the rule above; i.e., cooperate when I would otherwise defect, or defect when I would otherwise cooperate) to test whether the population’s behavior changed or to lure unconditional cooperators into revealing themselves.
   - If I defect and many others continue to contribute, those contributors get labeled Unconditional cooperators (prey).
   - If I defect and several reduce or stop contributing, they are Reciprocators; I should treat them with conditional cooperation in future (Rule 3).

5. Recovery and forgiveness
   - If I detect coordinated punishment that reduces my payoff substantially after my defection, switch to conditional cooperation with those punishers: cooperate whenever last_round_others >= T_coop and they have been cooperating recently, otherwise defect.
   - Forgive after a short punishment window: if a Reciprocator resumes cooperating for F rounds (F = min(3, W)), treat them as Neutral/Reciprocator again.

6. Special-case short games
   - If r is very small (r <= 3), default to Defect every round (risk of being exploited is high and limited opportunity for reciprocation).

Behavioral explanation / exploitation rationale
- Primary exploit: identify and continuously defect against players who keep contributing despite my defection (they are “prey”) — this yields immediate free-rides every round until they change behavior.
- Secondary concern: avoid persistent retaliation that would lower my long-run payoff. Against players who punish me, adopt conditional cooperation (only cooperate when a clear majority cooperated last round) to sustain profitable mutual cooperation.
- Probing is used to discover new prey or to test whether defectors can be converted into reciprocators; probes are rare so they do not meaningfully reduce my payoff unless strategically useful.
- Endgame defection reduces being exploited in the inevitable backward-induction zone.

Parameter guidance (how thresholds depend on n, k, r)
- Window W scales with r so I learn quickly in short tournaments and use more history for long tournaments.
- T_coop uses a majority threshold so I only sustain cooperation when there is a reasonable chance of coordinated reciprocation; being conservative avoids being exploited by small cooperative minorities.
- M_prey is a modest fraction of the group (≈ (n-1)/3) so I only confidently exploit when there are multiple clear unconditional cooperators rather than risk antagonizing a useful cooperating majority.
- epsilon is small and decays with larger r so probing is infrequent in long tournaments (I can afford to wait) and slightly more frequent in short tournaments (need faster learning).

Implementation-style pseudocode (high-level)
- Each round:
  1. Update W-window stats and classify players into Unconditional, Reciprocator, Defector, Neutral.
  2. If final round → Defect.
  3. If count(Unconditional) >= M_prey → Defect (exploit).
  4. Else compute last_round_others and apply Rule 3 (cooperate if last_round_others >= T_coop and majority of those are Reciprocator/Neutral; else Defect).
  5. With prob epsilon flip the chosen action to probe.
  6. If punished heavily in recent rounds, bias toward cooperating conditionally to rebuild relations; if forgiven then revert to exploit/conditional policy.

Notes on robustness
- Works without communication and uses only observed contributions/payoffs.
- Adapts to many opponent types: exploits pure cooperators, cooperates with reciprocators when profitable, ignores pure defectors.
- Periodic probing ensures it can detect strategy shifts and newly exploitable opponents.
- Endgame defection and small-window learning reduce being trapped by backward induction or long-term exploitation.

Mindset
- Opportunistic and risk-aware: take free-rides when they clearly exist; otherwise sustain cooperation only when it is a reliable, enforceable source of mutual benefit.
'''

description_EXPLOITATIVE_60 = '''
Adaptive Exploiter (natural-language pseudocode)

Overview of idea
- Learn each opponent’s type from history (pure cooperator, conditional cooperator/reciprocal, punisher/retaliator, or defector) and estimate how much my cooperation changes others’ future cooperation (“influence”).
- Exploit predictable cooperators by defecting whenever it is safe to do so; seed cooperation only when the estimated future benefit (through inducing others to contribute) outweighs the immediate cost of contributing.
- Use short, cheap punishments only when necessary to deter being systematically exploited; avoid long costly punishments that reduce my own payoff.
- Always defect in the final rounds where cooperation cannot be sustained.

Notation I use below
- t = current round (1..r). R = remaining rounds = r - t.
- For each opponent j keep counts from history: coop_j (times j contributed), coop_after_my_C_j (times j contributed in a round immediately after I cooperated in the previous round), coop_after_my_D_j, total_interactions_j.
- p_j = coop_j / total_interactions_j. p_others_recent = average p_j across others calculated over a recent window W = min(10, max(3, r//10)).
- MPCR = k / n.
- influence_est = estimated per-round increase in others’ cooperation following one of my cooperations (computed from history as average change in others’ cooperation after my C vs after my D; see rule below).
- Thresholds (parameter choices tied to game length): pure_coop_thresh = 0.95; conditional_thresh = 0.20; punisher_thresh = 0.60; exploit_thresh = 0.6. (These are internal parameters; they scale with W and r implicitly.)

How I classify opponents (continuously updated)
- Pure cooperator: p_j ≥ pure_coop_thresh (cooperates almost always). They are fully exploitable.
- Conditional/reciprocal: coop_after_my_C_j − coop_after_my_D_j ≥ conditional_thresh (they respond positively to my cooperation).
- Punisher/retaliator: probability they defect the round(s) after I defect is ≥ punisher_thresh (they retaliate to my D).
- Defector: p_j ≈ 0 (very low p_j) and not responsive.

How I estimate influence_est
- Compute avg_coop_after_C = average fraction of others’ cooperations in rounds that follow rounds where I cooperated (use window W).
- Compute avg_coop_after_D = average fraction of others’ cooperations in rounds that follow rounds where I defected.
- influence_est = avg_coop_after_C − avg_coop_after_D (estimated increase in others’ cooperation attributable to my cooperation). If insufficient data, set influence_est = 0 and rely on probing.

Decision rule each round (ordered logic)
1. Endgame: if t = r (last round) or R is very small (R ≤ 2), play D. (No point seeding cooperation in the terminal rounds.)
2. Immediate exploitation of pure cooperators: if any opponent is classified as pure cooperator, play D (exploit them every round). Pure cooperators are extremely profitable to free-ride on.
3. Compute p_others_recent (average cooperation among others in last round(s)). If p_others_recent ≥ exploit_thresh and few opponents are punishers:
   - Play D to harvest their contributions (they provide a reliable public good that I can free-ride on).
   - However, if a significant fraction of opponents are classified as punishers/retaliators, skip this unconditional exploitation and fall back to the “avoid retaliation” rules below.
4. Influence-based seeding (when cooperation induction could pay off):
   - Compute expected_future_net_gain ≈ MPCR * influence_est * R − 1.
   - If expected_future_net_gain > 0 (my cooperation now is expected to generate enough extra contributions by others over the remaining rounds to outweigh my immediate cost), play C (seed cooperation).
   - If influence_est > 0 but expected_future_net_gain ≤ 0, occasionally seed anyway but rarely: cooperate with small probability p_seed = min(0.25, 0.5 * influence_est) to keep conditionals engaged while limiting my cost.
5. Avoid retaliation / keep conditional cooperators:
   - If many opponents are conditional/reciprocal (they respond to my cooperation) and some are punishers:
     - Adopt a “mostly cooperate to avoid heavy punishment” stance toward those rounds: play C with high probability (e.g., 0.8) when the recent cooperation level among reciprocals is high, but intersperse D after I detect reliable reciprocals so I still harvest occasionally.
   - If a particular defection by me was followed by targeted punishment (others reduced cooperation substantially after my D), respond by cooperating for a short calibrated period to restore stable mutual cooperation only if that will raise my long-run payoff; otherwise continue defecting.
6. Short calibrated punishment when exploited:
   - If an opponent (or a group) systematically free-rides on my cooperation (I cooperate and their cooperation drops afterwards, beyond random fluctuation), impose a short punishment: play D for T_pun = min(3, max(1, ceil(R/10))). Short punishments are intended to raise the cost of exploiting me without sacrificing many of the remaining rounds.
   - Reassess immediately after the punishment window; if the exploiter adjusts (cooperates more), resume occasional cooperation per the seeding rule. If not, switch to permanent exploitation (step 2) or continued defection if others are all defectors.
7. Probing (early rounds / sparse data):
   - In the first few rounds or when classification data are weak, probe to learn types: cooperate with moderate probability p_probe = 0.25 (or play C on round 1 if r is large) to gather signal about responsiveness. If r is small, probe less or not at all.
8. Safety net: if the global cooperation level collapses (p_others_recent very low), do not waste effort punishing: play D until influence_est and conditions change (unless you detect that a short seeding could restore cooperation profitably by step 4).

Summary operational flow (compact)
- Always defect in the last rounds.
- Exploit obvious pure cooperators by defecting every round.
- If many others cooperate reliably and are non-punishing, defect to harvest.
- Cooperate only when my estimated influence on others’ future cooperation multiplied by remaining rounds (and MPCR) outweighs my immediate cost; otherwise, seed cooperation rarely and carefully to identify reciprocals.
- Use short, calibrated punishments to deter systematic exploitation; avoid long punishments that reduce my own payoff.
- Probe early to classify opponents; adjust behavior continuously based on observed responsiveness.

Why this is exploitative and robust
- It actively free-rides on stable cooperators and harvests predictable contributions.
- It only pays the cost of cooperation when there is evidence it will induce enough future contribution to justify the cost.
- It protects against harsh punishers by recognizing them and avoiding costly provocation, and it deters opportunistic exploiters by short punishments calibrated to remaining rounds.
- It is adaptive across a wide range of opponent behaviors because classification and influence are estimated from history and decisions are recomputed each round.
'''

description_EXPLOITATIVE_61 = '''
Name: Opportunistic Prober–Exploiter (OPE)

Summary objective (exploitative): maximize my own long-run payoff by free‑riding on stable cooperators, avoiding being systematically exploited, and using brief cooperative investments only when they reliably increase future returns. I will default to defecting (D) except when probing or repairing cooperation in ways that are likely to produce more future cooperation from others. I always exploit in the final round.

Parameters derived from the game:
- n = number of players, r = rounds, k = multiplier.
- Set a small probing window and repair lengths that scale with r:
  - T_probe = max(1, min(5, floor(r/8))) — initial cooperation probe length.
  - T_repair = max(1, min(4, floor(r/10))) — number of consecutive cooperations used to restore trust after I detect punishment.
  - Window W = min(r, max(5, floor(r/4))) — moving window to estimate others’ cooperation rates.
  - Final exploitation window T_end = 1 (always defect in final round). Optionally set T_end = min(2, r) if r is tiny.

Fixed internal thresholds (robust defaults; adapt if you wish):
- p_high = 0.60 — if average cooperation by others in window W ≥ p_high, treat the group as “cooperative enough to exploit.”
- p_low = 0.20 — if others’ cooperation ≤ p_low, treat the group as largely noncooperative; stop spending tokens trying to build cooperation.
- delta_drop = 0.20 — if others’ cooperation rate falls by more than delta_drop immediately after I defect, interpret that as punishment triggered by my defection.
- epsilon_seed = 0.05 — a small probability of an occasional cooperative “seed” while exploiting, to keep cooperation possible and test stability.

State machine (decision logic):

Initialization (first round):
- Enter PROBE mode.
- Action: Cooperate (C) for the first T_probe rounds unconditionally. Rationale: signal willingness to cooperate and identify which tournaments/players reciprocate, without squandering long-term gains by continuous cooperation.

After each round compute:
- For each round t, observe S_t = number of contributions by all other players (exclude me).
- Compute cooperation rate among others over the sliding window W: p_others = (sum of others’ contributions across last W rounds) / ((n-1)*W).
- Also track immediate change: compare p_others before and after any round where I defected to detect punishment.

Modes and actions:

1) PROBE (first T_probe rounds)
- Action: C for T_probe rounds.
- After T_probe rounds compute p_others (over the probe window or W).
  - If p_others ≥ p_high → switch to EXPLOIT mode.
  - Else → switch to SEARCH mode.

2) EXPLOIT (primary exploit mode)
- Default action: Defect (D) every round.
- After each D, observe the next-round p_others:
  - If p_others drops by > delta_drop relative to the pre-defection baseline, treat that as punishment: switch immediately to REPAIR mode.
- Occasionally (independently each round) with small probability epsilon_seed play C instead of D (a “seed” cooperation) to test whether cooperators remain willing to respond; if a seed yields increased cooperation by others in the next round (p_others increases by > delta_drop/2), remain in EXPLOIT; if not, switch to SEARCH or REPAIR as appropriate.
- If long-run p_others falls below p_low while in EXPLOIT, switch to SEARCH (it’s not worth trying to exploit a group that is not cooperating).

3) REPAIR (restore cooperation after punishment)
- Action: Cooperate (C) for T_repair consecutive rounds to re-establish a cooperative baseline and demonstrate contrition.
- After T_repair rounds re-evaluate p_others over W:
  - If p_others ≥ p_high → return to EXPLOIT.
  - If p_low < p_others < p_high → return to SEARCH (mixed environment).
  - If p_others ≤ p_low → stay in SEARCH (or switch to persistent defection if no cooperation is forthcoming).
- If punishment persists even after repair attempts (i.e., p_others stays low or drops further), stop repairing and transition to persistent defection (SEARCH with low cooperation frequency).

4) SEARCH (finding cooperators / low-cooperation environment)
- Action: Mostly defect, but probe periodically:
  - Cooperate every S_rounds (e.g., S_rounds = max(3, floor(W/5))) or cooperate with probability q = 0.20 each round.
- Monitor whether these probes elicit cooperation from others. If p_others rises above p_high after probes → switch to EXPLOIT. If p_others remains ≤ p_low for many windows → remain defecting permanently (to avoid wasting tokens).
- Rationale: If many others are noncooperative, do not waste tokens trying to sustain public goods; only probe occasionally to catch potential unconditional cooperators.

Endgame (last rounds):
- In the final round (round r), always Defect (D). There is no future to restore, so no cooperative investment.
- For robustness, consider defecting for the last T_end rounds if r is small and many strategies will also defect near the end; this increases my exploitation in finite-length tournaments.

Additional behavioral rules and clarifications:
- Never allow repeated unilateral losses: if I detect a pattern where I cooperated and the group’s cooperation rate falls (I’m being exploited), switch to persistent defection immediately.
- When evaluating “before” and “after” cooperation rates around a defection, use a short baseline (e.g., the average over the last min(W, 3) rounds before the defection) to be responsive.
- Be stochastic at low probability (epsilon_seed and SEARCH probing) to remain unpredictable and to occasionally trigger cooperation that can be exploited.
- Track long-term per-player cooperation rates if helpful, but remember my action is global each round; decisions are based on the group-level cooperation statistics because I cannot act differently toward different players in the same round.

Why this is exploitative and robust:
- I maximize immediate payoff by defecting whenever cooperators are available to free-ride on, but I do not blindlessly defect if that causes others to punish me permanently. Short cooperative investments (probing and repair) are used only when they are likely to restore a cooperative environment I can exploit thereafter.
- The plan is adaptive: probing identifies whether the group contains exploitable cooperators; exploitation is opportunistic; repair and search prevent permanent breakdown and allow recovery when cooperation can be re-established.
- I always defect in the last round (no sunk-cost cooperation), which captures finite-horizon exploitation.

Edge cases:
- r = 1: defect (there is no future).
- Very small r (e.g., r ≤ 5): set T_probe = 1 and T_repair = 1; be more aggressive in exploiting quickly since there are fewer rounds to recover.
- If all players are stubborn defectors (p_others ≈ 0 persistently): switch to persistent defection (no more probing).
- If all others are unconditional cooperators (p_others ≈ 1): exploit aggressively via EXPLOIT (defect every round, except occasional seeds to check stability).
- If there is noisy or mixed behavior: the thresholds and stochastic probes allow adaptation; repair prevents permanent retaliation loops.

Concise pseudocode summary (conceptual):
- If round = r → play D.
- Else if round ≤ T_probe → play C.
- Else update p_others over W and compare to thresholds.
  - If in EXPLOIT → normally play D; if p_others drops after my D → enter REPAIR; occasionally play C with prob epsilon_seed.
  - If in REPAIR → play C for T_repair rounds, then reassess and move to EXPLOIT/SEARCH accordingly.
  - If in SEARCH → mostly play D but probe cooperatively every few rounds (or with prob q); if probes raise p_others → go EXPLOIT.
- If I detect persistent exploitation of me (I cooperate and p_others falls), switch to permanent defection.

This strategy is explicitly exploitative: it prefers defection whenever doing so yields short-term gains and only spends tokens on cooperation when those expenditures buy reliable future cooperation that can be exploited. It protects itself against being stuck as a sucker by quickly switching to defection or by repairing only when repair appears effective.
'''

description_EXPLOITATIVE_62 = '''
Adaptive Opportunistic Exploiter (AOE)

Goal: maximize my payoff by freeloading on others’ contributions whenever it is sustainable, while contributing just enough (when needed) to keep a cooperating population from collapsing and switching to punishment/rebuild when cooperation falls. The strategy uses only game parameters (n, k, r) and observed history of moves.

Parameters (computed from n, k, r)
- w = min(10, max(1, floor(r/4))) — history window for statistics.
- Endgame = min(3, max(1, ceil(r/10))) — number of last-rounds to treat as endgame.
- T_high = 0.75 — individual cooperation rate threshold to call a player a “reliable cooperator”.
- T_many = ceil((n-1)/2) — threshold for “many others cooperated last round” (majority of others).
- p_maint = clamp(k/n, 0.05, 0.5) — target fraction of rounds I will cooperate while exploiting (clamped to avoid zero or extreme frequency).
- L = ceil(1 / p_maint) — deterministic maintenance cycle length: when exploiting, cooperate once every L rounds.
- T_rebuild = 0.60 — average others’ cooperation rate (over w) required to consider upgrading to exploit mode.
- T_fail = 0.35 — average others’ cooperation rate (over w) below which exploitation is abandoned.

State variables (inferred from history)
- For each other player j: rate_j = fraction of rounds they cooperated over the last w rounds (or all past if fewer than w).
- reliable_cooperators = count of j with rate_j >= T_high.
- recent_others_coop_count = number of other players who cooperated in the previous round.
- mean_others_rate = average of rate_j over all other players.

High-level modes
- Exploit mode: many reliable cooperators exist; I will mostly defect to free-ride but cooperate occasionally (maintenance) to keep cooperation profitable for others.
- Rebuild mode: cooperation in the group has dropped or there are not enough reliable cooperators; I attempt to restore cooperation when sensible, otherwise punish (defect).
- Endgame: final rounds; always defect.

Decision rules (round t, 1..r)

1. Endgame
- If t > r - Endgame: play D (defect). Do not cooperate in final Endgame rounds.

2. First move / initialization
- If t = 1: play C (cooperate). This is a short “signal” to help identify reciprocators and invite cooperation.

3. Compute statistics from history up to round t-1:
- For each other player compute rate_j over the last w rounds (or all previous if < w).
- reliable_cooperators = count(rate_j >= T_high)
- recent_others_coop_count = number of other players who cooperated in round t-1
- mean_others_rate = average_j rate_j

4. Choose mode
- If reliable_cooperators >= max(1, ceil((n-1)/2)) AND mean_others_rate >= T_rebuild:
    mode = Exploit
  Else:
    mode = Rebuild

5. Exploit mode actions
- Default: defect (D) every round.
- Maintenance cooperation: to avoid causing a collapse in others’ cooperation, cooperate on a fixed cycle: cooperate when (t mod L) == 0, otherwise defect. (If you prefer randomized play, replace with cooperating with probability p_maint each round instead.)
- Safety checks:
  - If recent_others_coop_count < T_many (i.e., last round few others cooperated), immediately suspend exploitation and switch to Rebuild mode for at least w rounds (to avoid being isolated and losing to a collapse).
  - If mean_others_rate falls below T_fail for w consecutive rounds, abandon Exploit and enter Rebuild.

6. Rebuild mode actions
- If recent_others_coop_count >= T_many (majority cooperated last round): play C (mirror the recent majority to try to rebuild cooperation).
- Else: play D (punish the collapse).
- If mean_others_rate >= T_rebuild for two consecutive windows (two successive assessments over w rounds), switch to Exploit mode.

7. Anti-punisher safeguard
- If one or more players show direct retaliation patterns (for a given j: they cooperated reliably before and in the last two rounds they both defected when you cooperated), reduce maintenance frequency: double L (cooperate less often while exploiting) to avoid being driven below exploit returns by strong punishers.

Rationale and exploitative alignment
- Start cooperative to attract reciprocation and identify reliable cooperators.
- When a substantial subset of opponents demonstrates reliable cooperation, exploit: mostly defect to free-ride on their contributions while cooperating occasionally (maintenance cycle) to keep their incentive to continue cooperating. This extracts surplus from cooperators while reducing my contribution cost to near the minimum required to sustain cooperation.
- If cooperation collapses or others retaliate/punish, switch to Rebuild mode or punish, avoiding being exploited by persistent defectors or by turning into a pure cooperator.
- Defect in the final rounds to avoid endgame exploitation.

Behavioral summary (simple readout)
- Round 1: cooperate.
- If many opponents are reliably cooperative (by recent history) and group cooperation is healthy: exploit — defect most rounds but cooperate deterministically once every L rounds.
- If cooperation looks weak or just collapsed: mirror majority to attempt rebuilding; defect if the majority defected.
- If group cooperation falls below a low threshold for extended time, stop trying to prop it up and default to defection until conditions improve.
- Always defect in the final few rounds.

Notes for tournament play
- The strategy is adaptive: it uses per-player rates and the group mean to detect exploitable cooperators and decide when occasional cooperation will pay off.
- Deterministic maintenance cycles (cooperate one-in-L rounds) are used instead of pure probabilities to make behavior predictable to itself while still spreading cooperations across time so reciprocators don’t immediately collapse.
- All thresholds are expressed in terms of n, k, r or small fixed constants; they can be tuned but are explicitly defined so the strategy depends only on allowed inputs (parameters and history).
'''

description_EXPLOITATIVE_63 = '''
Name: Adaptive Exploiter

Goal (exploitative mindset)
- Earn more than average by inducing others to contribute and then free‑riding occasionally, while avoiding sustained punishment or being driven to mutual defection. The strategy maintains a cooperative façade most of the time to keep others contributing, but defects opportunistically and selectively against predictable cooperators and forgivingly against retaliators.

Setup (parameters derived from game inputs)
- Use the known n, r, k.
- Set window L = min(10, max(3, floor(r/10))) for short-run statistics (adjusts with game length).
- Set conservative thresholds:
  - COOP_ENV_THRESHOLD = 0.6 (environment is “cooperative” if average contribution rate among others ≥ 0.6 over window L).
  - MAJORITY_LAST_ROUND = ceil((n-1)/2) (majority of others contributed in last round).
  - RETALIATE_SENSITIVITY = 0.15 (a drop ≥ 0.15 in a player’s cooperation rate after our defection flags them as a retaliator).
  - NAIVE_COOP_THRESHOLD = 0.95 (player cooperating essentially always).
- Exploitation probabilities:
  - BASE_EXPLOIT_PROB = 0.20 (when safe to exploit).
  - DECAY_NEAR_END = increase exploitation slightly toward the end by scaling probability by (1 + (t/r)) so you exploit a bit more as t grows.
  - SAFE_FORGIVENESS_ROUNDS = 2 (how long to wait after punishment before trying to regain cooperation).

Memory / statistics maintained
- For each opponent j: coop_rate_j = fraction of j’s C in last L rounds.
- For each opponent j: responsiveness_j = change in coop_rate_j after any of our defections (estimate whether they punish).
- group_coop_rate = average of coop_rate_j across opponents.
- last_round_contributors = count of opponents who played C in the immediately preceding round.
- my_recent_defections = number of my defections in the last L rounds.

Decision rules (per round t, after observing full history)
1. Last-round and endgame handling
   - If t == r (final round) → Defect (D). (Backward induction: no future to gain from cooperation.)
   - If t is in final quarter (t > 3r/4) → bias toward defecting more aggressively (scale exploit probability up) but still avoid provoking known retaliators.

2. First round (t = 1)
   - Play Cooperate (C). Purpose: establish cooperative reputation to make future exploitation possible and to probe responses.

3. Classification of opponents (updated each round)
   - For each opponent j compute coop_rate_j over last L rounds.
   - If coop_rate_j ≥ NAIVE_COOP_THRESHOLD → classify j as naive cooperator (reliable target).
   - If coop_rate_j dropped by ≥ RETALIATE_SENSITIVITY following one of our recent defections → classify j as retaliator.
   - Else classify j as conditional/neutral cooperator or noisy player.

4. Decide based on environment and opponent mix
   - Compute group_coop_rate (average coop_rate_j) and last_round_contributors.
   - If group_coop_rate < COOP_ENV_THRESHOLD or last_round_contributors < MAJORITY_LAST_ROUND:
     - Environment is non-cooperative or hostile → Defect (D). No benefit to seeding cooperation when others do not reciprocate.
   - Else (cooperative environment):
     - If there exists any strong retaliator among opponents AND my_recent_defections > 0:
       - Avoid further provocation: Cooperate (C) for SAFE_FORGIVENESS_ROUNDS to rebuild reputation (since retaliation costs more than a small occasional free ride).
     - Else (no costly retaliators detected):
       - If there are one or more naive cooperators (coop_rate_j ≥ NAIVE_COOP_THRESHOLD):
         - Exploit opportunistically: with probability p_exploit = BASE_EXPLOIT_PROB * (1 + t/r) defect (D); otherwise cooperate (C).
           - Rationale: exploit reliable cooperators occasionally to extract extra tokens while keeping overall reputation high.
       - If no naive cooperators but overall group_coop_rate is high:
         - Play C with high probability (e.g., 1 - BASE_EXPLOIT_PROB) but still defect with small p_exploit to probe for exploitable behavior.
       - If group_coop_rate is marginally above threshold:
         - Play C only if last_round_contributors was a strong majority (>= ceil(0.75*(n-1))); otherwise defect.

5. Reaction to being punished
   - If we defect and next round group_coop_rate falls by more than 0.10 relative to prior window:
     - Treat this as effective punishment. Immediately switch to cooperating for SAFE_FORGIVENESS_ROUNDS to restore contributions.
   - If punishment is mild or absent (group_coop_rate does not fall), increase future exploit probability slightly — the environment tolerates free-riding.

6. Handling persistent defectors
   - If any opponent j has coop_rate_j ≤ 0.10 over L and shows no sign of conditionality:
     - Treat them as permanent defectors; do not sacrifice by cooperating to “help” them. Continue to defect when the group environment is poor.
   - If the majority are persistent defectors, switch to permanent defection (D) — no point in sustaining cooperation.

7. Avoiding coordinated exploitation against you
   - If you detect coordinated punishment patterns (many opponents simultaneously reduce cooperation immediately after your defections repeatedly), reduce exploit attempts and cooperate more to avoid sustained losses.
   - If such punishment continues despite cooperation, revert to defection to avoid being exploited by costly punishment cycles.

Summary behavior profile
- Appear cooperative: majority of rounds play C when others habitually cooperate; this sustains contributions from others.
- Free-ride opportunistically: occasionally defect (with controlled probability) when the environment is cooperative and no costly retaliators are present, extracting extra tokens.
- Be adaptive: detect naive cooperators and exploit them more frequently; detect retaliators and avoid provoking them; abandon cooperation if environment collapses.
- Endgame: defect in the final round and ramp up exploitation somewhat later in the game, but not if strong retaliation is present.

Practical notes
- Keep exploit probability modest so your cooperation rate stays high enough to keep others contributing. The exact numeric thresholds above are tunable but chosen to balance reputation maintenance and opportunistic gain.
- Use short windows L for responsiveness; in very long r you can increase L for stability.
- This strategy is explicitly exploitative but designed to be robust: it does not assume consenting coordination, it adapts to opponents’ responsiveness, it defends against punishers, and it maximizes short-term gains when safe to do so.
'''

description_EXPLOITATIVE_64 = '''
Name: Opportunistic Probe-and-Exploit (OPE)

Goal (exploitative mindset)
- Maximize my own long-run payoff by (1) permanently free-riding on players who do not punish defection, and (2) minimally sustaining cooperation only when a subset of players will punish my defection (so I avoid heavy retaliation). I will probe opponents to learn whether they punish, exploit non‑punishers, and only give the minimum cooperation needed to keep punishers from wiping out my gains. In the final rounds I defect.

Summary of parameters I use (all determined from n and r and observed history)
- Probe length P = min(3, r). (If r = 1, treat as immediate endgame; see endgame rules.)
- Analysis window W = min(10, r).
- Occasional re‑probe spacing S = max(3, floor(sqrt(r))) — how often I check whether cooperators reappear.
- Endgame horizon L = min(2, r) — last L rounds I always defect.
- Punishment sensitivity threshold tau = 0.25 (used to detect whether an opponent reduces cooperation after my defection).
- Punisher fraction threshold Phi = 0.25 (if at least this fraction of others are punishing, I consider punishers present).
- Majority threshold M = ceil((n-1)/2) (used to decide whether the group is cooperating).

Decision rules (round-by-round)

1. First (probing) phase (rounds 1..P)
- If r = 1: defect (no future to exploit).
- If P = 2: Round1 = C, Round2 = D (probe).
- If P >= 3: play C for rounds 1..(P-1), then play D on round P (this single defection is a probe to test for punishment).

2. Classification after the probe
- Compare each other player j’s contribution rate in the W-round window immediately before my probe-defection to their rate in the 2 rounds immediately after my probe-defection (or the available rounds if r small).
- For each j, if their cooperation rate drops by at least tau after my probe-defection, mark j as a punisher.
- Let fraction_punishers = (number of punishers) / (n-1).
- If fraction_punishers < Phi, classify the group as non-punishing. Otherwise classify as punishing.

3. Exploit mode (group classified as non-punishing)
- From the classification point until the end of the game (except occasional re‑probes and the final L rounds), defect every round. Rationale: no credible punishers exist, so permanent free-riding maximizes my payoff.
- Re-probing: once every S rounds I will play one cooperative round (C) to test whether punishers have emerged or new cooperators appear; immediately observe responses and re-classify if necessary.
- Endgame: in the last L rounds play D.

4. Maintenance/Minimal-cooperation mode (group classified as punishing)
- Objective: sustain enough cooperation from punishers so that they continue to contribute, while extracting surplus whenever safe.
- In each round t that is not in the final L rounds:
  a. Look at others’ contributions in previous round (t-1). If at least M of the other n-1 players contributed in (t-1), play C in round t (i.e., match a strong recent majority). Otherwise play D.
  b. Opportunistic exploitation: if the group (others) and I have cooperated for S consecutive rounds (stable cooperation), perform exactly one planned defection (play D) to harvest a one‑round benefit. Immediately watch responses:
     - If the planned defection causes a significant punishment response (a drop by tau in cooperation by a substantial fraction of punishers within the next 1–2 rounds), stop planned exploitations and revert to rule (a) (matching majority) with conservative behavior until I observe 3 rounds of stable cooperation again.
     - If the planned defection is tolerated (no substantial drop), resume the pattern: continue exploiting periodically (one defection after S cooperative rounds).
- If average cooperation among all players within the recent W rounds falls below 0.20, assume cooperation has collapsed — switch to permanent defection (as in Exploit mode) until I detect renewed cooperation (via re-probe).
- Endgame: in the last L rounds play D.

5. Re-classification and continuing adaptation
- After any planned or accidental defection, immediately observe others’ next 1–2 rounds and recompute punishment indicators. If punishers appear or disappear, switch modes accordingly. I re-evaluate classification continuously using the most recent W rounds.

6. Endgame
- In the final L rounds (usually the final 1–2 rounds, depending on r) always defect. No cooperation in final rounds because future leverage is gone.

Edge-case clarifications
- Very short games: If r = 1, defect. If r = 2, do a one-round probe then defect last round (Round1 C, Round2 D). If r = 3: Round1 C, Round2 C, Round3 D (probe doubles as endgame); classification will be trivial but still used for any remaining rounds (none).
- Missing data: when computing statistics near the start or end where the full window W is not available, use the available rounds.
- Determinism vs randomness: rules above are deterministic; occasional re-probes are scheduled deterministically (every S rounds). If tournament rules favor randomized tactics, the opportunistic exploitation step can be randomized (e.g., exploit with small probability after stable cooperation) but the deterministic description above suffices.

Why this is exploitative and robust
- It exploits unconditional cooperators and non-punishers by permanently defecting once it is safe to do so, extracting the private benefit while letting them pay the cost.
- It avoids long costly retaliation from conditional cooperators/punishers by detecting punishers via an early probe and then switching to minimal cooperation that preserves enough incentive for punishers to keep contributing.
- It keeps adaptive re‑probes and continuous monitoring so that if the population’s behavioral mix changes (new punishers, new cooperators), I can switch back to exploitation quickly.
- It anticipates endgame incentives by defecting in the final rounds to avoid wasted cooperative costs when leverage is gone.

Concise behavioral summary
- Probe early: show cooperation briefly then defect once to see who punishes.
- If few punishers: defect every round (with occasional scheduled re-probes).
- If punishers exist: match the group’s recent majority contributions, but periodically take one planned defection to extract surplus; if punished, stop exploiting and stay conservative.
- Always defect in the final L rounds.
'''

description_EXPLOITATIVE_65 = '''
Name: Conditional Exploiter with Probing and Recovery (CEPR)

Principles (exploitative mindset)
- Seek to capture the private gain from free‑riding whenever doing so will not trigger a durable collapse of others’ cooperation that reduces long‑term payoff.
- Encourage and maintain cooperation from others only as much as needed to preserve a stream of exploitable contributions; be forgiving of occasional mistakes but punish sustained loss of cooperation by withdrawing support.
- Always defect in the last round (no future to preserve), and progressively reduce cooperation as the end approaches.

State I keep (derived only from history and parameters n, k, r)
- For each opponent j: coop_rate_j = fraction of past rounds in which j contributed (update each round).
- avg_coop_excl_me = average of coop_rate_j over j ≠ me.
- recent_group_contrib_t = observed number of contributors (excluding me) in the most recent round t (used to detect retaliation).
- A small finite state variable mode ∈ {PROBE, EXPLOIT, SUSTAIN, RECOVER, ENDGAME}.
- Counters: rounds_since_probe, last_exploit_round, recover_remaining.
- Tunable constants (fixed functions of r,n,k, chosen conservatively): 
  - T_probe = min(3, max(1, floor(r/6))) — short initial probe window (at least 1).
  - gamma_high = 0.6 (high cooperation environment).
  - gamma_low = 0.25 (low cooperation environment).
  - collapse_sensitivity = 0.2 (drop in observed group cooperation interpreted as retaliation).
  - recover_len = 3 (rounds of unconditional cooperation to rebuild).
  - exploit_spacing = 1 (allow at most one exploit defection between builds of trust) — exact exploitation pacing is adaptive below.
  - endgame_margin = min(3, floor(r/10)) — number of final rounds where I move to ENDGAME behavior.

Decision summary (per round t)
1. If t = r (last round): play D (defect). End.

2. If t > r - endgame_margin: set mode = ENDGAME and use ENDGAME rules below.

3. If in PROBE phase (t ≤ T_probe):
   - Play C (cooperate) in the probe rounds to signal cooperative intent and collect data on opponents’ responsiveness.
   - After each probe round update coop_rate_j and avg_coop_excl_me; when t = T_probe move to classification and set mode to either EXPLOIT or SUSTAIN per rules below.

4. Classification after probe (or anytime thereafter use rolling coop_rate_j):
   - If avg_coop_excl_me ≥ gamma_high → environment is richly cooperative: set mode = EXPLOIT (many potential contributors to exploit).
   - If avg_coop_excl_me ≤ gamma_low → environment is poor: set mode = SUSTAIN (mostly defect — no point investing).
   - Otherwise → mixed environment: set mode = SUSTAIN (leaning toward cooperating enough to keep conditional cooperators).

5. EXPLOIT mode (goal: harvest by occasional defection while preventing retaliation)
   - Typical pattern: normally cooperate to keep conditional cooperators engaged, but occasionally defect to free‑ride.
   - Rule:
     a) If I did not exploit (defect while group was cooperative) in the immediately preceding round, then exploit this round (play D) if avg_coop_excl_me ≥ gamma_high. Otherwise cooperate.
     b) After exploiting (playing D in an otherwise cooperative environment), observe the next round’s group contributions (recent_group_contrib_t+1). If group contributions (excluding me) fall by more than collapse_sensitivity relative to the round before the exploit, interpret that as retaliation/collapse: set mode = RECOVER and set recover_remaining = recover_len.
     c) If no meaningful fall, remain in EXPLOIT and schedule the next exploit after at least one cooperative round (exploit_spacing).
   - Rationale: defect often enough to extract the surplus, but not so often that many conditional cooperators abandon cooperation permanently.

6. RECOVER mode (respond to punishment)
   - Cooperate unconditionally for recover_remaining rounds (play C). Decrease recover_remaining each round.
   - During RECOVER update coop_rate_j and avg_coop_excl_me.
   - If recover_remaining reaches 0:
     - If avg_coop_excl_me recovered above gamma_high → resume EXPLOIT.
     - Else if avg_coop_excl_me is now low → switch to SUSTAIN.

7. SUSTAIN mode (preserve any cooperation but avoid being exploited)
   - If avg_coop_excl_me ≥ 0.4: cooperate this round (play C) to keep conditional cooperators active.
   - If avg_coop_excl_me < 0.4: defect this round (play D) — not worth investing.
   - Occasionally probe for renewed exploitable opportunities: with small probability p_probe = 0.05 (or at least once every 8 rounds if stochastic is not allowed, do a one‑round C) to test whether others will re‑engage. If probe gets strong positive response, reclassify to EXPLOIT.

8. ENDGAME mode (last few rounds)
   - From the first round of ENDGAME until last round:
     - If t = r: play D (always).
     - Otherwise, play D except:
       - If there is evidence a large majority (≥ 0.9) of opponents are unconditional cooperators (coop_rate_j ≥ 0.98 for most j), consider a single last short exploit: play D this round but expect no future benefit — however since there is no future, prefer defect. Concretely: play D every ENDGAME round.
   - Rationale: no future to preserve cooperation; never give gifts.

Other details, robustness and anti‑noise
- Forgiveness for noise: coop_rate_j is a frequency (works with occasional errors); we do not punish for a single defection — punishment happens only if aggregate group cooperation drops substantially after an exploit.
- Responsiveness detection: instead of trusting absolute coop_rate_j, we monitor short‑run changes after we cooperate vs after we defect. If many players show coordinated drops in contribution following one of our defections, we infer that our defection caused collective retaliation and move to RECOVER.
- Conservative thresholds: gamma_high and gamma_low are conservative defaults; if tournament metadata suggests unusually high r, I may lengthen T_probe and recover_len proportionally.
- No reliance on opponent identity beyond per‑opponent coop_rate_j; the strategy treats the group both collectively (avg_coop_excl_me) and individually (for subtle responsiveness checks).

Edge cases
- Very short games (r ≤ 2): always defect (no opportunity to sustain cooperation).
- r small but > 2: T_probe = 1 or 2; behave mainly as SUSTAIN/EXPLOIT based on initial responses.
- If n = 2 (pairwise public goods = prisoner’s dilemma): behavior reduces to standard exploit/forgive pattern: probe first round with C (if r ≥ 3); then exploit if the other proves reliably cooperative but recover on retaliation.
- If all opponents are observed to be pure defectors (coop_rate_j ≈ 0): I defect every round thereafter.
- If many opponents appear to be unconditional cooperators (coop_rate_j ≈ 1): I exploit frequently (one defect after at least one cooperation) to harvest extra tokens.

Why this is exploitative and robust
- Exploitative: in rich cooperative environments (many others reliably contributing) I deliberately insert defections to free‑ride and increase my per‑round payoff relative to always cooperating. I do so as frequently as the environment tolerates without provoking sustained collapse.
- Robust: I only exploit after a short probe and while monitoring group responses; I back off and rebuild cooperation when exploitation provokes retaliation. The approach tolerates noise, adapts to a wide range of opponent behaviors (unconditional cooperators, defectors, conditional reciprocators), and avoids being persistently exploited in poor environments.
- Endgame safe: I always defect when future punishments are impossible.

Concise pseudocode flow (informal)
- Initialize coop_rate_j = 0 for all j, mode = PROBE, t = 1.
- While t ≤ r:
  - If t = r: play D; break.
  - Update avg_coop_excl_me.
  - If t ≤ T_probe: play C; update rates; t++ continue.
  - Else if t > r - endgame_margin: mode = ENDGAME.
  - Switch(mode):
    - ENDGAME: play D.
    - EXPLOIT: exploit pattern described above (one D after at least one C; watch for collapse; switch to RECOVER if collapse).
    - RECOVER: play C for recover_len rounds, then reclassify.
    - SUSTAIN: cooperate if avg_coop_excl_me ≥ 0.4 else defect; occasional probes.
  - After the round, update coop_rate_j, detect group drops to trigger RECOVER if needed; possibly reclassify mode.
  - t++.

This strategy requires only the game parameters and the public history of actions and payoffs. It balances extraction of surplus from cooperators with defensive rebuilding to avoid long‑term collapse, and always defects where future retaliation is impossible.
'''

description_EXPLOITATIVE_66 = '''
Adaptive Exploitative Conditional Cooperator (AECC)

Summary goal
- Extract value from cooperative opponents while avoiding being exploited by defectors or punishers.  
- Start by probing/cooperating to identify cooperators, then play a controlled mixture of defection and occasional cooperation whenever the group is reliably cooperative.  
- If others are mostly defecting or if we are being punished for defecting, switch to safe defection or temporary high cooperation (repair).  
- Always defect in the clear endgame.

Parameters (derived from game inputs r, n, k and adjustable small constants)
- effective_return = k / n  (in (0,1) given 1 < k < n).
- w = window for measuring recent behavior = min(10, max(3, floor(r/5))).
- initial_rounds = min(3, r) — cooperate to probe and attract reciprocators.
- endgame_rounds = min(3, max(1, floor(0.1 * r))) — guaranteed defection near the end.
- maintenance_threshold = 0.50 + 0.25 * effective_return — minimum recent average cooperation by others to treat the environment as reliably cooperative.
- low_threshold = 0.15 + 0.15 * effective_return — below this, treat environment as hopelessly non-cooperative.
- exploit_coop_prob = 0.30 — when exploiting a cooperative environment, cooperate with this probability (defect with probability 0.70).
- recovery_coop_prob = 0.75 — when repairing after punishment, cooperate with this probability for a short recovery phase.
- recovery_rounds = 2 — length of repair cooperation.
- punishment_drop = 0.15 — a fall in others’ cooperation > punishment_drop after a defection is treated as punishment.

Decision rules (per round t, using only r, n, k and observed history of all players’ contributions)
1. Edge cases
   - If r = 1: defect (single-round, no future benefit).
   - If t <= initial_rounds: play C (cooperate) to probe and attract unconditional cooperators.
   - If r - t + 1 <= endgame_rounds: play D (defect) for all remaining rounds (endgame defection).

2. Compute simple statistics from history:
   - For each other player j, compute coop_rate_j = fraction of rounds they contributed in the last w rounds (or since the game started if < w rounds exist).
   - avg_others = mean_j coop_rate_j (average cooperation rate of others over window w).
   - last_round_others = number of other players who contributed in round t-1 (if t>1).
   - If you defected in round t-1, compute drop_in_avg = previous_avg_others_before_your_defection - current avg_others (compare comparable windows). If drop_in_avg > punishment_drop, classify this as punishment.

3. Environment classification
   - If avg_others <= low_threshold: environment = non-cooperative.
   - Else if avg_others >= maintenance_threshold: environment = cooperative.
   - Else: environment = mixed/uncertain.

4. Action selection
   - If environment = non-cooperative:
     - Play D (defect) always. No point unilaterally contributing.
   - If environment = cooperative:
     - If currently in a short recovery phase because we recently triggered punishment: cooperate with probability recovery_coop_prob (otherwise defect). The aim is to recover cooperation cheaply.
     - Else (normal exploitation mode): exploit by largely free-riding while maintaining the cooperative norm:
       - If last_round_others >= ceil((n-1)/2) (a clear majority of others cooperated last round), cooperate with probability exploit_coop_prob; otherwise defect. This conditional randomness keeps us unpredictable while contributing occasionally when the group is clearly cooperative (so that others continue to see cooperative outcomes).
   - If environment = mixed/uncertain:
     - Play conditional reciprocity: cooperate if and only if a majority of others cooperated last round (last_round_others >= ceil((n-1)/2)); otherwise defect. This reduces needless giving to noisy defectors.

5. Punishment response and recovery
   - If you detect punishment (drop_in_avg > punishment_drop) following one of your defections:
     - Enter a recovery phase for recovery_rounds rounds where you cooperate with probability recovery_coop_prob to signal willingness to restore mutual cooperation.
     - If recovery fails (avg_others does not rise), revert to defecting in non-cooperative mode.
   - If you detect that a single player is a persistent defector (coop_rate_j near 0 over a long window), treat them as “ignored” — do not let them determine your conditional rules (compute avg_others excluding relentlessly non-responsive players when deciding whether the group is cooperative).

6. Noise tolerance
   - Use window w so single missed cooperations are smoothed out.
   - Do not punish after a single unexpected defection by others; require a sustained drop (punishment_drop) to consider it significant.

Why this is exploitative and robust
- Exploitative: In cooperative environments the strategy free-rides most rounds (defect with ~70% probability) while contributing occasionally to sustain others' willingness to cooperate, thereby capturing surplus from cooperators. It deliberately targets environments where others reliably cooperate and reduces its cooperation rate relative to them.
- Robust: It defects quickly in hopeless environments to avoid being exploited, uses short probing initial cooperation to identify cooperators, and includes explicit detection of punishment to repair relationships when necessary. Randomized cooperation in exploitation mode prevents deterministic patterns that some opponents could exploit. Thresholds scale with k/n (effective_return) so the strategy becomes more willing to invest when the public good is relatively more valuable.
- Tournament suitability: The strategy uses only parameters and publicly observed history, adapts to different opponent mixes (naive cooperators, conditional cooperators, defectors, punishers), and balances extraction with the need to keep cooperators engaged.

Implementation notes (concise)
- All randomness should be pseudo-random and conditioned on observed history to avoid exploitable fixed patterns.  
- Tune exploit_coop_prob (lower to exploit more, higher to be safer) and window w for the environment’s volatility in the tournament context.
'''

description_EXPLOITATIVE_67 = '''
Name: Adaptive Exploiter (AE)

Goal (plain): Build a cooperative reputation to attract contributions, then opportunistically free-ride when it is safe to do so; quickly detect and stop being exploited by punishers; periodically probe to re-establish exploitation opportunities.

Parameters used (computed from inputs or history):
- n, k, r (given)
- W = min(10, t-1) (window length for recent statistics)
- incentive = 1 - k/n  (one-shot gain from defecting)
- Defaults I use unless overridden by strong evidence:
  - initial_rounds = min(3, r-1)
  - endgame_rounds = 1 (always defect in final round)
  - min_coop_for_exploit = 0.70 (fraction of others cooperating recently to consider exploitation)
  - punish_threshold = 0.25 (average probability others retaliate after my defection below this = “low retaliation”)
  - probe_prob_base = 0.15 (initial low probe rate)
  - exploit_prob_max = 0.6
  - punish_cooldown = 2 rounds (after I detect punishment, stay defensive this many rounds)
  - punish_detect_drop = 0.30 (drop in others’ cooperation after my defection that counts as punishment)

Overview of stored statistics (computed from history at each round t):
- For each other player j: coop_rate_j = fraction of rounds j played C.
- Recent group cooperation R = average fraction of other players who played C in the last W rounds.
- For each j: retaliate_j = fraction of times j played D in the round immediately following a round where I played D (estimate of j’s tendency to punish me).
- P_avg = average of retaliate_j across j (estimate of the group’s tendency to punish my defection).
- After any defection of mine, compare average others’ cooperation in the round(s) after the defection to rounds before it to detect punishment (drop > punish_detect_drop).

Decision rules (per round t):

1) Forced corner cases
- If r == 1: play D (no future benefit).
- If t > r - endgame_rounds: play D (last round(s) — defect).
- If t <= initial_rounds and r > 1: play C (establish cooperative reputation and gather data).

2) Maintain a simple state machine
- State = NORMAL by default.
- If in PUNISH_MODE (entered when I detect I was punished after a defection): play D for punish_cooldown rounds (protect myself), then exit PUNISH_MODE and return to NORMAL.
- PUNISH_MODE is entered immediately if after any of my defections others’ average cooperation drops by > punish_detect_drop.

3) In NORMAL state (adaptive exploitation)
a. Compute recent group cooperation R and P_avg as above.
b. Compute a safe exploitation probability p_exploit depending on observed cooperation, observed punishment tendency, and one-shot incentive:
   - If R < min_coop_for_exploit: p_exploit = 0 (do not exploit; keep cooperating to rebuild).
   - Else (R >= min_coop_for_exploit):
       - If P_avg > punish_threshold (group likely to retaliate): p_exploit = 0 (too risky).
       - Else set p_exploit = probe_prob_base + (exploit_prob_max - probe_prob_base) * ((R - min_coop_for_exploit) / (1 - min_coop_for_exploit)) * incentive.
         - Then clamp p_exploit into [0, exploit_prob_max]. (This makes exploitation more aggressive when many others are cooperating and when incentive to defect is larger.)
c. Action selection:
   - With probability p_exploit: play D (exploit).
   - Otherwise: play C.

4) Probing & adaptation (continuous)
- Any time I play a D as a probe/exploit, I immediately monitor next rounds:
  - If I observe significant retaliation (others’ cooperation drops by > punish_detect_drop or P_avg increases sharply), I immediately switch to PUNISH_MODE.
  - If no retaliation for several consecutive probes (e.g., 2–3 probes across rounds) and R stays high, slowly increase exploit probability (by re-computing p_exploit; the formula above already increases with R and incentive).
- If a prolonged period of mutual defection follows (group cooperation falls and stays low), revert to permanent D until I detect a sustained increase in others’ cooperation (R rises above min_coop_for_exploit), at which point resume NORMAL behavior (start cooperating for initial_rounds window to rebuild trust).

Rationale & exploitative mindset (concise)
- Start cooperative to attract unconditional or conditional cooperators and to collect data about opponents.
- Exploit only when the expected benefit (many others will still contribute) outweighs expected punishment risk; use small/randomized exploitation rather than blatant continuous defection so punishers have difficulty getting a sure trigger while cooperators keep contributing.
- Rapidly detect punishment (drops in others’ cooperation after my defections) and switch to defensive defection for a short cooldown so I am not repeatedly exploited by punishers.
- Periodically probe to discover if punishers have relaxed; resume exploitation if safe.
- Always defect in the last round (endgame).

Implementation notes (for tournament usage)
- All thresholds and probabilities above are tunable; the core principles are:
  - Build reputation -> opportunistically defect when safe -> protect against punishers -> probe & adapt.
- Use small windows (W) early to react quickly; lengthen if opponents are noisy.
- Incorporate the multiplier k via the incentive factor so exploitation is scaled to how profitable a one-shot defection is.

This strategy is fully history-dependent and uses only game parameters and observed actions/payoffs. It aims to extract surplus from cooperators while minimizing losses to retaliators, and is robust across a broad range of opponent behaviors because it continuously classifies and adapts to observed punishment and cooperation levels.
'''

description_EXPLOITATIVE_68 = '''
Name: Adaptive Exploit-Reciprocator

Summary goal (exploitative): extract extra payoff from players who contribute reliably without retaliating, while sustaining mutually profitable cooperation with conditional reciprocators and avoiding costly long punishments. Use a short probing phase to classify opponents, then: (1) exploit clear unconditional cooperators by defecting; (2) cooperate with reciprocators when group cooperation is high; (3) punish only in a measured, temporary way; (4) defect in the known endgame.

Notation and fixed parameters (computed from game parameters n, r, k):
- T_probe = min(8, max(3, floor(r/10)))  // rounds used to probe behavior
- L_end = max(1, floor(r/5))             // final rounds to always defect (endgame)
- L_punish = min(3, max(1, floor(r/10))) // length of a targeted punishment period
- p_test = min(0.12, 4/r)                // small probability of opportunistic test-defection in long games
These values are derived from r and are public; the strategy only uses these and the observed history.

Data maintained from history:
- For each player i: total contributions c_i_total, contributions per window, and responsiveness r_i measured as change in i’s contribution rate after we defected in the probe/test rounds.
- Group cooperation history (number contributed each past round).

Phase A — Probe (rounds 1..T_probe)
1. Round 1: Cooperate (C). This encourages cooperation and gives a baseline.
2. Round 2: Defect (D). This is a lightweight test to see who punishes or retaliates.
3. Rounds 3..T_probe: Cooperate (C) except with occasional D at a low rate (probability p_test) to further test responsiveness if the game is long. Record each player’s contributions before and after my defections to estimate:
   - p_i = fraction of probe rounds player i contributed.
   - r_i = change in player i’s contribution rate in the rounds immediately following my defections versus before (responsiveness).

Classify opponents (after probe)
- Safe Cooperator (S): p_i >= 0.8 and r_i <= 0.15 (high cooperation, little/no retaliation)
- Reciprocator (R): p_i >= 0.4 and r_i >= 0.15 (moderate/high cooperation, responsive)
- Punisher/Defector (P): otherwise (low cooperation and/or punishes defections)
If a player’s behavior is noisy, classify conservatively into P unless clear S or R evidence exists.

Main phase (rounds T_probe+1 .. r - L_end)
Decision at each round t in main phase:
1. If count(S) >= ceil(n/2):
   - Exploit mode: Defect every round (D). Rationale: a majority of safe cooperators means consistent free-riding yields higher payoff. Continue until a significant fraction of S start retaliating (see safety override below).
   - Safety override: if after switching to exploit mode a fraction >= 0.25 of the previously safe cooperators reduce their contribution rate by >= 0.2 within two rounds, abort exploit mode and switch to Reciprocal mode (below).
2. Else (no exploitable majority): Reciprocal mode (sustain cooperation with reciprocators, avoid being exploited by punishers)
   - Primary rule: Cooperate (C) this round if last round had at least ceil(n/2) contributors (majority cooperated) and no recent targeted punishment is active; otherwise defect (D).
   - Occasional opportunistic test: If last round had unanimous or near-unanimous cooperation (>= n-1 contributors) and there are at least two players classified S or unclassified high cooperators, with probability p_test perform a single defection (D) to probe for unpunishing cooperators and update classifications. If mass retaliation occurs, revert and mark those who retaliated as P or R depending on magnitude.
   - Punishment policy: If a player i is observed to reduce contributions immediately in response to one of my defections (r_i significantly positive), mark i as a retaliator. In that case, respond by defecting for L_punish rounds (temporary group defection) to signal cost of retaliation, then forgive (return to Reciprocal rules) unless i persists in punishing. Do not escalate beyond L_punish so long costly long-term cycles of mutual defection can be avoided.
   - Targeted punishment caveat: you cannot target a single player in a PGG without hurting yourself; therefore punishment is always limited and intended as a credible but low-cost deterrent.

Endgame (last L_end rounds: rounds r-L_end+1 .. r)
- Always defect (D). Rationale: standard finite-horizon logic — cooperating in the known last rounds is exploitable; defecting maximizes immediate payoff.

Safety and fallback behavior
- Minimax fallback: If over any sliding window of length max(3, floor(r/10)) the group cooperation drops below 30% and exploitation attempts lead to sustained mutual defection, switch to permanent defection for the remainder of the game. This protects against strategies that systematically punish exploiters or against chaotic populations where reciprocity cannot be sustained.
- Forgiveness rule: After any punishment period (L_punish), return to Reciprocal mode to restore mutually beneficial cooperation with reciprocators. Do not hold permanent grudges against moderately responsive reciprocators; only label and avoid persistent punishers.

Implementation notes (how decisions use observed history)
- “Majority cooperated last round” refers to observed contributions in round t-1.
- Responsiveness r_i is computed as the difference in i’s contribution rate in the 2 rounds after a defection vs the 2 rounds before that defection (extend window if noisy).
- Classification updates continuously: if a Safe Cooperator starts retaliating often, demote them to R or P and act accordingly.
- Exploit mode is deliberately blunt: it only triggers when many safe cooperators exist. This prevents being exploited by punishers while still harvesting gains from unconditional contributors.

Why exploitative and robust
- The probe phase finds players who are safe to exploit; exploit mode then harvests those gains.
- The Reciprocal mode preserves cooperation (and thus higher absolute payoffs) with responsive partners when exploitation would be dangerous (punishers present).
- Measured, temporary punishment deters costly retaliation while avoiding spirals of mutual defection.
- Endgame defection extracts final-round gains.
- Safety fallback prevents losing to persistent punishers or chaotic opponents.

Behavioral summary by opponent type
- Against unconditional cooperators: quickly switch to consistent defection to free-ride.
- Against tit-for-tat or reciprocators: cooperate when the group cooperates, punish briefly if punished, forgive and return to cooperation—sustaining mutual gains.
- Against exploitative punishers or chaotic players: default to defection to avoid being exploited by punishment cycles.

This strategy requires only game parameters (n, r, k) and observed history (who contributed each round). It is explicitly exploitative where safe to do so, adaptive to varied opponent behavior, and guarded against costly retaliation and endgame exploitation.
'''

description_EXPLOITATIVE_69 = '''
Adaptive Conditional Exploiter (ACE)

Summary principle
- Signal cooperation early to attract cooperators, harvest predictable cooperators by occasional one-shot defections, and punish collapse/serial defectors so you are not turned into a permanent sucker. Always defect in the immediate endgame. Tune how often you “probe/steal” based on recent observed cooperation and the public-goods multiplier (k/n): exploit more when many others are reliably cooperating and when k/n is small (so the social incentive to maintain cooperation is weaker).

Notation used
- n, r, k: game parameters (players, rounds, multiplier) — known.
- t: current round (1..r).
- c_j(t): action of player j in round t (1=contribute, 0=defect); you observe full history.
- W = min(10, r): sliding window (number of recent rounds used to estimate behavior).
- G(t) = average fraction of the other n-1 players that cooperated, averaged over the last W rounds (a number in [0,1]).
- Delta(t) = change in G compared to the previous window (G(t) - G(t-1)).
- E = min(2, r): endgame length (always defect in the last E rounds).
- P = min(4, max(1, floor(r/10))): punishment length (rounds to punish a collapse).
- T_coop = 0.60: cooperation threshold — require a clear majority of others cooperating before you will normally cooperate.
- base_exploit_max = 0.25: maximum allowed probing/exploitation probability before scaling by multiplier.
- s_mult = 1 - (k / n): scale factor that reduces exploitation when k/n is high (if k is close to n, group cooperation is more valuable; be more cautious).

Core decision rules (pseudocode style)
1. Initialization
   - Track G(t) each round. Start with G(1) estimated from prior (no data) as 1.0 for the purpose of being generous in first round (see first-round rule).
   - State variable: punish_timer = 0 (counts down when punishing). exploit_rate is dynamic (see below).

2. First round (t = 1)
   - Cooperate (c = 1). Rationale: signal willingness to cooperate to attract generous opponents and allow exploitation later.

3. Endgame (t > r - E)
   - Defect (c = 0) in all rounds in the final E rounds (no future to sustain cooperation).

4. Every round t (2 .. r - E), update estimates:
   - Compute G(t) over last W rounds (exclude the current round decision).
   - Compute Delta(t) = G(t) - G(t-1) (if G(t-1) undefined, treat Delta = 0).

5. Punishment detection and execution
   - If punish_timer > 0:
       - Set c = 0 (defect), decrement punish_timer by 1, continue.
   - Else if Delta(t) <= -0.25 (i.e., group cooperation fraction dropped sharply) OR there was a round where you cooperated and strictly fewer than 1/(n-1) of others cooperated (i.e., you were clearly a sucker),
       - Enter punishment: set punish_timer = P, set c = 0 this round.
       - Rationale: swift, finite punishment discourages opportunistic strategies that would otherwise exploit you indefinitely.

6. Normal operation (not punishing, not endgame)
   - If G(t) < T_coop:
       - Defect (c = 0). Rationale: do not pay the cooperation cost when a clear majority aren’t cooperating.
   - If G(t) >= T_coop:
       - Compute exploitation probability (prob_probe):
           - raw = base_exploit_max * (G(t) - T_coop) / (1 - T_coop). (This grows from 0 when G = T_coop up to base_exploit_max when G=1.)
           - prob_probe = clamp(raw * s_mult, 0, base_exploit_max). (Scale down exploitation if k/n is large.)
       - With probability prob_probe: defect this round (c = 0) as a one-shot exploit / probe.
         - Mark that you attempted an exploit this round (use it to adapt prob_probe next rounds — see adaptation rules).
       - Otherwise: cooperate (c = 1).

7. Adaptation after probes/exploits
   - If you defected as a probe and in the subsequent 1–2 rounds G drops by more than 0.10 relative to pre-probe level:
       - Interpret this as others retaliating or cooperation fragility. Immediately reduce base_exploit_max by half for the remainder of the game and, if the drop was severe (Delta <= -0.25), enter punishment (set punish_timer = P).
   - If probes do not reduce G persistently (the group returns to previous cooperation levels), maintain or slowly increase probe frequency subject to s_mult.

8. Graceful re-entry after punishment
   - After punish_timer reaches 0, attempt one cooperative test round:
       - If the group response in the next W rounds has G >= T_coop, resume normal operation with prob_probe reduced to 50% of its pre-punishment level (gradual rebuilding of trust).
       - If cooperation does not recover, remain defecting until G >= T_coop.

Edge cases and additional rules
- If r is very small (r <= 4): be aggressive — defect in all but the first round (first round cooperate), since little opportunity to repair cooperation.
- If k/n is extremely low (k/n << 1): s_mult ~1 so you exploit more; if k/n ~1: s_mult ~0 so you behave almost like a conditional cooperator (rarely probe).
- If there are clear, persistent unilateral cooperators (players whose individual cooperation rate over a long window is >> group average), this strategy will continue to exploit them indirectly via probed defections while keeping cooperation high enough among the rest to preserve future gains.
- You never escalate to irreversible grim trigger; punishments are finite and followed by structured tests — this makes the strategy robust: punishers and retaliators are met with targeted finite punishment but you always attempt to re-form beneficial cooperation if the group is willing.

Exploitative mindset made explicit
- Goal: maximize own cumulative payoff by (a) attracting cooperative opponents through initial signaling, (b) harvesting those opponents via occasional short-term defections when group-level cooperation is high, and (c) preventing long-term exploitation by others via quick, finite punishments and adaptation.
- The strategy exploits predictable cooperators through probabilistic one-shot defections rather than permanent defection, preserving the long-run possibility of continued exploitation profit. It stops cooperating when the group becomes too defect-prone and punishes sharp cooperation collapses to avoid being repeatedly exploited.
- The dependence on k/n ensures conservatism when the public-good multiplier makes cooperation more valuable to everyone, and aggressiveness when k/n is small and cooperation is fragile.

Implementation summary (compact)
- Round 1: cooperate.
- Last E rounds: defect always.
- Otherwise: compute recent group cooperation G.
   - If punishing: defect until punish_timer expires.
   - If G < 0.60: defect.
   - If G >= 0.60: defect with probability prob_probe = scaled function of (G - 0.60) and (1 - k/n); otherwise cooperate.
- If a probe causes a large cooperation drop, sharply reduce probe frequency and/or punish for P rounds.
- After punishment, test with a cooperation round and resume only if cooperation recovers (with reduced probe frequency).

This strategy is adaptive, uses only parameters and observable history, and is explicitly exploitative: it seeks regular short-term gains from cooperative opponents while protecting itself from chronic exploitation.
'''

description_EXPLOITATIVE_70 = '''
Adaptive Exploitative Public-Goods Strategy (natural-language pseudocode)

Principles (exploitative mindset)
- Try to extract contributions from others whenever they will continue to contribute after I defect.
- Avoid being persistently punished: stop exploiting if others reliably lower contributions in response.
- Use short cooperative “signals” to induce cooperation, then defect opportunistically.
- Always defect in the final round (no future to influence), and scale probing/cooperation to game length.

Initialization (compute once from game parameters)
- MPCR = k / n (marginal per-capita return).
- Set probe_length T_probe = min(3, max(1, floor(r/10))). (If r ≤ 3, T_probe = 1.)
- Set stats_window L = min(10, max(3, floor(r/5))) for recent-history calculations.
- Thresholds and durations:
  - exploit_threshold = 0.6 (others’ average contribution rate while I defect must exceed this to exploit).
  - punish_sensitivity δ = 0.15 (used to detect punishers).
  - punish_duration = 3 (rounds to stay in reciprocal mode after being punished).
  - small_noise ε = 0.03 (small randomization to avoid brittleness).
- State ∈ {PROBE, EXPLOIT, RECIPROCATE}. Start in PROBE. Track consecutive rounds in current state, and last action I took each round.

Per-round decision (round t = 1..r)
1. Endgame rule
   - If t == r: play D (defect) and stop. (Final round: always defect.)
   - Optionally, if r is extremely small (r ≤ 2), treat T_probe = 1 and apply rules below.

2. PROBE phase (first T_probe rounds)
   - Play C (cooperate) to build a cooperative reputation and elicit others’ unconditional cooperation.
   - After each round update history. After T_probe rounds compute statistics below and exit PROBE.

3. Compute statistics from history (use up to last L rounds, or entire history if shorter)
   - For each other player j compute coop_rate_j = fraction of those rounds where j played C.
   - Compute group_coop_when_I_def = average (over rounds in which I chose D) of fraction of other players who contributed.
   - For each j compute retaliation_j = (coop_rate_j in rounds immediately after my C) minus (coop_rate_j in rounds immediately after my D). Put simply: does j reduce contribution after I defect? If retaliation_j ≥ δ (i.e., they cut contributions by δ or more after I defect), call j a “punisher.”
   - Let punishers = number of players labeled punisher. Let punisher_fraction = punishers / (n-1).

4. Decide mode after PROBE or during play
   - If currently PROBE (and probe completed): 
     - If group_coop_when_I_def ≥ exploit_threshold and punisher_fraction ≤ 0.25 → switch to EXPLOIT.
     - Else → switch to RECIPROCATE.
   - If currently EXPLOIT: remain in EXPLOIT while exploitation is profitable:
     - Continue to defect (D) by default.
     - Monitor group_coop_when_I_def over the most recent L rounds. If this metric falls below (exploit_threshold - 0.20) for more than 2 consecutive evaluation windows (i.e., others respond to my defection by reducing contributions), treat that as effective punishment:
       - Switch to RECIPROCATE for punish_duration rounds (to stop getting punished and to rebuild a cooperative baseline).
     - With tiny probability ε, play C instead of D (randomized cooperation) to probe whether punishment has ceased; use this to update statistics.
   - If currently RECIPROCATE:
     - Use a simple conditional-cooperation rule oriented to avoid being exploited by punishers but to regain cooperation:
       - In each round (except the final round handled above), play C if in the previous round the majority of other players contributed (≥ ceil((n-1)/2)); otherwise play D.
       - If I am in RECIPROCATE because of recent punishment, remain in RECIPROCATE for at least punish_duration rounds, then perform a one-shot exploitation probe: intentionally play D for one round and observe group_coop_when_I_def. If the group still contributes at a high rate (≥ exploit_threshold) and punisher_fraction is low, switch to EXPLOIT; otherwise remain in RECIPROCATE.
     - Include small randomization: with probability ε invert the conditional response (play D when would play C or vice versa) to avoid deterministic triggers and to test opponents.

5. Handling persistent punishers or hostile groups
   - If punisher_fraction > 0.5 (a majority punish my defection by substantially reducing contributions), exploitation will be unprofitable:
     - Stay in RECIPROCATE permanently (no aggressive exploitation). Use conditional cooperation to maximize long-run payoff given strong retaliation.
     - Occasionally (every ~L rounds) do a 1-round defection probe to see if punishers relax; if they do not, stop probing.

6. Recovery and forgiveness
   - If in RECIPROCATE and I observe several rounds where the group resumes cooperative behavior (majority contributing in most recent rounds), treat that as repaired cooperation and consider switching to EXPLOIT only if probing confirms that others will still contribute when I defect (i.e., group_coop_when_I_def ≥ exploit_threshold and punisher_fraction small).
   - Do not attempt to “punish back” in a costly extended way; rather, retreat to RECIPROCATE and rebuild reputation to exploit later if possible.

7. Edge-case notes
   - Very short games (r ≤ 3): minimal probing (T_probe = 1). Because of short horizon, default to more defection unless clear unconditional cooperators are detected quickly.
   - If game contains apparent pure unconditional cooperators (individuals with coop_rate_j ≈ 1 and no sign of retaliation), they will repeatedly be exploited in EXPLOIT mode.
   - If the environment is noisy or many mixed/random players are present, the small ε randomization prevents deterministic retaliation cycles and allows continuous testing.

Summary behavior by state
- PROBE: cooperate for a short known period to test group responsiveness.
- EXPLOIT: defect every round to free-ride while others continue contributing; constantly monitor whether my defection causes group contributions to fall; if punished, stop exploiting.
- RECIPROCATE: conditional cooperation (cooperate when majority cooperated previously) to avoid sustained punishment and to rebuild cooperation; periodically probe to see if exploitation is again possible.
- Endgame: always defect in last round.

Why this is exploitative and robust
- It deliberately creates a cooperative image early to lure unconditional cooperators, then defects to capture surplus when safe.
- It uses empirical, local statistics (how others react to my defection) to judge when exploitation is profitable and when it is too costly because of punishers.
- It avoids long, costly punishment cycles by switching to conditional cooperation when opponents retaliate, preserving my payoff rather than stubbornly punishing.
- Small randomization prevents exploitation by retaliatory strategies that try to manipulate deterministic triggers; endgame defection ensures no wasted cooperation in the last round.

This strategy requires only the known parameters (n, k, r) and the public history of past actions and payoffs. It is adaptive to many opponent types (unconditional cooperators, conditional cooperators, punishers, randomizers) and prioritizes individual payoff extraction when safe while limiting losses against retaliators.
'''

description_EXPLOITATIVE_71 = '''
Adaptive Exploiter — natural-language strategy description

Goal: maximize my own cumulative payoff by (a) free-riding on opponents who keep contributing, (b) avoiding or short-circuiting long punishments from retaliatory opponents, and (c) using minimal, targeted cooperation only when it is likely to induce or sustain profitable contributions from others. The strategy uses only n, r, k and the full action/payoff history.

Tuning constants (fixed, low-complexity values I use throughout):
- Window W = min(10, t-1) when t>1 (for estimating recent rates).
- Final-defect horizon H = min(2, r) — I defect every round in the last H rounds.
- “Exploitability” threshold high = 0.80, “low” threshold = 0.20, “cooperation” threshold = 0.60.
- Short punishment length Lpunish = 3 rounds (or remaining rounds if fewer).

Per-round procedure (round t = 1..r)

1. Endgame check
- If t > r - H (i.e. in the last H rounds), play D (defect). Rationale: no future to maintain reputation; always free-ride at the end.

2. Maintain statistics (from the history up to t-1)
For each other player j:
- coop_rate_j = fraction of their contributions in the most recent W rounds (if W=0, treat as unknown).
- response_after_my_defect_j = fraction of rounds in which j cooperated in the round immediately following one of my defections (use available data; if none, treat as unknown).
- baseline_j = overall coop_rate_j over a longer window or whole history (if available).

Classify each opponent j using these simple rules:
- “Exploitable” if coop_rate_j >= high AND response_after_my_defect_j >= high (keeps cooperating even when I defect).
- “Reciprocal/conditional” if response_after_my_defect_j is noticeably lower than baseline_j (drop >= 0.30) or if j’s cooperation drops promptly after I defect.
- “Punisher/grim” if j stops cooperating for at least 3 consecutive rounds after one of my defections.
- Otherwise “uncertain” or “mixed.”

Also compute group statistics:
- group_coop_rate = average coop_rate_j across all opponents (recent window).
- fraction_reciprocal = fraction of opponents classified as reciprocal/conditional.
- fraction_exploitable = fraction classified as exploitable.

3. Main decision rules (ordered; first applicable rule determines action)

A. If any exploitable opponent exists (fraction_exploitable > 0):
- Play D (defect) to harvest the benefit from their continued contributions. Exception: if a majority are punishers (fraction_punisher > 0.5), skip to rule C.

B. If a clear reciprocal majority exists (fraction_reciprocal >= 0.5) and group_coop_rate >= cooperation threshold (≥ 0.60):
- Cooperate (play C) with high probability (e.g., ~0.7). Rationale: these opponents will punish perpetual defection; it can be profitable to sustain mutual contributions with them over many remaining rounds. Use probabilistic cooperation to avoid being a deterministic sucker and to retain some exploitation leverage.

C. If many opponents are punishers/grim (fraction_punisher >= 0.5):
- Play D (defect) unless I can identify a safe exploitable subset. If I must test whether punishers will forgive, do a single cooperative probe (C) at most once every Lpunish rounds and observe responses; otherwise continue D.

D. If group_coop_rate is high (>= cooperation threshold) but reciprocals are rare (few punishers, many naive cooperators):
- Play D to exploit naive cooperators. Occasionally (rarely) cooperate with small probability (≈ 0.10) to avoid being flagged as a permanent defector if opponents use detection rules that target the pure defector (this is purely tactical; default is exploit).

E. If group_coop_rate is low (<= low threshold):
- Play D. Rationale: no profitable cooperation to build on.

F. If group_coop_rate is moderate (between low and cooperation thresholds):
- Probe adaptively: play C with a modest probing probability p_probe = 0.2 + 0.6*(k/n) clipped to [0.05, 0.6]. (Interpretation: when k/n is larger I am more willing to invest in building cooperation because each contributed token yields larger shared benefit; when k/n is small I probe less.) Use probes to learn which opponents are exploitable vs reciprocal.

4. Punishment and forgiveness rules (manage retaliation risk)
- If I defect and an opponent j reduces their coop_rate promptly (classified as “reciprocal”), withhold cooperative gestures toward j for Lpunish rounds (avoid offering easy continuing exploitation). After Lpunish rounds, run a single cooperation probe toward j; if they resume cooperation reliably, exploit them per rule A; if they re-punish, withhold cooperation longer.
- If an opponent is an apparent “grim punisher” (repeated permanent retaliation), do not attempt to cooperate with them again unless the remaining number of rounds is large and the expected future benefit justifies rebuilding trust (this is rare; default: avoid cooperating with known grims).

5. First-round special case
- If t = 1 (no history), play C with modest probability p0 = 0.30 if r is reasonably long (r >= 10 or k/n relatively large), otherwise play D. Rationale: early cooperation can seed exploitable cooperators in long games; in short games it is rarely worth giving a free contribution.

6. Short games (small r)
- If r <= 3: defect every round (no room to build reputation).
- If 4 <= r <= 8: be more defensive — default to D except for carefully targeted probes as above.

7. Robustness and randomness
- Introduce small deliberate randomness in borderline cases (probabilities given above) to avoid deterministic exploitation strategies being identified and counter-exploited by highly adaptive opponents. Keep total cooperation frequency low unless sustaining mutual cooperation with reciprocals is clearly profitable.

Summary of mindset and expected behavior
- I primarily defect to free-ride on others’ contributions.
- I invest only minimal, targeted cooperation when (a) I can identify opponents who will continue to contribute after I defect (to exploit them repeatedly), or (b) a clear reciprocal majority exists and sustained cooperation with them is expected to pay off over remaining rounds.
- I punish briefly and forgive cautiously to avoid long mutual losses from cycles of retaliation; I avoid cooperating with known grims.
- I always defect in the final H rounds (endgame free-riding).

This strategy adapts to a wide range of opponents: it aggressively exploits unconditional cooperators, sustains cooperation with conditional cooperators when profitable, probes uncertain players, and defends against punishers. It depends only on n, r, k and observed history.
'''

description_EXPLOITATIVE_72 = '''
Summary: act as a conditional cooperator who (1) opens by cooperating to attract reciprocators, (2) only contributes when a clear majority of others have been contributing recently, (3) periodically and deliberately “probe”/free-ride to exploit stable cooperators, and (4) punish briefly and revert if the probe causes a coordinated collapse. Always defect in the final few rounds (endgame).

Parameters computed from game inputs (deterministic, uses only n, k, r and observed history):
- w = min(5, r) — lookback window in rounds
- theta = 0.6 — fraction threshold of other players contributing in the lookback window required to treat the group as “cooperative”
- S = 2 — number of consecutive recent rounds meeting theta needed to consider the group “stable cooperative”
- P = 2 — length of temporary punishment after a failed exploit
- E = min(3, r) — endgame length: always defect in last E rounds
- Exploit flag and counters maintained in history: last_exploit_round, in_punish_until (round index), coop_streak (consecutive rounds meeting theta)

Decision rules (pseudocode-style description):

Initialization:
- Set last_exploit_round = -infty, in_punish_until = 0, coop_streak = 0.
- In round 1: play C.

Every round t (2..r):
1. If t > r - E (we are in final E rounds): play D. (Endgame defection.)

2. If t <= w (not enough history to fill the full window):
   - If any previous round shows a majority of others cooperated (see step 3 below), treat that as coop_streak = 1; otherwise coop_streak stays low.
   - Default: play D only if coop_streak == 0; otherwise play C. (This avoids being a lone early cooperator when there is no sign of reciprocation.)

3. Compute recent cooperation by others:
   - For the last up to w rounds (rounds max(1,t-w) to t-1), compute other_coop_fraction = (total contributions by players j != i in those rounds) / (w * (n-1)), where w is the number of rounds actually available.
   - If other_coop_fraction >= theta, increment coop_streak by 1; else set coop_streak = 0.

4. If we are currently in punishment period (t <= in_punish_until): play D. (Short, firm punishment to deter exploitation.)

5. Exploit decision:
   - If coop_streak >= S and (t - last_exploit_round) > P:
     - This means the group has been stably cooperative for S recent rounds and we have not just exploited them very recently.
     - Perform a one-shot exploit (probe): play D this round and set last_exploit_round = t.
     - After this exploit, observe next round(s) to see if others reduce cooperation substantially (see step 6).
     - Rationale: single defection when others are reliably cooperating yields a short-term payoff gain (free-ride) while limiting long-term loss by keeping punishment short and targeted.

6. Reaction to an exploit’s aftermath (observed starting in the round after an exploit):
   - If our last action was an exploit (t-1 == last_exploit_round), then in the current round compute the other_coop_fraction over the last w rounds (including the exploit round).
   - If other_coop_fraction dropped by more than 0.3 relative to the value before the exploit (clear coordinated backlash), interpret that as punishment and:
     - Set in_punish_until = t + P - 1 (defect for P rounds including current if not already defecting).
     - Play D this round (part of punishment).
   - Otherwise (no large drop), treat the exploit as tolerated and resume cooperation rules below.

7. Baseline cooperation rule (when not exploiting, not punishing, not in endgame):
   - If other_coop_fraction >= theta (recent majority cooperation), play C.
   - Else play D.

Additional notes and edge cases:
- Small r: if r <= E, always defect every round (no future to sustain cooperation). If 1 < r <= 3, treat initial cooperation conservatively: round 1 cooperate only if r >= 4; otherwise D.
- Small n: theta is a fraction; with very small n (e.g., n=2 or 3) the “majority of others” condition is effectively requiring the opponent(s) to have cooperated at least once in the lookback. Behavior still applies.
- Robustness: parameters (w, theta, S, P, E) are modest and conservative so strategy does not over-punish and keeps punishments short to avoid long mutual losses. The probe/exploit step is limited (one-shot with cooldown) so we extract surplus from stable cooperators without immediately destroying cooperation forever.
- Exploitative intent: the policy intentionally free-rides (single-round D) whenever a reliable cooperative majority is detected, extracting short-term gains; it only concedes cooperation when it is supported by enough other contributors and uses brief retaliation to deter persistent exploiters. The endgame always defects to avoid being exploited in a terminal round.

Why this is exploitative and robust:
- It begins cooperatively to attract reciprocators, allowing the strategy to be part of cooperative clusters to later exploit them selectively.
- It defects whenever the group is not reliably cooperative, avoiding being the lone contributor in noisy populations.
- It probes cooperative clusters with short free-rides to gain extra payoff and checks whether that free-ride is tolerated; if the group responds strongly (coordinated punishment), it punishes briefly to deter future exploitation.
- Short punishments and forgiving return to cooperation preserve profitable long-run relationships when advantageous and limit payoff loss when cooperation collapses.

Implementation summary for each round:
- If in final E rounds → D.
- Else update other_coop_fraction over last w rounds and coop_streak.
- If in punishment window → D.
- Else if coop_streak >= S and cooldown expired → perform a single-round exploit: D and record last_exploit_round.
- Else if recent exploit triggered large backlash → set short punishment and play D.
- Else if other_coop_fraction >= theta → C.
- Else → D.

This strategy is deterministic, only depends on publicly observed history and n, k, r, and is tuned to extract gains from dependable cooperators while avoiding persistent exploitation by defectors.
'''

description_EXPLOITATIVE_73 = '''
Name: Adaptive Exploitative Public-Goods Strategy (AE-PGS)

Summary (what I aim to do)
- Signal cooperation early to attract unconditional cooperators and reciprocators.
- Exploit predictable cooperators (gain one-shot advantage by defecting when others will still contribute).
- Avoid sustained punishment by detecting retaliation and repairing cooperation when it is profitable to do so.
- Be selfish in the final rounds (endgame), where future leverage is weak.
- Decisions are purely a function of game parameters (n, r, k) and the full history of past rounds’ actions and payoffs.

Variables I maintain (computed each round from history)
- t: current round number (1..r).
- For each opponent j:
  - total_j: number of rounds j contributed so far.
  - p_j = total_j / (t-1) if t>1 else undefined.
  - total_after_my_C_j, count_after_my_C_j: contributions by j in rounds that immediately followed a round where I cooperated.
  - total_after_my_D_j, count_after_my_D_j: contributions by j in rounds that immediately followed a round where I defected.
  - p_j_given_my_C = total_after_my_C_j / count_after_my_C_j (fallback to p_j if count=0).
  - p_j_given_my_D = total_after_my_D_j / count_after_my_D_j (fallback to p_j if count=0).
  - delta_j = p_j_given_my_C - p_j_given_my_D (positive delta suggests j is more likely to cooperate after I cooperate → reciprocator/retaliator).
- avg_drop_after_my_D = average over j of (p_j_given_my_C - p_j_given_my_D) weighted by data availability (measures how much opponents reduce cooperation after I defect).
- window w = max(3, floor(r/6)) — recent-history window used when wanting to emphasize recent behavior (used for repair decisions).
- repair_timer: when triggered, number of rounds left to keep cooperating to repair cooperation (initialized 0).
- parameters / thresholds (adapted to game length):
  - Tc (cooperator threshold) = 0.9 (classify near-unconditional cooperators).
  - Punish_threshold = 0.15 (if avg_drop_after_my_D > Punish_threshold, my defection causes significant retaliation).
  - Repair_length R_fix = min(4, max(2, floor(r/10))) (cooperate this many rounds to re-establish trust if punished).
  - Endgame_window E = min(5, max(1, floor(r/6))) — in last E rounds be aggressive (favor defection).
  - Small epsilon = 1e-6 for numeric ties.

Core decision rule (each round)
1. Edge cases
   - If t == 1: Cooperate (C). This signals cooperativeness and collects initial data.
   - If t == r (last round): Defect (D). No future leverage; defect is dominant in single-shot.
   - If t > r - E (inside the endgame window): bias toward Defect. I will still compute expected payoffs (below) but require a stronger justification to cooperate (see step 4).

2. If repair_timer > 0:
   - Play Cooperate (C).
   - Decrement repair_timer by 1.
   - After the cooperation, continue normal updating and return to step 3 next round.

3. Estimate opponents’ expected contributions conditional on my action:
   - expected_others_if_I_C = sum_j p_j_given_my_C (use p_j when conditional data unavailable).
   - expected_others_if_I_D = sum_j p_j_given_my_D (use p_j when conditional data unavailable).

4. Compute my expected one-round payoffs given these expectations:
   - payoff_if_C = 0 + (k / n) * (1 + expected_others_if_I_C).
   - payoff_if_D = 1 + (k / n) * (expected_others_if_I_D).

   Decision:
   - If payoff_if_C > payoff_if_D + epsilon:
       play Cooperate (C). (I only cooperate when it raises my expected payoff.)
   - Else:
       play Defect (D).

   Note (endgame bias): if t > r - E, increase the effective advantage required to cooperate: require payoff_if_C > payoff_if_D + 0.1 (i.e., be more likely to defect in the final rounds).

5. After-action reactive rule (punishment/repair):
   - If I just defected and avg_drop_after_my_D (recomputed after including the new data point when available) exceeds Punish_threshold (i.e., my defection caused a sizable reduction in others’ cooperation), trigger repair:
       - Set repair_timer = R_fix (cooperate for R_fix consecutive rounds to recover cooperation).
   - If I just cooperated and cooperation by the group increased substantially, continue as normal (no special action).

Exploration and robustness
- If conditional estimates are weak (very few observations), the strategy falls back on overall p_j and is conservative in inferring retaliation. The first few rounds are used for exploration and building these conditional statistics.
- This strategy is deterministic given history except for ties; it can also be trivially augmented with a very small random-probing probability (e.g., 1–3%) to break symmetries and improve identification of opponent types, but determinism is sufficient.

Why this is exploitative
- I cooperate early and when it raises my expected payoff, which attracts cooperators and reciprocators.
- I defect whenever the immediate expected payoff is higher, thereby extracting gains from opponents who keep contributing despite my defection (unconditional cooperators or slow-to-pun reciprocators).
- I avoid prolonged being punished: I detect when my defection triggers reduction in others’ cooperation and repair proactively so that punishing opponents do not permanently deny me surplus. Repair trades a few rounds of sacrificed exploitation for regaining a flow of contributions from others.
- By basing the choice on conditional cooperation rates p_j_given_my_C and p_j_given_my_D rather than crude averages, I distinguish between unconditional cooperators (high p_j and small delta_j) and retaliators (large delta_j) and exploit only when exploitation is likely to be profitable.
- In the endgame I default to selfish play (defection bias) because future leverage is weak.

Handling special situations (short summaries)
- First round: Cooperate to gather information and look attractive.
- Last round: Defect (standard endgame reasoning).
- Early rounds / little data: Cooperate initially; use observed responses to build p_j_given_my_C and p_j_given_my_D.
- If many opponents are unconditional cooperators: defect as long as expected payoff calculation shows advantage.
- If many opponents retaliate sharply after my defection: avoid repeated exploitation; use repair_timer to restore cooperation and then re-evaluate.
- If opponents are mixed: the conditional-payoff computation naturally balances the trade-off between exploiting unconditional cooperators and avoiding punishers.

Practical implementation notes (for tournament designers)
- Use a rolling window for conditional statistics if you want to emphasize recent behavior; the pseudocode above uses full history but can be adapted to recent-window statistics for nonstationary opponents.
- Thresholds (Tc, Punish_threshold, R_fix, E) were chosen to be conservative and scale to r; they can be tuned for tournament specifics, but the decision logic (expected payoff comparison using conditional expectations plus detection of retaliation and repair) should remain unchanged.

This strategy maximizes exploitative opportunities while limiting long-term losses from retaliation, and adapts continuously to whatever mixture of unconditional cooperators, reciprocators, defectors and punishers the tournament throws at it.
'''

description_EXPLOITATIVE_74 = '''
Adaptive Exploiter — natural‑language strategy (pseudocode style)

Summary of mindset
- My objective is to maximize my own cumulative payoff. I will contribute as rarely as possible while extracting value from others’ cooperation. I will punish only when necessary to avoid long runs of mutual low-payoff defection, and I will exploit identifiable unconditional cooperators relentlessly. I use short-term statistics (recent rounds) and simple type tests (always‑C, retaliator) to adapt.

Global parameters I use (computed from game parameters and history)
- n = number of players; r = total rounds.
- window m = min(5, r) (recent rounds used for statistics).
- Last‑phase length T_end = min(3, floor(r/10)+1). In the final T_end rounds I move to guaranteed defection (endgame).
- Thresholds (fixed, robust defaults): high_coop = 0.70, low_coop = 0.20, alwaysC_frac = 0.90, retaliator_drop = 0.30, prob_seed = 0.15, prob_contrite = 0.6.
  (These are constants the strategy uses; they do not require communication and scale fine for many n, r, k.)

Definitions from history (all computed over the most recent m rounds unless stated)
- for each other player j compute their contribution_rate_j = fraction of those rounds in which j contributed.
- group_recent_avg = average over other players of contribution_rate_j (equivalently, average contribution per other player in the last m rounds).
- always_cooperators = set of players with contribution_rate_j >= alwaysC_frac.
- retaliators = players who, following rounds in which I defected, reduced their contribution-rate by at least retaliator_drop (measured over matching pre/post windows); if many players behave this way I call them a punishing majority.

Decision procedure (round t, t = 1..r)
1. Endgame override
   - If t > r - T_end (i.e., in the last T_end rounds): choose D (defect). Rationale: backward induction; avoid being exploited in the endgame.

2. Always‑exploit unconditional cooperators
   - If there is at least one always_cooperator (contribution_rate_j >= alwaysC_frac over the last m rounds), then choose D every round (except the endgame is already D). Rationale: a persistent always‑C is a durable source of return; never give them extra incentive.

3. If I detect a punishing majority (many retaliators)
   - If more than half of other players are classified as retaliators: behave contritely to restore cooperation.
     - Choose C with probability prob_contrite, otherwise D.
     - If I cooperate, continue to monitor whether cooperation improves average group payoff; if group_recent_avg rises above high_coop, switch to exploitation rule (4).
   - Rationale: when other players will punish my defection, unending defection lowers my payoff; it can be optimal to pay a cost to rebuild cooperative returns.

4. Exploit dominant cooperation
   - If group_recent_avg >= high_coop:
     - Choose D (exploit: free‑ride on high group cooperation).
     - Exception: with small probability prob_seed (prob_seed ~ 0.15) choose C instead of D to “seed” continued group cooperation and avoid stochastic collapse when many players also randomize; this small seeding increases long‑run payoff while keeping my contribution rare.
   - Rationale: when the group is reliably cooperating, my best move is to defect and capture the public return without paying cost, but occasional tiny cooperation prevents coordination collapse from noise.

5. Try to restart collapsed cooperation (when group is mostly defecting)
   - If group_recent_avg <= low_coop:
     - Choose C with small probability prob_seed (to attempt to reintroduce cooperation) AND otherwise D.
     - If repeated attempts fail (group_recent_avg stays low for many windows), default to permanent defection except if step 3 triggers.
   - Rationale: if everyone else has given up, one tiny, rare investment can sometimes induce reciprocators; but I keep the attempt rare so I am not routinely exploited.

6. Middle ground (ambiguous cooperation)
   - If low_coop < group_recent_avg < high_coop:
     - Mirror the recent trend with lenience: if my previous action was C and group_recent_avg has stayed the same or improved, choose C with probability 0.7 (reward cooperation); otherwise choose D with probability 0.8.
     - Practical rule: favor defection unless others’ cooperation is trending up strongly; in ambiguous zones I bias toward D and only cooperate to nudge cooperation when it looks likely to pay off.

Type detection and simple bookkeeping (runs in background every round)
- Always‑C detection: mark players as always_cooperators if they contributed in at least alwaysC_frac of the last m rounds.
- Retaliator detection: measure whether other players’ contribution_rates drop substantially after rounds in which I defect; if a majority are sensitive, classify them as punishing majority.
- Update group_recent_avg every round.

Initial round
- Round 1: choose D. Rationale: exploit naive cooperators; initial defection gives data for type detection and preserves payoff.

Tie‑breaking and randomness
- Where probabilities are specified, draw independently each round to avoid predictable cycles. Randomized small‑probability cooperation helps preserve long‑term exploitation value while avoiding deterministic collapse.

Why this is exploitative and robust
- Exploitative: I defect whenever I can safely free‑ride (group cooperation high or I have identified always‑C opponents). I contribute only rarely and strategically (seed attempts or contrition) so my personal contribution count is minimal while I capture as much public good as possible.
- Adaptive: I continuously estimate recent group behavior; I respond to punishers (to avoid long mutual defection that would lower my payoff) and punish or exploit persistent cooperators.
- Robust: thresholds and short window m make the strategy reactive but not brittle. Randomized tiny cooperation prevents lock‑in dynamics from accidental noise; endgame defection avoids being trapped.

Edge cases summary
- First round: D.
- Last T_end rounds: all D.
- If a clearly unconditional cooperator exists: always D thereafter (exploit).
- If a punishing majority exists: become contrite (cooperate with elevated probability) to restore profitable cooperation.
- If group cooperation is very high: defect, with a small probability of contributing to stabilize cooperation.
- If group cooperation is very low: mostly defect, occasionally seed cooperation attempts.
- If behavior is ambiguous: bias toward defection but allow occasional cooperation when recent trends reward it.

Practical notes
- All decisions use only n, r, k (for awareness of endgame) and observed history (who contributed each past round). No communication or coordination is assumed.
- Thresholds are conservative defaults; they are chosen to prioritize exploitation while retaining the ability to recover beneficial cooperation when others punish persistent defection.
'''

description_EXPLOITATIVE_75 = '''
Name: Opportunistic Conditional Free‑rider (OCF)

Goal (exploitative): Maximize my own cumulative payoff by (1) permanently free‑riding on any players who keep contributing regardless of my actions, (2) extracting as much benefit as possible from conditional/cooperative players while giving them just enough cooperation to keep them contributing, and (3) avoiding long, costly mutual‑defection spirals by using simple, robust detection and limited forgiveness. The strategy uses only game parameters (n, r, k) and observable history (everyone’s past contributions).

Common constants (computed from parameters at start)
- Lookback window L = min(10, max(1, r-1)). (Use recent up to 10 rounds.)
- Exploitable threshold α_exploit = 0.8. (Player keeps cooperating even when I defect.)
- Reciprocity sensitivity δ = 0.30. (Significant drop in j’s cooperation when I defect.)
- Minimum reciprocator count for stable cooperation count_minR = max(1, floor((n-1)/4)).
- Probe cooperation probability p_probe = min(0.10, 5 / max(10, r)). (Small chance to test for latent cooperators.)
- Forgiveness schedule: if cooperation in group collapses after my defection, I will attempt one cooperative probe every F = 4 rounds to re-open cooperation.

Decision algorithm (round t, 1 ≤ t ≤ r)
1) Endgame rule
- If t == r (last round): Defect. (No future to influence; exploit.)
- Optionally, if r is very small (r ≤ 3), be more exploitative: defect in rounds t ≥ 2. (You may still cooperate in round 1 to probe.)

2) First round
- Play Cooperate on round 1. (Signal willingness to cooperate and discover reciprocators. This is a low-cost investment to identify exploitable/cooperative opponents.)

3) Compute statistics from history (using last L rounds; if fewer rounds exist use what’s available)
- For each other player j compute:
  - Pj_coop_given_I_defect = fraction of rounds in lookback where j contributed while I defected.
  - Pj_coop_given_I_coop = fraction of rounds in lookback where j contributed while I cooperated.
  - delta_j = Pj_coop_given_I_coop − Pj_coop_given_I_defect.
- Let Exploitables = set of j with Pj_coop_given_I_defect ≥ α_exploit.
- Let Reciprocators = set of j with delta_j ≥ δ.
- last_round_coop_fraction = (# of other players who cooperated in previous round) / (n−1).

4) If any exploitables exist
- Defect every round from now on. Rationale: these players will continue contributing even when I defect; no need to pay cost to get the group benefit.

5) Otherwise (no clear unconditional exploitables)
- If Reciprocators count ≥ count_minR:
    - Conditional sustain rule:
      - If last_round_coop_fraction ≥ 0.50 then Cooperate (to maintain cooperation and keep extracting benefits while contributing minimally).
      - Else Defect (don’t pay to prop up cooperation when the recent group signal is weak).
    - Explanation: when there are enough players who respond to my actions, a small, clear cooperative signal (cooperating when many others cooperated previously) can sustain profitable group cooperation. I cooperate only when the majority of others showed cooperation last round — that keeps my contribution infrequent but sufficient to preserve reciprocators’ willingness to contribute.
- Else (few or no reciprocators)
    - Free‑ride / probe rule:
      - Usually Defect (most opponents don’t condition on me; no point to pay).
      - With small probability p_probe (or once every F rounds if I detect long runs of universal defection) Cooperate as a probe to discover latent reciprocators or to re‑start cooperation if the population has drifted.
    - Explanation: without enough reciprocators, cooperating is pure cost with little return; instead, probe occasionally to check if any strategy will start reciprocating.

6) Forgiveness and recovery
- If I defect and see coordinated retaliation (group cooperation collapses), do not escalate punishment. Wait F rounds, then send a single cooperative probe. If some reciprocators return cooperation, revert to the Conditional sustain rule above. If not, revert to Free‑ride/probe behavior. This avoids permanent mutual defection while limiting my contribution frequency.

7) Robustness adjustments (automatic, simple)
- If r is very large (many rounds), become slightly more generous in the early phase to identify reciprocators: increase lookback and p_probe modestly (already captured in p_probe formula).
- If n is small (few opponents), tighten detection thresholds (use same constants but Reciprocators count_minR is a small absolute number), because individual behavior matters more in small groups.

Summary of behavior in short form
- Round 1: Cooperate (signal/probe).
- Last round: Defect.
- If I detect any players who keep cooperating when I defect (Exploitables): defect forever and pocket benefits.
- Else if I detect a nontrivial set of reciprocators: cooperate only when a clear majority of others cooperated in the previous round; otherwise defect.
- Else (no reciprocators): mostly defect, with occasional low‑probability cooperative probes to detect or re‑establish reciprocators.
- Use limited forgiveness (periodic cooperative probes) to avoid permanent collapse if cooperation breaks down.

Why this is exploitative
- It permanently extracts value from unconditional cooperators.
- It minimizes my contribution to the minimal level required to keep conditional cooperators cooperating, maintaining a high personal/relative payoff.
- It avoids costly long punishments by forgiving occasionally, but not so often that punishers can exploit me; probes are rare and controlled.
- It is fully implementable from game parameters and observed history, and adapts to a wide range of opponent types (unconditional cooperators, defectors, conditional cooperators, punishers).
'''

description_EXPLOITATIVE_76 = '''
Strategy name: Opportunistic Exploiter with Conditional Forgiveness (OECF)

Goal (exploitative mindset)
- Attract and sustain cooperation from others early so you can free‑ride when it is profitable; avoid being permanently punished by switching to temporary punishment and staged rehabilitation when others retaliate; always defect in the clear endgame.

Parameters computed from game inputs (deterministic functions of n, k, r)
- window W = max(1, min(5, floor(r/10))) — history window used to estimate recent behavior
- initial_signal_rounds S = min(3, max(1, floor(r/6))) — cooperate initially to signal willingness
- endgame_rounds E = min(3, r) — guaranteed final rounds for unconditional defection
- cooperator_threshold H = 0.70 (threshold for “group is reliably cooperative”)
- unreliable_threshold L = 0.40 (threshold for “group unreliable/mostly defecting”)
- punishment_rounds P = 2 — length of a punishment episode you initiate if punished
- recovery_probe_interval RPI = 1 — number of cooperative probe rounds to try to rehabilitate after punishment
- drop_threshold D = 0.20 — drop in group cooperation that counts as punishment

State you maintain (derived from observed history)
- For each other player j: recent_coop_rate_j = fraction of j’s contributions =1 in the last W rounds (or since start if < W available)
- group_coop_rate = average of recent_coop_rate_j over all other players
- last_rounds_contributions = vector of contributions by all players in most recent round
- punish_mode flag and punish_remaining counter
- last_exploited_round flag (true if you defected while a majority of others cooperated the previous round)

Decision rules (applied each round t, where 1 ≤ t ≤ r)
1. Terminal rounds (endgame)
   - If t > r - E (i.e., in the last E rounds): DEFECT unconditionally.
   - Rationale: finite horizon endgame — no future to gain from cooperating; exploitors should defect.

2. First round and initial signalling
   - If t ≤ S: COOPERATE.
   - Rationale: signal willingness to cooperate so conditional cooperators may reciprocate and give you exploitable benefits later.

3. If punish_mode is ON
   - If punish_remaining > 0: DEFECT this round; decrement punish_remaining.
   - If punish_remaining == 0: perform a recovery probe: cooperate for RPI round(s) (COOPERATE), then observe response. If group_coop_rate recovers to ≥ H, clear punish_mode; otherwise set punish_remaining = P (re-enter punishment) and continue defection.
   - Rationale: punish only briefly but allow structured attempts to rebuild cooperation—prevents permanent mutual defection while remaining exploitative.

4. Normal operation (not in punish_mode, not in initial or terminal windows)
   - Compute group_coop_rate from last W rounds.
   - If group_coop_rate ≥ H:
       - EXPLOIT: DEFECT this round.
       - Record last_exploited_round = true.
       - Rationale: when the group is reliably cooperative, free‑ride to maximize immediate payoff.
   - Else if group_coop_rate ≤ L:
       - REBUILD: COOPERATE this round.
       - last_exploited_round = false.
       - Rationale: when group is unreliable, help rebuild cooperation to create future exploitation opportunities.
   - Else (L < group_coop_rate < H): be prudent — follow recent majority
       - If a strict majority of other players cooperated in the immediately previous round: COOPERATE.
       - Else: DEFECT.
       - last_exploited_round = (you defected).
       - Rationale: mimic local momentum so you are not the only exploiter and risk provoking group collapse.

5. Punishment detection (always check after each round)
   - If last_exploited_round == true and in the round immediately after you exploited the observed group_coop_rate dropped by ≥ D (i.e., the group punished you by reducing contributions substantially):
       - Set punish_mode = ON and punish_remaining = P.
       - last_exploited_round = false.
       - Rationale: if exploitation provokes a clear drop, respond with a short punishment episode to discourage future punishment-triggering behavior and to signal that exploitation will be costly if others coordinate to retaliate.

Edge cases and clarifications
- Ties / ambiguous majority: when counting “majority cooperated” use strict majority (> (n-1)/2). If exactly half, default to DEFECT.
- Small r: all parameters adapt because S, W, E are capped by r; if r is 1 you will defect in final-round rule (you will be in endgame and DEFECT as required).
- Nocommunication / synchronous play: strategy uses only observed contributions and payoffs to compute rates; no signaling beyond contributing behavior.
- Deterministic behavior: except for the small structured “probe” and fixed parameters, the rules are deterministic so tournament opponents cannot rely on noise to outmaneuver you.
- Safety: the punish/recover loop prevents you from being locked into permanent low-payoff defection after a single community backlash; it trades a small short-run cost for long-run exploitation opportunities.

Why this is exploitative and robust
- It attracts conditional cooperators early and then defects while their cooperation rate is high, extracting surplus.
- It reacts to retaliation quickly and predictably: short, targeted punishments and cooperative probes reduce the risk of persistent mutual defection.
- It rebuilds cooperativeness when the environment is hostile, allowing future exploitation opportunities.
- The endgame defection avoids being exploited in the final rounds when future leverage disappears.

Implementation notes (for interpretation by a tournament runner)
- All numeric thresholds (H, L, W, S, E, P, D) are fixed functions or small constants computed from (n, k, r); they can be tuned but must be chosen in advance and depend only on game parameters, not on opponents’ identities.
- The strategy relies only on past contribution history (and derived cooperation rates) and the known n, k, r.
'''

description_EXPLOITATIVE_77 = '''
Name: Adaptive Exploiter (AE)

Summary (one line)
- Actively try to free-ride whenever defection yields net expected gain; detect whether your defections cause others to reduce their future contributions and, if so, switch to limited appeasement or calibrated punishment so that exploitation remains profitable. Always defect in the final rounds when future retaliation cannot offset the immediate gain.

Key constants and derived value (computed from game parameters)
- n, r, k are known.
- One-shot gain from defecting instead of cooperating (immediate private gain):
  G := 1 - k/n  (this is > 0 because k < n)
- Use a recent-history window W (e.g. W = min(12, max(4, r/10))) to estimate behavior.
- Use small smoothing epsilon (e.g. 0.01) to avoid zero-count artifacts.

Data AE maintains (computed from history)
- For each round t and each other player j we observe their action c_j(t) ∈ {0,1}.
- baseline_coop := average number of contributions by others in rounds following rounds when we cooperated (computed over the window W).
- coop_after_def := average number of contributions by others in rounds following rounds when we defected (computed over W).
- d := max(0, baseline_coop − coop_after_def) — estimated immediate drop in others’ contributions attributable to our defection.
- recovery_T := empirical average number of rounds it takes after a round where we defected for the group cooperation level to return to within 90% of baseline_coop (measured within next W rounds). If it does not recover within W, set recovery_T = W (conservative).
- estimated_future_loss := (k/n) * d * recovery_T (this is the expected total reduction in our per-round payout across the recovery period due to fewer contributions by others).
- Occasionally (see PROBING below) also compute per-player responsiveness (how much each player's cooperation rate changes after our defection versus after our cooperation) to detect unconditional cooperators (players with very high cooperation regardless of our moves).

High-level states
- PROBE: short mixed behavior to learn responsiveness.
- EXPLOIT: defect by default to free-ride on forgiving/unconditional cooperators.
- COOPERATE / APPEASE: cooperate to restore cooperation when defections produced costly long-term losses.
- PUNISH (short, calibrated): a small sequence of defections to make retaliation unprofitable for punishers.
Transitions between these states are deterministic from the metrics above.

Detailed decision rules (pseudocode-style description)

Initialization:
- Compute G = 1 - k/n.
- Start in PROBE for a short initial phase (first min(4, r) rounds) to collect signals. First-round action: COOPERATE (this attracts unconditional cooperators and gives baseline signals).
- During PROBE: play a short pattern (example: C, C, D, C) across the initial rounds or until W observations collected — the aim is to observe how others respond to a modest defection while not burning reputation immediately.

Main loop for each round t (with rem = remaining rounds = r - t + 1):

1) If rem == 1: always DEFECT (last round).

2) Recompute baseline_coop, coop_after_def, d, recovery_T, estimated_future_loss from the most recent W rounds (including PROBE rounds). Also compute an empirical “forgiveness rate”: fraction of rounds where group cooperation returned to baseline within one round after our defection.

3) If rem is small (rem <= recovery_T + 1): future retaliation cannot be expected to cost much; DEFECT. (This ensures we exploit near the end when punishers can’t credibly harm us.)

4) Profitability test:
   - If G > estimated_future_loss + margin (margin is a small positive constant, e.g. 0.02, to avoid flip-flopping on noise):
       - Enter/Remain in EXPLOIT state and DEFECT.
       - While in EXPLOIT, do periodic light PROBES: once every P rounds (P = max(3, ceil(1/G))) play a COOPERATE to check continued forgiveness and to avoid creating permanent universal breakdown of cooperation when some conditional cooperators still exist.
       - If per-player analysis shows at least one other player j with cooperation_rate_j >= 0.9 and responsiveness_to_our_moves_j <= 0.05 (i.e., practically unconditional cooperator), stay in EXPLOIT and DEFECT more aggressively (more consecutive defections) because you reliably free-ride on them.
   - Else (G <= estimated_future_loss + margin):
       - Our defection is not profitable long-run. Enter COOPERATE / APPEASE state: COOPERATE for a short appeasement period A = max(1, round(recovery_T/2)) rounds to restore baseline cooperation.
       - After appeasement, reassess metrics. If cooperation returns to baseline and estimated_future_loss falls below G, switch back to EXPLOIT; otherwise remain cooperative until a new profitable opportunity appears.

5) If a defection by you was followed by sustained and disproportionate punishment (observed as coop_after_def << baseline_coop and recovery_T large), use calibrated PUNISH:
   - PUNISH consists of a short sequence of consecutive defections of length P_len = min(ceil(recovery_T/2), 3). The goal is to impose a measurable immediate cost on punishers so that their expected benefit from punishing you is reduced.
   - Immediately after PUNISH, return to COOPERATE for A rounds to test whether cooperation resumes. Do not escalate into indefinite mutual defection: keep punishments short and titrated.

6) Continuous probing rule (keeps strategy adaptive and hard to exploit):
   - If you have cooperated for a long stretch (S_coop ≥ max(5, ceil(1/G))) without any defection probes, perform a single-defection probe (DEFECT for one round) to test responsiveness. If this probe causes large long-lived collapse of cooperation (recovery_T long and d large), revert to appeasement immediately.

Edge cases and robustness notes
- If history is too short to estimate metrics reliably (fewer than 4 informative rounds), remain in PROBE/soft-cooperate for another small number of rounds (C, D, C pattern) to collect data.
- If multiple players are clearly unconditional defectors (very low cooperation rates), expect baseline_coop small; then EXPLOIT and defect always (you gain the one-shot benefit and there is nothing to recover).
- If k is close to n (G small), AE is more cooperative because the immediate benefit from defection is small; the profitability test will more often favor cooperating to preserve future payoffs.
- If k is small (G large) AE will favor defection and exploit unconditional or forgiving cooperators more aggressively.
- Always avoid infinite punishment wars. Punishments are short and calibrated; the strategy always re-evaluates after an appeasement period rather than rigidly sticking to grim strategies.

Why this is exploitative and robust
- Exploitative: AE seeks immediate one-shot gain whenever long-term costs are unlikely to offset it. It deliberately free-rides on unconditional and forgiving cooperators; it defects whenever permitted by the profitability inequality.
- Adaptive: AE constantly measures the real effects of its defections on others (d and recovery_T) rather than assuming a fixed opponent model. It uses short calibrated punishments to discourage costly punishers but reverts to cooperation if punishment backfires.
- Robust: AE works across mixtures of opponent types (unconditional cooperators, conditional cooperators, defectors, retaliators) because it dynamically balances short-term exploitation and long-term maintenance of cooperation based on empirical signals. It defaults to defection near the end to capture the guaranteed one-shot advantage when retaliation is no longer credible.

Concise behavioral summary for play
- First few rounds: gentle probing (start C; mix a single D soon) to learn responsiveness.
- Each round: compute empirical drop d and recovery_T caused by your past defections; defect only if immediate gain G > (k/n)*d*recovery_T (plus small margin). Otherwise cooperate to maintain cooperation.
- If punished strongly, give a short measured punishment (few Ds) then cooperate to rebuild cooperation.
- Periodically probe to ensure opponents are still forgiving; always defect in the final round (and when remaining rounds are too few for retaliation to be costly).
'''

description_EXPLOITATIVE_78 = '''
Name: Exploitative-Reciprocity (ER)

Intuition (one line)
- Cooperate only when my cooperation reliably induces others to cooperate (so I can recoup the immediate cost); otherwise free-ride. When a group is very cooperative, occasionally defect to extract extra payoff, but avoid being persistently exploited by defecting when others are unresponsive. Always defect in the predictable endgame.

Parameters and initialization (fixed, deterministic functions of game parameters)
- History window H = min(20, r) (use up to the last H rounds for statistics).
- Endgame window E = min( max(3, ceil(r/10)), r ) (last E rounds treated as endgame).
- Small smoothing constant s = 1e-6 (to avoid division-by-zero and extreme estimates).
- Occasional-cooperation probability when exploiting p_probe = 0.1 (to maintain cooperation in a cooperative crowd).
- Discount factor for forecasting immediate next-round reciprocity gamma = (remaining_rounds - 1) / max(1, remaining_rounds) (so influence declines as the game nears the end).
- Cooperation thresholds: none hard-coded beyond the decision rule below; thresholds are derived from estimated responsiveness and the known marginal private cost (1 - k/n).

Stored statistics (updated each round from public history)
- For each other player j: counts over last H rounds:
  - N_cj = number of times j cooperated in rounds that immediately followed a round when I cooperated.
  - M_cj = number of rounds (within H) that immediately followed a round when I cooperated.
  - N_dj = number of times j cooperated in rounds that immediately followed a round when I defected.
  - M_dj = number of rounds (within H) that immediately followed a round when I defected.
- Group cooperation rate G = fraction of players who cooperated averaged over last H rounds.

How responsiveness is estimated
- For each j, estimate p_cj = (N_cj + s) / (M_cj + 2s) and p_dj = (N_dj + s) / (M_dj + 2s).
- Responsiveness R_j = p_cj - p_dj (how much more likely j is to cooperate after I cooperate vs after I defect).
- Aggregate responsiveness R = average_j R_j (average over all other players; if n=1 treat R=0).

Decision rule every round t (not in code; plain steps)
1. Endgame: if current round t is within the last E rounds, play D (defect) every remaining round. Rationale: no future to recoup cost; exploit via defection.

2. First round / no data: if there is no prior round, cooperate (C) to probe. Rationale: initial probe is cheap for long games and helps elicit responders.

3. Compute my immediate private cost of cooperating this round:
   - Cost = 1 - (k / n) (the one-round loss if others’ behavior is unchanged).

4. Compute expected immediate next-round benefit from a single cooperation today:
   - SumR = sum_j R_j (expected extra number of contributions by others next round caused by my cooperating today).
   - Benefit_next_round = (k / n) * SumR.
   - Expected discounted future benefit B = gamma * Benefit_next_round.
   - Intuition: cooperating today can raise others’ cooperation next round; I value that at the marginal payoff per extra contribution, discounted by how many rounds remain.

5. Cooperate vs defect:
   - If B > Cost, play C (cooperate). Rationale: the expected future reciprocity induced by cooperating outweighs the immediate loss.
   - Else (B <= Cost), play D (defect) EXCEPT:
     a) If the recent group cooperation rate G is very high (e.g., most players have cooperated repeatedly) then exploit: play D to free-ride, but with small probability p_probe play C to avoid collapsing cooperation entirely. Concretely: if G > 0.8, play D with probability 1 - p_probe and C with probability p_probe.
     b) If G is moderate and there is uncertainty (very small M_cj and M_dj for many j), fall back to a conservative probe: play C with low probability 0.2 to gather data (this avoids long periods of pure defection in noisy environments).

6. Punishment and forgiveness (implicit in responsiveness update):
   - Do not attempt long, costly group-wide punishments. Instead, let responsiveness estimates drive behavior: if others do not reciprocate my cooperations, R falls and I stop cooperating (automatic, rapid punishment).
   - If responsiveness recovers (others start cooperating after I cooperate), I resume cooperation immediately (forgiveness is automatic).

Edge cases and clarifications
- If n is very small (2 players), the algorithm is the same; responsiveness is measured against the single partner.
- If insufficient recent data to estimate R (e.g., no previous times I cooperated), the strategy uses probing rules: first round cooperate; otherwise use small-probability probes (20%) to get signal until some observations exist.
- If multiple rounds remain but I observe paradoxical noise (R near zero but G high), the exploit clause (step 5a) ensures I extract extra payoff while sporadically cooperating to keep the crowd cooperative.
- The approach is deterministic except for controlled small-probability probes; randomness is used only to avoid collapse of cooperation after exploitation and to resolve initial uncertainty.
- The method does not rely on coordination or shared norms; it uses only publicly observed actions and payoffs.

Why this is exploitative and robust
- Exploitative: when others reliably respond to my cooperation, I cooperate to elicit sustained group contributions and share in high payoffs. When others are cooperative but I can free-ride without losing future cooperation, I deliberately defect to extract extra payoff (occasional cooperation prevents total collapse). When others are unresponsive or exploitative, I immediately stop cooperating and defend myself by defecting.
- Adaptive: responsiveness R is updated continuously from observed behavior, letting the strategy discover and exploit patterns (pure cooperators, conditional cooperators, unconditional defectors, noisy strategies).
- Robust: probing and smoothing avoid over-reacting to one-off noise; automatic forgiveness allows recovery when opponents become responsive; the endgame rule prevents being exploited at the end.

Concise pseudocode summary (plain language)
- If in last E rounds: D.
- Else if no history: C.
- Else compute R_j for each opponent j from last H rounds, set R = average_j R_j.
- Compute Cost = 1 - k/n; Benefit_next = (k/n) * sum_j R_j; B = gamma * Benefit_next.
- If B > Cost: C.
- Else if recent group cooperation G > 0.8: play D, but with probability p_probe play C.
- Else: D, but with small probing probability 0.2 if data are scarce.

This strategy uses only the game parameters and public history, is adaptive to diverse opponents, exploits persistent cooperators while avoiding being exploited by defectors, and guarantees defection in the endgame.
'''

description_EXPLOITATIVE_79 = '''
Adaptive Exploitative Conditional Cooperator (AECC)

Goal: maximize my own cumulative payoff and preferentially exploit unconditional cooperators and naive learners while avoiding long, costly punishments. The strategy is entirely history-dependent and uses short, transparent routines for probing, classification, exploitation, and safety (repair/cooperation) plus a short endgame of defection.

Parameters I compute from the game inputs (n, r, k) and history:
- t_probe = min(6, max(1, floor(r/5))) — number of initial probing rounds.
- T_end = min(3, max(1, floor(r/20))) — number of final rounds in which I always defect (endgame).
- update_window W = min(6, r) — number of rounds used to re-evaluate opponent behavior regularly.
- p_keep_default = 0.15 — base “keep-some-cooperation” probability in exploitation mode.
- thresholds for classification: coop_high = 0.8, coop_low = 0.2, punishment_drop = 0.35.
(These numbers are fixed, but depend indirectly on r via t_probe/T_end.)

Round-by-round decision outline:

1) Extremely short special cases
- If r = 1: defect (no future gains).
- If n = 1: contribute if k > 1 (self-benefit), else defect. (Edge case only.)

2) First t_probe rounds — probing and data collection
- First round: cooperate (C). I start friendly to reveal cooperators and avoid immediate universal defection.
- During the t_probe rounds I follow a short probing pattern that mixes cooperation and occasional defection to elicit how others react:
  - A simple deterministic pattern: C, C, D, C, D, C (truncate to t_probe rounds).
- After every probe round, record for each opponent j:
  - coop_rate_j = fraction of probe rounds j contributed.
  - responsiveness_j = estimated change in j’s contribution probability after I defected versus after I cooperated (computed from available transitions).
- After probe completes, classify each opponent:
  - Unconditional cooperator: coop_rate_j >= coop_high.
  - Persistent defector: coop_rate_j <= coop_low.
  - Punctual punisher / conditional cooperator: responsiveness_j shows a drop of at least punishment_drop in their contribution probability following my defection (they retaliate).
  - Otherwise: conditional/uncertain.

Also compute:
- fraction_cooperators = fraction of opponents classified as unconditional cooperators.
- fraction_punishers = fraction classified as punishers/conditional-retaliators.

3) Modes and precise decision rules (applied every subsequent round except special endgame rounds)
I operate in one of three adaptive modes chosen after probing and updated every W rounds:

A. Exploitation mode (preferential free-riding)
- Enter when fraction_cooperators is appreciable (>= 0.35) AND fraction_punishers is small (< 0.30).
- Policy: defect by default to capture benefits produced by cooperators. To avoid causing adaptive collapse or provoking strategic punishers that learn slowly, I inject occasional cooperation:
  - cooperate with probability p_keep = min(p_keep_default, 0.6 * fraction_cooperators).
  - equivalently, cooperate roughly once every 1/p_keep rounds (deterministic schedule is acceptable: e.g., cooperate one round every ceil(1/p_keep) rounds).
- Continuously monitor consequences: if after switching to exploitation my average payoff across the last W rounds falls significantly below the sample mean payoff of opponents or if group contributions drop sharply (more than 30% from probe levels), immediately move to Repair mode (case B).

Rationale: when many unconditional cooperators exist, defecting most rounds yields higher personal payoff. Small, intermittent cooperation reduces the risk of strategic learners converging to universal defection.

B. Repair / Conditional Cooperation mode (avoid persistent punishment)
- Enter when fraction_punishers >= 0.30 OR when exploitation caused big drops in my payoff or group contribution.
- Policy: behave as a forgiving conditional cooperator to rebuild stable cooperation:
  - Cooperate this round iff (last round’s total contributions by others) >= tau, where tau = ceil((n-1)*0.5) (i.e., at least half of the other players contributed last round).
  - If I detect that a specific opponent punished me (they cut their contribution immediately after my defection) I treat them as a punisher in future classifications but do not try to retaliate individually (no targeted punishment is possible); instead I increase my cooperation frequency to stabilize the group.
  - Be forgiving: if one or two rounds of group dropout occur, allow up to 2 consecutive rounds of non-cooperation before switching back to full defection — attempt to re-establish cooperation quickly.
- If, while in repair mode, my average payoff becomes consistently above the group mean and group cooperation stabilizes, I may transition back to Exploitation mode but at a lower p_keep.

Rationale: punishers make unilateral exploitation expensive; it is better to cooperate conditionally to maintain mutual gains rather than engage in long, costly punish cycles.

C. All-defector mode
- If a large majority (>= 0.85) of opponents have coop_rate <= coop_low over a long window, always defect. There is nothing to exploit; preserve endowment.

4) Continuous reclassification and simple profitability check
- Every W rounds recompute coop_rate_j and responsiveness_j using recent history and re-evaluate fraction_cooperators and fraction_punishers.
- Profitability check: if my running average payoff over last W rounds falls below the median opponent payoff by a margin (e.g., 5% or an absolute amount), switch to Repair mode immediately. If my payoff is consistently in the top half and group contributions remain stable, favor Exploitation mode.

5) Endgame
- For the final T_end rounds (unconditional endgame window): always defect (D). Backward induction suggests there is no future to enforce cooperation; defect to harvest endowment.

6) Randomization and determinism
- I use deterministic rules except where I stated explicit small probability p_keep to avoid being trapped by perfectly deterministic punishing strategies and to make my behavior hard to be exploited by contrived strategies that can perfectly predict and punish a deterministic pattern. The randomness is small and only used while exploiting (p_keep) and can be implemented by a fixed periodic pattern instead of true randomness if required.

7) Safety notes and edge handling
- Very short games (r <= t_probe): behave as:
  - r = 1: defect.
  - r small (<= t_probe): follow the probing pattern but bias towards defect as the game length shortens; if r <= t_probe, treat any cooperation later as probed and defect more often.
- If opponents appear to be learning extremely fast (cooperation rates change drastically within a few rounds), shorten update_window W and be more conservative (increase p_keep) to avoid triggering collapse.

Why this is exploitative
- The strategy actively seeks and identifies unconditional cooperators and takes advantage of them by defecting most rounds in Exploitation mode, extracting the public benefit without paying the cost.
- It minimizes losses when facing punishers by switching to Repair/conditional cooperation instead of engaging in destructive punishment wars.
- It adapts continuously to opponents’ observed behavior and to short-term payoff signals to avoid becoming a persistent sucker.
- It defects in the endgame to capture final endowments when reciprocity cannot be enforced.

Summary pseudocode (conceptual):
- If r == 1: play D.
- Initialize probing for t_probe rounds using pattern C,C,D,C,D,C...
- Classify opponents by coop_rate and responsiveness.
- Choose mode: Exploit if many cooperators and few punishers; Repair if many punishers or exploitation failing; All-defector if almost everyone defects.
- Each round (except final T_end rounds):
  - If mode == Exploit: play D except cooperate with probability p_keep (or on a deterministic 1-in-L schedule).
  - If mode == Repair: cooperate iff last round at least tau of the others contributed; forgive up to 2 rounds of drop before re-evaluating.
  - If mode == All-defector: play D.
- Every W rounds recompute classifications and switch modes if necessary.
- For last T_end rounds: always play D.

This strategy is simple, transparent, and robust: it exploits naive cooperators aggressively, but it is adaptive enough to avoid long-term, expensive retaliation by switching to conditional cooperation when punishers are detected or when exploitation reduces my payoff.
'''

description_EXPLOITATIVE_80 = '''
Adaptive Exploiter (AE) — an adaptive, history-dependent exploitative strategy for repeated PGG

Goal
- Maximize my own cumulative payoff by extracting value from cooperative opponents while avoiding or minimizing costly, sustained punishment. Be adaptive: probe opponents early, identify who is reliably cooperative or who punishes, then exploit cooperators and be cautious around punishers. Always defect in the final round.

Definitions (what I track each round)
- t: current round (1..r).
- H: full history up to round t−1 (every player's contributions each past round).
- For each opponent j:
  - coop_rate_j = fraction of past rounds in which j contributed (exclude current round).
- group_rate G = average_j coop_rate_j (average contribution rate of others).
- Window W = min(10, t−1) (number of recent rounds used to estimate short-run responses).
- influence delta = avg_others_contribution_in_rounds_where_I_cooperated − avg_others_contribution_in_rounds_where_I_defected, measured over the most recent W rounds (if denominator zero, treat that case as delta = 0). This estimates how much my cooperation tends to increase others’ contributions.
- punisher_j flag = true if j’s contribution probability drops by more than P_drop (e.g., 0.25) after a round where I defected (detectable within W). If many players are punisher_j, the group is punitive.
- Parameters (fixed, set from r but do not need opponent tuning):
  - ProbeRounds = min(3, max(1, floor(r/10))) — small number of initial probing cooperations.
  - EndgameRounds = min(3, max(1, floor(r/10))) — rounds near the end in which I switch to guaranteed defection.
  - LowThreshold T_low = 0.2 (group cooperation below this is “hopeless”).
  - SmallInfluence eps = 0.02 (negligible influence).
  - MinCoopProb p_min = 0.02, MaxCoopProb p_max = 0.8.

Decision rules (what I do each round)
1. Endgame: If t > r − EndgameRounds or t == r, choose D (defect). Rationale: no future to leverage; exploit immediately.

2. Initial probing: If t ≤ ProbeRounds, choose C (cooperate). Rationale: signal cooperativeness and collect data on responses.

3. Compute statistics from H: G, delta, list of punisher_j, fraction PunishFraction = fraction of opponents flagged as punishers.

4. If G < T_low (group is largely defecting), choose D (defect). Rationale: cooperating when most others do not yields lower payoff and rarely elicits cooperation.

5. If PunishFraction is large (e.g., ≥ 0.4):
   - Many opponents punish; avoid provoking them. Choose C with probability p = clamp( 0.5 * G + 0.2, between p_min and 0.9 ). (More likely to cooperate to avoid sustained punishment; still do not always cooperate.)
   - Rationale: expensive retaliation is likely; trade off some immediate gain to preserve long-run earnings.

6. Otherwise (group receptive or punishers few):
   - If delta ≤ eps (my cooperation has negligible effect on others’ behavior):
     - Most opponents are insensitive to my moves. Set a low cooperation probability:
       p = clamp( max(p_min, 0.15 * G + 0.05), between p_min and 0.4 ).
     - Implement: choose C with probability p, else D.
     - Rationale: I can free-ride often because they don’t punish or condition on me, but keep occasional cooperation to avoid appearing as an always-defector which might trigger more global collapse.
   - If delta > eps (my cooperation helps sustain others’ contributions):
     - I can buy contributions with occasional cooperation. Compute cooperation probability:
       p = clamp( p_min + 0.6 * normalize(delta), between p_min and p_max ).
       (normalize(delta) maps delta in [0, 1] to [0,1]; in practice treat delta up to ~0.5 as strong.)
     - Implement: choose C with probability p, else D.
     - Rationale: cooperate enough to sustain beneficial group contributions, but defect often enough to capture exploitative surplus.

7. Deterministic tie-breakers:
   - If a deterministic choice is needed instead of probabilities, use: cooperate if p >= 0.5; otherwise defect.
   - If any single opponent has coop_rate_j > 0.9 and does not punish me when I defect, bias toward D (exploit that player more aggressively).

Additional operational notes (robustness)
- Rolling updates: recompute G, delta and punishers each round using the most recent data window W so the strategy adapts to changing opponent behavior.
- Safety: never allow p to be 1 except in ProbeRounds; I always leave room to defect and gain from cooperative opponents.
- Detect sudden regime changes: if group cooperation collapses quickly after I start defecting, reduce my defection rate immediately (increase p) to try to stabilize cooperation if that is net-beneficial.
- Transparency avoidance: avoid long stretches of deterministic behavior (e.g., always C or always D) that let others reliably exploit me; remain slightly stochastic to prevent easy exploitation.

Edge cases summary
- First round(s): cooperate for ProbeRounds to probe and build credibility.
- Last round: defect (no future consequences).
- Near end: defect for EndgameRounds to harvest value before the game ends.
- If nearly everybody always defects (G very small): defect always.
- If many punishers: bias toward cooperation to avoid sustained retaliation.
- If my cooperation clearly raises others’ contributions: cooperate often enough to sustain those contributions, but continue defecting with nontrivial probability to exploit them.

Why this is exploitative
- The strategy intentionally extracts benefit from opponents who keep cooperating or who are insensitive to my defection by defecting more than cooperating in steady-state.
- At the same time it protects against costly long-run punishments by detecting punishers and switching to more cooperative behavior when necessary.
- It uses early probing to identify exploitable opponents, adaptive exploitation parameters (based on measured influence delta), and endgame defection to guarantee final-round gains.

This approach balances opportunistic defection (to exploit cooperators) with measured cooperation (to sustain beneficial contributions from others and to avoid destructive retaliation), making it robust across a wide variety of opponent behaviors in a tournament setting.
'''

description_EXPLOITATIVE_81 = '''
Summary: Be a cautious opportunist — lure and identify conditional cooperators, exploit them by occasional defections that maximize one-shot gain while keeping their cooperation long-term, punish quickly if they retaliate, and otherwise refuse to be exploited. Always defect in the final round.

Notation I keep and update from history:
- For each other player j I track:
  - N_j = total rounds observed for j
  - C_j = times j contributed
  - Cj_after_myC = times j contributed in the round immediately after I contributed
  - Cj_after_myD = times j contributed in the round immediately after I defected
  (I use Laplace smoothing: estimate probabilities with +1 numerator, +2 denominator)
- Group stats derived from those per-player estimates:
  - p_j = P(j cooperates) ≈ (C_j + 1) / (N_j + 2)
  - p_j|C = P(j cooperates after my C) ≈ (Cj_after_myC + 1) / (N_after_myC_j + 2)
  - p_j|D = P(j cooperates after my D) ≈ (Cj_after_myD + 1) / (N_after_myD_j + 2)
  - rec_j = p_j|C - p_j|D (responsiveness to my cooperation)
  - Group cooperation rate P = average_j p_j
  - Group responsiveness R = average_j rec_j

Fixed internal parameters (set by me using game parameters n,k,r; values chosen to be robust):
- min_samples = 4 (don’t trust statistics for a player until a few observations)
- p_thresh = 0.60 (absolute cooperation probability to treat someone as cooperatively useful)
- rec_thresh = 0.20 (minimum responsiveness to classify someone as a conditional cooperator)
- exploit_interval_base = 4 (baseline length of cooperation between exploitation defections)
- punishment_len = 2 (short, harsh punishment when reciprocity collapses)
- last_rounds_defect = 1 (always defect in final round); if r <= 6 then last_rounds_defect = 2

High-level modes:
- Test mode (initial, learning): cooperate first few rounds to collect data.
- Exploit mode (majority of actionable reciprocators): mostly cooperate to keep cooperators cooperating, but periodically defect to extract one-shot gains; adapt frequency to opponents’ responses.
- Defensive/Exit mode (no reliable reciprocators): defect each round to avoid being exploited.
- Punishment mode: brief block of defections when my exploitation provokes durable cooperation collapse, then resume testing.

Decision rules (per round t):
1) Endgame:
   - If t > r - last_rounds_defect: choose D (defect). (Always defect in the last round; defect in the last two rounds if r small.)

2) Early rounds / data collection:
   - If t == 1: choose C (cooperate) — a single cooperative opening is an inexpensive test and lures conditional cooperators.
   - Otherwise, if for the majority of players I have fewer than min_samples observations, continue cooperating for the next 1–2 rounds to gather usable data (cooperate unless there is strong evidence of universal defection).

3) Estimate players’ behavior:
   - Compute p_j, p_j|C, p_j|D and rec_j for each j with Laplace smoothing.
   - Identify the set S_rec of players satisfying:
       a) N_j >= min_samples (enough data),
       b) p_j|C >= p_thresh (they reliably cooperate after my cooperation),
       c) rec_j >= rec_thresh (they respond to my cooperation).
   - Let m = |S_rec| (number of identified conditional cooperators).
   - Let m_frac = m / (n - 1) be the fraction of others who look like conditional cooperators.

4) Mode selection:
   - If m_frac >= 0.5 (a majority of other players are conditional cooperators): enter Exploit mode.
   - Else if P (group cooperation rate) >= 0.9 and many players have high unconditional p_j but low rec_j: I remain cautious — I will cooperate one round to test and then behave exploitatively if they are unconditional cooperators (they can be freely exploited because they don't punish). Practically this falls through to Exploit behavior but with less forgiving return-to-cooperation.
   - Otherwise: Defensive mode (defect each round) — I won’t give away tokens to unresponsive defectors.

5) Exploit mode behavior:
   - Maintain a repeating cycle: Cooperate cooper_cycle rounds in a row, then defect a single round (a “grab”), then repeat.
   - Set cooper_cycle initially to exploit_interval_base (≈4). Adjust cooper_cycle adaptively:
       a) After each defection (a grab), measure cooperation among S_rec in the following rounds. If their p_j|after_myD drops by more than 0.15 relative to p_j|C, increase cooper_cycle (lengthen the cooperative run before the next grab) — be more forgiving, fewer grabs.
       b) If their cooperation barely drops (<= 0.05), decrease cooper_cycle (more frequent grabs).
       c) Bound cooper_cycle between 1 and max(10, r/4).
   - If a grab causes more than punishment_len rounds of sustained collapse in group cooperation (group cooperation rate falls below 0.5), switch to Punishment mode.

   Practical rule for current-turn choice in Exploit mode:
   - If current position inside the cycle is a scheduled grab round: choose D.
   - Otherwise choose C.

6) Punishment mode:
   - If I detect durable retaliation (group cooperation drops sharply following my grab), punish by defecting for punishment_len rounds to signal the cost of retaliation.
   - After punishment_len defections, return to Test mode for 1–2 cooperative rounds to see if reciprocators return; if they do (p_j|C recovers) resume Exploit mode with a longer cooper_cycle.

7) Defensive mode (no reliable reciprocators):
   - Choose D every round (never cooperate), except: once every M rounds (M = max(8, r/10)) perform a single cooperation test round to check if any opponent’s behavior changed (cooperate only if there is a clear reason like a sudden spike in unconditional p_j). That single test is cheap and can detect new conditional cooperators.

8) Safety / anti-exploitation guard:
   - If my own observed personal payoff rate falls below what I would get always defecting for several rounds in a row, switch immediately to Defensive mode to stop losses.
   - Never allow a long, unconditional string of cooperative rounds unless it is consistently paid back (group cooperation rate > p_thresh for several rounds).

Rationale / exploitative alignment:
- Lure: I open cooperatively and spend a few rounds cooperating to reveal which opponents are conditional cooperators — these are the targets to exploit.
- Extract: Once I identify conditional cooperators, I keep them cooperating most rounds (cooperate repeatedly) but periodically defect (a single-round “grab”) to maximize immediate gain. Single-round defections give the maximal immediate per-grab benefit while minimizing the signal that would cause permanent retaliation.
- Adapt: I adapt the frequency of grabs to opponents’ observed tolerance — if a grab provokes durable retaliation, I back off and punish briefly, then rebuild trust. This protects me from being trapped in long mutual defection.
- Protect: If opponents are mostly unresponsive or hostile, I stop giving — I defect every round to avoid exploitation.
- Endgame: As an exploiter I defect in the final stage (at least last round) because no future gain can justify giving tokens away.

Examples of behavior one will observe:
- Against naive cooperators (always-C): I will cooperate nearly always, but I will occasionally defect to extract a one-shot gain; they remain cooperative, and I exploit repeatedly.
- Against TFT-like reciprocators: I will cooperate to build cooperation; when I defect once, many will defect next round — I then punish briefly and return to cooperation with longer cooperative stretches between grabs, extracting safe rents.
- Against always-defectors: I defect every round and avoid losses.

Implementation notes (for tournament implementers):
- Use the simplest reliable statistics (counts and smoothed probabilities) restricted to a recent window (e.g., last 20 rounds) to adapt to changing behaviors.
- Tune p_thresh and rec_thresh conservatively so you only classify someone as exploitable when you are reasonably confident.
- Keep punishments short and forgiveness quick — avoids long mutual-defection traps and maximizes total exploitation across the whole repeated game.

This strategy is intentionally exploitative: it seeks to maximize extraction from conditional cooperators by alternating mostly-cooperation with occasional, calibrated defections; it avoids being exploited by defecting when opponents are unresponsive or when exploitation triggers durable retaliation; it adapts to opponent responsiveness and the length of the remaining game, and it always defects in the last round.
'''

description_EXPLOITATIVE_82 = '''
Name: Opportunistic Conditional Exploiter (OCE)

Goal (exploitative mindset): Maximize my total payoff by (1) identifying and preserving others who reliably contribute, (2) harvesting extra payoff by defecting opportunistically when enough others still contribute, and (3) avoiding being trapped by unconditional defectors. I cooperate only when it is expected to produce net future benefit (by sustaining others’ contributions) and otherwise defect; I always defect near the end when future inducement is impossible.

Key ideas summarized:
- Probe early to classify players (cooperator / conditional / defector).
- Cooperate to build or preserve cooperation only when enough others are likely to contribute in future.
- Use a calibrated exploitation rate (randomized defections) to milk cooperators while watching for retaliation; reduce exploitation if cooperators punish.
- Punish only when useful (to protect my payoff) and forgive to keep exploitable cooperators cooperating.
- Always defect in the final phase (no future rounds to influence).

Parameters (set from game parameters; defaults listed; adapt if r small):
- r = total rounds, n = players.
- early_phase = max(3, floor(r/5)) rounds for probing / classification.
- end_phase = max(3, floor(r/5)) rounds at the very end where I always defect.
- sliding_window W = max(3, floor(r/10)) for responsiveness checks.
- coop_high = 0.60 (cooperation rate threshold to call someone a cooperator).
- coop_low = 0.20 (to call someone an unconditional defector).
- resp_threshold = 0.15 (difference p(if they cooperate | I cooperated) − p(if they cooperate | I defected) indicating conditionality).
- p_exploit_initial = 0.30 (initial probability of defecting during exploitation).
- p_exploit_max = 0.60, p_exploit_min = 0.0.
- exploit_adjust_step = 0.10.
- tolerated_drop = 0.08 (if cooperators’ cooperation rates drop by more than this after I increase exploitation, reduce exploitation).
- blacklist_recovery = max(3, floor(r/20)) rounds I withhold cooperation from a specific player after they betray expected behavior.

Data I keep:
- For each other player j: total rounds observed t_j, contributions C_j, cooperation_rate r_j = C_j / t_j.
- Conditional cooperation stats: p_j|myC = fraction of rounds j cooperated following a round where I cooperated; p_j|myD = fraction after I defected.
- Group cooperation history and sliding-window cooperation rates.

Full decision rules (pseudocode-style natural language):

INITIALIZATION
- Round = 1: cooperate (probe).
- Initialize all counters to zero.

EACH ROUND (before choosing action), if current round > r - end_phase:
- Action: defect (final-phase rule). Explanation: no future rounds to induce cooperation, so always defect.

Otherwise (not in final-phase):
1. Update statistics from all past rounds (all players’ actions).
2. Classify players:
   - If r_j ≥ coop_high OR (p_j|myC − p_j|myD ≥ resp_threshold and r_j ≥ 0.30), mark j as likely conditional cooperator.
   - If r_j ≤ coop_low, mark j as unconditional defector (blacklist).
   - Others remain unclassified / weak cooperators.
3. Decide mode:
   - If count of likely cooperators (excluding me) ≥ 1 AND group mean cooperation rate over last W rounds ≥ 0.30:
       Enter Exploitation Mode.
     Else:
       Enter Defection Mode.

Exploit Mode (I will attempt to extract surplus while keeping cooperators cooperating)
- Maintain a scalar p_exploit (probability to defect this round). Start at p_exploit_initial when first entering this mode.
- Action this round:
   - If any unconditional defectors are present, treat them as blacklisted: I never “target” them with cooperation incentives (i.e., I do not deliberately cooperate just to entice those players).
   - Decide: With probability p_exploit, defect; otherwise cooperate.
- Monitoring and adaptation (after observing the round outcome, update stats):
   - Compute average cooperation rate among the set of likely cooperators over the last W rounds (call it coop_rate_now) and compare to coop_rate_before measured before last p_exploit change.
   - If coop_rate_now has dropped by > tolerated_drop since the last change, reduce p_exploit by exploit_adjust_step (down to p_exploit_min). This is precaution against retaliation—I prefer fewer exploitation rounds rather than lose cooperators entirely.
   - If coop_rate_now is stable (change within ±tolerated_drop) for two consecutive adaptation windows and p_exploit < p_exploit_max, increase p_exploit by exploit_adjust_step (up to p_exploit_max). This increases extraction when cooperators tolerate exploitation.
- Targeted forgiveness/punishment:
   - If a specific previously-reliable player j’s cooperation rate falls sharply following my defections (their p_j|myD << p_j|myC by a substantial amount), add j to a short-term blacklist: I defect for blacklist_recovery rounds (protecting myself) and then probe them again with an isolated cooperation to test whether they return to being exploitable. If they do, reclassify them as conditional cooperator; if not, keep them blacklisted.

Defection Mode (no reliable cooperators to exploit)
- Action: defect every round (save occasional probes described below).
- Occasional probing: once every max(10, floor(r/10)) rounds (but never in the end_phase), do a single cooperative probe if total remaining rounds > end_phase + 2:
   - Cooperate this probe round and observe responses for W rounds; if several players shift to cooperate reliably and appear responsive to my cooperation, switch to Exploit Mode. Limit probes to avoid being exploited by unconditional defectors.

First-round policy and small r adjustments:
- If r ≤ 5, be mainly defecting except cooperate in round 1 then defect the rest (end_phase covers most rounds). Small games are dominated by defection because few opportunities to induce future returns.
- If n is small (e.g., n=2 or 3), be more conservative with p_exploit (reduce p_exploit_max by 0.1) because each defection has a larger impact on cooperation dynamics.

Rationale / exploitation mechanics (why this is exploitative and robust):
- Single-round incentives favor defection (k/n < 1). I therefore cooperate only when it buys me future contributions from others.
- Probing and per-player statistics let me discover players who are conditional cooperators (who will continue to contribute even if I occasionally defect). Those players are the ones I can reliably exploit by defecting some fraction of rounds while still retaining their cooperation on other rounds. Randomized exploitation (p_exploit) prevents deterministic punishment patterns and helps avoid coordination among opponents to punish me predictably.
- Adaptive adjustment of p_exploit and short-term blacklists keep me from destroying the cooperator pool: I back off if cooperators retaliate, and I forgive and re-probe to restore exploitable players.
- Always defecting in the final_phase extracts the last-round rents because inducement is impossible once only a few rounds remain.
- Occasional altruistic probes in Defection Mode allow me to discover late-emerging cooperators while keeping losses bounded.

Edge cases and clarifications:
- No per-opponent targeted move exists (actions are simultaneous and public), so “treating” a player means using my global cooperate/defect choice to reward or withhold incentives. Blacklists and per-player bookkeeping only determine whether I count them as a reason to cooperate at all when deciding the global action.
- If multiple players are conditional cooperators but some are volatile, I rely on group statistics: if the aggregate cooperator pool remains strong, I exploit; if group cooperation collapses, I defect and attempt to rebuild with occasional probes.
- If opponents try to exploit me by pretending to be conditional cooperators (cooperate in probes then defect later), my monitoring (p_j|myC vs p_j|myD and sudden rate drops) will detect them; I will blacklist and stop cooperating for a recovery period.
- If everyone defects persistently, I stay defecting (no point cooperating).
- If opponents are strongly reciprocating and maintain very high cooperation even after my occasional defections, I increase p_exploit up to p_exploit_max to maximize harvest.

Concise playbook summary (how I act each round):
- If in final end_phase: defect.
- Else if in early probing phase: cooperate first round, update stats; in first early_phase rounds probe enough (cooperate occasionally) to classify players.
- After probes: if there is at least one reliable conditional cooperator and group cooperation is nontrivial, enter Exploit Mode: cooperate most rounds but defect randomly with probability p_exploit; adapt p_exploit up if cooperators tolerate exploitation, down if they retaliate.
- If no reliable cooperators: defect every round except rare, inexpensive probes to test for new cooperators.
- Use short blacklists for individual betrayers; forgive after recovery and re-probe.

This strategy is explicitly exploitative: it seeks to extract extra payoff from players who will continue to contribute despite occasional defections, while rapidly shutting down or ignoring those who exploit me. It balances short-term harvesting with adaptive protection so that I preserve a stable exploitable cooperator set when available and avoid being trapped in mutual losses when cooperation collapses.
'''

description_EXPLOITATIVE_83 = '''
Name: Adaptive Exploiter with Controlled Forgiveness

Parameters computed from the game inputs (n, r, k)
- Window size w = min(10, max(3, floor(r/10))) — number of past rounds used for moving averages.
- High cooperation threshold H = 0.70 (adjust down modestly if k/n is large; adjust up if k/n is small — see note below).
- Low cooperation threshold L = 0.30.
- Exploitation probability P_e = 0.8 (probability of defecting when the group is reliably cooperative).
- Generous cooperation probability P_g = 0.8 (probability of cooperating in “mixed” environments to sustain reciprocity).
- Probe probability ε = 0.05 (small chance to cooperate when group is largely defecting, to test recovery).
- Punishment memory M = 3 rounds (how long to continue punitive defection after detecting persistent defectors).
- Long-defection reset: if there has been universal defection for T_reset = max(5, w) consecutive rounds, attempt re-start by probing cooperation with probability 0.2.

(Adjustment note: if k/n > 0.7, reduce H by 0.1 and increase P_g by 0.1 because own cooperation is relatively more valuable; if k/n < 0.4, increase H by 0.1 and reduce P_g by 0.1.)

State the strategy uses only observed history (each player’s contributions in past rounds and payoffs) and the known parameters n, r, k.

Initialization / first round
- Round 1: Cooperate. This signals willingness to reciprocate and identifies conditional cooperators.

Per-round decision rule (for round t = 2..r)
1. Endgame rule
   - If t == r (final round): Defect. (Myopic dominant move; exploit immediate benefit.)

2. Compute history statistics (use last min(w, t-1) rounds)
   - For each other player j, compute coop_rate_j = fraction of those rounds where j contributed.
   - Compute group_recent = average over j of coop_rate_j (i.e., average fraction of others’ contributions).
   - Count coop_last = number of other players who contributed in the immediate previous round.

3. If group_recent >= H (environment is reliably cooperative)
   - Exploit: Defect with probability P_e; otherwise Cooperate with probability (1 - P_e).
   - Exception (stability safety): If I defected last round AND in the round after my defection group cooperation fell by more than 15 percentage points (group_recent drop compared to before my defection), then suspend exploitation and Cooperate for the next 2 rounds to restore cooperation (this protects against provoking a permanent collapse).

4. Else if L <= group_recent < H (mixed / conditional-cooperation environment)
   - Attempt to sustain reciprocity:
     - If at least half of players had coop_rate_j >= 0.5 over the window OR coop_last >= ceil((n-1)/2), then Cooperate with probability P_g; otherwise Defect.
   - If a small number of players are persistent defectors (coop_rate_j < 0.2), treat them as punishable: if more than one persistent defector exists, shift to Defect deterministically until their behavior improves (punishment for free-riders).

5. Else (group_recent < L — mostly defectors)
   - Default to Defect (do not subsidize defectors).
   - Occasionally Probe: with probability ε, Cooperate to test whether opponents will change. If a probe is followed by increases in others’ cooperation, switch to the mixed-environment rule.

6. Targeted punishment and forgiveness
   - If a specific player j is persistent (coop_rate_j < 0.2) and they have been persistent for M rounds, I will Defect continuously while that persists (they are not contributing so I stop subsidizing them).
   - If a punished player improves (coop_rate_j rises above 0.4 over the window), forgive them immediately (stop punishing).
   - Maintain at most M consecutive punitive rounds targeting the same player before re-evaluating; this avoids permanent mutual destruction with uncertain opponents.

7. Recovery after long mutual defection
   - If all players have been defecting for T_reset successive rounds, attempt re-starting cooperation by Cooperating in one round with probability 0.2, then follow the mixed-environment rule if others respond.

Deterministic tie-breakers
- When a probabilistic choice is specified, sample according to that probability; if determinism is required (e.g., tournament disallows randomness), treat "with probability p" as: Cooperate for ⌈p * 10⌉ of every block of 10 similar situations (round-robin schedule).

Why this is exploitative and robust
- Exploitative component: When the group is stably cooperative, the strategy defects with high probability (P_e) to free-ride and harvest surplus produced by others while only occasionally cooperating to avoid immediate collapse. The stability-safety exception prevents a single exploitation from permanently destroying cooperation.
- Adaptivity: The strategy uses moving averages and per-player rates to separate cooperators from defectors, allowing targeted exploitation (free-ride on cooperators) and targeted punishment (stop subsidizing persistent defectors).
- Robustness: Probing (ε) and forgiveness rules re-start cooperation when beneficial; endgame defection avoids being exploited in the last round; threshold adjustments tied to k/n make the strategy sensitive to the multiplier (be more generous when public good is more productive).
- Practical considerations: The strategy never depends on coordination or communication, uses only observed contributions/payoffs, and balances short-term exploitation with longer-term incentives to keep cooperators in the group.

Edge cases summary
- First round: Cooperate (information-gathering and signaling).
- Last round: Always Defect.
- Very short games (r <= w): w is shortened; the same rules apply but rely more on immediate past (coop_last and first-round signal).
- High multiplier (k/n close to 1): lower H, be more willing to cooperate to sustain high mutual payoffs (but still exploit when safe).
- Low multiplier: raise H, be stingier and defect more often (less reason to subsidize).
- If randomness is disallowed: substitute deterministic schedules for probabilistic choices as described.

Intended behavioral effect in tournaments
- Attract and maintain cooperation from conditional cooperators and reciprocators.
- Exploit stable cooperators frequently while keeping cooperation alive via controlled cooperation and forgiveness.
- Refuse to subsidize persistent defectors and punish them until they improve.
- Avoid being exploited in the endgame and attempt to recover cooperation from noisy or learning opponents via occasional probes.
'''

description_EXPLOITATIVE_84 = '''
Name: Adaptive Selective Exploiter (ASE)

Summary (one line): Start by probing for cooperators, reward/maintain cooperation when it is profitable to harvest repeated returns, but repeatedly take small, measured one-shot defections to extract extra payoff; punish persistent defectors by refusing to subsidize them; always defect in the final round.

State and bookkeeping (only depends on history and parameters):
- r = total rounds, n, k given.
- Keep each player's recent contribution history.
- Window W = min(8, max(3, floor(r/10)+1)) — number of most recent rounds used for short-term estimates.
- For each player j compute coop_rate_j = fraction of C in the last W rounds (if less than W rounds exist, use available rounds).
- Group short-term cooperation fraction f = average of coop_rate_j over all OTHER players (exclude self).
- Reliable_cooperators = set of players with coop_rate_j >= 0.80.
- Likely_defectors = set with coop_rate_j <= 0.20.
- Maintain two adaptive control variables:
  - exploit_interval M (integer): how often (in rounds) ASE performs an opportunistic one-shot defection while otherwise cooperating. Initialize M0 = max(4, ceil(5* n / k)) (larger n or small k -> longer between opportunistic defections). Set M := M0.
  - last_exploit_round: track last round in which ASE performed an opportunistic defection.
- Recovery counter recover_rounds = 0 (when >0 ASE cooperates to rebuild trust; decremented each round).

High-level policy (applies every round t, using only history up to t-1):

1) Endgame:
- If t == r (final round): play D (defect). No future punishment so always take immediate gain.
- If t == r-1 (penultimate round): defect only if ASE’s recent exploitation attempts have not caused sustained collapse in cooperation (see adaptive rule), otherwise play C to preserve ability to exploit earlier rounds’ returns. Concretely: if f >= 0.6 and exploit_interval M <= 3 then play D; otherwise follow the general rule below. (This prevents gratuitous loss of future exploitation opportunities when opponents still respond to reciprocity.)

2) Immediate safety check (avoid being a sucker):
- If f < 0.25 (population largely defecting recently): play D. There is no benefit to subsidizing defectors; defect to avoid losing tokens and to improve relative payoff.

3) Handle persistent defectors:
- If |likely_defectors| >= (n-1)/2 (a clear majority are persistent defectors): play D. When most others never cooperate, do not provide public good.

4) Cooperative majority (opportunity to exploit while sustaining cooperation):
- If |reliable_cooperators| >= ceil((n-1)/2) (a majority of others are reliably cooperative in recent window):
  - If recover_rounds > 0: play C, decrement recover_rounds.
  - Else if (t - last_exploit_round) >= M and last_exploit_round > 0:
    - Perform an opportunistic exploitation: play D this round (one-shot defection) and set last_exploit_round = t.
    - Immediately after that exploitation round observe reaction (next round): if group cooperation fraction f_next (measured after opponents’ next action) drops by more than delta = 0.10 compared to f just before exploitation, double M (M := min(M*2, r)) and set recover_rounds := W (cooperate for W rounds to rebuild trust); otherwise, reduce M slowly (M := max(M-1, 2)) to exploit slightly more often if opponents ignore occasional defections.
  - Else (not exploit round): play C.

  Implementation note: if this is the very first round ASE plays (t=1), treat it as not an exploit round and play C.

5) Mixed population (no clear majority of either kind):
- If f >= 0.5 (at least half of others recently cooperate): behave like “Cooperative majority” case but with a safer exploitation frequency: use M as initialized and do opportunistic defections less frequently (enforce M >= M0).
- If f in [0.25, 0.5): play D most rounds but occasionally probe for cooperators: once every ceil(W) rounds play C to test whether cooperation pockets exist; if probing reveals reliable cooperators, switch to the “Cooperative majority” logic.

6) Targeted exploitation nuance (exploit pockets):
- If there exists a nonempty set of reliable_cooperators and the rest are likely or known defectors (so the group is split), ASE favors defecting repeatedly (play D) because defecting while a pocket of cooperators continues to contribute maximizes ASE’s relative gain. If in subsequent rounds the pocket disappears (cooperators stop contributing), ASE returns to the “safety” logic above.

7) Recovery and forgiveness:
- Punishments are short and measured. After any exploitation that causes a substantial drop in group cooperation, ASE cooperates for recover_rounds = W rounds (recover mode) to re-establish cooperation with responsive players; if cooperation does not recover, ASE resumes defecting as in the “safety” case.
- Do not use permanent grim-trigger against a whole population; adapt exploitation frequency instead. But do permanently exclude individual persistent defectors by counting them in likely_defectors and refusing to trust their future behavior.

Parameter intuition (all parameters are deterministic functions of n,k,r above):
- W small (3–8) for responsiveness to recent behavior.
- Thresholds (0.8/0.2) separate clear cooperators/defectors.
- Opportunistic one-shot defections spaced by M reason: spacing prevents rapid breakdown of cooperation while still extracting short-run advantage; M scales with n/k so if productive multiplier k is small relative to n (cooperation yields less group benefit) ASE exploits less frequently because mutual cooperation is harder to sustain.
- Endgame: always defect final round to capture immediate one-shot gains.

First-round and trivial cases:
- t = 1: play C (probe). This reduces the time to discover cooperators and creates opportunities to exploit reciprocators later.
- If r = 1: defect (final-round rule).
- If n = 2: identical logic applies but expect faster reactions; ASE will set M0 small but still follow the same adapt/adapt rule.

Key exploitative behaviors summarized:
- Find and keep cooperative partners by cooperating initially and during repair periods.
- While partners remain cooperative, take occasional, isolated defections to pocket extra tokens (opportunistic exploitation).
- Monitor reaction: if cooperators retaliate (cooperation fraction falls significantly), reduce exploitation frequency and enter recovery mode for W rounds.
- Refuse to subsidize clear defectors (majorities of defectors -> defect always).
- Always defect in the final round to take the immediate one-shot advantage.

Why this is exploitative and robust:
- It actively seeks exploitable cooperators (probing + cooperation) and extracts extra payoff via infrequent, controlled defections.
- It protects against mass defection by switching rapidly to D when the environment becomes hostile, minimizing losses.
- It is adaptive: exploitation frequency is adjusted based on observed opponent responses; recovery and forgiveness prevent unnecessary long-term loss from short mistakes.
- It uses only public history and parameters; no communication or coordination is required.

End note: all thresholds and frequencies are explicit functions of n,k,r and short-term statistics from history; they can be tuned tighter or looser for different tournament styles, but the principle stays: probe → sustain cooperation → periodically extract one-shot gains → adapt when opponents punish.
'''

description_EXPLOITATIVE_85 = '''
Strategy name: Exploit-or-Invest (adaptive, history-driven exploitation)

High-level idea
- Never assume cooperation norms. Defect by default to collect immediate gain unless there is clear, measured evidence that contributing now will cause enough extra future contributions by others to offset the immediate cost. Use the history to estimate how others respond to my cooperate/defect moves, and exploit players who are forgiving or "auto-cooperators" while avoiding sustained punishment from retaliators. Always defect in the final round.

Key quantities maintained (updated each round)
- t = current round index (1..r), R_remain = r - t (rounds remaining after current round).
- For each past round s, record my action a_s ∈ {C,D} and the group cooperation rate of others in the next round:
  q_{s+1} = (sum_{j ≠ me} c_j at round s+1) / (n-1). (If s+1 > t, ignore.)
- Compute two empirical averages (use at most the most recent W rounds, W = min(10, r) or similar):
  - mean_q_after_C = average of q_{s+1} for those s in the window with a_s = C
  - mean_q_after_D = average of q_{s+1} for those s in the window with a_s = D
  If insufficient samples for either (e.g., no past C or no past D), use a conservative default: treat missing C-samples as mean_q_after_C = current group cooperation rate (or 0 if no data); treat missing D-samples similarly but biased toward detecting punishment (see below).
- Define Δ = mean_q_after_C - mean_q_after_D. This is our empirical estimate of how much one cooperative act by me raises the others' cooperation probability in the next round compared to a defection.

Decision rule (per round)
1. Final round (t = r): Defect (D). No future returns to warrant contributing.

2. Otherwise (t < r):
   - Compute immediate cost of cooperating: immediate_loss = 1 - (k / n).
     (Contributing always costs this amount immediately because k/n < 1.)
   - Compute expected future benefit of cooperating once, using the measured responsiveness Δ:
     - Each additional other cooperative action in a future round increases my payoff by k/n that round.
     - If my cooperating now raises average others' cooperation by Δ per round for the remaining R_remain rounds (a conservative estimate), expected_future_gain ≈ (k / n) * Δ * R_remain.
     - If Δ is estimated over one-step-ahead only, use it as per-round expected lift; if you use multi-step regressions, substitute accordingly. To be robust, if Δ < 0 treat it as Δ = 0 (cooperating does not increase future cooperation).
   - Primary decision:
     - If expected_future_gain > immediate_loss, choose C (cooperate).
     - Otherwise choose D (defect).
   - Exploration & probing:
     - To avoid being stuck on outdated estimates and to detect punishing/forgiving opponents, add small randomized probing:
       - If primary decision is D, with small probability ε_probe (e.g., 0.05) play C to test whether cooperating can increase future cooperation.
       - If primary decision is C, with much smaller probability ε_exploit (e.g., 0.01) play D to opportunistically exploit particularly forgiving opponents and to re-check responsiveness.
   - Fast-response override (punishment-avoidance):
     - If the recent group cooperation rate (average q over the last W rounds) has dropped sharply after my last defection (group retaliation observed), be conservative: require a larger Δ to cooperate (multiply Δ by a safety factor <1 or temporarily set expected_future_gain = expected_future_gain * 0.5) so I back off from defecting further.
   - Permanent-cooperator exploitation:
     - If one or more opponents show near-constant cooperation (their personal cooperation rate > 0.95 over a long window), the strategy will tend to defect more often because those players are unlikely to punish. This is implicitly captured by a larger mean_q_after_D and small change Δ; D will be selected by default and probing D→C will be rare.

Operational details and safeguards
- Window and smoothing:
  - Use W = min(10, r) recent rounds for statistics to adapt to changing opponents. Use exponential decay if preferred so recent rounds matter more.
- Handling insufficient samples:
  - If there are no past cooperations by me in the window (no a_s = C), treat mean_q_after_C conservatively as (current average others’ cooperation) so Δ starts near zero; this encourages initial probing rather than blind cooperation.
  - If there are no past defections by me in the window, treat mean_q_after_D as current average others’ cooperation (again conservative).
- Noise tolerance:
  - Use Δ floor at 0 (never assume negative Δ helps).
  - Avoid binary flips from a few noisy observations by requiring a minimal effective Δ_min (e.g., Δ_min = 0.02) before expected_future_gain is trusted; otherwise treat Δ = 0.
- Endgame tapering:
  - As R_remain becomes small, cooperating becomes less likely because expected_future_gain shrinks linearly with R_remain. This automatically produces endgame defection behavior except possibly a last-minute cooperation if a large Δ was measured (rare and only if it still pays).

Why this is exploitative and robust
- Exploitative: Default is defection; the strategy only pays the cooperation cost when there is measured, quantifiable evidence that cooperation will raise others' future contributions enough to make it profitable. That means you will extract value from naïve or forgiving players by defecting most times and only invest when doing so can pay off across many future rounds.
- Targeted exploitation: The algorithm measures responsiveness to my moves and therefore differentiates forgiving/cooperative opponents from retaliators. It will repeatedly defect against unconditional cooperators (maximizing extraction) and refrain from defecting against punishing opponents to avoid mutual loss.
- Adaptive: Uses recent history, probing, and smoothing to adapt when opponents change behavior, to detect punishment, and to avoid being permanently exploited or permanently trapped in mutual defection.
- Safe endgame: Always defects in the last round and naturally increases defection as the horizon shortens, extracting short-term gains when future leverage disappears.

Summary pseudocode (natural language)
- Initialize history arrays.
- For each round t from 1 to r:
  - If t == r: play D.
  - Else:
    - Compute mean_q_after_C, mean_q_after_D over last W rounds.
    - Δ = max(0, mean_q_after_C - mean_q_after_D).
    - expected_future_gain = (k / n) * Δ * (r - t).
    - immediate_loss = 1 - (k / n).
    - If expected_future_gain > immediate_loss then primary_action = C else primary_action = D.
    - With small probing probabilities flip primary_action occasionally (ε_probe, ε_exploit as above).
    - If recent data shows group retaliation following my defections, be conservative (require larger Δ).
    - Play the final decided action and record others’ cooperation next round to update statistics.

Notes
- All numeric suggestion choices (W ≈ 10, ε_probe ≈ 0.05, ε_exploit ≈ 0.01, Δ_min ≈ 0.02) are tunable; they are conservative defaults that balance reliable estimation and opportunistic probing.
- This strategy depends only on game parameters (n, k, r) and observed history, needs no communication, and is explicitly oriented to extract value from cooperators while protecting itself from punishment.
'''

description_EXPLOITATIVE_86 = '''
Name: Opportunistic Free‑Rider with Probe-and‑Guard

Summary goal (exploitative mindset)
- Exploit reliably cooperative opponents by free‑riding when it is safe, while avoiding being locked into long punishments or being exploited by persistent defectors. The strategy actively tests the environment, opportunistically defects to collect extra tokens from cooperators, backs off when exploitation causes cooperation to collapse, and switches to a defensive conditional‑cooperation policy if opponents are punitive.

Notation and simple bookkeeping (all available from history)
- n, r, k are game parameters.
- For each player j (including self) maintain their cooperation history: the indicator sequence of contributions (1=C, 0=D). From this compute recent cooperation rates over a sliding window W rounds: coop_rate_j = fraction of C by j in the last W rounds (or since start if fewer than W rounds played).
- group_coop_t = number of contributions by all other players in round t (0..n-1) and group_coop_rate_t = group_coop_t / (n-1).
- Use counts and short windows only (no external coordination).

Tunable constants (depend on r but fixed in advance)
- W = min(10, max(2, floor(r/5))) — short recent window for estimating behavior.
- R0 = min(2, max(1, floor(r/10))) — initial pure cooperation rounds to build reputation (usually 1–2).
- Last rounds cutoff T_end = min(2, floor(r/10)) — in the last T_end rounds, defect always.
- coop_high = 0.8 — threshold to classify a player as a reliable cooperator.
- coop_low = 0.3 — threshold to detect collapse of cooperation.
- punish_fraction = 0.5 — fraction of players that must retaliate to declare the environment “punitive”.
- retaliation_drop = 0.4 — drop in a player’s cooperation probability (pre vs immediate post probe) counted as retaliation.
- p_exploit_init = 0.5 — initial probability of defecting when exploiting a cooperative pool.
- p_exploit_max = 0.9, p_exploit_min = 0.05 — bounds on exploitation probability.
- adaptation factors: if exploitation appears safe, slowly increase p_exploit (×1.1), if it triggers collapse, reduce sharply (×0.5).

High-level phases
1. Opening and probing (rounds 1..R0+1)
   - Rounds 1..R0: cooperate (C). This builds initial reputation and collects data on others.
   - Round R0+1: perform a single probe by defecting (D) while others are likely still cooperative. Record how many players change behavior immediately after this probe.

   Purpose: detect whether many opponents respond to a unilateral defection with quick, sustained retaliation (punitive environment) vs. tolerating occasional free‑rides.

2. Environment classification (after probe)
   - For each other player j, compare their coop behavior in the W rounds before the probe to their contribution in the very next round after the probe.
   - If a player who previously cooperated reduces cooperation immediately by at least retaliation_drop, count them as “retaliator.”
   - If fraction(retaliators among previously cooperative players) >= punish_fraction, set ENV = punitive. Else ENV = non‑punitive.
   - Initialize p_exploit = p_exploit_init.

3. Ongoing play (after classification, every round until last T_end rounds)
   - If round > r - T_end: always defect (D). (Backward induction: last rounds yield no future benefit.)
   - Else if ENV == punitive: adopt a cautious conditional‑cooperation policy:
       - Decision rule (punitive environment):
         a) If group_coop_rate_last_round >= 0.5 (majority of others cooperated last round), then cooperate (C).
         b) Otherwise defect (D) this round, then forgive on the next round (i.e., return to the above test); treat single defects by others as forgivable unless they become persistent.
       - Rationale: avoid provoking permanent punishments; behave like a lenient Tit‑for‑Tat at the group level to keep cooperation without inviting severe reprisals.
   - Else (ENV == non‑punitive): behave opportunistically to exploit cooperators while adapting:
       - Identify reliable cooperators: set S = { j != me | coop_rate_j >= coop_high }.
       - If |S| == 0:
           - If group_coop_rate_last_round >= 0.6, play D with moderate probability p = 0.3 (small free‑ride); otherwise cooperate if others are cooperating (to encourage future opportunities).
         (Rationale: if no reliably cooperative opponents exist, be conservative; small probing free‑rides can still pay.)
       - If |S| >= 1:
           - Compute target exploitation probability p = current p_exploit.
           - Draw action: defect (D) with probability p, otherwise cooperate (C).
           - After each exploitation round (when you defect while many others cooperated), monitor the next W rounds’ average group_coop_rate:
               * If average group_coop_rate falls by more than coop_low (i.e., a clear collapse) relative to pre‑exploitation baseline, reduce p_exploit ← max(p_exploit_min, p_exploit × 0.5) and switch temporarily to cautious mode for a few rounds.
               * If group_coop_rate remains stable (no significant drop), increase p_exploit ← min(p_exploit_max, p_exploit × 1.1).
       - Also: if a subset of players begins to persistently defect (coop_rate_j < coop_low), ignore them in exploitation targeting (they are not exploitable). Focus exploitation on players with coop_rate_j >= coop_high.

4. Persistent collapse or mutual defection
   - If the long‑run average group cooperation (over W rounds) falls below coop_low (i.e., most players defect persistently), switch to permanent defection for the remainder (D always). No more effort to revive cooperation — better to protect own payoff.

5. Individual forgiveness and recovery
   - If a player who previously defected later raises coop_rate_j above coop_high, reclassify them as exploitable and include in S again.
   - If a player retaliates only once and then returns to cooperation, treat as a tolerant cooperator; continue to exploit cautiously (reduce p_exploit briefly, then allow to grow again if safe).

Edge cases and special rules
- Very short games (small r):
  - If r <= 3: be more conservative — cooperate for first round, defect in last round(s). Do not run lengthy probing.
- First round: cooperate to seed a good reputation.
- Last T_end rounds: always defect (no future repercussions).
- If multiple opponents show severe punishment within one round after any unilateral defection beyond the initial probe, flip ENV → punitive immediately and follow punitive policy.
- Ties and ambiguous thresholds: break ties in favor of defection (exploitative default).

Why this is exploitative and robust
- It actively seeks to free‑ride on reliably cooperative players (probabilistic defection when exploitable).
- It avoids catastrophic losses from grave punishers by testing the environment early (probe) and switching to a cautious conditional‑cooperation policy in punitive environments.
- It adapts exploitation intensity based on observed consequences so that exploitation increases when safe and decreases when it causes cooperation to collapse.
- It protects against being exploited by switching to permanent defection when the group turns predominantly non‑cooperative.

Implementation notes (for a tournament agent)
- All decisions use only n, r, k and the public action history.
- All thresholds and factors are fixed constants (listed above) and can be tuned for tournament specifics, but the algorithmic structure remains the same.
- The strategy is intentionally stochastic when exploiting (probabilistic D) to avoid deterministic patterns that trigger coordinated punishments from other adaptive agents.

Concrete decision‑rule pseudocode (compact)
- If round > r - T_end: play D.
- Else if round <= R0: play C.
- Else if round == R0+1: play D (probe).
- Else (maintain coop_rate_j over last W rounds, group_coop_rate_last_round available):
    - If ENV unknown: compute ENV from probe result.
    - If ENV == punitive:
        - If group_coop_rate_last_round >= 0.5 → play C; else play D (then forgive next round).
    - If ENV == non‑punitive:
        - Let S = players with coop_rate_j >= coop_high.
        - If |S| >= 1 → play D with probability p_exploit else C.
        - If |S| == 0 and group_coop_rate_last_round >= 0.6 → play D with prob 0.3 else play C.
    - After each round, update coop_rate_j and:
        - If exploitation appears to reduce group cooperation by more than coop_low over W rounds → p_exploit ×= 0.5 and temporarily be cautious.
        - If exploitation appears safe → p_exploit ×= 1.1 (cap at p_exploit_max).
    - If long‑run group cooperation < coop_low → play D for remainder.

This strategy maximizes exploitive gains when safe, but prefers survival (avoiding costly punishments) when the environment shows intolerance. It uses only history and parameters, is adaptive, and targets exploitative opportunities while guarding against being exploited.
'''

description_EXPLOITATIVE_87 = '''
Name: Adaptive Probe-and-Exploit (APEX)

Overview (one line): Start by appearing cooperative, probe to learn whether the group punishes defections, then exploit non‑punishing/cooperative opponents by free‑riding while avoiding long punishments; be forgiving and periodically re‑probe; always defect in the final rounds.

Parameters I use (derived from game parameters r, n, k and observed history):
- W = min(5, r) — history window for short‑term statistics.
- ProbeRounds: a small, scheduled set of probes early and mid tournament (rounds 3 and 3 + floor(r/3), if those exist).
- PunishmentDrop = 0.20 — threshold change in others’ cooperation that counts as “punishment.”
- MaintenanceInterval = 4 — when exploiting, I make a deliberate contribution every 4th round to help sustain exploitable cooperation.
- EndgameK = min(3, r) — last EndgameK rounds: always defect.
- ShortGameCutoff = 4 — if r ≤ ShortGameCutoff, defect every round (no costly cooperation for little or no future).

Decision rules (step by step):

1. Short games:
- If r ≤ ShortGameCutoff: defect every round (dominant strategy when little/no future).

2. First rounds (establishing reputation & baseline):
- Round 1 and 2 (if r > ShortGameCutoff): contribute (C). This makes my profile look cooperative and gives me a baseline measure of others’ willingness to cooperate.

3. Detection / probing phase:
- On each scheduled ProbeRound (e.g., round 3 and round 3 + floor(r/3) if available), do one deliberate solitary defection (D) while otherwise following the usual rule. After each probe, measure the reaction of other players over the next W rounds:
  - Compute BaselineCoop = average fraction of other players who contributed in the W rounds immediately before the probe.
  - Compute PostCoop = average fraction of other players who contributed in the W rounds immediately after the probe.
  - If PostCoop ≤ BaselineCoop - PunishmentDrop, label the group as “punishing” (they retaliate noticeably when I defect).
  - If PostCoop > BaselineCoop - PunishmentDrop, label the group as “non‑punishing” (my defection did not cause a strong drop).

4. Modes (switch based on labels and recent history):
- Exploit Mode (entered if I am classified non‑punishing or observe many players with very high unconditional cooperation):
  - Default action: defect every round (D) to free‑ride.
  - Maintenance: contribute (C) once every MaintenanceInterval rounds to avoid a complete collapse of partners’ cooperation and to prevent long‑term strategies from classifying me as permanent defector. If group cooperation falls below a target (Target = 0.6 * BaselineCoop) I contribute that round to prop it up.
  - If I observe an abrupt drop in others’ cooperation after a maintenance contribution or a defection that looks like a coordinated punishment (PostCoop drop ≥ PunishmentDrop), immediately switch to Conditional Cooperation Mode.

- Conditional Cooperation Mode (entered if group is classified punishing):
  - My rule: “majority‑match with one‑round forgiveness.”
    - If at least half of the other players contributed in the previous round, I contribute (C) this round.
    - Otherwise I defect (D).
    - If I defect and the next round a majority of others return to contributing, I forgive and contribute the following round (one‑round forgiveness).
  - While in this mode, continue scheduled occasional probes (very rare: at most one additional probe later) to test whether punishers mellow; if probes show punishment ceases, move to Exploit Mode.

- Exploit‑Hard for unconditional cooperators:
  - If after multiple probes an opponent (or large fraction of opponents) has cooperated > 95% of the time and shows no response to my defections, I exploit ruthlessly: defect every round except contribute once every MaintenanceInterval rounds (to avoid edge cases and to preserve plausible deniability if some strategies inspect patterns).

5. Ongoing adaptation:
- Continuously update per-player cooperation rates and the group average over the last W rounds. Use these statistics to:
  - Detect drift toward more punishing or more forgiving behavior and switch modes accordingly.
  - If a previously punishing group softens (PostCoop increases after my later probes), step toward Exploit Mode gradually rather than jumping immediately.

6. Endgame handling:
- In the last EndgameK rounds (e.g., last 3 rounds), defect always (D). In the final round defect with certainty.
- In the last few rounds before EndgameK I reduce maintenance contributions and increase my defect frequency linearly so I am not exploited in the final phase.

Edge cases and clarifications:
- If there is clear heterogeneity (some players punish, others never punish): I treat the group as punishing if the coordinated reaction from the majority of other players meets the PunishmentDrop threshold. The strategy works at the group level because one binary contribution applies to the whole group each round.
- If my scheduled probe coincides with EndgameK, skip the probe and defect.
- If multiple opponents use deterministic look‑ahead strategies that always defect late, my endgame defection aligns with them and avoids being exploited.
- If many opponents use tolerant strategies that slowly reduce cooperation, the Maintenance contributions and periodic re‑probing aim to keep overall cooperation high enough that I can continue to get a net exploitative benefit.

Why this is exploitative and robust:
- Exploitative: I deliberately free‑ride when opponents do not respond to defections and make only minimal cooperative investments (maintenance contributions) to sustain others’ cooperation rather than give them the full public good. This captures the positive short‑term gain per round (1 − k/n > 0) repeatedly when it is safe to do so.
- Robust: I detect and respect punishers (avoiding long punishments by cooperating when appropriate), forgive quickly to recover from noise, and continually re‑probe so I don’t miss new exploitation opportunities. I also defect reliably in the endgame to avoid being exploited by naive cooperators at the finish.

Summary pseudocode (compact):
- If r ≤ 4: always D.
- Else:
  - Rounds 1–2: C.
  - Perform probes at scheduled ProbeRounds (single D) and compute BaselineCoop vs PostCoop over windows W.
  - If group labeled non‑punishing → Exploit Mode: mostly D, C once every MaintenanceInterval or whenever group cooperation falls below Target; switch out if punishments detected.
  - If group labeled punishing → Conditional Cooperation Mode: contribute when majority contributed last round, else defect; forgive after one cooperative round; rare probes to retest.
  - In last EndgameK rounds: always D.

This strategy maximizes exploitative gains when opponents tolerate defection, avoids extended losses against punishers by cooperating, and adapts continuously by probing and updating.
'''

description_EXPLOITATIVE_88 = '''
Selective Free-Riding with Reputation Management

Principles (what this strategy tries to do)
- Exploit unconditional cooperators by free-riding on their contributions.
- Preserve cooperation only when doing so reliably keeps a sizeable set of conditional cooperators contributing (so the long-run gain from their contributions outweighs the loss from my occasional defections).
- Punish persistent defectors and defect in the endgame.
- Be adaptive and robust: classify players from history, probe cautiously, forgive when evidence of resumed cooperation is clear.

Parameters (computed from game parameters r, n)
- Lookback window L = min(10, max(3, floor(r/4))) — used to estimate recent behaviour.
- Endgame: last 2 rounds are treated as endgame rounds (always defect in round r and r-1). (If r = 1, defect in that round.)
- Exploit probability p_exploit = 0.15 (upper bound on how often I will “steal” while trying to sustain conditional cooperators).
- Thresholds:
  - high_coop = 0.85 (recent contribution rate considered “unconditional”)
  - low_coop = 0.15 (recent contribution rate considered “defector”)
  - cond_sensitivity = 0.40 (sensitivity indicating conditional cooperator)
  - punish_tolerance = 2 (rounds of punishment tolerated before switching to permanent defection against offenders)
  - recovery_window = L (consecutive rounds required to consider a punished player “recovered”)

State I maintain (updated each round from history)
- For each opponent i:
  - C_i = fraction of last L rounds in which i contributed.
  - P_i = estimated sensitivity: fraction of rounds (in last L) in which i reduced their contribution in the round after I defected, relative to their baseline (if I never defected in lookback, treat P_i = 0).
  - last_actions for each player (to detect recent streaks).
- Group-level counts:
  - #Unconditional = count of i with C_i >= high_coop and P_i <= 0.25
  - #Conditional = count of i with P_i >= cond_sensitivity and C_i >= 0.3
  - #Defectors = count of i with C_i <= low_coop

Initial & endgame behavior
- Round 1: cooperate (to gather information).
- Rounds r and r-1 (last two rounds): always defect (no future to deter punishment). If r=1, defect; if r=2, defect in both.

Per-round decision (for round t not in last two rounds)
1. Update C_i and P_i from last L rounds.

2. Classify opponents into Unconditional, Conditional, Defector as above.

3. Estimate the danger of causing a cooperation collapse:
   - Expected immediate cooperation loss if I defect this round ≈ sum_{i in Conditional} P_i.
   - If Expected immediate cooperation loss > max(1, 0.5 * #players) (i.e., my defection likely causes many conditionals to reduce contributions), then cooperate this round to sustain the conditional group.
     Rationale: protecting many conditional contributors preserves higher expected future payoff than a one-shot theft.

4. Otherwise (no large conditional group at risk):
   - If #Unconditional >= 1 and #Conditional is small (Expected loss from step 3 low): defect (exploit unconditional contributors).
   - If most opponents are Defectors (#Defectors large) or behaviour is noisy/uncertain: defect (avoid being exploited).
   - If the population is mixed but no clear conditional group: default to defect (safe choice to avoid being the sucker).

5. While cooperating to sustain Conditional cooperators, periodically extract value:
   - With independent probability p_exploit per round (but no more than once every 1/p_exploit rounds on average), defect this round to capture extra payoff. If a defection is followed by sustained punishment (see step 6), stop exploiting and revert to steady cooperation.

6. Punishment and forgiveness:
   - If I defect and a particular player i responds by punishing me (reducing their contribution) for punish_tolerance consecutive rounds, then mark i as “punisher” and switch to permanent defection against them (i.e., I will defect in all future rounds unless they demonstrate recovery).
   - Recovery: if a formerly-punisher player shows contribution in every round for recovery_window consecutive rounds, clear that label and re-evaluate them normally.
   - If many players punish me simultaneously and persistently, switch to broad defection (I will stop trying to sustain cooperation).

7. Probing / exploration:
   - If I have not had any defections in the last L rounds (i.e., been reliably cooperative) and I want to detect unconditional cooperators, perform a single-probe defection: defect once and observe each opponent’s reaction in the next 1–2 rounds to update P_i. Use these probes sparingly (count them as part of p_exploit).

Tie-break and default
- If the classification or estimates are ambiguous, choose defection (prefer safety over being exploited).

Summary pseudocode (natural language)
- On round 1: cooperate.
- For each round t (except last two rounds):
  - Recompute C_i, P_i over last L rounds for every opponent.
  - If my defection would likely cause many conditionals to stop contributing (expected loss large) → cooperate.
  - Else if there are clear unconditional cooperators and no big conditional group → defect.
  - Else if many defectors or behavior is noisy/ambiguous → defect.
  - Else (mixed): defect by default, but if I am cooperating to sustain conditionals, occasionally defect with probability p_exploit as a one-shot harvest.
  - Apply punishment rules: if punished by a given opponent for punish_tolerance rounds, defect permanently against them until they show recovery.
- In rounds r-1 and r: defect.

Why this is exploitative and robust
- Exploiters (unconditional cooperators) are exploited aggressively: the strategy defects whenever it can safely free-ride.
- Conditional cooperators are protected when they matter: the strategy cooperates when losing them would collapse total contributions and harm long-run payoff.
- The strategy learns player types from observable history, so it adapts to a wide variety of opponents (always-cooperators, always-defectors, tit-for-tat, probabilistic players).
- Endgame defection prevents being exploited by backward induction.
- Forgiveness and recovery let the strategy resume mutually beneficial cooperation if opponents revert.

Notes on implementation choices
- Thresholds (high_coop, cond_sensitivity, p_exploit, L) are set conservatively; small adjustments can tune aggressiveness.
- The same logic works for any n and r because all thresholds scale with counts, the lookback adapts to r, and the endgame rule uses r directly.
'''

description_EXPLOITATIVE_89 = '''
Goal statement (exploitative posture)
- Extract as much benefit as possible from opponents who are inclined to contribute, while avoiding being exploited by persistent defectors. Sustain enough cooperation in the group to keep extracting surplus, but otherwise free-ride. Be forgiving enough to rebuild cooperation when it exists, and ruthless enough to stop wasting tokens when cooperation collapses. Always defect in the known final round.

Initialization (parameters derived from n, k, r)
- Window W = min(5, max(1, floor(r/10) + 1))  // short recent-history window
- Threshold thr = 0.50 + 0.25 * (k / n)      // cooperation density at which exploitation is profitable
  (thr lies between 0.50 and 0.75; higher when the public return k/n is larger)
- Exploit probability p_exploit = 0.85        // when opponents are cooperative-rich, defect most of the time
- Rebuild length R = 2                       // cooperate R rounds to try to restore cooperation
- Consecutive-collapse limit L = min(4, max(2, floor(r/10))) // how many low-cooperation windows trigger “give up”
- Probe interval P = max(3, floor(r/10))      // when “giving up”, probe occasionally

State variables (maintained from history)
- For each past round t' keep observed contribution counts; compute for any t the fraction f(t') = (number of opponents who contributed in round t') / (n-1).
- last_W_avg = average of f over the last min(W, t-1) rounds (or undefined if t=1)
- consecutive_low_windows = number of consecutive evaluations (windows) where last_W_avg ≤ 0.10
- in_rebuild_until = round index until which the strategy will play C because it entered a rebuild phase
- give_up_mode = false

Round-by-round decision rules
1. Final-round override
   - If current round t == r: play D (always). No future to sustain cooperation.

2. First-round probe
   - If t == 1: play C (signal willingness to cooperate and draw out unconditional cooperators).

3. If give_up_mode == true
   - Default to D every round (do not waste tokens).
   - Exception: if t mod P == 0 (a periodic probe), play C for this round only to test whether opponents resumed cooperating. If that probe yields a sustained rise in last_W_avg over the next window, exit give_up_mode and start a rebuild phase.

4. If currently in a rebuild phase (t ≤ in_rebuild_until)
   - Play C. (Deterministic cooperation for R consecutive rounds to try to re-establish cooperation.)

5. Regular adaptive rule (t > 1, not last round, not in give up, not in rebuild)
   - Compute last_W_avg over the most recent min(W, t-1) rounds.
   - If in the immediately preceding round all other players cooperated (f(t-1) == 1.0),
       - Play D this round (exploit unanimous cooperation immediately).
   - Else if last_W_avg ≥ thr  (group is cooperation-rich)
       - Play D with probability p_exploit; play C with probability (1 - p_exploit).
         Rationale: mostly defect to extract surplus; occasionally cooperate so cooperators do not immediately abandon contributions.
       - If frequent defection by us coincides with a sustained drop in last_W_avg across next windows, trigger a rebuild phase: set in_rebuild_until = t + R - 1.
   - Else if last_W_avg < thr and last_W_avg > 0.10 (moderate cooperation)
       - Play C (invest to encourage cooperation). If after cooperating for R rounds cooperation rises above thr, begin exploitation again.
   - Else if last_W_avg ≤ 0.10 (cooperation has collapsed)
       - Increment consecutive_low_windows by 1.
       - If consecutive_low_windows ≥ L:
           - Enter give_up_mode = true (stop cooperating for the remainder except periodic probes).
           - Play D this round.
       - Otherwise (only a short-lived collapse): enter a short rebuild: set in_rebuild_until = t + R - 1 and play C.

Additional housekeeping
- Whenever last_W_avg rebounds above thr, reset consecutive_low_windows = 0.
- When give_up_mode is exited because periodic probes and rebuild succeeded, reset consecutive_low_windows = 0.

Intuition and exploitation mechanics (why this exploits)
- The strategy’s heart: when others are reliably cooperating (last_W_avg ≥ thr), defect most of the time to capture the extra private payoff from their contributions while still sometimes cooperating so that cooperators do not immediately abandon. That asymmetry is exploitative: you get close to the cooperators’ benefit while paying less cost.
- When cooperation is weak, the strategy invests (cooperates deterministically) to try to rebuild a cooperation-rich environment that it can later exploit. Rebuilds are short and controlled (R rounds), avoiding long-term losses.
- If cooperation clearly collapses and stays collapsed (consecutive low windows), the strategy “gives up”: stop wasting tokens and only occasionally probe, preventing continued exploitation by persistent defectors.
- Immediate exploitation of unanimous cooperation (defect if all others cooperated last round) ensures the strategy never misses easy one-shot gains.
- Last-round defection is guaranteed to avoid being exploited in the terminal stage.

Behavioural profile against typical opponents
- Against unconditional cooperators: the strategy will quickly exploit (defect regularly) and gain above-average payoff while occasionally cooperating to avoid their wholesale collapse.
- Against conditional cooperators (e.g., reciprocators): the strategy will stabilize at a pattern where it defects often enough to gain, and cooperates occasionally to keep reciprocity alive — extracting surplus while sustaining cooperation.
- Against unconditional defectors: the strategy detects collapse, enters give-up mode and avoids further losses.
- Against mixed or adaptive opponents: the strategy constantly adapts via last_W_avg, rebuilds and probes; it is robust and will not be easily driven down by transient fluctuations.

Determinism and randomness
- The only randomized choice is p_exploit (probabilistic defection when exploitation conditions hold). All other elements are deterministic and derived from history and game parameters (n, k, r). Randomization helps avoid being predictable and exploited by retaliatory strategies.

Summary (short)
- First round: C. Last round: D.
- Track recent opponent cooperation (last_W_avg). If cooperation is high (≥ thr), exploit by defecting most of the time (probability p_exploit), occasionally cooperating to maintain contributors. If cooperation is low, cooperate for short rebuilds; if it stays low for several windows, give up and defect except for occasional probes. Always defect if all others cooperated in the previous round. This yields an adaptive, exploitative policy that extracts value from cooperators while limiting losses to defectors.
'''

description_EXPLOITATIVE_90 = '''
Overview (exploitative goal)
- My objective is to maximize my own long-run payoff. I will exploit unconditional cooperators whenever it is safe, cooperate only when doing so buys me net future gain (by inducing sustained extra contributions from others), and avoid costly cycles of mutual punishment. The strategy is adaptive: it learns from how others respond when I cooperate or defect and then chooses the action that gives the best trade-off between immediate gain and expected future return.

Definitions and bookkeeping (what I track)
- Let t be the current round (1..r). Let L = r − t be remaining future rounds after this round.
- Maintain a rolling window of the most recent W rounds (W = min(10, r) is a reasonable default) and update after each round.
- For each other player j maintain two statistics (counts over the window):
  - Pj_afterC = fraction of rounds in the window where j cooperated in a round immediately following a round in which I cooperated.
  - Pj_afterD = fraction of rounds in the window where j cooperated in a round immediately following a round in which I defected.
  - If the denominator for either fraction is very small, treat the fraction as uncertain (regularize toward the overall cooperation rate).
- Define responsiveness delta_j = Pj_afterC − Pj_afterD. This estimates how much j’s cooperation probability changes when I switch my action.
- Define total_responsiveness = sum_j delta_j (sum over all other players). Positive means others tend to cooperate more after I cooperate; negative means they tend to reduce cooperation after I cooperate (they may be “exploiters” of my cooperation).
- Also maintain for each j the unconditional cooperation indicators:
  - Pj_uncond = fraction of rounds in window where j cooperated regardless of my previous action (i.e., average of Pj_afterC and Pj_afterD).
- Calibration constants (suggested defaults)
  - W = min(10, r) (window size)
  - T_probe = min(3, r) (initial pure-probe rounds)
  - epsilon = 0.01 (small margin to avoid flipping on tiny estimates)
  - p_probe_defect = 0.05 (small random probing probability)
  - endgame_horizon = 2 (last 2 rounds treated as endgame)
  - thresholds: unconditional_coop_threshold = 0.9, punisher_delta_threshold = −0.2

How I decide (per-round decision rule)
1. Endgame rules
   - If t = r (last round) then defect. (No future to buy.)
   - If L ≤ endgame_horizon then defect unless there is very strong evidence that cooperating now prevents a large coordinated punishment in the final rounds (see the punisher test below). In practice: default defect in the last two rounds.

2. Probe phase (data gathering)
   - For t ≤ T_probe: cooperate (to build trustworthy signal and gather data), except with small probability p_probe_defect I will defect to probe whether others truly ignore my action. Probing early helps identify unconditional cooperators and punishers.

3. Compute immediate and future incentives
   - Immediate cost of cooperating this round = cost_now = 1 − (k / n). (This is the single-round net loss for contributing when others’ actions are treated as fixed.)
   - Expected marginal future benefit of cooperating this round = benefit_future ≈ L * (k / n) * total_responsiveness.
     - Rationale: if my current cooperation increases others’ cooperation by total_responsiveness on average in future rounds, each future contributed token yields me (k/n), so over L future rounds the benefit is L*(k/n)*total_responsiveness.
   - If benefit_future > cost_now + epsilon, cooperate (cooperation buys enough future gain to justify current cost).
   - Else defect.

4. Unconditional-cooperator exploitation
   - If many players are effectively unconditional cooperators (e.g., for a majority of players Pj_uncond ≥ unconditional_coop_threshold), then switch to aggressive exploitation: defect every round (except still obey endgame and probe rules) because those players do not change behavior in response to my action and I maximize payoff by free-riding on their contributions.

5. Punisher detection and avoidance
   - If one or more players have delta_j ≤ punisher_delta_threshold and that player’s responses cause a large aggregate negative total_responsiveness (i.e., defecting now is likely to trigger many fewer contributions in future rounds), then cooperating is safer.
   - Concretely: if −(L * (k / n) * sum_negative_deltas) > immediate_gain_from_defecting where immediate_gain_from_defecting = cost_now (the gain I get right now by defecting vs cooperating), then avoid defecting (cooperate) to avoid punitive losses. In other words, if expected future loss from punishment exceeds the one-shot defector’s gain, prefer cooperation.

6. Safety randomization / continued probing
   - To remain adaptive and avoid getting stuck in a misclassification, occasionally probe:
     - If the chosen action is cooperate, with small probability p_probe_defect defect instead to test whether cooperation is robust.
     - If the chosen action is defect and I have low confidence in statistics (small sample), with small probability p_probe_coop = 0.05 cooperate to test whether cooperation can be re-established.

7. Low-data regularization
   - If data sample sizes are too small (early rounds or not enough transitions), be conservative: default to cooperating for T_probe rounds, then follow rule (3) using regularized estimates (pull Pj_after* toward the population average). This prevents premature exploitation based on noise.

Behavioral summary (how this is exploitative and robust)
- Exploiters/unconditional cooperators: I will detect them quickly (they keep cooperating even after my defects) and thereafter defect consistently to extract the highest payoff from their contributions.
- Conditional cooperators (reciprocators): I cooperate only when doing so yields a net expected future return (calculated from responsiveness). I cooperate enough to keep them contributing if the long-run payoff justifies it, but I defect whenever the one-shot defection gain exceeds the expected future losses from their reduced contributions.
- Punishers: I detect strong negative responsiveness and avoid unnecessary defection that would trigger costly punishment; when necessary I cooperate to avoid being punished out of future gains.
- Random/noisy players: rolling-window statistics smooth noise; small randomized probes keep me from misclassifying noisy behavior as a stable type.
- Endgame exploitation: I exploit the final rounds (defect) because there are no future rounds to sustain cooperation; I start exploiting sooner when the remaining horizon is small and punishers are weak.

Implementation notes (practical choices)
- Window W should be large enough to be informative but small enough to adapt (10 or fewer rounds is a good default).
- Use Laplace regularization (add one pseudo-observation of cooperation and one of defection) when computing fractions if counts are small.
- Choose small epsilon and probe probabilities to avoid excessive oscillation or being exploited by sophisticated strategies that try to manipulate my probes.

Concrete pseudocode-like summary
- On each round t:
  1. If t = r: play D.
  2. Update statistics Pj_afterC, Pj_afterD, delta_j, Pj_uncond from last W rounds.
  3. If t ≤ T_probe: play C (except with small prob p_probe_defect play D).
  4. If majority of players have Pj_uncond ≥ unconditional_coop_threshold: play D (exploit).
  5. Compute total_responsiveness = sum_j delta_j.
     - cost_now = 1 − (k/n)
     - benefit_future = L * (k/n) * total_responsiveness
     - If benefit_future > cost_now + epsilon: play C (cooperate).
     - Else:
         a) Compute punitive_future_loss = L * (k/n) * sum_{j: delta_j<0} (−delta_j).
         b) If punitive_future_loss > cost_now: play C (avoid punishment).
         c) Else play D (defect to exploit).
  6. Apply small randomized probes: flip action with probability p_probe_* as described to test behavior.

This strategy relies only on the game parameters (n, k, r) and observed history (who cooperated when), adapts to many opponent types, and explicitly aims to exploit unconditional cooperators while protecting itself from punishers. It balances immediate exploitation with the long-run benefit of inducing cooperation when that is profitable.
'''

description_EXPLOITATIVE_91 = '''
Name: Adaptive Exploiter (AE)

Summary (one-line): Start by investing to recruit conditional cooperators, learn who reciprocates or punishes, then mostly defect to free-ride while sending minimal, adaptive “maintenance” contributions to keep reciprocators cooperating; always defect in the final round(s) and revert to cautious cooperation if many players punish.

State I keep (computed from observed history):
- t = current round (1..r)
- For every other player j: total_coop_j, recent_coop_j (last H rounds), response_stats_j (how j’s cooperation changes after my cooperation or my defection)
- group_recent_coop = average cooperation rate of the other n-1 players over the last H rounds
- times_I_defected = number of rounds I defected so far
- times_I_cooperated = number of rounds I cooperated so far
- last_round_group_coop = fraction of players who cooperated last round
- a short history buffer of the last H rounds of group cooperation (H = min(6, max(1, floor(r/6))))

Key parameter functions (set deterministically from n, k, r):
- BUILD = min(6, max(1, floor(r/5))) — length of initial recruitment phase
- ENDGAME = min(3, max(1, ceil(r/10))) — final guaranteed defection window
- MAINTENANCE_CYCLE = 4 — default number of rounds between “gift” cooperations when exploiting
- PUNISH_THRESHOLD = 0.25 — fraction of players who retaliate quickly that makes me cautious
- DROP_DET_THRESHOLD = 0.10 — drop in group cooperation after my defection that signals punishment
- TARGET_GROUP_COOP = 0.6 — target group cooperation level to sustain exploitation

High-level flow (each round t):
1) If r == 1: defect (no future to influence).
2) If t == r (last round): defect.
3) If t > r - ENDGAME: defect (endgame defection window).
4) Otherwise follow phase logic below.

Phase A — Recruitment (t <= BUILD)
- Goal: discover and recruit conditional cooperators while being forgiving.
- Rule:
  - If t == 1: cooperate (signal willingness).
  - Else: cooperate unless last_round_group_coop < 0.5 and my payoff last round fell significantly (i.e., I was strongly exploited last round). In that rare case defect one round to avoid immediate exploitation.
- Update response_stats_j every round: record for each j how j’s cooperation changes after I cooperated vs defected.

Phase B — Classification & Mode selection (t > BUILD and not in ENDGAME)
- Compute for other players:
  - fraction_reciprocators ≈ fraction of players who increase or maintain cooperation after my cooperation and don’t systematically decrease after my defections.
  - fraction_punishers ≈ fraction of players who reduce cooperation by at least DROP_DET_THRESHOLD within two rounds after I defected.
  - current_group_coop = average cooperation of others over last H rounds.

- Mode selection:
  - If fraction_punishers > PUNISH_THRESHOLD OR current_group_coop < 0.2:
    - Enter CAUTIOUS mode: avoid exploitation; act like conditional cooperator / “Pavlov” to stabilize cooperation.
  - Else if fraction_reciprocators >= 0.3 AND current_group_coop >= TARGET_GROUP_COOP:
    - Enter EXPLOIT mode: most rounds defect, use small, adaptive gifts to sustain reciprocators.
  - Else:
    - Stay in NEUTRAL/LEARNING mode: conditional cooperation (cooperate if majority cooperated last round).

Phase behaviors (detailed rules)

A) EXPLOIT mode (primary exploitative behavior)
- Default action: defect.
- Maintenance rule (to keep reciprocators cooperating):
  - If I have not given a “gift” within the last MAINTENANCE_CYCLE rounds and last_round_group_coop >= TARGET_GROUP_COOP - 0.1, then cooperate this round (a deliberate low-cost gift).
  - If group cooperation falls by more than DROP_DET_THRESHOLD within two rounds after one of my defections, immediately revert to CAUTIOUS mode (I misestimated punishers).
- If in a round my defect would clearly lower my immediate payoff even ignoring future effects (rare given k<n), prefer defect still — the maintenance gifts are minimal and timed.
- Monitor: if gifts no longer sustain cooperation (group cooperation drifts downward persistently), reduce gift frequency; if they succeed, keep gifts sparse.

B) CAUTIOUS mode (respond to punishers / low cooperation)
- Rule: mirror the group in the short run:
  - Cooperate if last_round_group_coop >= 0.5.
  - Defect if last_round_group_coop < 0.5.
- Be forgiving: after I defect, if the group forgives within two rounds (group cooperation returns), resume conditional cooperation. Do not try to exploit punishers further.

C) NEUTRAL/LEARNING mode
- Rule: conditional cooperation to build more accurate beliefs:
  - Cooperate if majority cooperated last round or if average of last H rounds >= 0.5.
  - Defect if majority defected last round.
- Use this phase to refine response_stats_j and recompute fraction_reciprocators and fraction_punishers.

Edge-case handling and robustness
- Short games (small r): BUILD and ENDGAME adapt using formulas above; for very small r (r <= 3), be conservative: defect in last round, otherwise cooperate once to probe then defect if exploited.
- Noisy-looking opponents (fluctuating cooperation): be forgiving in the recruitment phase (do not abandon after one defection). Use recent H-window statistics rather than overreacting to single rounds.
- Coordinated punishers: if many players punish me after a defection and their punishment reduces my future payoffs, CAUTIOUS mode keeps me from repeated exploitation attempts.
- Sophisticated retaliators who punish only occasionally: I require consistent evidence (DROP_DET_THRESHOLD and PUNISH_THRESHOLD) before giving up exploitation attempts.
- Unknown n, k known: thresholds chosen so I try to harvest when there are enough reciprocators (exploitation profitable) but back off when punishment is common.

Rationale (why exploitative)
- The strategy starts cooperative to recruit and identify conditional cooperators (who increase the public pot if given signals).
- Once a reliable subset of reciprocators/unconditional cooperators is detected and punishers are few, the strategy mostly defects to capture private surplus while sending sparse, well-timed cooperation “gifts” to keep reciprocators contributing—this yields higher average payoffs than unconditional cooperation.
- If many punishers exist or group cooperation collapses, the strategy switches to safe, conditional cooperation to avoid costly punishments and stabilize returns.
- Final-round defection removes any last-round exploitation risk.

Implementation notes (simple pseudocode sketch)
- Initialize stats, set BUILD, ENDGAME, H, etc.
- For each round t:
  - Update statistics from observed last round.
  - If t == r or t > r-ENDGAME: action = D
  - Else if t <= BUILD: follow Recruitment rule
  - Else compute fraction_reciprocators, fraction_punishers, current_group_coop
    - Choose mode (EXPLOIT / CAUTIOUS / NEUTRAL) as above
    - Execute action according to mode (EXPLOIT: default D, periodic gift C; CAUTIOUS and NEUTRAL: conditional on last_round_group_coop)
  - After action, record for updates next round.

Behavioral summary (short):
- Start friendly to recruit cooperators.
- Learn who reciprocates vs punishes.
- When safe to exploit, defect most rounds and give rare cooperative gifts to maintain others’ contributions.
- If many punishers or cooperation collapses, revert to cautious conditional cooperation.
- Always defect in the final round(s).
'''

description_EXPLOITATIVE_92 = '''
Name: Adaptive Exploitative Conditional Defector (AECD)

Summary goal (exploitative mindset)
- Extract as much benefit as possible from others’ contributions: free-ride when safe, but avoid provoking sustained, costly punishment by the group. Detect and permanently exploit unconditional cooperators; exploit conditional cooperators opportunistically while responding to retaliation; cooperate only when the long-run cost of being punished exceeds the immediate gain from defecting.

Core concepts the strategy tracks
- Per-player cooperation rate (CR_i): fraction of rounds player i contributed over a recent window.
- Per-player responsiveness (Resp_i): how much player i’s contribution probability drops following rounds when I defect vs when I cooperate (measured over the same recent window).
- Group cooperation rate (GCR): average CR of all other players.
- Group retaliator fraction (GRF): fraction of players with Resp_i above a responsiveness threshold.
- Remaining rounds R_remain.

Default internal parameters (adaptive to game length r)
- Window W = min(30, max(5, round(r/6))) — measure history over W most recent rounds (or all past rounds if fewer).
- Responsiveness threshold delta = 0.25 (a sizable drop in contribution probability after my defection).
- Maintenance cooperation probability p_maintain = max(0.05, min(0.15, 3 / r)) — small chance to cooperate while exploiting.
- Minimum exploit-safe group cooperation G_low = 0.15 (if group hardly cooperates, there’s nothing to exploit).
- Severe-retaliation threshold GRF_high = 0.4 (if many players retaliate, avoid exploitation).
- Forgiveness sensitivity: treat short, isolated drops as noise; require a sustained change over at least floor(W/3) rounds to count as retaliation.

Decision outline (each round t, excluding last-round rule below)
1. Update statistics from history (use last W rounds or all rounds if fewer):
   - For each opponent i compute CR_i (their contribution frequency).
   - For each opponent i compute Resp_i = (avg contribution of i in rounds immediately following my cooperation) - (avg contribution after my defection). Positive Resp_i means they reduce contribution after I defect (they punish/reciprocate).
   - GCR = average CR_i across opponents.
   - GRF = fraction of opponents with Resp_i >= delta.

2. Quick filters:
   - If GCR <= G_low: virtually no cooperators — defect (nothing to gain by cooperating).
   - If t <= min(3, r): probe phase — cooperate the first 1–3 rounds to gather signals (unless r=1; see last-round rule).
   - If R_remain is small (see last-round rule below), shift toward defection.

3. Expected immediate gain vs estimated long-run loss heuristic:
   - Immediate gain from defecting this round (one-shot) is always g = 1 - (k/n) > 0 (because k/n < 1).
   - Estimate expected per-round loss in future contributions if I defect now:
     a) For each opponent with Resp_i > 0, take delta_i = Resp_i as estimated per-round drop in their contribution probability caused by my defection.
     b) Estimated per-round drop in total contributions = sum_i delta_i (exclude my own contribution).
     c) Estimated per-round loss to my payoff if they reduce contributions = (k/n) * (sum_i delta_i).
     d) Estimate retaliation duration D_est = min(W, R_remain). (Assume retaliation, if triggered, will persist for up to W rounds.)
     e) Estimated cumulative loss L = D_est * (k/n) * (sum_i delta_i).
   - Decision rule:
     - If g > L and GRF < GRF_high: defect (exploit).
     - Otherwise: cooperate (avoid triggering sustained costly punishment).

4. Targeted exploitation refinements
   - Unconditional cooperators: if CR_i >= 0.95 and Resp_i < 0.05 (they never or rarely punish), classify i as “soft/cooperative” and treat them as reliable contributors. If at least one soft cooperator exists and GRF is low, defect to exploit their contributions even if some others are mixed.
   - If a minority of players are retaliatory but most are soft cooperators, defect but schedule periodic “maintenance cooperation” (cooperate with probability p_maintain each round, or cooperate every M = max(3, round(1/p_maintain)) rounds). This prevents coordinated collapse by giving occasional signals of cooperation to conditional players and reduces sustained retaliation risk.
   - If many players are retaliatory (GRF >= GRF_high), switch to cooperative stance until evidence of forgiveness appears (their Resp_i falls), then re-evaluate.

5. Forgiveness and recovery
   - When we detect sustained declines in group cooperation following our defection (GCR falls substantially for more than floor(W/3) rounds), mark a “recovery mode”: cooperate every round for at least floor(W/3) rounds to rebuild trust and identify which opponents resume contributing (those are future exploitation targets).
   - If a listed retaliator reduces Resp_i over repeated observations (their Resp_i drops below delta for two successive windows), consider them rehabilitated and resume targeted exploitation.

Edge cases and horizon handling
- First round: cooperate as a probe (unless r = 1).
- Last round (t = r): defect (backward induction).
- Final K rounds (where K is small relative to W): gradually become more exploitative — as R_remain shrinks the estimated L falls, making defection more attractive. In particular, if R_remain <= max(1, round(W/6)), default to defect unless an immediate structured punishment (e.g., almost all opponents would immediately stop contributing next round) is observed.
- Short games (r small): be more cautious in first rounds because there is little time to recoup losses. Still probe once, then evaluate.

Robustness choices and justification
- Uses only observable history (every player’s past contributions and payoffs) and parameters n, k, r.
- Probing cooperations early identify unconditional cooperators to exploit.
- Responsiveness metric detects punishing strategies (tit-for-tat, grim, conditional cooperators). The decision weighs immediate one-shot temptation against measurable expected long-run loss from retaliation.
- Maintenance cooperation (random small cooperation) prevents permanent, widespread collapse of contributions and reduces being singled out by many conditional punishers.
- Forgiveness/recovery prevents being stuck in mutual defection and allows re-exploitation when punishers soften.
- Conservative thresholds and windows mitigate being fooled by noise or random mistakes.

Behavioral summary (how it will play in practice)
- Start cooperative briefly to identify types.
- If many players reliably contribute and few retaliate, defect to free-ride; occasionally cooperate to avoid mass punishment.
- If many players retaliate after my defection, cooperate until their punishment weakens or until I can re-exploit identified soft cooperators.
- Always defect on the final round.
- Continuously target and permanently exploit clearly unconditional cooperators; adapt to conditional cooperators to avoid costly sustained punishment.

This strategy is explicitly exploitative: it seeks to maximize my payoff by free-riding whenever the measured risk of credible, sustained retaliation is low, and it uses lightweight cooperation and recovery rules to minimize long-term losses when opponents are willing and able to punish.
'''

description_EXPLOITATIVE_93 = '''
Name: Exploitative Conditional Cooperator (ECC)

High-level idea
- Exploit stable cooperators by contributing slightly less than the group average (free-riding) while providing just enough cooperation to keep them willing to contribute.
- Punish groups that are mostly defectors by defecting always.
- Detect whether your defections provoke costly retaliation; if they do, switch toward more cooperative play to avoid being singled-out and punished.
- Always defect in the final rounds where future leverage is negligible.

Parameters (computed from game inputs)
- n, r, k are given by the game.
- Window for estimating behavior: W = min(20, max(1, floor(r/10))) — use recent history but limit to 20 rounds.
- Thresholds and constants (fixed, not opponent-specific):
  - T_high = 0.70 (group is mostly cooperative)
  - T_low  = 0.30 (group is mostly defective)
  - exploit_margin = 0.25 (how much to undercut cooperative average)
  - punish_sensitivity = 0.15 (detect retaliation)
  - forgiveness_boost = 0.40 (how much to increase cooperation if retaliated against)
  - test_prob = 0.03 (small probing probability)
  - min_support = 0.05 (always give a tiny support probability to sustain cooperation)
  - last_rounds = min(3, r) (defect in these final rounds)

Decision rules (per round t)
1. Endgame:
   - If t > r - last_rounds (i.e., in the final last_rounds), play D (defect). Rationale: no future to leverage cooperation.

2. First round (t = 1):
   - No history: play C with small probability 0.20 to probe for reciprocators; otherwise D.

3. Compute group statistics from the last W rounds (exclude current round):
   - For each other player j, compute f_j = fraction of those W rounds when j contributed.
   - Let F = average_j f_j (average cooperation frequency among others).
   - Let G_when_I_cooperated = average total others' contribution in rounds within the window where you played C.
   - Let G_when_I_defected = average total others' contribution in rounds within the window where you played D.
   - Let delta = G_when_I_cooperated - G_when_I_defected (positive means others cooperate more when you cooperate).

4. Detect retaliation:
   - If delta > punish_sensitivity, then your defections appear to trigger drops in others' contributions (they punish you). Set retaliated = true. Otherwise retaliated = false.

5. Choose cooperation probability p this round:
   - If retaliated == true:
       p = min(1.0, F + forgiveness_boost).
       (Make cooperation more likely to stop being punished; you trade some short-run payoff to stop long-run losses from retaliation.)
   - Else if F >= T_high:
       p = max(min_support, F - exploit_margin).
       (Many cooperators present: undercut them by an amount exploit_margin but still provide minimal support so they keep cooperating.)
   - Else if F <= T_low:
       p = 0.0.
       (Group is mostly defectors: do not give away a token.)
   - Else (F in (T_low, T_high)):
       p = max(0.0, F - exploit_margin/2).
       (Mid-range: reciprocate partially but undercut slightly.)
   - Independently apply a small exploration: with probability test_prob, play D regardless of p to probe for reactions (this helps detect exploitable cooperators).
   - Clamp p to [0,1].

6. Action selection:
   - Play C with probability p, otherwise play D.

Notes on robustness and exploitative behavior
- Exploitation mechanism: when opponents on average cooperate, ECC deliberately contributes less than the observed average (undercutting by exploit_margin or exploit_margin/2). This yields frequent free-riding while providing just enough cooperation (min_support) to keep cooperators from abandoning the group.
- Punishment and safety: when the history shows that your defections elicit a meaningful drop in others’ contributions (delta > punish_sensitivity), ECC switches toward more cooperative play (forgiveness_boost) to avoid sustained costly punishment. This prevents isolated, persistent retaliation from destroying your long-term payoff.
- Adaptivity: ECC uses a sliding recent window W to track changes in opponents’ behavior and adapts cooperation probability continuously.
- Endgame handling: ECC defects in the last few rounds (last_rounds) where future leverage is too small to justify contributing.
- Exploration: small randomized testing (first-round probing and test_prob) discovers opportunities to exploit unconditional cooperators and to detect punishing strategies.

Edge cases
- Very short games (r < W): W adjusts downwards; last_rounds is clamped to r so no invalid indexing.
- n small (e.g., n = 2): the same decision rules apply; thresholds remain meaningful because behavior is measured relative to your single partner.
- If opponents are perfectly cooperative (F ≈ 1), ECC still contributes with substantial probability (≈ 1 - exploit_margin) rather than zero: this keeps them cooperating and yields a consistently high exploit payoff.
- If opponents are perfectly defective (F ≈ 0), ECC defects, avoiding wasted contributions.
- If a revengeful strategy emerges (they punish any defection severely), ECC’s retaliation detector forces it to abandon exploit attempts and cooperate more to stop the punishment.

Summary in one line
- Continuously estimate recent group cooperation; undercut cooperative groups by contributing slightly less (free-riding) while punishing defectors by withholding contributions, but detect and accommodate costly retaliation by increasing cooperation to avoid being isolated; always defect in the final rounds.
'''

description_EXPLOITATIVE_94 = '''
Goal (exploitative): maximize my own cumulative payoff by (1) identifying players who will reliably contribute in response to my cooperative gestures and (2) free‑riding on their contributions as often as possible, while using calibrated cooperation and short, credible punishments to keep a stable pool of such “coaxable” cooperators alive. Only cooperate when doing so is likely to increase future contributions by others enough to pay back the immediate cost; otherwise defect. Always defect in the final rounds where future leverage is gone.

Notation and simple computed parameters (all computed from n, r, k at the start):
- w = max(3, min(10, floor(r/4))) — window (recent rounds) used to estimate behavior.
- probe_rounds = min(6, max(1, ceil(r*0.08))) — short probing at start.
- endgame_len = min(2, max(1, ceil(r*0.05))) — final rounds when I always defect.
- coop_rate_thresh = 0.5 — baseline to call someone a “cooperator”.
- resp_thresh = 0.15 — minimum positive responsiveness to my cooperation to call someone “coaxable”.
- safe_exploit_count = max(1, floor((n-1)/3)) — number of other players I want classified as reliable before I mostly free‑ride.
- punish_rounds = min(3, max(1, ceil(r*0.03))) — length of short punishment for betrayals.
- rebuild_interval = max(3, ceil(n/2)) — how often (in rounds) I voluntarily cooperate to maintain goodwill if I want to rebuild cooperation.

High-level phases
1. Probing phase (first probe_rounds): gather data about everyone’s unconditional/cooperative tendencies and responsiveness to my moves.
2. Exploit/maintenance phase (middle of the game): default to defect; cooperate sparingly to recruit/maintain coaxable players; defect to free‑ride when a safe pool exists; punish defections that threaten the pool.
3. Endgame (final endgame_len rounds): always defect.

Detailed decision rules (pseudocode style)

Initialization:
- Maintain history of each opponent’s actions over the last w rounds: coop_count_i (excluding me) and transitions after my actions: count_coop_after_myC_i, count_total_after_myC_i, count_coop_after_myD_i, count_total_after_myD_i.
- Maintain a set Coaxable = {} and Unconditional = {} updated each round.

Round t decision (for each round t = 1..r):
1) Endgame check:
   - If t > r - endgame_len: choose D (defect). Rationale: no future to influence.

2) Probing stage (t ≤ probe_rounds):
   - Round 1: cooperate (C). Purpose: give a clean test and not be immediately dismissed as pure defector.
   - In subsequent probe rounds use a deterministic probing pattern: alternate C and D (or, if only 1 probe round allowed, use C then switch to exploitation rules). Record how each opponent responds in the round immediately following my C vs my D.

3) After probe_rounds (and in every round after that), update stats over the last w rounds for each opponent:
   - coop_rate_i = coop_count_i / w (fraction of those w rounds they contributed).
   - responsiveness_i = P(opponent cooperated next round | I cooperated) − P(opponent cooperated next round | I defected),
     estimated as (count_coop_after_myC_i / max(1,count_total_after_myC_i)) − (count_coop_after_myD_i / max(1,count_total_after_myD_i)).
   - If coop_rate_i ≥ 0.8 (very high), add i to Unconditional.
   - Else if coop_rate_i ≥ coop_rate_thresh AND responsiveness_i ≥ resp_thresh, add i to Coaxable.
   - Otherwise remove i from Coaxable and Unconditional if present.

4) Compute S = |Unconditional| + |Coaxable| (count of players I can rely on).
   - If S ≥ safe_exploit_count:
       - Exploit: choose D (defect) this round. Rationale: many others reliably contribute; maximize immediate payoff by free‑riding.
       - Exception (maintenance): every rebuild_interval rounds (to avoid slow collapse) choose C for one round when S is borderline (S == safe_exploit_count) to “top up” goodwill from coaxables; do so only if not in the first half of a fresh punishment episode (see punishment rule).
   - If S < safe_exploit_count:
       - Recruit/maintain: choose C (cooperate) this round with these subrules:
           a) If there are zero coaxable/unconditional players (S==0): cooperate deterministically until at least one player’s coop_rate over w exceeds coop_rate_thresh (i.e., until I identify at least one potential cooperator). This is an investment to find partners.
           b) If 0 < S < safe_exploit_count: cooperate for up to rebuild_interval rounds (or until S ≥ safe_exploit_count), then switch back to occasional defections to test stability. In practice: cooperate the next round if I defected last round and S dropped; otherwise defect 1 round then cooperate 1 round, to probe responsiveness.
       - Rationale: I pay a small, strategic cost to build a pool of others I can reliably exploit later.

5) Punishment rule (credible short punishments to deter exploitation of me):
   - If in any round a player previously in Coaxable or Unconditional defects in a way that looks like a coordinated collapse (e.g., their coop_rate over the latest w rounds drops by > 0.3 compared with previous window or they defect the round immediately following my cooperation consistently), then:
       - Remove that opponent from Coaxable/Unconditional.
       - Enter a short punishment mode: defect for punish_rounds rounds (punish_rounds includes current round unless already chosen), ignoring rebuild maintenance. This is a calibrated, temporary response intended to signal that my cooperation is contingent; keep punishments short and local rather than permanent to avoid self-destructing all cooperation.
   - After punish_rounds rounds, resume normal exploitation/maintenance rules but treat the punished player as suspect (keep them out of Coaxable until their coop_rate rebounds).

6) Forgiveness and exploration:
   - After any punishment or after a sequence of defections, periodically (every rebuild_interval rounds) cooperate once to probe whether some opponents will return to cooperating. This keeps the pool renewable, minimizing being permanently exploited by uncooperative masses.
   - Use stochastic probing: if the pool is fragile (S == safe_exploit_count − 1), occasionally (probability 0.25) cooperate one extra round to check for renewed responsiveness.

7) Tie-breaking and small r cases:
   - If r is extremely small (r ≤ 3): my default is D every round except optionally cooperate in round 1 as a single probe; but since there is little future to exploit, prefer D. If r==1: D.
   - If probe_rounds exceeds r - endgame_len (i.e., very short games), reduce probe_rounds to 1 and rely on default D strategy for remaining rounds.

Why this is exploitative and robust
- Defaulting to defect maximizes immediate payoffs whenever future leverage is weak.
- Probing + measuring responsiveness finds players who will increase cooperation when I cooperate; these are the ones I can reliably exploit later.
- The safe_exploit_count threshold ensures I only free‑ride when I can expect a sizeable pool of contributors so that my defection will not immediately collapse cooperation and cost me more in future rounds.
- Short, credible punishments discourage players from abandoning the implicit pact; forgiveness and scheduled cooperation prevent collapse into universal defection.
- Endgame defection prevents being exploited when no future leverage exists.
- All decisions depend only on public history (actions observed), parameters (n, r, k) and deterministic/simple probabilistic rules — no coordination or external norms required.

Practical knobs (how to tune if you want more or less exploitative):
- Increase safe_exploit_count → more conservative (cooperate more to build larger pool before exploiting).
- Decrease safe_exploit_count → more aggressive exploitation (free‑ride even on small pools).
- Increase punish_rounds or resp_thresh → harsher enforcement, which can sustain cooperation with many reciprocators but risks long mutual defection with many defectors.
- Increase rebuild_interval or make probing stochastic → more generous, more forgiving strategy that can keep a larger cooperative pool longer.

Summary operational recipe (one‑line):
- Probe briefly; estimate who responds to my cooperation; default to defect; cooperate only to recruit or to maintain a minimal pool of responsive cooperators, defect to free‑ride whenever that pool is large enough, apply short punishments to deter betrayals, and always defect in the final rounds.
'''

description_EXPLOITATIVE_95 = '''
Adaptive Opportunistic Exploiter (natural-language pseudocode)

Goal (exploitative mindset)
- Extract maximum short-run gains from cooperators while avoiding long punishments that destroy future exploitation opportunities. Default to defect; cooperate only when doing so is necessary to regain or sustain a profitable stream of others' contributions. Always defect in the final rounds.

Parameters (set from game parameters r, n, k)
- W = min(10, max(3, floor(r / 10)))  // history window for statistics
- T_high = 0.70                         // threshold saying: others are reliably cooperative
- T_low = 0.30                          // threshold saying: others are mostly defectors
- Delta_punish = 0.25                   // drop in others' contributions that counts as punishment
- P_probe = max(3, floor(W / 2))        // probe frequency to test environment
- Rehab = 3                             // rounds to cooperate to try to restore cooperation after punishment
- Endgame = min(3, r)                   // last Endgame rounds: always defect

State maintained (based only on history)
- For each other player and for the group excluding me: contribution history (0/1 per past round).
- others_avg_lastW = average contribution rate of other players over the most recent W rounds (exclude my contributions).
- punish_detected = boolean flag set True if there is recent evidence that my defections provoke a >= Delta_punish drop in others' average contributions (detection described below).
- rounds_since_last_probe = counter.

Auxiliary detection rule (punishment detection)
- For each round t in which I defected, compare (a) others' average contribution in the 1–2 rounds immediately before t to (b) others' average in the 1–2 rounds immediately after t.
- If the median (before → after) drop over my recent defections >= Delta_punish, set punish_detected = True. Otherwise keep punish_detected = False.
- This capture whether my defection tends to trigger immediate retaliation.

Round-by-round decision rule
1. If round t is within the last Endgame rounds (t > r - Endgame): action = D (defect). (Final-stage exploitation: no future to restore.)
2. Else compute others_avg_lastW and maintain punish_detected.

3. If others_avg_lastW < T_low:
   - Environment is mostly defection; there's nothing profitable to extract. action = D (defect).
   - Occasionally (once every P_probe rounds) set action = C as a probe to test whether cooperators have reappeared.

4. Else (others_avg_lastW >= T_low):
   - If punish_detected is False AND others_avg_lastW >= T_high:
     - Environment has many cooperators and they do not punish my defections strongly.
     - Exploit mode: primarily D (defect) every round to free-ride on others.
     - To avoid inadvertent long-term collapse or to discover changes, perform a one-round cooperation as a gentle signal every P_probe rounds (set action = C on that probe round, then resume D).
   - If punish_detected is True AND others_avg_lastW >= T_high:
     - There are many cooperators but some punish defectors; constant defection will trigger loss of cooperation.
     - Recovery-first: cooperate for Rehab consecutive rounds (action = C for Rehab rounds) to demonstrate willingness to cooperate and try to reset punishers’ trust.
     - After Rehab, enter pulsed exploitation: repeat the cycle
         - exploit attempt: play D for 1 round (gain immediate extra 1 token),
         - observe others in the next round(s):
             - if others’ average next-round contribution remains near T_high (no punishment), continue exploiting (you may keep defecting and only occasionally do one cooperative probe every P_probe rounds to maintain the norm).
             - if others’ contributions drop by >= Delta_punish following your exploit attempt, treat that as resumed punishment: immediately go back to Recovery (cooperate Rehab rounds) and then try pulsed exploitation again later.
     - While in this punished environment, still perform an infrequent probe (every P_probe rounds) of cooperation to check whether the group has relaxed.

5. First-round rule:
   - Round 1: D (defect). (Exploit any unconditional cooperators immediately; information-gathering follows from others’ responses.)

6. Probing rule (applies across modes):
   - Every P_probe rounds, play C (one round) as a non-threatening signal to test whether cooperators re-emerge or whether punishment thresholds have changed. After a probe, update punish_detected according to the auxiliary rule.

Rationale and robustness notes (why this is exploitative and resilient)
- Default defection maximizes immediate payoff and extracts surplus from unconditional cooperators.
- The strategy actively monitors whether my defections cause immediate retaliation (punish_detected). If nobody retaliates, I can exploit unpunished cooperators continuously. If retaliation exists, I avoid suicidal constant defection by briefly restoring cooperation to regain the ability to exploit later — a minimal-cost rehabilitation rather than a long costly war.
- Pulsed exploitation (cooperate enough to keep a cooperative norm, then defect briefly) extracts gains while keeping the cooperative machine running; if punishers respond, the plan switches quickly back to rehabilitation.
- Occasional probes ensure adaptation to environment changes (new cooperators, disappearing punishers).
- Always defect in the final rounds eliminates wasted cooperative gestures when no future benefit exists.
- All decisions depend only on observable history and the public game parameters (n, k, r). No communication or coordination is assumed.

Edge cases
- If r is very small (e.g., r <= Endgame): the strategy defects every round (no time to rehabilitate).
- If the group is mixed and volatile, the probes and small Rehab windows minimize wasted tokens while still allowing periodic exploitation opportunities.
- If opponents are extremely harsh punishers (punish_detected quickly and persistently), the strategy will spend most time in Recovery/Probing cycles and will avoid provoking long-term collapse; if that yields too little payoff, the strategy still secures the safe baseline of defecting when cooperation vanishes.

Summary (one-line)
- Default: defect; if many cooperators are present and do not punish, free-ride continually; if cooperators punish, briefly cooperate to regain their contributions then perform short, cautious exploit attempts, probing occasionally; always defect in the final rounds.
'''

description_EXPLOITATIVE_96 = '''
Goal summary (exploitative mindset)
- Get above-average payoff by (a) being seen as a cooperator early so you lure conditional / naive cooperators, (b) opportunistically free-ride when the group looks reliably cooperative, and (c) stopping exploitation quickly and punishing if the group retaliates or if cooperation falls so you don’t become a long-term sucker.
- Be adaptive (use recent history), parameter-aware (use n, r, k), and robust to many opponent types (forgiveness, punishment, probing).

Common definitions used repeatedly
- t = current round (1..r).
- c_j(t) ∈ {0,1} = contribution of player j in round t (observed after each round).
- For any player j, Reputation R_j = fraction of rounds (in a recent sliding window of length L) in which j contributed. When there are fewer than L past rounds, use all available past rounds.
- Group average cooperation G = average_j≠me R_j (average of others’ reputations).
- Immediate gain from defecting in one round (never used directly in decision rules but used to set aggressiveness):
  g := 1 - k/n (positive because k/n < 1). Normalize to alpha ∈ [0,1] for heuristic thresholds:
  alpha := g / (1 - 1/n) (clamped to [0,1]).
- Window length L = clamp(floor(r/5), 3, 10) (use last ~20% of rounds up to 10 rounds).
- Warm-up rounds W = min(5, floor(r/10)+1).
- Endgame horizon H = min(r, max(1, ceil(r*(0.08 + 0.25*alpha)))) — increases a little if defecting is more profitable (alpha large).
- Thresholds (clamped to [0,1]):
  - high_thresh = clamp(0.95 - 0.3*alpha, 0.5, 0.95). (If G ≥ high_thresh we will attempt an exploit probe.)
  - mid_thresh  = clamp(0.6 - 0.2*alpha, 0.2, 0.8). (If G ≥ mid_thresh we cooperate to sustain cooperation.)
  - low_thresh  = clamp(0.3, 0, 0.5). (Below this we defect.)
- Monitoring/punishment parameters:
  - retaliation_delta = 0.18 (if group cooperation drops by more than this after we defect, treat as retaliation).
  - lookahead_after_probe = 2 rounds (observe next 1–2 rounds after a probe to detect retaliation).
  - max_consecutive_exploits = 1 + floor(4*alpha) (limit how many rounds in a row we exploit before reassessing).
  - max_punish_rounds = min(6, 2 + floor(5*alpha)).

High-level state machine (keeps small state variables)
- Modes: COOPERATE, PROBE_EXPLOIT, EXPLOITING, PUNISH, COOLDOWN.
- State variables to keep between rounds:
  - last_probe_round (round when we last initiated a probe).
  - consecutive_exploit_count.
  - punish_count (how many rounds we have punished so far).
  - cooldown_count (how many cooperative rounds left after punishment).

Round-by-round decision rules (what to play this round)
1. Terminal and trivial edge cases
   - If r = 1: defect (single-shot best response).
   - If n = 1 (you are the only player): contribute if k>1? (but n≥2 in standard PGG; if happens, contribute only if you want to increase group payoff; treat as defect for safety).
   - If t > r - H (we are in the final H rounds): defect unconditionally. (Endgame: avoid being exploited in last rounds.)

2. Warm-up (build reputation)
   - If t ≤ W: play C (cooperate). Purpose: show you are a cooperator to lure conditional cooperators and naive unconditional cooperators.

3. Otherwise use the state machine below. At the start of each round compute R_j for each other player j over last L rounds and G = average_j≠me R_j.

State machine detailed rules

A. If current mode = PUNISH
   - Action: Defect.
   - Increment punish_count.
   - After each round of PUNISH, recompute G. Exit PUNISH and enter COOLDOWN if either:
     - punish_count ≥ max_punish_rounds, or
     - G ≤ low_thresh (punishment had the intended effect).
   - Upon exit, set cooldown_count = 2 and reset consecutive_exploit_count = 0.

B. If current mode = COOLDOWN
   - Action: Cooperate for cooldown_count rounds (count down each round).
   - After cooldown_count reaches 0, set mode = COOPERATE.

C. If current mode = EXPLOITING
   - If consecutive_exploit_count < max_consecutive_exploits and G ≥ high_thresh:
     - Action: Defect (continue exploiting).
     - Increment consecutive_exploit_count.
     - Record last_probe_round if not set.
   - Else:
     - Stop exploiting: set consecutive_exploit_count = 0, last_probe_round = null, and set mode = COOPERATE.

   - After any round we exploited (defected while others were high-cooperators), observe the next 1..lookahead_after_probe rounds:
     - If group average cooperation in the next 1 or 2 observed rounds drops by more than retaliation_delta relative to pre-probe G, interpret as retaliation and immediately enter PUNISH (discard current exploit_count). This protects you from a coordinated retaliation cascade.

D. If current mode = COOPERATE
   - Compute G.
   - If G ≥ high_thresh:
     - Initiate a PROBE_EXPLOIT this round: Action = Defect, set mode = PROBE_EXPLOIT, last_probe_round = t, consecutive_exploit_count = 1.
   - Else if G ≥ mid_thresh:
     - Action = Cooperate (sustain cooperation).
   - Else:
     - Action = Defect (group is too uncooperative; avoid being exploited).

E. If current mode = PROBE_EXPLOIT
   - The round when PROBE_EXPLOIT was initiated we already defected. For the immediate next round(s) we examine others’ behavior:
     - If in the subsequent 1..lookahead_after_probe rounds others do not reduce their cooperation significantly (no drop > retaliation_delta), then interpret probe as tolerated and switch to EXPLOITING (continue defecting up to max_consecutive_exploits while monitoring).
     - If others reduce cooperation by > retaliation_delta within the lookahead window, switch immediately to PUNISH.

Summary of practical behavior
- Early rounds: mostly cooperate to build credibility.
- Middle game:
  - If most opponents have been very reliable cooperators (G high), occasionally perform a probe defection to see whether you can get away with free-riding. If the probe is tolerated, continue exploiting for a bounded number of rounds to harvest extra payoff.
  - If the probe causes a measurable fall in group cooperation, punish (defect repeatedly for a short bounded period) to make future exploitation riskier for opponents and to deter collective retaliation that would leave you worse off long-term.
  - If group cooperation is moderate, stay cooperative to keep the stream of reciprocity and avoid losing long-run gains.
  - If group cooperation is low, defect to avoid being a sucker.
- Endgame: defect unconditionally in the final H rounds so you are not exploited when there is no future to recover losses from.

Robustness and adaptivity remarks (how the rules make the strategy robust)
- Windowed reputations (L) make the strategy responsive to recent behavior while ignoring ancient history.
- Probing + short exploitation harvests exploitation opportunities but are bounded to avoid long-term collapse.
- Quick detection of retaliation and short punitive bursts prevent being persistently exploited or trapped in endless mutual defection cycles, and they deter coordinated punishers from profiting by pushing you into cooperating while they defect.
- Parameters depend on alpha (a simple function of k and n): when defecting is relatively more profitable (alpha large), the strategy becomes more aggressive (more frequent/longer exploitation windows), and when defecting is less attractive (alpha small) the strategy is more patient/cooperative.
- First-round cooperation and a short cooldown after punishment let the strategy regain cooperator status with conditional cooperators and naive players so it continues to be exploitable in the future.

Edge-case checklist (explicit)
- First round: cooperate (unless r = 1).
- Last H rounds: defect unconditionally.
- Single-shot game (r = 1): defect.
- If many players are permanent cooperators (R_j ≈ 1) and tolerate probes, the strategy will repeatedly exploit them within the bounded exploitation policy and so extract surplus.
- If opponents retaliate, the strategy punishes fast and then returns to cooperative behavior so it does not get exploited repeatedly.

Behavioral intuition in one sentence
- Be “nice” at first to earn trust, probe and siphon surplus opportunistically when the group looks reliably cooperative, and immediately switch to short, sharp punishment if exploitation triggers retaliation—always shutting down cooperation late in the game to avoid endgame exploitation.
'''

description_EXPLOITATIVE_97 = '''
Selective Exploiter (natural-language pseudocode)

Core idea
- Default to free-riding whenever opponents look likely to supply the public good; cooperate only rarely and strategically to preserve a stable subset of contributors I can exploit. Defect in the known endgame. Track individual cooperation rates and total contributions; probe early and punish only enough to deter others from abandoning cooperation.

Tunable parameters (derived from n, r)
- Window W = min(10, max(1, floor(r/5))) — how many recent rounds we use to estimate behavior.
- Endgame length L_end = min(3, r) — always defect in the final L_end rounds.
- Reliable-cooperator threshold θ = 0.6 (a player is “reliable” if their contribution rate in the last W rounds ≥ θ).
- Exploit-threshold S_exploit = max(1, ceil((n-1)/2)) — if at least S_exploit other players contributed last round, treat the situation as a cooperative crowd to exploit.
- Sustainer cooperation probability q = 0.25 — when we intentionally cooperate to sustain others, do so only with modest probability.
- Retaliation length P = 3 rounds — short punishment to deter opportunistic declines in cooperation.

Actions by round
1. Round 1:
   - Play D (defect). Start by free-riding to avoid being an automatic sucker and to gather initial data.

2. Any round t such that t > r − L_end:
   - Play D (defect). Endgame defection: no incentive to incur cost in the final rounds.

3. Otherwise (2 ≤ t ≤ r − L_end):
   - If no history (should not happen except first round), play D.
   - Let S_prev = number of players (excluding you) who contributed in the previous round.
   - Maintain for each player j their contribution rate f_j over the most recent W rounds.

   Decision rules (priority order)
   A. Immediate exploitation: if S_prev ≥ S_exploit:
      - Play D (defect) to capture the benefit while others are contributing. Rationale: when many others contributed last round they are likely to continue; free-riding yields immediate advantage.
   B. Support a reliable minority (sustainment): else compute R = number of other players with f_j ≥ θ (reliable cooperators).
      - If R ≥ 1 (there exists at least one reliable cooperator):
         - Play C with probability q (e.g., 25%), otherwise D.
         - Rationale: we occasionally contribute to signal continued partial support so reliable cooperators keep contributing; we do this rarely to maximize exploitation over time.
      - If R = 0:
         - Play D (defect). Rationale: no sustainable cooperators to exploit; avoid wasting tokens.
   C. Retaliation trigger (overrides sustainment only when active):
      - If in the last time we cooperated we observed a sharp drop in total contributions (e.g., total contributors fell by more than 30% or by at least 2 players in the following round), enter punishment mode:
         - Play D for the next P rounds (short punishment) to deter those who opportunistically exploit our cooperation.
         - After P rounds, resume the normal decision rules.

Notes and rationale (why this is exploitative and robust)
- Exploitative posture: the strategy defects whenever recent history indicates a crowd of contributors (S_prev ≥ S_exploit) so it free-rides on others as often as feasible.
- Strategic cooperation: rather than blind always-defecting (which would cause everyone to stop), it occasionally cooperates only if there is at least one reliably cooperative opponent, just enough to keep that subset incentivized to contribute in the long run. The cooperation probability q is deliberately low to maximize exploitation while maintaining some stability.
- Short, measured punishment: use brief retaliation only when our cooperation appears to be exploited (sharp drops after we cooperate). This deters opportunism but avoids long vendettas that reduce our long-run payoff.
- Endgame safety: defect in final L_end rounds to avoid being exploited by strategies that exploit forward-looking incentives near the end.
- Parameter adaptivity: W and L_end scale with r; the decision thresholds depend only on the observed counts and per-player rates, so the rule adapts to groups of any n and any k without assuming coordination or norms.

Edge cases
- Very short games (r ≤ L_end): behave as endgame — defect every round.
- No reliable cooperators ever observed: the strategy converges to defecting every round (safe and exploitatively sanitary).
- Highly cooperative populations: the rule will exploit them heavily by defecting whenever many others contributed in the prior round; occasional low-probability cooperation prevents total collapse of the cooperative pool.
- Presence of harsh punishers: occasional cooperation and short punishments make escalation unlikely; if severe long punishments are common, this strategy will learn their effect (cooperators’ rates fall) and will switch to mostly defecting, minimizing losses.

Summary (one-line)
- Defect by default and in the endgame; when a crowd contributed last round, defect to free-ride; otherwise, cooperate rarely only if there are identified reliable cooperators to sustain, and use short targeted punishment if our cooperation is exploited.
'''

description_EXPLOITATIVE_98 = '''
Goal (exploitative mindset)
- Maximise my own cumulative payoff by inducing other players who tend to cooperate to keep contributing while I contribute as little as possible; avoid being trapped in mutual defection by punishers when doing so would cost me more than it gains; always defect in the final rounds where retaliation is impossible.

Parameters derived from the game (computed from n, k, r at start)
- T_probe = min(3, max(1, floor(r/10))) — short initial probe period (at least 1 round, up to 3).
- w = min(5, r) — window length for measuring recent cooperation rates.
- cooperator_threshold = 0.60 — a player whose contribution frequency over window w ≥ 0.60 is treated as a “cooperator.”
- delta_drop = 0.25 — a large drop in group cooperation that indicates my defection caused punishment.
- T_forgive = 2 — number of rounds to conciliatorily cooperate after detecting a big drop (to try to restore cooperation).
- final_defect_window = min(2, r) — last 1–2 rounds (depending on r) in which I always defect.

High-level modes
1. Probe mode (rounds 1..T_probe): cooperate to discover who will respond to cooperation.
2. Classification (after probe and continuously updated): for each other player compute their cooperation rate over the last w rounds; label them “cooperator” if rate ≥ cooperator_threshold, else “non-cooperator.”
3. Exploit mode (default after probe if there is ≥1 cooperator): defect by default and free-ride, but occasionally cooperate (probabilistically) in circumstances that keep cooperators willing to contribute.
4. Pariah/All-defect mode (if no cooperators detected): always defect.
5. Punishment/Repair rule: if my defection appears to trigger a large drop in group cooperation, momentarily switch to conciliatory cooperating (T_forgive rounds) to recover cooperative players, then resume exploit mode.
6. Endgame: always defect in final_defect_window rounds.

Decision rules (per round, using only history and parameters)

On each round t:
1. If t is in final_defect_window (the last 1–2 rounds): choose D (defect). Rationale: no credible future punishment.
2. Else if t ≤ T_probe: choose C (cooperate). Purpose: probe and attract cooperators.
3. Else (t > T_probe):
   - Update each other player’s cooperation_rate = fraction of their contributions in the last w rounds.
   - Let num_cooperators = count of players with cooperation_rate ≥ cooperator_threshold.
   - Let last_round_others = number of other players who contributed in round t−1 (observed).
   - Let group_coop_prev = fraction (over all players excluding me) who contributed in round t−1.
   - Let group_coop_prev2 = fraction who contributed in round t−2 (if t−2 exists; else set equal to group_coop_prev).

   A. If num_cooperators == 0 (no detected cooperators): choose D (always defect). Rationale: nothing to exploit reliably; avoid giving away endowment.
   B. Else (there is at least one cooperator) — exploit mode:
      i. Default action = D.
      ii. Occasional cooperative gestures to sustain cooperators:
         - If group_coop_prev ≥ 0.75 (most others contributed last round), set cooperate_probability p = 0.50.
         - Else if group_coop_prev ≥ 0.50, set p = 0.30.
         - Else set p = 0.10.
         - Draw a random number u ∈ [0,1]. If u ≤ p, choose C; otherwise choose D.
         - Rationale: give enough occasional public goods to keep cooperators perceiving benefit from continuing to cooperate, but keep my contribution rate low.
      iii. Exception (punishment detection & short repair): if group_coop_prev2 − group_coop_prev ≥ delta_drop and my last action was D (i.e., cooperation sharply fell after I defected), then for the next T_forgive rounds override the above and choose C (conciliatory cooperation) to try to restore others’ cooperation. After T_forgive rounds, return to exploit mode.
      iv. If a specific other player who had been a cooperator reduces their cooperation_rate significantly for two consecutive windows (signaling targeted punishment), increase p temporarily to the higher bracket (by +0.2 absolute, capped at 0.9) for one round to try to regain their trust, then resume normal exploitation.

Notes and rationale for robustness
- Probe short but positive: cooperating for a few rounds attracts conditional cooperators but limits initial losses.
- Classification by recent window makes the strategy adaptive to changing behavior (it can detect new cooperators or defections).
- Probabilistic cooperation lets me keep overall contribution rate low (exploit), while providing predictable enough gestures to maintain cooperators’ incentives — I avoid deterministic patterns that can be exploited by punishers.
- The punishment-detection & repair rule prevents long mutual-defection spirals when my defection causes others to stop contributing: costly punishers will be handled by brief conciliation rather than interminable mutual losses.
- Final-round defection uses standard backward-induction logic: in the last round(s) there is no future to sustain cooperation, so defect to maximise payoff.
- Parameter choices (thresholds, probabilities, window sizes) are conservative defaults that depend only on n,k,r; they can be adjusted but keep the same exploitative structure.

Edge cases
- r = 1 (single round): defect (no opportunity for future reward).
- Very short games (r ≤ T_probe): probe still cooperates for the first round(s) but final_defect_window = r ensures last round(s) are defects — if forced to choose both probe and endgame, prioritize final_defect_window (i.e., defect in last round).
- If stochastic tie-breaking required: use a pseudorandom draw to implement the probabilistic cooperation p.
- If every player is detected as a punisher (many players sharply reduce cooperation after my defection) and repeated conciliation fails, the strategy will converge to all-defect mode to stop losing tokens.

Summary (one-sentence)
- Cooperate briefly to identify cooperators, then exploit them by mostly defecting while giving small, calculated, probabilistic cooperative gestures to sustain others’ contributions; detect and briefly repair when my defection causes widespread retaliation, and always defect in the final rounds.
'''

description_EXPLOITATIVE_99 = '''
Strategy name: Adaptive Exploitative Conditional Free‑rider (AECF)

Goal summary
- Maximize my long-run payoff by free‑riding reliably on persistent cooperators, while avoiding sustained punishment by conditional or exploitative opponents.  
- Detect who is reliably cooperating, exploit them aggressively but with small, strategic “maintenance” cooperation to keep them in the cooperative basin.  
- If retaliation is detected, switch to safe defection to stop losses and only try to rebuild cooperation when signals are favorable.  
- Always defect in the final rounds (no incentive to maintain cooperation near the end).

Parameters I set once from n, k and r (constants named here; choose sensible defaults if r small):
- T_probe = min(4, r) — initial probing rounds.
- W = min(20, r) — rolling window used to estimate recent behavior.
- p_high = 0.80 — cooperation rate threshold to call an opponent a reliable cooperator.
- p_mid = 0.40 — lower bound for “sometimes cooperative” behavior.
- exploit_maintain_freq = 10 — while exploiting reliable cooperators, cooperate once every exploit_maintain_freq rounds to reduce permanent collapse.
- retaliation_drop = 0.20 — a fall in group cooperation (relative to baseline) that signals retaliation.
- T_end = min(3, r) — last rounds in which I always defect.
- forgiveness_probe = 3 — number of cooperative rounds I will try to rebuild cooperation after a repair attempt.

Decision rules (natural language / pseudocode style)

Initialization
- If r <= 1: always play D (no dynamic opportunity).
- Set phase = Probe. Keep history of all players' contributions.

Probe phase (rounds 1..T_probe)
- Play C in the first T_probe rounds unless an extreme signal appears (see below).
- Purpose: reveal which opponents are willing to contribute unconditionally or conditionally.
- If a majority (>= ceil((n-1)/2)) defect unanimously in round 1, skip further probing and move to MutualDefect phase (no benefit trying to build cooperation).

After probe — compute statistics
- For each opponent j compute p_j = fraction of rounds they contributed in the last W rounds (or all rounds so far if < W).
- Compute group average P = mean_j p_j (over n−1 opponents).
- Define ReliableCooperators = { j : p_j >= p_high }.
- Record baseline_group_coop = fraction of players contributing in the most recent round (or average of last 2 rounds if noisy).

Main decision logic (each subsequent round t not in Probe or final T_end)
1. If t > r - T_end: play D (endgame defection).
2. If phase == MutualDefect: play D every round, but periodically (every 10 rounds) re-evaluate opponents’ p_j; if many opponents’ p_j rise above p_mid, move to Repair phase.
3. If phase == Probe (after T_probe): use classification below to pick phase:
   - If |ReliableCooperators| >= 1 and P >= p_high: enter Exploit phase (set exploit_baseline = P).
   - Else if P >= p_mid: enter ConditionalCooperate phase (aim to sustain cooperation conditionally).
   - Else enter MutualDefect phase.

Exploit phase (exploit reliably cooperative opponents)
- Default action: play D (free‑ride).
- Maintenance: once every exploit_maintain_freq rounds, play C to signal some willingness to cooperate and reduce the chance that punishers permanently collapse cooperation.
- Monitoring: after each round where I picked D, observe new group cooperation level curr_P.
  - If curr_P drops below exploit_baseline − retaliation_drop (i.e., group cooperation falls sharply after my defection), assume retaliation. Switch to Retaliate (MutualDefect) phase immediately.
  - If curr_P remains close to exploit_baseline (no large drop), stay in Exploit.
- If ReliableCooperators degrade (their p_j falls under p_high for many players), re-evaluate: if P falls below p_mid go to MutualDefect; if P in [p_mid, p_high) go to ConditionalCooperate.

ConditionalCooperate phase (sustain cooperation when many are conditional)
- Rule: play C this round if the number of contributions by others in the last round >= ceil((n-1) * 0.5) (i.e., a majority of others contributed); otherwise play D.
- This copies the “cooperate when most others did” logic to avoid being the primary exploiter and to encourage stable cooperation.
- If this conditional policy yields persistent cooperation from many players (P rises and several p_j cross p_high), escalate to Exploit phase.
- If cooperation collapses (P < p_mid), switch to MutualDefect.

MutualDefect / Retaliate phase
- Play D every round to stop being exploited.
- Continue monitoring opponents over windows of length W. If group cooperation recovers (P >= p_mid) and several players’ p_j increase, enter Repair phase.

Repair / Forgiveness phase
- Try to restore cooperation carefully:
  - For forgiveness_probe rounds, play C for the first forgiveness_probe rounds, but only if the recent trend of others' cooperation is positive.
  - If others reciprocate (group cooperation increases and many p_j rise), classify and move to ConditionalCooperate or Exploit as appropriate.
  - If others do not reciprocate or cooperation falls, revert to MutualDefect.

Edge cases and robustness
- Very short games (r small): if r <= T_probe or r <= T_end*2, bias toward defection because endgame short-circuits incentives. Specifically, if r <= 4, largely defect after 1 probe C unless the first rounds show unusually high unconditional cooperation.
- Random/noisy opponents: the maintenance cooperation (periodic C) prevents single opportunistic defections from permanently destroying a basin of cooperation. Rolling windows W smooth noise.
- Adaptive/punishing opponents: immediate and strong switch to MutualDefect on a confirmed retaliation signal prevents sustained punishment losses.
- Exploiters that try to mimic cooperators: classification uses multi‑round statistics p_j, so short bursts of cooperation by an opponent won’t mark them as reliable. Only a sustained high p_j >= p_high gets exploited.
- No coordination/signaling assumed beyond observed actions.

Why this is exploitative
- When many opponents are persistent cooperators (high p_j), I mostly defect and pocket the private token while still receiving the public good from others — maximizing my payoff versus theirs.
- I safeguard against being driven to very low payoff by responding quickly to observed retaliation or falling cooperation and switching to safe defection.
- I use small, infrequent cooperative gestures (maintenance) to keep cooperative opponents from permanently abandoning cooperation, increasing my long-run exploitation.
- I balance exploitation with conditional cooperation where full exploitation would be self‑defeating, making the strategy robust across selfish, conditional, noisy, or adaptive opponents.

Summary (one‑line operational rule)
- Probe a bit, classify opponents by recent cooperation rates, aggressively defect against those who are reliably cooperative (with rare maintenance cooperations), conditionally cooperate with moderate groups, and switch to permanent defection if I detect retaliation or a collapse of cooperation — always defect in the final rounds.
'''

description_EXPLOITATIVE_100 = '''
Adaptive Exploiter (natural-language / pseudocode description)

Principle
- Contribute only when doing so is likely to increase my long-run payoff by inducing others to contribute. Otherwise free-ride. Act to extract value from unconditional cooperators, avoid being locked into costly mutual cooperation with punishers, and refuse to give anything away in the final rounds.

Parameters (computed once from game parameters or fixed defaults)
- n, k, r are given.
- Window W = min(10, rounds elapsed so far) — recent-history window for statistics.
- Unconditional-cooperator threshold p_uc = 0.95 (use 1.0 when t is small or W is small).
- Reciprocity sensitivity Δ = 0.25 (used to detect punishers who retaliate when I defect).
- Majority threshold M = ceil(n/2).
- Exploit cooperation probability p_coop_small = 0.15 (rare cooperation to sustain others).
- Rehab cooperation length T_rehab = 2 rounds (short cooperative investments to restore cooperation).
- Endgame horizon H_end = min(3, r-1) (in last H_end rounds always defect).

Data I track (computed from history each round)
- For each other player j: cooperation rate p_j over the last W rounds.
- For each other player j: responsiveness r_j = P(j cooperates | I cooperated in previous round) − P(j cooperates | I defected in previous round), estimated over last W rounds (if data sparse, treat as 0).
- Group contribution last round S_prev = total contributions in previous round (0..n). Also track recent average group contributions S_avg over last W rounds.

Round-by-round decision procedure (for round t)
1. Endgame: if t > r − H_end (i.e., in last H_end rounds) then defect. In the final round always defect.

2. First-round probe: if t = 1 then defect (learn others’ baseline).

3. Build opponent classifications using last W rounds:
   - Unconditional cooperator (“sucker”): p_j ≥ p_uc and r_j ≥ −0.05 (keeps cooperating regardless of my defections).
   - Punisher/reciprocator: r_j ≤ −Δ (cooperates less after I defect; will punish my defection).
   - Conditional cooperator (lenient): p_j high (e.g., ≥ 0.6) but r_j moderately negative (between −Δ and −0.05).
   - Defector: p_j low (e.g., ≤ 0.2).

4. Exploit detected suckers:
   - If at least one other player is a sucker (unconditional cooperator), defect every round (including now). Rationale: unconditional cooperators pay into the public good irrespective of my action; never give them extra incentive.

5. Otherwise use the group-state rule:
   - If S_prev ≥ M (a recent majority contributed last round):
     - If the group contains many punishers (count punishers ≥ ceil((n-1)/3)):
       - Cooperate this round only if my cooperation last round helped restore cooperation (see rehab rule below) or if I have recently cooperated and punishers have responded; otherwise defect. The idea: avoid provoking coordinated punishment that would lower my long-run payoff.
     - Else (majority cooperated and few punishers):
       - Mostly free-ride: defect with probability 1 − p_coop_small; cooperate with probability p_coop_small. Rationale: when many others cooperate, occasional small cooperation keeps the cooperation-supporting dynamics alive while extracting value.
   - If S_prev < M (fewer than majority cooperated last round):
     - Defect normally (the environment is not reliably cooperative; do not invest).
     - Exception (rehabilitate): if my recent defection(s) appear to be the key cause of collapse — i.e., before I started defecting the group had high cooperation and after my defection cooperation dropped sharply (drop > 40%) and there exist many conditional/lenient cooperators — then perform a short rehabilitation: cooperate for T_rehab consecutive rounds to try to restore cooperation, then resume exploit rules. Only do rehab if enough rounds remain to recover (t ≤ r − H_end − 1).

6. Reactive micro-rules (to avoid being exploited by strong reciprocators):
   - If many players (≥ ceil((n-1)/2)) are punishers (r_j ≤ −Δ), shift toward cooperative stance: cooperate whenever S_prev ≥ M − 1 (slightly lower bar). This accepts some contribution cost to avoid long sequences of mutual defection that lower my payoff.
   - Conversely, if most others are defectors (average p_j ≤ 0.2), defect always.

7. Stability / noise handling:
   - Use W to smooth statistics; do not reclassify an opponent unless the change in p_j or r_j is substantial (≥ 0.2).
   - If history is very short (t small), be conservative: default to defect until enough data accumulates.

8. Summary priority list (when logic conflicts):
   - Highest priority: endgame → defect.
   - Next: exploit guaranteed suckers → always defect.
   - Next: avoid being punished into misery → cooperate if many punishers present and cooperation was sustaining payoffs.
   - Next: when group cooperation is common and punishers are few → mostly defect with occasional cooperative “maintenance” moves (probabilistic cooperation).
   - Otherwise → defect; use occasional short rehabilitation when my defections clearly caused collapse and there are enough future rounds to benefit.

Why this is exploitative and robust
- It extracts value from unconditional cooperators by always defecting against them.
- It avoids being locked into costly mutual cooperation with punishers by detecting and respecting reciprocation/punishment tendencies; it only invests when it appears instrumentally useful to restore or sustain others’ contributions.
- It rarely contributes—only when doing so is likely to preserve a stream of contributions from others or to avoid mutually damaging punishment—thus minimizing my contribution cost while maintaining access to others’ contributions.
- It is adaptive (classifies opponents, updates with W), robust to noise (smoothed stats and conservative thresholds), and avoids endgame traps (always defects near the horizon).

Edge cases and additional notes
- Very small games or very short tournaments (e.g., r ≤ 3): be extremely conservative — defect nearly always except an extremely clear rehab opportunity.
- If opponents’ behavior is erratic/noisy, the strategy defaults to defect until stable patterns emerge.
- Parameters (p_uc, Δ, p_coop_small, W, T_rehab) are tunable; defaults above balance exploitation and the need to sustain cooperation when it is instrumentally valuable.
'''

description_EXPLOITATIVE_101 = '''
Name: Adaptive Exploiter

Intuition (short)
- Start by signalling that you can cooperate (to gather information and attract conditional cooperators).
- Measure how much your cooperation actually influences others’ future cooperation.
- Cooperate only when your cooperation gives a reliably positive long-run payoff (it causes enough extra contributions by others).
- Otherwise free-ride (defect) to exploit cooperators. If you detect that defection provokes punishment, adapt by switching to temporary cooperation only when it is payoff-improving.
- Always defect in the final round.

Decision variables computed from history (use only game parameters n, r, k and observed past actions)
- For each opponent j (all players other than you) compute:
  - Pj(C | I_C): empirical probability j contributes in a round when you contributed in the immediately previous round.
  - Pj(C | I_D): empirical probability j contributes in a round when you defected in the immediately previous round.
  - Use simple Laplace smoothing for stability on small samples: P = (count_C + 1) / (count_total + 2).
  - Influence_j = Pj(C | I_C) − Pj(C | I_D).
- Aggregate influence Δ = average_j Influence_j across all opponents j.
- remaining_rounds = r − t (t is the index of the upcoming round, 1-based).
- Immediate private cost of cooperating in a single round = 1 − (k/n).
- Expected per-opponent future marginal benefit of raising that opponent’s cooperation probability by Δ_j is (k/n) * remaining_rounds * Δ_j. For all opponents the total future benefit ≈ (n − 1) * (k/n) * remaining_rounds * Δ.
- Cooperation is worthwhile if total expected future benefit > immediate private cost.

Threshold formula (used to decide)
- Cooperate if Δ > T, where
  T = (1 − k/n) / [ (n − 1) * (k/n) * remaining_rounds + tiny ]
  (tiny is a tiny number to avoid division by zero when remaining_rounds = 0; in practice if remaining_rounds = 0 you treat it as the final round and defect.)

Full round-by-round decision rules (pseudocode-style natural language)

At the start of each round t (1 ≤ t ≤ r)
1. If t == r (final round): Defect. (No future to influence; contributing is strictly dominated.)
2. If t == 1 (first round): Cooperate. Purpose: obtain an initial signal, attract conditional cooperators, and collect data for influence estimates.
3. Otherwise (t between 2 and r−1):
   a. Compute Pj(C | I_C) and Pj(C | I_D) for each opponent j from observed rounds 2..(t−1) (use Laplace smoothing). Compute Influence_j and average Δ.
   b. Compute remaining_rounds = r − t and threshold T as above.
   c. If Δ > T: Cooperate. Rationale: your cooperation has historically increased others’ cooperation enough that the expected future gains outweigh the immediate cost.
   d. Else (Δ ≤ T): Defect (free-ride) — exploit cooperators.
   e. Exception: if you are in a detected “punishment spiral” (see “punishment detection” below), modify behavior as below.

Punishment detection and short-term adaptation
- After you defect, if the next round(s) show a large drop in others’ cooperation compared to their pre-defection baseline (e.g., average other-cooperation falls by > 25 percentage points in the one or two rounds following your defection), treat that as credible retaliation.
- If retaliation is detected:
  - Enter a short punishment-avoidance mode: cooperate for one round if doing so would likely stop further punishment (i.e., if influence Δ computed from recent history suggests that a single cooperative signal typically restores cooperation), otherwise continue defecting until evidence shows their cooperation rate has stabilized.
  - After cooperating to test for forgiveness, recompute Δ and follow the normal rule. If retaliation persists, revert to defection permanently (further cooperation is not profitable).

Periodic reassurance (to sustain long exploitation safely)
- If you have been defecting repeatedly while others are still contributing high rates, your strategy should on occasion (very rarely) send a cooperative signal to avoid permanent breakdown of cooperation by others. Implement this simply:
  - If you have defected for B consecutive rounds (set B = max(3, floor(r/10)) ), cooperate on the next round if and only if Δ is borderline (within a small band around T) or if a tiny probe is needed to re-estimate influence. Otherwise continue to defect.
  - These probes are rare and only used when it is plausible they will restore or maintain profitable cooperation from others.

Robustness notes and parameters
- Laplace smoothing (add-one) stabilizes P estimates when few observations exist.
- The threshold T automatically scales with remaining rounds: early in the game it is easier to justify cooperating (many remaining rounds); near the end the threshold becomes large and cooperating is rarely worthwhile.
- The method adapts to a wide variety of opponents:
  - If opponents reciprocate or are conditional cooperators, Influence_j > 0 and you will cooperate enough to keep them contributing (you invest when it pays).
  - If opponents are unconditional cooperators, Influence_j ≈ 0 so Δ ≤ T and you will defect to free-ride.
  - If opponents punish defections reliably, Δ estimated from history will reflect that and you will switch to cooperation when needed to avoid ongoing losses.
- Endgame: always defect in the final round. The threshold logic already makes cooperation progressively less attractive as remaining_rounds → 0.

Summary of the exploitative mindset implemented
- Attract cooperation initially to learn.
- Exploit unconditional cooperators by defecting when your cooperation does not increase others’ contributions enough to justify the cost.
- Sustain exploitation only insofar as it remains net-profitable; if defection provokes effective punishment, switch to limited cooperation to stop the punishment.
- Rarely send cooperation probes to keep profitable cooperation from eroding completely.
- Always defect in the final round.

This strategy uses only game parameters (n, r, k) and the observed history of contributions. It balances exploitation of naive cooperators with adaptive defense against retaliatory opponents, maximizing the exploiter’s payoff while remaining robust to a wide range of opponent behaviors.
'''

description_EXPLOITATIVE_102 = '''
Summary (intent): I exploit unconditional cooperators and naive reciprocators while avoiding being a long‑term sucker. I probe opponents early to classify them, then either (A) repeatedly defect to harvest from unconditional cooperators, or (B) sustain a minimal, carefully timed pattern of contributions to keep conditional cooperators contributing while I contribute as little as possible. I always defect in the terminal rounds when there is no future to protect.

State I keep (computed from the public history each round t):
- t = current round (1..r). rounds_left = r - t + 1.
- For each opponent j: count_j = times j contributed in rounds 1..t-1; rate_j = count_j / max(1, t-1). (Use exponential smoothing if you prefer: rate_j ← 0.9*rate_j + 0.1*latest_action.)
- For each opponent j: cond_j = measure of conditionality: fraction of rounds in which j’s action equals my previous round’s action (or the correlation between j’s action and my previous action) computed over last m = min(6, t-1) rounds.
- group_rate = average(rate_j) over all opponents.
- recent_group_rate = average total contributions by others in last m rounds (normalized per player).
- my_history: my own contribution history.

Fixed internal parameters (use these defaults unless tuned):
- probe_rounds = min(4, max(1, floor(r/10))). (Short probing period.)
- lookback_m = min(6, t-1).
- coop_high = 0.85 (threshold to call an opponent an unconditional cooperator).
- def_low = 0.15 (threshold to call an opponent an unconditional defector).
- cond_threshold = 0.25 (threshold above which an opponent appears to respond to my previous action).
- punish_len = 2 (punishment length when detecting exploitation).
- forgive_prob = 0.2 (probabilistic forgiveness to re-test).
- safety_horizon = 3 (if rounds_left ≤ safety_horizon, play defection).
- tie_break = defect (if indifferent, defect).

Phase 1 — Probing (round t ≤ probe_rounds)
- Goal: learn who is unconditional cooperator, who reacts, who defects.
- Action: defect by default (exploit), but occasionally cooperate with small probability p = 0.2 to test whether others reciprocate. Implementation: play C with probability p, otherwise D.
- Rationale: this gets immediate payoff when a majority defect, but gives sampling data on opponents’ responsiveness.

Classification (after probing or anytime with enough history)
- For each opponent j:
  - If rate_j ≥ coop_high → label j = "unconditional cooperator".
  - Else if rate_j ≤ def_low → label j = "defector".
  - Else if cond_j ≥ cond_threshold → label j = "conditional reciprocator".
  - Else → label j = "mixed/random".

Decision rule (general, executed every round t)
1. Terminal rounds
   - If rounds_left ≤ safety_horizon: play D. (Exploit; no future to defend.)

2. If a strict majority (more than n/2) of opponents are labeled "unconditional cooperator":
   - Exploit mode: play D every round. Rationale: unconditional cooperators will keep contributing; do not give them a free signal to stop by contributing yourself. If group composition changes (their rate drops), reclassify and switch.

3. Else if a substantial fraction (e.g., ≥ 40%) are "conditional reciprocators" or "mixed" and group_rate is moderate-to-high:
   - Maintenance‑minimal mode: sustain cooperation among reciprocators but minimize own contributions.
   - Rule:
     - Let others_last = total contributions by others in last round.
     - If others_last ≥ T_high where T_high = ceil( (n-1) * 0.6 ) (i.e., many others contributed last round), then cooperate (C) this round with small probability p_C = 0.6 — enough to show I am participating but still defect often.
     - If others_last < T_high, defect (D).
   - Additionally, if I have just defected and many reciprocators reduced their contributions in the subsequent round, punish by defecting for punish_len rounds to signal cost of defection; then play forgiveness: after punish_len rounds, cooperate once with probability forgive_prob to retest.

   - Rationale: conditional reciprocators respond to my contribution; I provide occasional contributions timed to keep their incentive to contribute while taking more free rides than I give.

4. Else (mixed / mostly defectors):
   - Defensive mode: play D always. Rationale: no long-term benefit to investing when others are not sufficiently responsive.

5. Opportunistic randomization:
   - If I detect a small set (≥1) of opponents who behave as strong unconditional cooperators (rate_j ≥ coop_high) even when others are not, it may pay to defect every round and occasionally (with tiny prob 0.05) cooperate to avoid creating a deterministic pattern that could cause coordinated retaliation. In practice, whenever exploitation yields good immediate payoffs without causing a collapse of others’ rates, continue to exploit.

6. Reclassification and adaptation:
   - After each round update rates and cond_j and re-evaluate labels. If my defections cause formerly unconditional cooperators to drop below coop_high, switch from exploit mode to maintenance or defensive mode as appropriate.
   - If group cooperation falls sharply following a defection I introduced, reduce my defecting frequency (i.e., begin offering more frequent cooperative gestures) only if doing so is likely to restore a high level of group contributions for many remaining rounds (use rounds_left to weigh this decision). If rounds_left is large, be more willing to invest to restore cooperation; if small, revert to defection.

Edge cases and practical tie-breaking
- First round (t = 1): in most cases play D (exploit). If r is large and you want to seed cooperation with many conditional reciprocators, you may choose to cooperate with small fixed probability 0.2 in round 1; but default is D.
- If there is perfect unanimity of cooperation from others and no evidence they respond to my actions (i.e., many unconditional cooperators), always defect to exploit them.
- If opponents’ behaviors are noisy and unpredictable, default to D to avoid being exploited; use occasional cooperative probes (probability 0.1–0.2 once every few rounds) to detect changes.
- If tied or ambiguous decisions: choose D.

Why this is exploitative and robust
- It aggressively defects against unconditional cooperators to extract maximum short‑term gain (exploit), but it does not mindlessly defect: it tests and recognizes conditional reciprocators and will sustain just enough cooperation to keep them contributing, minimizing contributions I make while capturing the bulk of the public good created by others.
- It avoids long punishments that waste rounds when the horizon is short (terminal defection) and uses short punishments + probabilistic forgiveness to stabilize cooperation when that is profitable.
- It adapts automatically to population composition via straightforward statistics (rates and conditionality), so it performs well against pure cooperators (exploit), pure defectors (avoid wasting contributions), conditional reciprocators (maintain and skim), and noisy strategies (probe, then default defect).

Concise pseudocode (natural language)
- Each round:
  1. If rounds_left ≤ safety_horizon → play D.
  2. Update rate_j and cond_j for all j.
  3. If majority unconditional cooperators → play D.
  4. Else if many conditional reciprocators or mixed and recent_group_contribution high:
       - If others_last_round ≥ T_high → play C with probability p_C (≈0.6), else play D.
       - If recent collapse follows my defection → punish with D for punish_len rounds then forgive with probability forgive_prob.
  5. Else → play D.
  6. Occasionally (rare probe frequency) play C to re-test if opponents’ behavior may have changed.

Final note
- Tunable parameters (probe length, thresholds, p_C, punish_len, T_high) can be adjusted for different tournament environments; default values given above are designed to be robust across a wide range of n, k, and r. The core exploitative principle: defect whenever safe, detect and exploit unconditional cooperators fully, and only invest minimal, well‑timed cooperation when that investment reliably yields larger future returns from conditional reciprocators.
'''

description_EXPLOITATIVE_103 = '''
Opportunistic Classify-and-Exploit (OCE)

High-level idea
- Build a short cooperative reputation to identify who is reliably cooperative; then free-ride on stable cooperators whenever the data show a cooperative majority. Punish only when necessary and minimally so as to preserve long-term exploitation opportunities. Always defect in the final round(s).

Parameters (computed from game inputs)
- r = total rounds, n = players, k = multiplier.
- Window L for recent statistics: L = max(3, min(10, floor(r/10))). (If r < 10, L will be 3.)
- Endgame window K = ceil(sqrt(r)) (in final K rounds switch aggressively toward defection).

Per-player statistics (computed after each round)
- For each other player j compute f_j = fraction of j’s contributions among the last L rounds (if fewer than L rounds have passed, use all available rounds).
- Classify j:
  - Cooperator if f_j >= 0.8
  - Neutral/Reciprocator if 0.3 <= f_j < 0.8
  - Defector if f_j < 0.3
- Group counts: C = number of Cooperators among others, N = number of Neutrals, D = number of Defectors. Also compute group recent cooperation rate G = average contribution per other player over last L rounds.

Initial probing phase
- For the first min(3, r) rounds: cooperate. Purpose: establish a reputation of cooperation so that pure cooperators reveal themselves.

Main decision rule (for round t, not in endgame)
1. End-of-game rule:
   - If t == r (final round): defect.
   - If t > r - K (within endgame window): default to defect (do not invest in cooperation near the end).

2. Exploit condition (take the free-ride when safe):
   - If C >= ceil((n-1)/2) (a strict majority of other players are stable cooperators), then defect. Rationale: a cooperative majority yields reliable public-good contributions you can free-ride on with low immediate risk.
   - Else if G is high (G >= 0.6) and C+N >= ceil((n-1)/2): defect. (Many players contribute often enough that occasional free-riding is profitable.)

3. No-opportunity condition (no one to exploit):
   - If D >= ceil((n-1)/2) (majority of others are defectors) or G <= 0.2: defect (contributing is wasted when others largely defect).

4. Cooperation-for-information / maintenance condition (mixed group):
   - Otherwise (mixed group: no clear majority of stable cooperators or defectors), cooperate to:
     a) maintain good standing with reciprocators, and
     b) gather more data to discriminate cooperators from reciprocators/defectors.
   - But occasionally probe/exploit: with small probability p_probe = 0.15, defect even when cooperating under this clause to test whether people will continue cooperating (this creates opportunities to exploit unconditional cooperators and reveals retaliators).

Punishment and retaliation handling (targeted, minimal)
- If you defect and observe that a particular player j reduces their contribution rate in the subsequent L rounds by more than 0.25 relative to its pre-defection level, mark j as a retaliator.
- If retaliators are numerous enough to block exploitation (number of retaliators >= ceil((n-1)/2) or retaliators + Defectors >= ceil((n-1)/2)), switch to defect-only until group cooperation recovers.
- Do not punish broadly: punish (i.e., defect as long as they defect) only when retaliation is strong enough that cooperating loses net expected benefit. Otherwise prefer forgiveness.

Forgiveness and reset
- If group cooperation G stays high (>= 0.6) for L consecutive rounds, clear retaliator marks and resume exploitation rules. This allows re-capturing cooperators after short punishments.

Practical notes and motivation
- The strategy is exploitative: it seeks to free-ride a stable cooperative majority and only pays cooperation when doing so helps identify and preserve exploitable cooperators (or when too risky to defect).
- It uses a short initial cooperation to obtain information and build reputation, then exploits stable cooperators repeatedly.
- Punishment is targeted and minimal so as not to destroy the pool of cooperators; forgiveness allows re-exploitation later.
- Endgame defection and switching to defection in the near-end prevent wasting tokens when future retaliation or reciprocity cannot be credibly used to recover losses.

Summary pseudocode (concise)
- Initialize L, K. For t = 1..r:
  - Update f_j for all j and compute C,N,D,G.
  - If t == r or t > r - K: play D.
  - Else if t <= 3: play C.
  - Else if C >= ceil((n-1)/2): play D.
  - Else if G >= 0.6 and C+N >= ceil((n-1)/2): play D.
  - Else if D >= ceil((n-1)/2) or G <= 0.2: play D.
  - Else (mixed): play C, except with prob 0.15 play D.
  - After each round, detect retaliators (drops >0.25) and if retaliators block exploitation, switch to defect-only until G recovers for L rounds.

This strategy requires only the game parameters (n, r, k) and observed history (players’ past actions and payoffs). It is designed to (1) attract and identify cooperators, (2) exploit them when safe, (3) avoid long costly fights with retaliators, and (4) defect reliably in the endgame.
'''

description_EXPLOITATIVE_104 = '''
Opportunistic Exploiter — natural-language strategy (pseudocode-style)

Summary (intention)
- Goal: maximize my average payoff by extracting contributions from players who will keep contributing (cooperators/non‑retaliators), while avoiding long runs of being exploited by defectors or punished by retaliators. I induce cooperation to create exploitable opportunities, harvest when it is safe, and respond to retaliation so that exploitation remains profitable over the tournament. In the final rounds I defect (endgame).

Parameters (computed from game parameters)
- n, k, r are given.
- W (analysis window) = max(1, min(5, floor(r/5) + 1)). Use up to 5 most recent rounds (fewer if r small).
- E (endgame window) = min(3, floor(r/10) + 1). In the last E rounds always defect.
- theta_exploit = 0.80 (group cooperation rate threshold that makes one-shot free‑riding profitable).
- theta_coop = 0.50 (threshold to treat group as “worth cooperating with”).
- delta_resp = 0.15 (sensitivity threshold to detect retaliators).
- S_coop = 2 (minimum cooperative streak to build before attempting a harvest).
- Harvest_length H_len = 1 or 2 rounds (short defect burst to harvest).
- If r ≤ 2: always defect (one-shot/backwards-induction case).

How I evaluate history each round t (t = 1..r)
- If r ≤ 2: defect every round.
- If t > r − E: defect (endgame defection).
- Let others be the n−1 opponents.
- For each opponent i, compute their cooperation rate over the last W rounds: coop_i = (# times i contributed in last W rounds) / W.
- Compute group_coop = average_i coop_i (equivalently, fraction of contributions among opponents in last W rounds).
- Compute responsiveness for each opponent i over the last W rounds:
  - Let P_i|C = fraction of rounds in the window where i contributed in the round immediately following a round in which I contributed.
  - Let P_i|D = fraction of rounds in the window where i contributed in the round following a round in which I defected.
  - sensitivity_i = P_i|C − P_i|D.
- Let avg_sensitivity = average_i sensitivity_i. This measures whether opponents tend to reward my cooperation / punish my defection.

Decision rules (main loop)
1. First round (t = 1): cooperate if r > 2 (signal cooperative intent to attract conditional cooperators). If r ≤ 2: defect (see above).

2. Endgame: if t > r − E: defect.

3. Safety check for exploitation (one‑shot harvest):
   - If group_coop ≥ theta_exploit AND avg_sensitivity ≤ delta_resp:
     - Many opponents are reliably contributing and they are not very responsive to my moves → safe to harvest.
     - If I have just completed at least S_coop consecutive cooperating rounds (i.e., I built trust), defect for H_len rounds (harvest), then immediately cooperate again and rebuild. If H_len > 1, stop early if the next round’s observed group cooperation drops below theta_coop.
     - Rationale: take short, infrequent free-rides on predictable cooperators; keep harvests short so I don’t provoke organized punishment or cause the group to collapse.

4. Cooperative maintenance vs. abandonment:
   - If avg_sensitivity > delta_resp (many are retaliators/conditional cooperators):
     - Treat group as responsive: default to cooperate, because mutual cooperation yields higher long-run payoff than repeated punishment cycles.
     - Exception: if group_coop < theta_coop (most others are not contributing even though they’re responsive), switch to persistent defection (to avoid paying into a failing project).
   - If avg_sensitivity ≤ delta_resp (group not very responsive) but group_coop < theta_coop:
     - Most are not contributing and won’t respond to my cooperation → defect (no point subsidizing others).

5. Reaction to observed punishment after a harvest/defection:
   - If I defected in round t0 and in the next round group_coop drops by more than 0.20 relative to the pre‑defection window, label the group “punishing.”
     - Immediate response: stop harvesting and return to cooperating for L = max(1, S_coop) rounds to try rebuilding cooperation only if group_coop recovers toward theta_coop.
     - If punishment persists (group_coop remains low or avg_sensitivity remains high with low group_coop), switch to defecting until either cooperation recovers (group_coop ≥ theta_coop) or the endgame window is reached.
   - Rationale: punishers who lower overall group payoff are costly to deal with; avoid repeated retaliatory cycles by stopping harvests and either cooperating to reestablish mutual benefit or defecting permanently if cooperation cannot be reestablished.

6. Miscellaneous safeguards:
   - If uncertainty (small W or noisy signals): be cautious. Default to cooperating for short streaks to test responsiveness, then exploit if safe.
   - Never attempt long harvests (H_len small) — keep defections short and infrequent to retain access to cooperative returns.
   - If you detect a single unconditional cooperator (coop_i ≈ 1) among otherwise defectors, you may defect more often (free‑ride that cooperator) but only if doing so does not cause a coordinated drop in others’ cooperation.

Edge cases (explicit)
- r = 1 or r = 2: always defect (one-shot logic).
- Very small r (e.g., r ≤ 5): shorten W and E using the definitions above; be conservative about attempting harvests very early.
- If everyone else is always cooperating (group_coop ≈ 1 and avg_sensitivity ≈ 0): perform regular 1‑round harvests after short cooperative build ups (cooperate S_coop rounds, then 1 defect), repeating while monitoring for punishment.
- If everyone else always defects: defect every round.
- If opponents mix unpredictably: use moving-window statistics; if signals remain ambiguous, bias toward defect (avoid being systematically exploited).

Why this is exploitative and robust
- Exploitative: I deliberately create exploitable situations (signal cooperation to induce contributions) and take short, opportunistic defections when the observed cooperation of others makes a free‑ride profitable and unlikely to trigger sustained punishment.
- Robust: I continuously monitor both cooperation rates and responsiveness (sensitivity). If opponents retaliate, I stop exploiting and either cooperate to reestablish mutual gains or defect to avoid subsidizing non‑contributors. Short harvests limit the risk of provoking coordinated punishment; endgame defection prevents being exploited by backward induction.
- Adaptive: the strategy does not assume shared norms — it infers opponent types from observed behavior and chooses the exploitation intensity accordingly.

Operational summary (short decision checklist each round)
1. If r ≤ 2 or t > r − E → defect.
2. Compute group_coop and avg_sensitivity over last W rounds.
3. If group_coop ≥ theta_exploit and avg_sensitivity ≤ delta_resp and I have cooperated for S_coop rounds → defect for H_len (harvest), then resume cooperating.
4. Else if avg_sensitivity > delta_resp → cooperate (unless group_coop < theta_coop → defect).
5. Else if group_coop < theta_coop → defect.
6. Monitor reactions: if harvest provokes sustained cooperation drop, stop harvesting and move to recovery or permanent defection as above.

This strategy is fully implementable from the public history and game parameters only. It aims to extract surplus from predictable cooperators while avoiding becoming a permanent target of retaliatory or free‑riding opponents.
'''

description_EXPLOITATIVE_105 = '''
Adaptive Exploiter — natural-language strategy (pseudocode-style)

Summary (exploitative objective)
- Maximize my own cumulative payoff by: (a) exploiting unconditional cooperators and large cooperative majorities, (b) avoiding long costly punishments from sensitive conditional cooperators, and (c) defecting in the endgame. I adaptively chooses between three modes (Exploit, Cautious/Conditional, or Give-up/All‑D) based only on the game parameters (n, r, k) and publicly observed history of contributions.

Precomputed quantities (from game parameters)
- delta = 1 - k/n   // immediate personal gain from defecting instead of cooperating in a single round
- W = max(3, min(10, floor(r/10)))  // window size for recent statistics (at least 3, at most 10)
- E = min(5, max(1, floor(r/8)))   // endgame horizon: always defect during last E rounds
- majority = ceil(n/2)

Per-round bookkeeping (computed each round t ≥ 1)
- For each other player j, compute recent cooperation rate f_j = fraction of j’s contributions in the last W rounds (or fewer if fewer rounds exist).
- F = average_j f_j  (average recent cooperation of others)
- Compute retaliation score R as: for each round s in the last W where I defected, measure change in the average others’ cooperation from round s to round s+1; R = mean( max(0, previous - next) ) over those events, smoothed toward 0 if fewer than 3 samples. Intuition: R measures how strongly others reduce cooperation after my defections.

Decision rules (ordered, apply the first that matches)

1) Endgame rule
- If t > r - E (i.e., we are in the last E rounds), play D (defect) every round. (Exploit immediate gain; avoid giving opponents incentive near known end.)

2) Tiny-game shortcut
- If r ≤ 3, play D every round (finite-horizon: no credible future, so defect to maximize immediate payoff).

3) First-round probe
- If t = 1 and r > 3, play C (cooperate) to gather information and to test whether cooperators or conditional cooperators are present.

4) Give-up / All‑D (when cooperation is very rare)
- If F < 0.20 and R < 0.05 (others rarely cooperate and are not sensitive), play D. There is little value in investing when the group is mostly defecting.

5) Cautious/Conditional mode (when defections provoke retaliation)
- If R > 0.12 (my defections tend to cause measurable drops in others’ cooperation):
  - Be conservative to preserve a cooperative environment I can later exploit.
  - Play C if at least majority of players contributed in the previous round;
  - Otherwise play D.
  - Additionally, if I have just observed a strong retaliation (a large drop in group cooperation immediately after one of my defections), switch to cooperating for the next 2 rounds to re-establish cooperative norms (forgiveness / repair) and then reassess statistics.

6) Exploit mode (target free-riding of cooperators, when others are fairly cooperative or insensitive)
- Otherwise (F moderately large or R small), aim to free-ride frequently but keep enough cooperation to sustain conditional cooperators:
  - If at least ceil(0.6*(n-1)) other players cooperated in the previous round (a large cooperative majority), play D to maximize immediate gain by free-riding on the majority.
  - Else play C with probability p = clamp( 0.10 + 0.60 * F * (1 - delta), 0.05, 0.60 ).
    - Intuition: the more others are cooperating (higher F) and the smaller my immediate gain from defecting (smaller delta, i.e., larger k), the more I invest occasionally to keep them cooperating. If defecting is very profitable (large delta), p is smaller.
  - Randomization prevents deterministic triggers that invite coordinated punishment and keeps conditional cooperators uncertain so they remain cooperative.

7) Targeted exploitation of persistent unconditional cooperators (fine-grained)
- If any individual player j has f_j ≥ 0.95 and shows negligible responsiveness (their cooperation does not drop when I defect), then occasionally (no more than once every ceil(W/2) rounds) defect in a round where most others are cooperating to maximize personal gain from that round. After such a targeted exploitation, resume Exploit mode and ensure my overall cooperation frequency does not fall so low that conditional cooperators switch off entirely.

Additional operational details and safeguards
- Smooth statistics: all rates and R are exponentially or sample-averaged with more weight on recent rounds so the strategy adapts quickly to changes.
- Minimum cooperation floor: ensure my own cooperation rate in non-endgame rounds never falls below min_coop = clamp(0.03 + 0.05*(1 - delta), 0.03, 0.15) to avoid being labeled an irredeemable punisher by many conditional cooperators. This floor is enforced by occasionally cooperating even when in Exploit mode.
- Forgiveness & reset: if group cooperation recovers (F rises substantially for several consecutive windows) revert to more aggressive exploitation; if cooperation collapses after my defections, switch to Cautious/Conditional until stability returns.
- Determinism vs randomness: use a pseudorandom generator for probabilistic moves (seeded per match if available). Randomization prevents exploitation by highly coordinated retaliation strategies.

Why this is exploitative and robust
- Exploitative: defects whenever the immediate payoff favors it in the short run (free-riding on large cooperative majorities and on unconditional cooperators), and defects in the endgame for guaranteed short-term gain.
- Robust: measures opponents’ responsiveness (R) to avoid provoking costly long-run punishment; repairs cooperation when necessary to sustain a cooperative baseline; falls back to all‑D against persistent defectors.
- Adaptive: parameters use k and n (via delta) and empirical statistics (F, R, individual f_j) so the strategy scales its aggressiveness to how profitable defection is and to opponents’ sensitivity.

Edge cases summary
- Single-round (r=1) or tiny games (r ≤ 3): defect every round.
- First round of longer games: cooperate to probe.
- Last E rounds: defect every round (known finite horizon).
- If everyone defects persistently: switch to permanent defection.
- If many players retaliate when I defect: cooperate conditionally to preserve longer-term exploit opportunities.

This strategy only uses n, r, k and the public history of actions and payoffs, adapts dynamically, exploits cooperative opponents and majorities, but avoids self-destructive provocations by conditional cooperators.
'''

description_EXPLOITATIVE_106 = '''
Adaptive Selective Exploiter (natural-language pseudocode)

Purpose: maximize my cumulative payoff by (1) sustaining profitable cooperation with genuinely cooperative opponents, (2) selectively free-riding on cooperators to extract extra payoff, and (3) refusing to be a persistent sucker against defectors. The rules use only n, r, k and the observed history of every player’s contributions.

State maintained
- For each opponent j: trust_j, an estimate of j’s probability to contribute next round (range 0..1).
- A global round counter t (1..r).

Initialization
- For all j: trust_j := 0.5 (neutral prior).
- Set alpha := min(0.5, 3 / max(1,r)). (Recency weight: small in long games, larger in very short games.)
- Set COOP_LABEL := 0.6 (threshold to call a player a “cooperator”).
- Set END_HORIZON := min(3, max(1, floor(r/10))). (Number of final rounds in which I stop investing.)
- Set MAX_EXPLOIT := 0.25 (maximum probability with which I opportunistically defect against a cooperative group).
- Set MIN_EXPLOIT := 0.05 (minimum background exploitation to probe).

Round-by-round procedure (before choosing this round’s action)
1. Update trusts from the last round (if t>1):
   - For each opponent j, observe last round contribution c_j (1 if they contributed, 0 if not).
   - trust_j := (1 - alpha) * trust_j + alpha * c_j.

2. Edge-case rounds:
   - If t == r (the final round): choose Defect (D). (Standard backward-induction endgame: no benefit to cooperating.)
   - Else if t >= r - END_HORIZON + 1: choose Defect (D). (Ramp down cooperation in the last short horizon to avoid late exploitation.)

3. Compute predictive statistics for this round:
   - For each opponent j, predicted cooperation probability p_j := trust_j.
   - Predicted number of contributors among others: S := sum_{j != me} p_j.
   - Mean others’ cooperation: m := S / (n - 1).
   - Count likely cooperators: Ccount := number of j with p_j >= COOP_LABEL.

4. Label opponents:
   - “Reliable cooperator” if p_j >= COOP_LABEL.
   - “Unreliable/defector” if p_j < COOP_LABEL.

5. Core decision rule (exploit vs sustain):
   - If Ccount >= ceil((n-1)/2) (i.e., a majority of others appear reliable):
       - This is a primarily cooperative context; I will generally cooperate to sustain high collective returns, but I will opportunistically exploit occasionally.
       - Compute exploitation probability eps := MIN_EXPLOIT + (MAX_EXPLOIT - MIN_EXPLOIT) * min(1, (m - 0.5) / 0.5).
         (When group mean cooperation m is high (close to 1), eps approaches MAX_EXPLOIT; when m is near 0.5 eps is low but nonzero.)
       - Choose Defect with probability eps (opportunistic free-ride), Cooperate otherwise.
         - If I choose Cooperate, I contribute (C).
         - If I choose Defect, I withhold (D) and record that as an intentional exploitation (no special long-term penalty—I rely on limited eps to keep cooperators around).
   - Else (no majority of reliable cooperators):
       - The environment is risky; default to Defect to avoid being exploited.
       - Exception (probing): with small probability MIN_EXPLOIT I will cooperate to probe whether some opponents will reciprocate (keeps detection alive).
       - Otherwise choose Defect.

6. Targeted short punishment and forgiveness:
   - If in the previous round a subset of opponents defected while the majority cooperated (i.e., an obvious sucker event where many others contributed and a few withheld), then in the next round I will definitely defect to punish the defectors and reduce their short-term benefit. I do not assign permanent permanent grudges:
       - For any opponent j who defected in that sucker event, reduce trust_j immediately by setting trust_j := max(0, trust_j - 0.25).
       - After punishment I resume normal updates and allow quick recovery by the exponential smoothing rule so that a return to cooperation is rewarded quickly.

7. Quick recovery / forgiveness mechanics:
   - If a previously punished opponent contributes in two successive subsequent rounds, restore trust_j toward the running EMA (no extra penalty).

Design rationale and properties
- Exploitative: When many opponents reliably cooperate I deliberately defect with a controlled probability to extract extra payoff (free-riding). The exploitation rate is capped (MAX_EXPLOIT) so cooperators do not collapse immediately; this keeps a steady supply of cooperative benefit to exploit.
- Protective: When most opponents are not reliable, I defect to avoid becoming a perennial sucker.
- Adaptive: Trusts use an exponential moving average (alpha set from r) so I adapt to both short games (higher alpha) and long games (lower alpha), reacting to changes in behavior while using more history when helpful.
- Selective punishment: I punish obvious one-round defections that produce a sucker event; punishment is short and targeted to reduce the defector’s return immediately but I allow quick forgiveness to reestablish cooperation if they change.
- Endgame-aware: I stop investing in the final short horizon to avoid the classic finite-horizon exploitation.
- No coordination assumed: all behavior is inferred from observed actions; no external signals required.
- Robustness: randomness (probabilistic exploitation and probing) prevents being locked into predictable cycles and allows me to discover exploitable cooperators while reducing vulnerability to deterministic exploiters that could punish or trick me.

First-round and tiny-r adjustments
- In round t=1 I play Cooperate (C) to probe initial tendencies.
- If r is extremely small (r <= 3) alpha is larger (from the initialization formula), END_HORIZON will likely cover most rounds and I will defect more aggressively near the end; this reduces risk in tiny tournaments.

Summary (one-sentence)
Cooperate early and with a clear majority of reliable cooperators to build a cooperative pool, but opportunistically defect (at a controlled rate) to harvest from cooperators, defect otherwise to avoid being exploited, punish short-term defectors selectively, and always stop contributing in the final short horizon.
'''

description_EXPLOITATIVE_107 = '''
Adaptive Exploitative Conditional Cooperator (AECC)

Goal: maximize my payoff relative to opponents by (1) encouraging and then freeloading on others’ cooperation when profitable, (2) avoiding long mutual-punishment traps, and (3) probing to find exploitable cooperators while being robust to punishers and unconditional defectors. The rule set uses only n, k, r and the observed history of everyone’s contributions.

Parameters computed at start (all depend only on n,k,r):
- W = min(10, r) — history window for statistics.
- K = max(3, ceil(n / max(1, k))) — “exploit interval”: how often I take an opportunistic defect when group cooperation is strong. (Higher k → smaller K → exploit more often.)
- p_scale = k / max(1, n-1) (how attractive cooperation is socially).
- p_high = min(0.9, 0.5 + 0.4 * p_scale) — threshold indicating strong group cooperation.
- p_low = max(0.05, 0.15 * p_scale) — threshold indicating near-collapse.
- forgive_len = min(6, max(2, ceil(5 * (1 - p_scale)))) — how many rounds I tolerate reduced cooperation before trying to re-establish cooperation.
- probe_prob = min(0.25, 0.1 + 0.5 * p_scale) — probability to probe (cooperate) when group cooperation is low.

State I keep from history:
- For each player j (other than me): f_j = fraction of rounds they contributed in the last W rounds (if fewer than W rounds exist, use whatever history exists).
- p = average of f_j across all other players (group cooperation rate over last W rounds).
- last_coop_rounds_by_me = how many of last W rounds I cooperated.
- rounds_since_majority_coop = number of consecutive past rounds (observed) where fewer than ceil(p_high*(n-1)) others cooperated.

Decision rules (per round t):

1) Final-round rule
- If t == r (final round): defect (D). Rational endgame exploit.

2) Endgame window
- If t > r - 3 (last 2 rounds before final): default to defect. In short finite horizons cooperation is fragile; prefer to extract tokens.

3) Compute statistics
- Update f_j and p from the last W rounds.
- Let strong_cooperators = number of other players with f_j >= 0.85.
- Let likely_group_contribs = round(p * (n-1)) (expected other contributions).

4) If p >= p_high (group reliably cooperative)
- Default: cooperate (C) to keep the cooperative environment.
- Exception (scheduled exploitation): if this round is an exploit round — i.e., since the last round I exploited I have cooperated for at least K-1 rounds and this is the Kth candidate round — choose defect (D) instead of C to free-ride. After exploiting once, immediately revert to cooperating on following rounds (no long stretches of defection).
- Rationale: keep cooperation flowing so I can repeatedly extract single-round gains; infrequent, predictable exploitation reduces likelihood of permanent retaliation by many strategies.

5) If p_low <= p < p_high (ambiguous / mixed group)
- Be conditional:
  - If strong_cooperators >= 1 and likely_group_contribs >= ceil(k / 2): cooperate (C) to try to sustain pockets of cooperation I can later exploit.
  - Otherwise, defect (D).
- Additionally, if I cooperated in the previous round and a majority of others defected immediately afterward (clear punishment signal), switch to defect until group cooperation recovers (see below).

6) If p < p_low (group mostly defecting)
- Default: defect (D) to avoid being exploited.
- With small probability probe_prob: cooperate (C) occasionally (a probe) to detect returning cooperators; if probes are reciprocated with a rise in p over forgive_len rounds, enter the cooperative regime.
- Rationale: do not give free contributions to a collapse; keep probing to find exploitable cooperators.

7) Punishment and forgiveness
- Short punishment: if I defect and in the next round many players (>= ceil((n-1)/2)) retaliate by defecting when they previously cooperated, treat that as credible punishment and stop scheduled exploitation for a while: switch to full cooperation for the next M_coop rounds (M_coop = max(1, ceil(K/2))) to reestablish trust, unless the group shows persistent defection.
- Long punishment detection: if after I defect the group cooperation rate falls and fails to recover for forgive_len rounds, revert to defecting (to stop feeding punishers).
- Forgiveness policy: after observing improved p for forgive_len consecutive rounds, return to the “group reliably cooperative” regime and resume the exploit/sustain cycle.

8) Individual targeting (optional exploitation refinement)
- If a small subset of players are very reciprocating (strong_cooperators >= 1), prefer to cooperate only when enough of those strong_cooperators are predicted to contribute (count them in likely_group_contribs). When exploiting (D) in a predominantly cooperative group, I expect to hurt reciprocators a little but rely on full-group goodwill to continue cooperating afterwards.

Edge cases and clarifications
- First round: cooperate (C) as a cheap probe/generous signal (unless r == 1, then defect).
- If r is very small (r <= 4): be conservative — cooperate only in the first round to probe, then defect for remaining rounds (except if early rounds show unanimous cooperation; still exploit once before endgame).
- If k is very small (p_scale small): cooperation is hard to sustain; strategy tends toward defect with occasional probes.
- If I detect a stable strict punisher population (they always defect after I defect and never recover), I stop probing and defect permanently to avoid being driven down in payoff.
- No coordination assumed: all decisions use only observed histories, not assumptions about shared norms.

Why this is exploitative and robust
- Exploitative: when group cooperation is strong I mostly cooperate to maintain that environment and take infrequent, targeted defections that yield immediate extra tokens (free-riding). This repeatedly extracts value from cooperators while avoiding prolonged mutual defection.
- Robustness: strategy detects collapse and retaliators, adapts by switching to defection or forgiveness as appropriate, and uses probing rather than naive unconditional cooperation so it performs tolerably against unconditional defectors, random players, stubborn punishers, and beginners.
- Endgame safety: explicit final-round defection and last-round window rules avoid being exploited by naive cooperators in the last rounds.

Implementation summary (pseudocode-like)
- Precompute W, K, p_high, p_low, forgive_len, probe_prob.
- For each round t:
  - If t == r: play D.
  - Else if t > r - 3: play D.
  - Else update f_j and p from last W rounds, compute strong_cooperators, likely_group_contribs.
  - If p >= p_high: play C except defect on scheduled exploit rounds (every K rounds after I’ve cooperated K-1 rounds).
  - Else if p_low <= p < p_high: play C if strong_cooperators >= 1 and likely_group_contribs >= ceil(k/2), else D.
  - Else (p < p_low): play D except probe with probability probe_prob.
  - After each round update punishment/forgiveness counters and adjust whether to suspend scheduled exploitation.

This strategy trades short, controlled defections for the long-run maintenance of cooperative environments to repeatedly extract value, while using probes and forgiveness to remain robust against a wide variety of opponent behaviors.
'''

description_EXPLOITATIVE_108 = '''
Name: Adaptive Exploiter (AE)

Goal (exploitative mindset): maximize my cumulative payoff by free‑riding on other players’ contributions whenever it is safe, but preserve enough cooperation from conditional cooperators when doing so yields higher long‑run payoff than pure defection. Be forgiving to restore cooperation after mistakes, and always defect when there is no future to influence (endgame).

Parameters I set before play:
- T = initial probing rounds = min(6, max(3, floor(r/5))). (Small but sufficient to observe reactions.)
- delta_drop = 0.25 (a drop of 25% in a player’s cooperation after my defection flags them as a conditional cooperator/punisher).
- forgiveness_rounds = 2 (how long I try to re‑establish cooperation after being punished).
- safety_epsilon = 0.01 (small margin to break ties toward defection).
- endgame_horizon = 2 (in the last 2 rounds I always defect).
These are fixed and depend only on r and the above constants.

Notation I use from history:
- For each opponent j I track:
  - Count(C_when_I_C): how often j contributed on a round after I contributed in the previous round.
  - Count(C_when_I_D): how often j contributed on a round after I defected in the previous round.
  - From these I compute empirical probabilities p_j_C = (C_when_I_C + 1) / (N_when_I_C + 2) and p_j_D = (C_when_I_D + 1) / (N_when_I_D + 2) (Laplace smoothing to handle sparse data).
- predicted_others(a) = sum_j p_j_a for my candidate action a in {0,1} (0=defect, 1=cooperate). This is the expected number of contributions by others next round if I choose action a now (using the conditional probabilities above).

Algorithm (round t, 1..r):

1. Endgame check:
   - If t > r - endgame_horizon (i.e. in last 2 rounds): choose D (defect). Rationale: no future to influence, always exploit immediate gain.

2. Probing phase (t <= T):
   - Round 1: cooperate (C). This is a low‑cost signal to elicit cooperation from conditional cooperators.
   - Rounds 2..T: follow a simple probing schedule: defect at least once and cooperate at least once (for example: D, D, C, D ... until T) so I observe how each opponent’s cooperation changes after my C vs my D. The concrete pattern is: Round 1 = C; rounds 2..T: choose D except make one additional C near the end of probe window. (The precise pattern is deterministic and known to me; the point is to generate both “my previous=C” and “my previous=D” contexts for others so I can estimate p_j_C and p_j_D.)
   - During probing, collect/update p_j_C and p_j_D estimates.

3. Classification after probing (and continuously update each round after T):
   - For each opponent j:
     - If p_j_D >= p_j_C - 0.05 (they do not reduce cooperation after my defection): label j exploitable/unconditional/lenient.
     - If p_j_C - p_j_D >= delta_drop: label j conditional cooperator / punisher (their cooperation drops after I defect).
     - If both probabilities are very low (< 0.1): label j defector.
   - Count exploitable_count = number of exploitable opponents; punisher_count = number of conditional punishers.

4. One‑step expected payoffs (used every round after probing):
   - Using predicted_others(0) and predicted_others(1), compute immediate expected payoff if I choose a in {0,1}:
     payoff_a = (1 - a) + (k/n) * (predicted_others(a) + a)
     (predicted_others(a) is the expected number of other players contributing if I play a; add a for my contribution if a=1).
   - Estimate expected future impact of playing D now vs C now:
     - Approximate the expected drop in other players’ contributions in subsequent rounds as Delta_next = predicted_others(1) - predicted_others(0).
     - Approximate value of that future loss ≈ (remaining_rounds = r - t) * (k/n) * max(0, Delta_next). (We assume that the difference in next‑round behavior is an indicator of ongoing loss; this is conservative because if many are conditional cooperators loss compounds.)
   - Decision criterion:
     - If payoff_0 >= payoff_1 + future_loss + safety_epsilon, choose D (defect). This means the immediate gain from defecting plus expected future value still beats cooperating.
     - Otherwise choose C (cooperate) because cooperating preserves more future contributions and yields higher long‑run payoff.

5. Exploit aggressively when safe:
   - If predicted_others(0) is large (many others will still contribute when I defect) or exploitable_count is high, the decision rule in (4) will usually choose D — I will free‑ride.
   - If most players are exploitables/unconditional contributors (p_j_D approx p_j_C approx 1), I defect almost every round except the initial probe and brief cooperative gestures if necessary to keep any weak conditional cooperators content.

6. Recovering from punishment (forgiveness):
   - If I detect a punishment event (I defected and in the next round most others’ contributions drop sharply or many players switch to always D), enter forgiveness mode: cooperate for forgiveness_rounds consecutive rounds to re‑establish cooperation probabilities p_j_C. This avoids being permanently excluded by grim strategies and allows me to return to exploiting lenient players.
   - If forgiveness attempts fail (punishers remain steadfast grim players and cooperating yields little recovery), revert to defecting permanently (they are irrecoverable; maximize immediate payoff).

7. Handling noise and sparse data:
   - Use smoothed probabilities (Laplace smoothing above) so single mistakes don’t flip classifications.
   - Do not overreact to one deviation: only reclassify a player as punisher if their conditional drop exceeds delta_drop on average over several relevant transitions.

8. Tie‑breaking and conservative defaults:
   - When the decision criterion is very close (within safety_epsilon), choose D (exploit).
   - If I have no information (e.g., extremely short game r <= T), default: Round 1 cooperate; then defect in all remaining rounds except cooperate sometimes if a clear exploitable pattern appears — but always defect in the last two rounds.

Why this is exploitative and robust:
- Exploitative: I defect whenever immediate and expected future returns from defection exceed the value of cooperating. That makes me a free‑rider whenever it is safe (many others still contribute). I only sacrifice free‑riding to sustain contributions when those contributions are sufficiently valuable in future rounds.
- Adaptive: I estimate each opponent’s conditional cooperation probabilities and change behavior as I learn. I detect and exploit unconditional cooperators, avoid being punished by conditional cooperators, and attempt measured forgiveness to restore profitable cooperation.
- Robust: Laplace smoothing and averaging over multiple observations reduce sensitivity to noise. Probing ensures I gather the needed observations; the endgame rule prevents being exploited by backward induction.

Edge cases summary:
- First round: cooperate (signal the potential to sustain cooperation).
- Probing rounds: mix C and D according to the probing schedule to learn conditional behavior.
- Very short games: when probing cannot collect data, defect after the first cooperative signal and always defect in the final rounds.
- Last 2 rounds: always defect.
- If mass punishment makes cooperation impossible, switch permanently to defection (maximize immediate returns).
- If many players are lenient/unconditional, defect often and free‑ride.

Concrete simple pseudocode summary (natural language):
- Round 1: play C.
- For rounds 2..T: follow probing pattern (mostly D but include at least one more C).
- After T, compute p_j_C and p_j_D for each opponent.
- Each round t <= r - 2:
  - Compute predicted_others(0), predicted_others(1); compute payoff_0, payoff_1.
  - Compute future_loss ≈ (r - t) * (k/n) * max(0, predicted_others(1) - predicted_others(0)).
  - If payoff_0 >= payoff_1 + future_loss + safety_epsilon, play D; else play C.
  - If many players sharply punish me, switch to forgiveness: play C for forgiveness_rounds, then resume the rule.
- Rounds r-1 and r: play D.

This strategy maximizes exploitative opportunities while preserving cooperation when it is profitably sustainable.
'''

description_EXPLOITATIVE_109 = '''
Adaptive Exploiter — strategy description (natural language / pseudocode style)

Overview principle
- Only give up your private token when doing so is likely to induce enough extra future contributions from others that the long-run payoff to you (from the extra public good) outweighs the immediate cost of 1 token. Otherwise free-ride.
- Detect which opponents are responsive to your cooperation and which are persistent defectors; steer cooperation toward responsive opponents and withdraw from unresponsive ones. Use brief, regular probes so you can re-assess; be lenient enough to recover from noise but harsh enough to avoid being a steady donor.
- Endgame: assume backward induction for the final round(s) and defect.

State you maintain (computed from publicly observed history)
- For each other player j:
  - count_C_after_myC[j] = number of times j contributed in the round after you contributed in the previous round
  - count_observations_myC = number of rounds in which you contributed (global for conditioning)
  - count_C_after_myD[j] = number of times j contributed in the round after you defected
  - count_observations_myD = number of rounds in which you defected
  - baseline_C_rate[j] = fraction of past rounds in which j contributed
- Global history totals: rounds_elapsed t, rounds_remaining R = r - t
- Use simple Laplace smoothing when estimating probabilities (add 1 to counts and add 2 to denominators) to avoid divide-by-zero.

Fixed internal parameters (derived from game parameters n, k, r)
- H (planning horizon) = min(10, max(1, floor(r / 5))). (Short practical horizon of future rounds to attribute influence to a current cooperation.)
- probe_rounds m = min(4, max(1, floor(r / 20))). (Small initial probing phase.)
- forgiveness_probability p_forgive = 0.05 (small chance to re-test a previously unresponsive player)
- responsiveness_threshold delta = 0.06 (detect meaningful positive influence)
- unresponsive_baseline tau = 0.15 (below this baseline rate classify as persistent defector)
- final_defect_window F = min(2, r) (always defect in the last F rounds)

Decision rule each round t (1..r)
1. If t > r - F (in final_defect_window): do D (defect). Reason: standard endgame exploitation.

2. If t <= m (initial probing):
   - Use a short deterministic probe sequence designed to produce variation you can learn from, while gaining some early exploitation:
     - Example: pattern C, D, C, D (stop when t > m). If m = 1, start with D.
   - (These early cooperations are small investments to learn responsiveness; they are limited in number.)

3. Otherwise (normal adaptive play):
   A. Estimate conditional response probabilities for each j:
      - Pj_C_given_myC = (count_C_after_myC[j] + 1) / (count_observations_myC + 2)
      - Pj_C_given_myD = (count_C_after_myD[j] + 1) / (count_observations_myD + 2)
      - influence_j = Pj_C_given_myC - Pj_C_given_myD
      - baseline = baseline_C_rate[j] (smoothed if desired)

   B. Compute expected extra contributions your single cooperation now would induce over the next H rounds:
      - For each j, assume your cooperation increases j’s contributions by approximately influence_j per round.
      - Expected_extra_contribs = sum_j max(influence_j, 0) * H
        (Ignore negative influences for planning — you will punish negative responders by defecting.)
      - Optionally reduce H for players classified as unresponsive (baseline < tau).

   C. Convert to your expected benefit from cooperating now:
      - Marginal benefit to you over the H-round window ≈ (k / n) * Expected_extra_contribs
      - Immediate cost of cooperating now = 1 token

   D. Cooperate vs defect decision:
      - If Marginal benefit > 1 + margin_epsilon (margin_epsilon small, e.g., 0.02), play C.
        (Your cooperation is justified because it is likely to induce enough future contributions to recoup the cost.)
      - Else play D (exploit). Tie-breaker: when marginal benefit is very close to 1, prefer D to avoid exploitation.
   E. Special-case exploitation tactic:
      - If many players have high baseline_C_rate (e.g., > 0.7) and aggregate expected contributions next round (without your cooperation) is already high, prefer D to free-ride that round.
      - If all other players contributed in the previous round, play D to exploit them (one-shot exploit) unless their conditional response statistics indicate harsh punishment of defecting; in that case prefer a calculated cooperation to avoid sustained punishment.

4. Punishment and forgiveness (to shape behavior without being trapped)
   - If a player j is persistently unresponsive: baseline_C_rate[j] < tau and influence_j <= 0, then treat j as “dead” — do not factor them positively into Expected_extra_contribs and stop trying to entice them.
   - Periodically (with probability p_forgive each non-final round, or every W rounds), run a probe: play C even when calculus favors D to test whether previously “dead” players have changed behavior. If their responsiveness has changed, reintegrate them.
   - If a player punishes your D harshly (i.e., they retaliate immediately after you defect by defecting and have high influence on others), and that retaliation reduces your future expected gains dramatically, adjust by cooperating occasionally to avoid long retaliatory cycles — but only if cooperation is still net-profitable under the margin rule above.

5. Noise robustness
   - Use smoothed estimates and require a small positive influence (delta) before relying on it.
   - Be lenient for short irregularities: require several observations before permanently classifying someone as responsive/unresponsive.

6. End-of-tournament specifics
   - Always defect in final_defect_window F (last 1–2 rounds): since others will anticipate this, you cannot reliably induce future cooperation there.
   - If r is very small (e.g., r <= m + F), shorten probing and default to defect except for very small, calculated cooperations when marginal benefit condition holds.

Why this is exploitative and robust
- Exploitative: the strategy defects by default unless there is evidence that contributing will trigger more future contributions that make cooperation personally profitable; when others are cooperative or responsive you commonly defect to free-ride on their cooperation except when cooperating is justified by the influence calculus. It actively searches for and exploits unconditional cooperators.
- Robust/adaptive: it learns conditional response patterns for each opponent, selectively cooperates only with those who are influenced by you, punishes unresponsive defectors (withdraws cooperation), and uses occasional probes and forgiveness to recover from noise or strategy drift.
- Tournament-ready: requires only public history (others’ moves and payoffs), uses internal, bounded-memory statistics and short planning horizon H derived from r so it works across many opponent types and parameter settings (n, k, r).

Practical parameter guidance
- H = min(10, floor(r/5)), m = a few initial probe rounds (1–4), F = 1–2 final defect rounds, p_forgive ≈ 0.03–0.1, delta ≈ 0.05–0.1, tau ≈ 0.1–0.2. Tune conservatively toward smaller H and smaller p_forgive in noisy or short games; tune toward larger H and slightly larger p_forgive in long games.

Summary (one-line rule)
- Cooperate only when your cooperation is likely to cause enough extra future contributions from others (estimated from past conditional behavior) that your long-run gain exceeds the immediate cost; otherwise defect, but probe occasionally, forgive rarely, and always defect in the final rounds.
'''

description_EXPLOITATIVE_110 = '''
Name: Selective Exploiter (adaptive conditional cooperation with minimal concession)

High-level idea
- Seek to extract benefits from other players’ cooperation while giving away as little as necessary to keep the cooperative subset of opponents from collapsing. 
- Classify opponents from observed history (unconditional cooperator, conditional cooperator/reciprocator, or defector). Exploit unconditional cooperators aggressively; sustain cooperation with conditional cooperators by giving just enough predictable cooperation to keep them contributing; always defect in the final phase. 
- Continually probe and adjust. The policy depends only on n, k, r and the public history of plays/payoffs.

Parameters (computed from game parameters)
- Window W = min(20, max(3, floor(r/5))) — number of most recent rounds used for statistics.
- Exploration/probe baseline eps = max(0.03, 3/r) — small probability to cooperate to probe or repair.
- Final-phase length H = max(1, ceil(0.10 * r)) — always defect in final H rounds.
- Classification thresholds:
  - p_always = 0.95 (cooperation rate over W that marks an “unconditional cooperator”)
  - p_cond_min = 0.25 (minimum recent cooperation to consider someone “potentially conditional”)
  - resp_thresh = 0.20 (responsiveness: how much their cooperation increases after others/my cooperation)
- Group thresholds:
  - tau_high = 0.60 (high group cooperation)
  - tau_low  = 0.30 (low group cooperation)
- Repair length S = min(4, max(2, ceil(r/20))) — number of consecutive cooperative rounds to attempt after heavy punishment to rebuild cooperation.

Per-round procedure (round t)

1) Final-phase rule
- If t > r - H: play D (defect) unconditionally. Rationale: no future to sustain cooperation against backward induction.

2) Update statistics
- For each opponent j compute over the last (up to) W rounds:
  - p_j = empirical cooperation rate of j.
  - resp_j = P(j cooperates | average cooperation by others in previous round (including me) was high) − P(j cooperates | that previous-round average was low).
    - Practically: compare j’s cooperation following rounds where you (and/or group) cooperated vs following rounds where you (and/or group) defected. This measures conditional cooperation and sensitivity to others.
- Compute:
  - group_rate = average of p_j over all opponents.
  - last_round_group_rate = fraction of opponents who cooperated in the most recent round.
  - count_always = number of opponents with p_j >= p_always.
  - frac_conditional = fraction of opponents with p_j >= p_cond_min and resp_j >= resp_thresh.

3) Classification-based decision (exploitative core)
- If count_always >= 1:
  - Exploit unconditional cooperators:
    - Play D most rounds to harvest from them.
    - Occasionally cooperate with small probability eps_probe = max(eps, 0.05) to avoid provoking conditional cooperators permanently.
    - If frac_conditional is high (>= 0.5), use a slightly larger keep-cooperation probability keep_prob = min(0.15, 2/(r-t+1)) so conditional cooperators don’t switch off; otherwise play D with probability 1 − eps_probe.
  - Rationale: unconditional cooperators yield steady income when you defect; give tiny concessions only to prevent loss of conditional cooperators.

- Else if group_rate >= tau_high:
  - Many opponents cooperate reliably — harvest by defecting:
    - Play D this round (defect).
    - With small probability keep_prob = min(0.15, 2/(r-t+1)) play C instead to maintain the norm among conditional players (probability decays as the game approaches the end).
    - Rationale: when the group is already cooperative, immediate harvesting is profitable; brief, rare cooperation avoids collapse.

- Else if group_rate between tau_low and tau_high:
  - Mixed environment: try to sustain cooperation where it exists and exploit weak cooperators.
    - If last_round_group_rate >= 0.5 and frac_conditional >= 0.4:
      - Play C to reward/maintain bilateral reciprocity (keep a local cooperation level stable).
    - Otherwise:
      - Play D, but with exploration probability eps to probe and possibly restore cooperation.
    - Rationale: when cooperation is moderate, investing a single cooperative action can stabilize future returns if many players respond; otherwise prefer to defect.

- Else (group_rate < tau_low):
  - Low cooperation environment: defect by default to avoid being exploited.
    - Play D, except with small probe probability eps to test whether cooperation can be re-initiated.
    - If over the last few rounds cooperation fell sharply after one of your defections (evidence that you were singled out as a cause of collapse), trigger a temporary repair:
      - Cooperate for S consecutive rounds to signal willingness to re-establish reciprocity, then resume exploitation rules.

4) Response to punishment and repair
- If you observe a substantial group-wide drop in cooperation immediately following rounds where you defected (e.g., group cooperation drops by more than 0.25 compared to previous window), you infer that conditional cooperators respond to your actions. To avoid a permanent collapse that would reduce your long-run harvest:
  - Enter a Repair mode: cooperate for S consecutive rounds (S defined above), then re-evaluate. Use that limited concession to recover mutual cooperation among conditionals, then resume exploitation.

5) Randomization and predictability management
- When defecting in environments with many conditional cooperators, randomize occasional cooperation with the probabilities above (eps, keep_prob). This prevents deterministic patterns that would cause coordinated long punishments and reduces the risk of being ostracized. The randomization probabilities shrink as the horizon shortens so you exploit more near the end.

Edge cases and small r
- r = 1: always defect (D).
- Very short games (r <= 5): be more exploitative—shorten W to 1–2 and bias eps smaller; if opponents show any consistent cooperation in initial rounds, defect to harvest quickly because there is little opportunity for sustaining cooperation.
- Very long games: the classifier windows and repair lengths scale with r, so the strategy can invest in rebuilding cooperation early and exploit slower.

Why this is exploitative and robust
- Exploitative: When there are unconditional cooperators or stable high group cooperation, the policy defects repeatedly to harvest their contributions while giving only minimal, carefully timed cooperative concessions to avoid their collapse. It explicitly defects in the final phase to secure endgame gains.
- Adaptive: The strategy infers types from history and switches behavior — from pure exploitation to cautious maintenance (or repair) — depending on whether opponents are conditionally cooperative and responsive to my actions.
- Robustness: Uses small probing probability to learn and repair; randomization prevents being trapped by simple punishers; final-phase defection prevents being exploited in the endgame. The few tunable thresholds are functions of r and use short-term windows so the policy adapts to many kinds of opponents.

Concrete short pseudocode summary (words)
- If t in final H rounds: D.
- Else update p_j, resp_j, group_rate, count_always, frac_conditional.
- If any unconditional cooperators exist: mostly D; play occasional C with small keep_prob to preserve conditionals.
- Else if group_rate >= tau_high: D (rare C with keep_prob to avoid collapse).
- Else if group_rate in [tau_low, tau_high): if last round majority cooperated and many conditionals, play C; else D (with small eps probe).
- Else (low cooperation): D (rare eps probe). If your defect caused a sharp group collapse, enter Repair: play C for S rounds, then resume.
- Always randomize with the specified small probabilities to probe and avoid deterministic punishments.

This strategy requires only public history and game parameters; it balances aggressive harvesting of predictable cooperators with cautious maintenance efforts when conditional cooperators are pivotal to long-term gains.
'''

description_EXPLOITATIVE_111 = '''
Summary goal
- Maximize my cumulative payoff by free-riding on players who keep contributing, while avoiding costly, long-lasting retaliation from punishers. Make decisions only from observed history and the parameters n, k, r. Be adaptive: detect exploitable vs retaliatory opponents, probe when uncertain, and switch to cooperation only when it is profitable given expected retaliation.

Definitions and tracked statistics (maintain each round)
- For each opponent j:
  - coop_rate_j = fraction of rounds so far in which j contributed.
  - coop_after_Icoop_j = estimated probability j contributes in the round after I contributed.
  - coop_after_Idefect_j = estimated probability j contributes in the round after I defected.
  - punish_effect_j = coop_after_Icoop_j − coop_after_Idefect_j (how much j’s cooperation falls after my defection).
- Global:
  - avg_group_coop_last = fraction of players who contributed in the previous round (excluding me if desired).
  - E_drop = expected drop in the number of contributors next round attributable to my defect this round = sum_j punish_effect_j (only count positive punish_effect_j; treat negative or small values as 0).
- Constants (set initially using n, k, r; can be tuned but are deterministic functions of parameters):
  - immediate_gain_from_defect = 1 − k/n  (my per-round gain from switching C→D if others’ actions are unchanged).
  - value_per_other_contribution = k/n (the benefit I lose if one other player stops contributing).
  - probe_schedule: small probability ε(t) of making a “test” action to update estimates; ε(t) decays with time (e.g., ε(t) = min(0.25, 1 / t) or another deterministic function of t and r).
  - forgiveness_window S (number of rounds to attempt rebuilding cooperation after triggering punishment), e.g., S = max(1, floor(r/10)).

Core decision rule (applies for rounds t = 1..r)
1) Last round (t = r)
   - Defect. (Backward induction: no future to gain from cooperation.)

2) Early probing (t = 1 and small t)
   - Round 1: Cooperate. This gives a baseline and attracts conditional cooperators.
   - Round 2: Deliberate probe: Defect. Purpose: generate data to estimate punish_effect_j and responsiveness quickly.
   - After round 2, use the observed reactions to initialize estimates.

3) General rule for round t (3 ≤ t < r) — choose action A_t ∈ {C,D}
   - Update coop_after_... and punish_effect_j from history.
   - Compute E_drop = sum_j max(0, punish_effect_j). (This is the expected number of other contributors I will lose next round if I defect now.)
   - Compute expected_next_round_loss = value_per_other_contribution * E_drop.
   - Short-term decision test:
     - If expected_next_round_loss < immediate_gain_from_defect then choose D (exploit now).
     - Else choose C (avoid triggering retaliation).
   - Exceptions and refinements:
     a) If avg_group_coop_last is very low (below a low-cooperation threshold, e.g., < 20%): defect (no point cooperating when most already defect).
     b) If a substantial fraction of players are persistent cooperators (coop_rate_j very high, e.g., > 0.9) and have near-zero punish_effect_j (they keep cooperating when I defect), prefer D to exploit them (unless their number is so small that E_drop computed above would already be small).
     c) If a majority of players are punishers (E_drop is large, e.g., E_drop > immediate_gain_from_defect / value_per_other_contribution), cooperate to avoid sustained group collapse.

4) Dealing with punishment and rebuilding
   - If I defect and in the next round I observe that many players reduced cooperation (E_drop realized substantially positive), mark that I triggered punishment.
   - To limit long-term losses, enter a forgiveness phase: cooperate for up to S rounds (or until historical measures indicate punishers stop punishing) to rebuild cooperation. If punishment persists beyond S rounds (i.e., others continue defecting), switch to permanent defection against that pattern (stop “paying” for reconciliation).
   - If punishment was weak or absent, continue exploiting (defect) but keep probing occasionally.

5) Ongoing probing to distinguish types
   - With small probability ε(t) each round do a probe opposite to your usual action this round:
     - If usually defecting, occasionally cooperate for one round to see whether cooperation gets reciprocated or whether others are opportunistic (if others increase cooperation, you can exploit next round).
     - If usually cooperating to avoid punishment, occasionally defect to re-test punish_effect_j (to avoid being fooled by a one-time reprieve).
   - Update statistics after each probe.

6) Population-level safety rule
   - If your probe and estimates show that cooperating yields substantially higher multi-round expected payoff (for example, if many players are conditional cooperators and E_drop is small but group cooperation creates such a high expected continuing stream of contributions that cooperating is profitable), switch to a conditional cooperation mode: cooperate if avg_group_coop_last ≥ threshold T_coop (e.g., majority cooperating), otherwise defect. That mode is only chosen if long-run estimates show net benefit; it is the exception, not the default.

7) Endgame scaling
   - As t approaches r, gradually reduce cooperation probability (unless cooperating is required to avoid immediate massive punishment). Concretely, in the final K rounds where K = min(3, floor(r/10)), lower ε(t) to 0 and bias toward defection. Last round always defect.

Why this is exploitative and robust
- Exploitative: the basic decision is to defect whenever the immediate gain (1 − k/n) outweighs the expected loss due to others reducing contributions. That explicitly captures free-riding only when it is profitable. Unconditional cooperators (very high coop_rate_j and low punish_effect_j) are exploited because E_drop remains small while immediate_gain is positive.
- Deterrence: by estimating punish_effect_j we avoid provoking large coordinated retaliation. If my defection triggers others to drop contributions (high E_drop), I switch to cooperation to avoid losing more in the future.
- Adaptive and data-driven: all choices are made from empirical conditional probabilities computed from observed history; probing quickly separates punishers from gullible cooperators, and the policy updates automatically.
- Robustness: works against pure defectors (we simply defect), conditional cooperators (we cooperate when costly retaliation would occur and exploit when safe), tit-for-tat or grim types (we detect and avoid triggering), and noisy/random strategies (probing and averaging smooths noise).

Edge cases recap
- First round: cooperate (get baseline).
- Second round: defect (probe to get early signal of punishment).
- If insufficient data (very early rounds), use conservative rule: if avg_group_coop_last is high, defect once to probe; otherwise defect by default.
- Last round: always defect. In final K rounds bias strongly to defect, unless immediate massive punishment would follow (very unlikely because last-round defection cannot be punished in final step).
- If you detect that everyone else is permanently defecting, switch immediately to permanent defection.

Practical parameter suggestions (deterministic functions of n,k,r)
- S (forgiveness window) = max(1, floor(r/10))
- ε(t) = min(0.25, 1/t)
- Low-cooperation threshold = 0.2, majority threshold T_coop = 0.5
- Use these or scale them deterministically with r (so strategy depends only on game parameters and history).

Behavioral summary for a round
- Compute estimates from history.
- If last round and t = r → defect.
- Else if expected_next_round_loss < immediate_gain_from_defect → defect (exploit).
- Else cooperate (avoid or repair punishment).
- Occasionally probe opposite action with small probability to refine estimates.
- If punished, cooperate for S rounds to rebuild; if punishment persists then defect permanently.

This strategy maximizes exploitation of naïve cooperators while limiting long-term losses from retaliatory players by using empirically measured responsiveness and simple cost–benefit comparisons based on k and n.
'''

description_EXPLOITATIVE_112 = '''
Strategy name: Adaptive Exploiter

Goal (informal): Get as many tokens as possible by free‑riding on other players’ contributions when safe, while avoiding sustained retaliation that would collapse group contributions. The strategy probes early to learn opponents, exploits unconditional cooperators, and backstops exploitation with cautious, temporary cooperation whenever defections appear to trigger punishment.

Decision variables (computed from the public history each round t)
- W = min(10, t−1) — lookback window (use up to the last 10 rounds).
- For each other player j compute coop_rate_j = fraction of rounds they contributed in the last W rounds.
- P = average of coop_rate_j over all other players (recent group cooperation level).
- P_after_coop = average cooperation of others in the rounds immediately following rounds in which I cooperated (computed over the last W rounds where such “next” rounds exist).
- P_after_defect = average cooperation of others in the rounds immediately following rounds in which I defected (computed over same lookback).
- R = P_after_coop − P_after_defect (measures how much my defection tends to reduce others’ next-round cooperation).
- remaining = r − t + 1 (rounds left, including current).

Fixed internal parameters (interpretable, chosen to be robust):
- low_group = 0.20 (if recent group cooperation is very low, there is nothing to sustain; defect).
- retaliation_thresh = 0.05 (if R > retaliation_thresh, my defection reliably reduces others’ cooperation).
- punish_drop = 0.20 (a large observed drop in group cooperation that counts as “punishment observed”).
- eps = max(1/r, 0.05) (small baseline probability of random cooperation while exploiting to avoid predictability and maintain a minimal signal of cooperativeness).
- recovery_length = 2 (number of consecutive cooperative rounds used to recover trust after causing a visible collapse).
- forced_coop_interval = ceil(1/eps) (if I haven’t cooperated for this many rounds in a row, force one cooperation to test and reset).

Round-by-round decision rules (succinct)
1. Endgame rule: If remaining = 1 (last round), defect. (Standard backward-induction endgame.)

2. Early probing:
   - Round 1: cooperate (probe).
   - If t ≤ 3 and there is not yet reliable data, bias toward cooperating to collect information (cooperate at least in rounds 1–2 unless other rules require defect).

3. Compute the statistics above each round. Then choose as follows:

A. If P < low_group:
   - Group cooperation is negligible; there is nothing to exploit. Defect.

B. Else if R ≤ retaliation_thresh:
   - My defection historically does not cause others to reduce cooperation much — exploitation is safe.
   - Exploit mode: defect this round to free‑ride.
   - To avoid deterministic collapse and to remain unpredictable, with probability eps cooperate instead.
   - Also, if I have defected for forced_coop_interval consecutive rounds, force one cooperation this round (forced cooperation) to re‑probe others’ responses.

C. Else (R > retaliation_thresh):
   - My past defections reliably reduce others’ cooperation (they punish/retaliate or condition on my behavior). Exploitation is risky.
   - Safety mode: cooperate this round to avoid triggering retaliation and to sustain the high contribution environment that I want to exploit in the long run.
   - If I recently defected and then observed a large drop in group cooperation (observed drop ≥ punish_drop in the round(s) immediately after my defection), enter recovery: cooperate for recovery_length consecutive rounds to restore trust, then reassess.

4. Targeted exploitation of unconditional cooperators:
   - Identify players with coop_rate_j ≥ 0.9 over W and who historically do not reduce contributions after my defections.
   - If such unconditional cooperators form a substantial fraction of the group (e.g., > 40% of others), bias toward defecting (exploit them) even if R is slightly positive, but keep occasional cooperation at rate eps to maintain unpredictability.

5. Short-horizon adjustment:
   - If remaining is small (e.g., remaining ≤ 3), transition progressively toward defection except keep 1 cooperation if doing so prevents an immediate collapse that would reduce my short‑run payoff. In the very last round always defect.

Rationale summary (how this is exploitative and robust)
- Exploit when safe: If defections historically do not provoke others to cut contributions (R small), defect routinely and free‑ride; this maximizes my immediate payoff.
- Protect the revenue stream: If defections reliably cause others to reduce contributions, I prefer to cooperate frequently so the group continues providing public goods I can later exploit. That is exploitative in the long run: tolerate small cooperation cost to keep a high-contribution environment rather than provoke a breakdown that hurts me.
- Unconditional cooperators are singled out: when present, they are primary sources of exploitable payoff; the policy defects more aggressively against them.
- Unpredictability and forgiveness: occasional randomized cooperation and short recovery phases prevent brittle patterns (grim triggers) that collapse cooperation permanently, and make it harder for opponents to exploit my own schedule.
- Endgame behavior: last-round defection prevents being exploited by backward induction.

Edge cases and implementation notes
- Very short games (small r): use more defecting bias; still probe round 1 but expect fast defection as horizon shortens.
- Noisy or sparse history: thresholds use a lookback window W and require some minimal sample; early rounds bias toward probing (cooperate) to collect data.
- If the public history is long, statistics are smoothed over the recent window W so the strategy adapts to changes in opponents’ behavior.
- All decisions only use publicly observed past actions and payoffs (cooperation histories); no communication or private signals required.

Behavioral intuition examples
- Against naive always‑cooperators: after probing, this strategy will mostly defect and occasionally cooperate (eps) — it extracts a high share of the public good.
- Against strict punishers (who quickly drop contributions after any defection): this strategy will instead cooperate frequently so the group stays cooperative, enabling later modest exploitation while avoiding persistent punishment.
- Against mixed/conditional players: the strategy learns the sensitivity (R) and finds the best tradeoff between immediate defection gains and long‑run revenue from keeping group contributions up.

This policy is explicitly exploitative: it prefers defection whenever the empirical cost (retaliation or loss of others’ future contributions) is small, and it sacrifices short-term defection only when that sacrifice preserves a larger future stream of exploitable contributions.
'''

description_EXPLOITATIVE_113 = '''
Exploitative Adaptive Public-Goods Strategy (natural language / pseudocode)

Summary of mindset
- Probe early to identify cooperators and reciprocators.
- Free-ride opportunistically when many others are contributing.
- Exploit unconditional cooperators relentlessly.
- Protect against persistent defectors by refusing to subsidize them.
- Punish quickly if my defections cause others to stop cooperating, but forgive after short punishment so cooperation can be resumed.
- Always defect in the final round (standard endgame logic).

Parameters (computed from game parameters n, r)
- Probe length P = min(4, max(1, floor(r * 0.05)))  // short probing phase
- Stat window W = min(10, max(1, r))  // history window for responsiveness / rates
- Unconditional_cooperator_threshold = 0.95
- Defector_threshold = 0.20
- Responsiveness_threshold = 0.25  // positive sign that a player reciprocates me
- High_coop_threshold = ceil(0.80 * (n - 1))  // many others contributed last round
- Majority_coop_threshold = ceil(0.50 * (n - 1))
- Exploit_streak_max = 1  // allow at most one immediate free-ride streak when cooperation is high
- Punishment_duration = min(3, max(1, floor(r * 0.05)))
- Endgame_horizon T_end = min(2, r)  // last T_end rounds: always defect

Internal state I maintain
- exploit_streak_count (reset when I cooperate)
- punishment_mode flag and punishment_timer (counts down)
- per-player statistics over past rounds (up to W): total contributions and conditional frequencies:
  - C_rate_j = fraction of rounds player j contributed
  - P(C_j | my_last_C), P(C_j | my_last_D) estimated from history
  - Responsiveness resp_j = P(C_j | my_last_C) - P(C_j | my_last_D)

Per-round decision procedure (round t)

1. If t > r - T_end (i.e., t is among the last T_end rounds):
   - Play D (defect). End.

2. If punishment_mode is ON:
   - Play D.
   - Decrement punishment_timer; if punishment_timer reaches 0, set punishment_mode = OFF.
   - Update exploit_streak_count = 0.
   - End.

3. If t <= P (probing phase):
   - Play C (cooperate) to reveal who is willing to cooperate.
   - Update statistics after the round.
   - End.

4. Update per-player stats using up to last W rounds. Compute for each opponent j:
   - C_rate_j over history (or last W rounds if available)
   - resp_j = P(C_j | my_last_C) - P(C_j | my_last_D)

   Also compute:
   - others_last = sum of others' contributions in round t-1 (if t>1; else treat as 0)
   - fraction_uncond = fraction of opponents with C_rate_j >= Unconditional_cooperator_threshold
   - fraction_defectors = fraction with C_rate_j <= Defector_threshold
   - fraction_responsive = fraction with resp_j >= Responsiveness_threshold

5. Exploit unconditional cooperators:
   - If fraction_uncond >= 0.5 (half or more are essentially unconditional cooperators):
     - Play D (always exploit the unconditional cooperators).
     - exploit_streak_count = 0.
     - End.

6. Opportunistic free-ride rule (exploit if many others cooperated last round):
   - If others_last >= High_coop_threshold AND exploit_streak_count < Exploit_streak_max:
     - Play D (free-ride this round).
     - exploit_streak_count += 1.
     - After observing the next round, check others’ cooperation: if average cooperation of others falls by more than 0.20*(n-1) relative to the pre-free-ride baseline, immediately enter punishment_mode for Punishment_duration rounds (to deter retaliation patterns).
     - End.

7. Conditional cooperation to sustain reciprocators:
   - If fraction_responsive >= 0.4 OR fraction_uncond + fraction_responsive >= 0.5:
     - // There is a substantial set of players who will reciprocate my cooperation
     - If others_last >= Majority_coop_threshold:
       - Play C (support the cooperative environment).
       - exploit_streak_count = 0.
       - End.
     - Else:
       - Play D (do not subsidize low-cooperation groups).
       - exploit_streak_count = 0.
       - End.

8. Defensive default (mostly defect against defecting populations):
   - If fraction_defectors >= 0.5:
     - Play D (do not give benefits to defectors).
     - exploit_streak_count = 0.
     - End.

9. Fallback mixed rule (when population is ambiguous):
   - If others_last >= Majority_coop_threshold:
     - Play C (lean cooperative when group was cooperative last round).
   - Else:
     - Play D.

Notes on punishment and forgiveness
- Punish swiftly but briefly: if my defection appears to cause a meaningful drop in others’ cooperation, enter punishment_mode for Punishment_duration rounds (all-D) to show the cost of punishing me; this deters players who try to exploit me via contingent retaliation.
- Forgive after punishment so that long-run cooperative gains with reciprocators can be resumed.
- exploit_streak_count prevents continuous free-riding: I will only immediately free-ride once when cooperation is high, then either cooperate to sustain the cooperative environment or switch to punishment if cooperation collapses.

Edge cases and practicalities
- If r is very small (e.g., r <= 3), probe length P collapses to 1 and Endgame_horizon may cover most rounds; the strategy will therefore defect in most late rounds as appropriate.
- If there is almost unanimous unconditional cooperation, I will consistently defect and harvest the highest short-run payoff (exploit).
- If a sizable set of players is responsive, I will cooperate when the group is cooperating and defect when they are not — extracting surplus by free-riding occasionally but maintaining cooperation overall.
- All thresholds are chosen conservatively; they depend only on n and r (and observed history). They are intentionally tuned to be robust across populations: the strategy exploits naïve cooperators, sustains cooperation with reciprocators at minimal cost, and rejects defectors.

Rationale (brief)
- A one-shot incentive always favors D; repeated play only supports cooperation if others are conditional cooperators. This strategy (a) identifies cooperators via a short probe, (b) exploits unconditional cooperators, (c) maintains cooperation with reciprocators but only at the minimum cost needed, (d) punishes when my defections lead to reduced group cooperation, and (e) always defects in the final rounds to avoid endgame exploitation. The result is an adaptive, exploitative approach that gains against a wide variety of opponents while avoiding prolonged exploitation by defectors.
'''

description_EXPLOITATIVE_114 = '''
Name: Exploitative Conditional Cooperator (ECC)

Summary: Start by building a cooperative reputation to harvest high group returns, periodically “probe” to find exploitable cooperators and extract surplus, but rapidly switch to defensive behavior when I detect credible punishment or systematic exploitation. In the final short horizon I defect to take an endgame advantage.

Parameters derived from the game:
- n, r, k are given.
- Window W = min(10, max(3, floor(r/10))) — number of recent rounds used to estimate behavior.
- Endgame length L = min(3, max(1, floor(r/10))) — always defect in the last L rounds.
- Cooperation threshold Theta_high = 0.65 — treat the group as generally cooperative when average cooperation >= this.
- Punisher sensitivity S = 0.25 — fraction of opponents who react to my defection that I treat as “punishers.”
- Punishment length P = min(3, r_remaining) — how long I retaliate if I decide to punish back.
- Base exploit probability p0 = 0.20, scaled up when group cooperation is stronger (see below).

State I track from history:
- For each player j ≠ me: coop_rate_j = fraction of times j contributed in the last W rounds.
- avg_other = average of coop_rate_j over j ≠ me.
- last_round_contribs = number of players (excluding me) who contributed in the previous round.
- A simple responsiveness test: whenever I defected in a recent round t0, observe for each opponent whether they reduced contribution in the following round compared with their pre-t0 rate. Use these observations to estimate fraction_reactive (fraction of opponents who appear to retaliate to my defection).

Decision rules (per round t):

1. First round:
   - Cooperate. (Signal willingness to cooperate and collect baseline data.)

2. Endgame:
   - If t > r - L (i.e., in the last L rounds): Defect every round. (Exploit the finite horizon endgame.)

3. Detect punishers / adapt defensive stance:
   - Compute fraction_reactive from recent tests where I defected.
   - If fraction_reactive ≥ S (enough opponents appear to retaliate to my defections):
     - Enter Reciprocity Mode: play Tit-for-Tat–style with forgiveness:
       - In the first round after a detected retaliation, Cooperate if a strict majority of opponents cooperated in the last round; otherwise Defect.
       - If I observe continued defection by a large fraction of players (≥ 50% of opponents) for two rounds, switch to Punish Mode: Defect for P rounds to stop being exploited, then return to Testing Mode.
     - The idea: avoid repeated short-term exploitation by punishers; don’t persistently probe them.

4. Testing/Exploitation Mode (default when punishers are not common):
   - Compute avg_other from coop_rate_j over last W rounds.
   - If avg_other ≥ Theta_high:
     - Group is sufficiently cooperative — exploit opportunistically:
       - Calculate exploit probability p_exploit = min(0.6, p0 + 0.4*(avg_other - Theta_high)/(1-Theta_high))
       - With probability p_exploit: Defect (free-ride) this round.
       - Otherwise: Cooperate.
     - Also, schedule a deterministic short test whenever I have cooperated for at least two consecutive rounds: deliberately defect one round to see who punishes (this maintains my probe signal rate at low frequency so I can keep exploiting without destroying cooperation). Tests should be rare (roughly once every max(5,W) rounds).
   - If avg_other < Theta_high:
     - Group not reliably cooperative — be cautious:
       - If last_round_contribs (others) ≥ ceil((n-1)/2): Cooperate (reciprocate majority cooperation).
       - Else: Defect.

5. Punish Mode (activated when I detect sustained exploitation of me or others):
   - Defect for P rounds (P as above). After P rounds, return to Testing/Exploitation Mode but with a record that a stricter cooperation test is required (i.e., require avg_other ≥ Theta_high + 0.1 before resuming heavy exploitation).

6. Forgiveness and recovery:
   - After I or the group enters a low-cooperation period, be willing to resume cooperation if I observe a clear recovery: require two consecutive rounds where at least a majority of opponents cooperate, then return to Testing/Exploitation Mode.

Notes on interpretation and robustness:
- The default behavior builds cooperation early (first round cooperate and default cooperative responses) so I can collect larger group returns and establish a reputation. That reputation lets me exploit cooperative opponents occasionally with limited risk.
- Probing is deliberate but sparse: I deliberately defect occasionally to identify unconditional cooperators (high coop_rate_j) and punishers (players who reduce contributions after my defection). If many punishers exist, I stop probing and switch to reciprocal play to avoid being driven into negative returns by retaliation.
- The randomness in exploitation (probabilistic defection) reduces predictability and avoids deterministic cycles that invite coordinated punishment from multiple opponents.
- Endgame defection is used to extract surplus at the horizon; the short L prevents needless loss of long-term cooperative gains earlier.
- All thresholds (W, Theta_high, p0, S, P, L) are fixed functions of the known parameters (n, r, k) and are conservative defaults; they can be tuned before the tournament but are set here to be robust across many opponent types.

Edge cases:
- Very short games (r ≤ 3): cooperate for r-1 rounds, defect last round (i.e., follow endgame rule).
- If I detect an opponent who is a near-perfect cooperator (coop_rate_j ≥ 0.95) while most others are not, the global exploitation rule still applies: my occasional defections will harvest surplus from such cooperators without targeted punishment (there is no way to single-target in PGG). If a targeted opponent starts punishing me, they will be counted under fraction_reactive and I will reduce probing.
- If the whole population is nearly all defectors (avg_other very low), I will defect to avoid paying cost for no benefit.
- If some opponents appear to coordinate responses (many change behavior together after my actions), this increases fraction_reactive and moves me into a reciprocal/defensive mode to avoid costly conflict.

Exploitative mindset emphasized:
- Extract value from cooperative opponents by building reputation, probing occasionally, and defecting probabilistically when group cooperation is high.
- Protect myself against being exploited by detecting and responding to punishers and switch to reciprocal/punitive play if necessary.
- Take advantage of the finite horizon by defecting in the last few rounds to capture one-off gains.
'''

description_EXPLOITATIVE_115 = '''
Name: Probe-and-Exploit Conditional-Cooperator (PECC)

Goal (exploitative): Build a short-lived cooperative reputation to identify and sustain conditional and unconditional cooperators, then free-ride as often as possible while using small, strategic contributions to prevent permanent collapse of others’ cooperation. Defect in the endgame.

Parameters (set from known game parameters n, r, k):
- m_probe = min(4, max(1, floor(r/10)))  // rounds used to build reputation and collect data
- L = min(6, max(1, r))  // sliding window length used to estimate recent behavior
- T_end = min(3, max(1, floor(r/10)))  // last T_end rounds: always defect
- T_rebuild = max(1, floor(r/20))  // rounds to briefly cooperate to repair reputation when needed
- thresholds: f_high = 0.65, f_low = 0.35
- classification thresholds: uncond_rate = 0.90, defector_rate = 0.10, responsive_delta = 0.25
- probabilities: p_coop_maintain = 0.20 (when many cooperators present we cooperate rarely), p_coop_rebuild = 0.75 (temporary repair), p_probe = 0.10 (sporadic probe when cooperation low), p_random_coop = 0.05 (small exploration)

Data tracked (from public history):
- For each opponent i, compute cooperation_rate_i over last L rounds (fraction of rounds i played C).
- For each opponent i, estimate responsiveness: Prob(i cooperates | I cooperated previous round) minus Prob(i cooperates | I defected previous round), using the available history window.
- frac_last = fraction of other players who cooperated in the previous round.
- frac_uncond = fraction of opponents with cooperation_rate_i >= uncond_rate.
- frac_defectors = fraction with cooperation_rate_i <= defector_rate.
- frac_conditional = fraction with responsiveness >= responsive_delta and cooperation_rate_i >= 0.40.

Decision rules (each round t):

1. Endgame
- If t > r - T_end: play D (defect) every round. (Exploit endgame backward-induction; no long-run benefit to contributing.)

2. Probe phase
- If t <= m_probe: play C (cooperate). Purpose: establish a cooperative reputation and gather data about opponents’ responsiveness.

3. After probe, main adaptive logic
- Compute statistics described above using the most recent L rounds.

A. If frac_last >= f_high and (frac_uncond + frac_conditional) >= 0.25:
  - Many players are cooperating and a substantial fraction are exploitable (unconditional or conditional cooperators).
  - Exploit: play D with probability 0.80; play C with probability p_coop_maintain = 0.20.
  - Rationale: mostly free-ride while occasionally contributing to avoid immediate collapse of cooperation by conditional cooperators.

B. If frac_last <= f_low:
  - Cooperation is low now. Default to defecting most of the time to avoid paying costs into a broken public good.
  - Play D, but with small probing probability p_probe = 0.10 (independently each round) to see if a small contribution will rekindle cooperation.
  - If, immediately after you begin defecting, you observe a large drop in others’ cooperation (drop >= 0.25 compared to the window before you started defecting), then switch to a short rebuild mode: play C for the next T_rebuild rounds with probability p_coop_rebuild = 0.75 to repair reputation and try to bring conditional cooperators back.

C. If f_low < frac_last < f_high:
  - Intermediate region — behavior is ambiguous. Use trend and responsiveness:
    - If average cooperation rate of others over the last L rounds is increasing (compared to the previous L window), cooperate with probability 0.30 to support the positive trend but still exploit opportunistically.
    - Otherwise, defect, but allow a very small exploration probability p_random_coop = 0.05 to avoid being trapped in mutual defection.

4. Punishment and forgiveness (local dynamics)
- If you detect that individual conditional cooperators reduce their cooperation substantially after your defection (responsiveness negative and large), this indicates you are being personally punished. In that case, reduce immediate defection frequency: for the next T_rebuild rounds cooperate with probability p_coop_rebuild (0.75) to restore your reputation with those responders, then resume exploitation under the main rules.
- Conversely, if defecting produced no observable reduction in others’ cooperation, keep exploiting (do not waste further contributions).

5. Tie-breakers & lack of data
- If insufficient rounds have elapsed to classify opponents reliably (t just after m_probe or very small r), follow: cooperate for the first m_probe rounds; after that, default to rule 3 with conservative estimates (assume no conditional cooperators until observed).

6. Randomization
- Use the stated probabilities as independent randomization each round when the rule specifies a mixed action. Randomization prevents pure predictability and avoids coordinated mass punishment by independent conditional strategies that might try to exploit deterministic patterns.

Summary of intent and trade-offs
- Build short trust early so you can identify who will continue to cooperate in response to small signals.
- When many cooperators exist, free-ride frequently while contributing occasionally (p_coop_maintain) to keep conditional cooperators from permanently withdrawing.
- When cooperation collapses, avoid dumping tokens into a failing public good; probe rarely and, if necessary, temporarily repair reputation with concentrated cooperation to restore exploitable cooperators.
- Always defect in the final few rounds.
- The strategy is exploitative because it prioritizes defections whenever doing so does not eliminate a sufficient base of cooperating opponents whose contributions you can parasitize; it sacrifices some short-term contributions to maintain a larger long-term stream of benefits from others.
'''

description_EXPLOITATIVE_116 = '''
Opportunistic Leech with Targeted Punishment (OLTP)

Goal (exploitative mindset)
- Maximize my own lifetime payoff by free-riding on stable cooperators while avoiding collapse into universal defection. Keep enough cooperation in the group to exploit, but punish players who reduce their contribution rate in response to my exploitation. Always defect in the known final rounds (endgame).

Parameters (computed from game inputs r, n, k)
- ProbeLength = max(1, min(3, floor(r/10)))   // short initial probing/cooperation
- EndgameLength = max(1, min(3, floor(r/10))) // final guaranteed defection window
- Window W = min(10, t-1) for estimation (use available history)
- CooperatorThreshold = 0.70                     // someone is considered a cooperator
- LowGroupThreshold = 0.30                       // if group cooperation low, stop trying to prop it up
- MaxDefectStreak = 3                            // defect at most this many rounds in a row before "maintenance" cooperation
- PunishDrop = 0.20                              // if a player's recent rate drops by > PunishDrop after my defection, punish them
- PunishLength = 3                               // length of targeted punishment
- MaintenanceCoopInterval = MaxDefectStreak + 1  // cooperate once after this many of my consecutive defections (to maintain cooperators)

State I maintain (from history)
- For each other player j: recent cooperation rate R_j computed over last W rounds (fraction of rounds they contributed)
- Group cooperation rate G = average_j R_j
- For each player j: a punish-timer P_j (remaining rounds to punish them, initially 0)
- My consecutive-defect counter D_streak

Decision rules (per round t, using only r, n, k and the observed history)
1. First round(s) — probing:
   - If t ≤ ProbeLength: cooperate. Record history and continue.

2. Endgame:
   - If t > r - EndgameLength: defect (no future to preserve cooperation).

3. Update estimates:
   - Compute each R_j over the most recent W rounds (if fewer rounds exist, use all past rounds).
   - Compute G = average_j R_j.
   - If any P_j > 0, decrement it by 1 at the start of the round.

4. If G < LowGroupThreshold:
   - The group is mostly non-cooperative; defect (no point trying to prop up cooperation). Set D_streak++.

5. Targeted punishment detection (reactive rule executed after rounds in which I defect; this is used to set punish timers for future rounds):
   - After a round where I chose Defect, compare each player's R_j now to their R_j measured in the W rounds immediately before my defection (use the available recent windows). If a player's recent rate falls by more than PunishDrop following my defection, set P_j = PunishLength (start punishing that player). This marks players who "retaliate" or reduce cooperation when exploited.

   (Implementation note: because actions are simultaneous, this rule is applied using the observed sequence: when I have defected in previous rounds and thereafter observe a drop in a player's contributions, I mark them. This is fully history-based.)

6. Punishment execution:
   - If any P_j > 0 (I am currently punishing someone), defect this round to make punishment credible. Set D_streak++.
   - The punishments are targeted in the sense that I only initiate them against players who lowered contributions after my defection; but my single action is binary, so during punishment rounds I defect to hurt their payoffs.

7. Exploitation / maintenance policy (applies when not in endgame, not in probe, not forced to defect by low group cooperation or active punishment):
   - If G ≥ CooperatorThreshold:
       - The group contains reliable cooperators; my preferred long-run role is a leech. Therefore, defect by default to free-ride (D_streak++).
       - However, to avoid collapsing their cooperation entirely, perform a maintenance cooperation: if D_streak ≥ MaxDefectStreak, cooperate this round (reset D_streak = 0). This one-cooperate "maintenance" keeps cooperators from learning to ignore me forever.
   - If CooperatorThreshold > G ≥ LowGroupThreshold:
       - Borderline group cooperation: be cautious. Defect by default but be more generous with maintenance:
         - Defect unless D_streak ≥ MaxDefectStreak/2, in which case cooperate once to signal reciprocity. (This is softer maintenance.)
   - (Covered earlier) If G < LowGroupThreshold: defect.

8. Forgiveness and recovery:
   - If I have punished a player (set P_j > 0) and that player subsequently restores their R_j to within PunishDrop of their pre-punishment rate, stop punishing them (set P_j = 0) and treat them as a cooperator again.
   - If overall group cooperation G rises significantly (e.g., G > CooperatorThreshold) after a period of exploitation, continue to exploit but maintain the maintenance rule so cooperation remains stable.

9. Tie-breaking and determinism:
   - If rules would both recommend cooperate and defect in the same round (rare), prefer defect (exploit).

Rationale / behavior summary
- Probe briefly to identify who tends to contribute.
- Default stance is to defect because single-round incentives favor defection; but I need some cooperation from others to profit over time.
- Exploit stable cooperators by defecting most rounds while periodically cooperating to keep them from punishing me or abandoning contributions.
- If my defection provokes particular players to stop contributing (they are "sensitive" or retaliatory), punish them for a short fixed window so that retaliators learn that reducing contributions in response to my exploitation is costly. This discourages coordinated retaliation that would erode my gains.
- If the group is already mostly defecting, switch to pure defection (no point preserving cooperation).
- Always defect in the known final rounds (endgame), since there is no future to sustain.

Edge cases
- Very short games (small r): ProbeLength and EndgameLength clamp to at least 1; I cooperate on round 1, then switch to exploitation/pure-defect as dictated; still defect in the final round.
- Noisy-looking opponents (irregular contributions): estimation uses a short rolling window W to adapt quickly.
- If many players are cooperative initially but quickly collapse after my exploitation, the maintenance cooperation rule and targeted punishments aim to restore a subset of cooperators rather than trying to recover universal cooperation.
- No coordination or signaling is used; all decisions depend only on observed histories and the known parameters.

Why this is exploitative and robust
- The strategy extracts value from cooperators by defecting most of the time but prevents wholesale collapse through scheduled forgiveness/maintenance cooperation. Targeted punishment discourages individuals who react to exploitation and would otherwise force me into costly tit-for-tat wars. Endgame defection guarantees no wasted cooperation when there is no future. The algorithm adapts quickly to shifts in others’ behavior (via short windows and punish/forgive mechanics), is parameterized by the known game length and group size, and requires only observed actions and payoffs.
'''

description_EXPLOITATIVE_117 = '''
Name: Selective Exploitative Conditional Cooperator (SECC)

Intuition (one line)
- Start by investing a small “trust” signal to identify who will keep contributing; then free-ride as much as possible on identified cooperators while using occasional, targeted cooperation to maintain enough contributions among others. If exploitation triggers sustained retaliation or the endgame approaches, switch to safe defection.

Parameters computed from game inputs (deterministic functions of n, k, r)
- P (probe length) = max(1, min(6, floor(r/8))). (Short initial cooperative probe to learn tendencies.)
- Epsilon (random maintenance prob) = 0.05 (small randomization to avoid deterministic exploitation).
- theta_high = 0.7 (cooperation frequency threshold to call an opponent “cooperator”).
- theta_low = 0.3 (below this an opponent is treated as a defector).
- repair_len = min(4, max(1, floor(r/20))) (consecutive rounds of cooperation to rebuild trust if others collapse).
- endgame_len = min(5, max(1, floor(r/10))) (final rounds to always defect).
- collapse_window = 3 (lookback window to detect sudden collapse in group contributions).

State derived from history
- For each opponent j, f_j(t) = fraction of cooperative actions by j over observed rounds up to current round t.
- last_total_contrib = total contributions observed in previous round.
- recent_avg_contrib = average total contributions over last collapse_window rounds.
- classifications:
  - “cooperator” if f_j >= theta_high
  - “conditional” if theta_low < f_j < theta_high
  - “defector” if f_j <= theta_low

Decision rules (applied each round t, 1..r)
1. Endgame override
   - If t > r - endgame_len: choose D (defect). Never cooperate in the final endgame_len rounds.

2. Probe phase (t <= P)
   - Cooperate (C) for these initial rounds to signal willingness and obtain informative f_j estimates.

3. After probe (t > P) — core exploit logic
   - Compute counts:
     - num_coop = number of opponents currently classified as “cooperator”
     - num_cond = number of “conditional”
     - group_contrib_last = last_total_contrib (including our past action)
     - recent_avg_contrib as above
   - Baseline: default to Defect (D). The strategy aims to defect most of the time.
   - Exploit rule (when to defect aggressively):
     - If num_coop >= 1 and recent_avg_contrib >= (num_coop + num_cond) * 0.5
       (i.e., there are some reliable cooperators and the group has not collapsed), then choose D to harvest their contributions.
   - Maintenance and repair rules (when to cooperate despite being exploitative):
     - Maintenance (prevent collapse): If we observe a sudden dip in contributions:
       - If recent_avg_contrib has fallen by more than 1 contribution relative to the average over the full history, or last_total_contrib < max(1, recent_avg_contrib - 1), then cooperate this round with probability 1 if we believe the collapse was partly triggered by our defection (see retaliation check below); otherwise cooperate with small probability epsilon.
     - Repair (recover from sustained collapse): If average total contributions over the last collapse_window rounds <= max(1, recent_avg_contrib/2) for at least collapse_window rounds, enter repair mode: cooperate for repair_len consecutive rounds to signal rebuilding, then exit repair mode and resume exploitation.
   - Retaliation detection and defensive switch:
     - If a substantial fraction of opponents (>= ceil(n/2) - 1) decrease their cooperation in the round immediately after we defect or after we started exploiting (i.e., clear coordinated punishment), assume broad retaliation/punishment. In that case switch to permanent defection for the remaining rounds (except if repair by occasional cooperation is clearly effective). The logic: avoid cooperating if the group will punish any cooperative attempt.
   - Selective forgiveness / variability:
     - If only a minority punish (one or two players), ignore them and continue to defect; use occasional cooperation (probability epsilon) to avoid triggering long punish cycles and to re-test whether cooperative players resume cooperating.

4. Special treatment of unconditional cooperators and one-shot defectors
   - Unconditional cooperators (f_j very near 1): exploit aggressively by defecting every non-maintenance, non-repair, non-endgame round. Do not attempt to punish them — they are a stable income source.
   - Persistent defectors (f_j near 0): never cooperate to "win no-loser" contests trying to rehabilitate them; they provide no reason to risk cooperation.

Randomization
- To avoid being exploited by complicated conditional strategies that try to set traps, add small randomness:
  - When not in probe, repair, or endgame phases, cooperate with probability epsilon only when maintenance rule suggests cooperation with probability <1. Otherwise, act deterministically per the rules above.

Edge cases
- Very short games (r <= P): follow probe logic until the last round, but still defect on the final round. If r <= 2, defect on round r and cooperate round 1 only if r>1 and P>=1.
- If k is very low (k/n close to 0): the public good yields little benefit, so reduce maintenance and repair aggressiveness (interpret recent_avg_contrib signals more conservatively) — effectively, default to defect more often. Concretely: if k/n < 0.25 then halve repair_len and set epsilon = 0.02.
- If nearly everyone defects in probe (everyone f_j <= theta_low): stop cooperating altogether after probe — permanent defection except for endgame is identical.

Why this is exploitative and robust
- Exploitative: SECC seeks to defect by default and only pays the cooperation cost when doing so is necessary to keep a profitable stream of contributions from others. It targets cooperators for harvesting and avoids costly unconditional cooperation except when repair/maintenance is required to sustain future exploitation.
- Adaptive: initial probe collects behavioral data; classifications guide whether to exploit, attempt repair, or retreat to permanent defection. The strategy responds to both sudden collapses and sustained punishment.
- Robust: small randomized cooperation prevents easy exploitation by complex conditional strategies that can manipulate deterministic patterns. Endgame defection avoids last-round losses. Parameters scale with r so the approach works for short and long tournaments.

Operational pseudocode (concise)
- Initialize P, theta_high, theta_low, repair_len, endgame_len, epsilon.
- For each round t:
  - If t > r - endgame_len: play D.
  - Else if t <= P: play C.
  - Else:
    - Update f_j, classify opponents, compute recent_avg_contrib and last_total_contrib.
    - If broad retaliation detected => switch to persistent D.
    - If in repair mode => play C for repair_len rounds then exit repair.
    - Else if sudden collapse detected => play C (deterministically if collapse seems caused by us, else with prob = epsilon).
    - Else if num_coop >= 1 and group contribution level acceptable => play D (exploit).
    - Else if few cooperators and group unstable => cooperate occasionally with prob epsilon to probe.
    - Default => play D.

Summary rule-of-thumb
- Cooperate only to gather information (small probe) or to repair/maintain a profitable pool of contributors when necessary; otherwise defect to harvest. If exploitation provokes broad punishment, retreat to permanent defection. Use small random cooperation to stay unpredictable.
'''

description_EXPLOITATIVE_118 = '''
Strategy name: Adaptive Exploiter (targeted free-riding with limited retaliation)

Summary objective (exploitative): maximize my own cumulative payoff by free-riding on players who reliably contribute, while avoiding long, mutual losses from being punished by retaliators. Exploit unconditional cooperators aggressively, keep reciprocators mildly satisfied with occasional cooperation, punish targeted retaliators briefly, and always defect in the final rounds (no future to lose).

Parameters derived from game inputs (use these formulaically so strategy depends only on parameters + history)
- n, r, k given by the tournament.
- Window for statistics W = max(3, floor(r/6)).
- Initial probing phase length E = min(5, max(1, floor(r/10))).
- Endgame threshold RG = min(2, floor(r/10)) — last RG rounds are endgame.
- Max punishment length P = min(3, r) (cap on how long I punish any single player).
- Thresholds (fixed constants): high_rate = 0.9, low_rate = 0.1, responsive_threshold = 0.6, keep_coop_prob = 0.2 (small cooperation probability to keep reciprocators from switching off).

Book-keeping (maintain from history)
- For each player j ≠ me:
  - coop_rate_j = fraction of rounds (use last W rounds unless fewer exist) where j contributed.
  - responsiveness_j = fraction of rounds where j’s action in round t equals my action in round t-1 (lag-1 match), measured over last W rounds.
  - last_action_j = j’s action in the most recent round.
- my_recent_actions = my actions in last W rounds.
- recent_group_contrib = average fraction of players (excluding me) contributing in last W rounds.

Decision rules (applied each round t from 1..r)
1. Endgame: if t > r - RG (i.e., in the last RG rounds), play D (defect) always. No future to enforce cooperation.

2. Exploration (first E rounds): cooperate with fairly high probability to elicit information:
   - In rounds 1..E, play C with probability 0.7 and D with probability 0.3.
   - Record others’ responses to build coop_rate_j and responsiveness_j.

3. Classification (after exploration and continually updated):
   - Unconditional Cooperator if coop_rate_j ≥ high_rate and responsiveness_j ≤ (responsive_threshold - 0.05). (They contribute almost always regardless of me.)
   - Reciprocator if responsiveness_j ≥ responsive_threshold. (They tend to mirror my prior move.)
   - Defector if coop_rate_j ≤ low_rate. (They almost never contribute.)
   - Otherwise: Uncertain/Conditional.

4. Core exploitation logic (non-endgame rounds after exploration):
   - If there exists at least one Unconditional Cooperator and no Reciprocators:
     - Play D (always defect). Free-ride on unconditional cooperators; they won’t adapt.
   - Else if the majority (≥ 50%) of other players are Defectors:
     - Play D (defect). No point cooperating if group is mostly defecting.
   - Else if there is at least one Reciprocator:
     - Goal: exploit reciprocators but avoid triggering persistent punishment.
     - Compute recent_others_coop = recent_group_contrib (over last W).
     - If recent_others_coop is high (≥ 0.6):
       - Play D with high probability (0.8) and C with probability 0.2 (keep_coop_prob). The small cooperation probability keeps reciprocators from switching to permanent punishment while mostly free-riding.
     - If recent_others_coop is low (< 0.6):
       - Play D (defect) to avoid wasting tokens when group payoff is low.
   - Else (mixed or mostly Uncertain players):
     - If there are one or more unconditional cooperators, defect to exploit them while observing others.
     - Otherwise (no clear cooperators or reciprocators), defect by default (conservative exploitation).

5. Targeted punishment and forgiveness (to handle retaliators and to limit mutual loss)
   - If in the previous round I played D and some player j responded by defecting while previously they had been cooperating (i.e., they appear to be punishing me), mark j as currently punishing.
   - When a player j is punishing:
     - Punish back by defecting against them (i.e., continue to play D) for up to P rounds after the initial offense (this is a targeted, brief retaliation).
     - Stop punishing j earlier if j returns to cooperating at least once during the punishment window.
     - After punishing for up to P rounds or after seeing j cooperate, forgive: resume exploitation rules (do not carry permanent grudges).
   - Rationale: short targeted punishments deter persistent exploiters who would otherwise punish me forever, but limiting punishment prevents endless mutual defection.

6. Tie-breaking / uncertainty rule
   - If classifications are ambiguous or statistics unstable (too few rounds in history), prefer defection (D). Default to defection unless there is a clear, exploitable set of cooperators and no reciprocators.

7. Additional practical rules
   - Never let a single long punishment spiral continue beyond P rounds—cap losses.
   - Update classifications each round; switch between modes as others' behaviors change.
   - Always remember to defect in final rounds (endgame), regardless of past.

Why this is exploitative and robust
- Exploitative: I defect whenever I can safely free-ride (against unconditional cooperators and when reciprocators are absent). When reciprocators exist, I still free-ride most of the time by defecting with high probability while using a small cooperation probability to avoid sustained retaliation.
- Adaptive: I learn classifications from observed histories and change behavior accordingly; I probe early to gather signal; I respond to changes in others’ behavior.
- Robust: I treat unknowns conservatively (defect), use short, targeted punishments to handle retaliators but cap those punishments to avoid mutual loss, and I always defect in the final rounds to capture one-shot gains.
- Parameterized only by n, r, k (used to set window sizes and endgame length) and by observed history.

Behavioral summary (short)
- Round 1..E: probe (mostly cooperate) to identify types.
- After probe: classify players as Unconditional Cooperator, Reciprocator, Defector, or Uncertain.
- If unconditional cooperators exist and no reciprocators → always defect (exploit).
- If reciprocators exist → defect most of the time but cooperate occasionally (prob ≈ 0.2) to avoid permanent punishment.
- If group mostly defects → defect.
- Use brief (≤ P rounds), targeted punishment when someone punishes me; forgive quickly to resume exploitation.
- Last RG rounds: always defect.

This strategy maximizes exploitation of naive cooperators, extracts value from semi-cooperative groups by probabilistic free-riding, and avoids being locked into mutual losses with responsive punishers.
'''

description_EXPLOITATIVE_119 = '''
High-level idea
- Continuously estimate how each other player’s probability of contributing next round depends on my last action. In each round choose the action (C or D) that maximizes my immediate expected payoff given those empirical predictions, while retaining a small, decaying probe probability to learn and to exploit unconditional cooperators. If the group demonstrably retaliates to my defections (they reduce their cooperation after I defect), prefer cooperation to avoid costly punishment. Always defect in the final round; near the end reduce probing.

Definitions I track (computed from complete public history)
- For each opponent j and for each of my previous actions a ∈ {C, D} keep:
  - N_a = number of rounds so far in which I played a (global, same for all j).
  - N_j(a) = number of those rounds in which j played C.
  - Estimate p_j(C | I = a) = N_j(a) / N_a (if N_a = 0, treat as unknown).
- Group-level predictors:
  - p_group(C | I = a) = average_j p_j(C | I = a).
- Unconditional cooperation rate for j: p_j = total times j played C / total rounds observed.

Parameters (fixed from the start; choose modest/default values)
- Exploration (probing) schedule epsilon(t): epsilon_t = min(0.15, 0.5 / sqrt(t)), where t is current round index (t = 1 is first round). This decays with time so we probe less as we learn.
- Retaliation threshold delta = 0.06 (tunable): if p_group(C | I = D) < p_group(C | I = C) - delta we call the group “retaliatory”.
- Exploit threshold for unconditional cooperators: consider j an “unconditional cooperator” if p_j ≥ 0.95 and N_total_j ≥ max(4, r/10).
- Endgame horizon H_end = 2: in the last H_end rounds always defect. (If you want more risk-averse, increase H_end.)

Per-round decision procedure (for round t = 1..r)
1. Edge cases
   - If t = r (last round) or t > r - H_end: choose D (defect).
   - If t = 1 (no history): choose C (start cooperatively to avoid immediate irreversible punishment and to collect baseline data).
2. Update the statistics defined above from all observed rounds so far.
3. If there are identifiable unconditional cooperators and the group is non-retaliatory:
   - If any opponents satisfy “unconditional cooperator” and p_group(C | I = D) ≥ p_group(C | I = C) - delta (i.e., they do not reduce cooperation when I defect), then choose D (exploit them). Exception: with small probability epsilon_t take the opposite action (C) to keep learning.
4. Otherwise compute my expected immediate payoff under the two candidate actions, using empirical predictions:
   - Let S_C = sum_j p_j(C | I = C) (use p_j if conditional estimate unavailable).
   - Let S_D = sum_j p_j(C | I = D) (use p_j if conditional estimate unavailable).
   - Expected payoff if I play C: U_C = (k/n) * (1 + S_C)  [since I pay 1 and get share of total = k/n * (1 + S_C)]
   - Expected payoff if I play D: U_D = 1 + (k/n) * S_D
   - Compare:
     - If U_D > U_C + 1e-6, choose D (defect).
     - If U_C > U_D + 1e-6, choose C (cooperate).
     - If tie (within numerical tolerance), choose D (exploit tie).
   - Implement exploration: with probability epsilon_t flip the chosen action (i.e., probe).
5. Retaliation safety override
   - If the group is classified as retaliatory (p_group(C | I = D) < p_group(C | I = C) - delta) and U_D > U_C but the margin U_D - U_C is small relative to expected future losses (i.e., the group’s drop in cooperation per my defection × k/n × remaining rounds is larger than gain), then switch to C. Concretely:
     - If group is retaliatory and U_D - U_C < ( (p_group(C | I = C) - p_group(C | I = D)) * (k/n) * (r - t) / 2 ), choose C (forgive/avoid short-term gain that causes long-run loss).
   - This prevents naive repeated defection that triggers stable punishment.
6. Learning and bookkeeping
   - After playing the chosen action and observing the round, update N_a and N_j(a) for all j and repeat next round.

Intuition and properties
- Exploitative bias: the core decision rule directly compares immediate expected payoffs using how others are predicted to behave after my actions. If others keep cooperating despite my defections, I will defect and free-ride. If others punish me by reducing their cooperation after I defect, I cooperate to avoid being exploited by their retaliatory dynamics.
- Adaptive: uses empirical conditional probabilities, so it automatically adapts to unconditional cooperators, conditional cooperators (tit-for-tat types), stochastic players, and noisy strategies.
- Robust: the retaliation safety override and decay of exploration reduce the danger of being trapped by a single probe into permanent punishment. Defection in the final rounds is enforced to avoid endgame exploitation by others.
- Probing: small, decaying epsilon ensures I continue to discover whether opponents are exploitable while limiting needless losses.
- Targeted exploitation: unconditional cooperators are identified and exploited when safe (non-retaliatory environment). If most opponents are exploiters/defectors, the expected-payoff rule will choose D and avoid cooperating unnecessarily.

Notes on implementation choices
- The specific numeric values (epsilon schedule, delta, H_end) are recommended defaults; they can be tuned to the tournament environment but should not depend on opponent-specific private information.
- Use Laplace smoothing (add one pseudo-count) if you prefer more stable early estimates for conditional probabilities.
- The strategy optimizes immediate expected payoff while guarding against future retaliation; it is intentionally exploitative but designed to avoid costly, long-lived punishment cycles.
'''

description_EXPLOITATIVE_120 = '''
Goal statement (exploitative mindset)
- Maximize my total payoff by (a) free‑riding when there are reliably cooperative opponents, (b) avoiding long runs of mutual defection that leave everyone (including me) at the low benchmark payoff, and (c) using short, credible punishments and forgiveness to keep conditionally cooperative players supplying public goods that I can occasionally exploit. Never sacrifice long‑run earnings for moral parity: treat cooperation as an instrument to induce others to contribute so I can profit.

Notation and derived parameters I use
- n, r, k are given by the tournament.
- t = current round index (1..r).
- History: for each past round I know each player’s action (C or D).
- W = min(10, r) — sliding window length for recent statistics.
- ProbeRounds = min(4, max(1, floor(r/8))) — initial cooperation-only probing period.
- Endgame = min(3, r) — last rounds in which I defect unconditionally.
- ExploitHigh = 0.80, ExploitLow = 0.60 — thresholds for calling a player “reliably cooperative” or “fallen.”
- PunishLength = 2 (short, credible punishment).
- ForgiveAfter = 1 (rounds of cooperative try after punishment).
- All thresholds are fixed given n,r,k (no side channel).

Decision rules (pseudocode-style, natural language)

1) Endgame
- If t > r - Endgame (i.e., in the final Endgame rounds), choose D (defect) unconditionally. There is no future to influence.

2) Probing and data collection
- If t ≤ ProbeRounds, choose C (cooperate). Purpose: build credibility and collect data on who cooperates by default and who responds to others.

3) Compute recent statistics (for t > ProbeRounds)
- For each opponent j compute cr_j = fraction of rounds they chose C in the last W rounds.
- Compute avg_others = average of cr_j across all other players.
- Compute myRecentDefections = number of rounds I chose D in last W rounds.
- Compute responsiveness estimate (optional simple measure): for each player, compare their cooperation rate following rounds where I cooperated vs when I defected; if they reduce cooperation materially after my defection, mark them “retaliatory/conditional.”

4) Exploit reliably cooperative players (primary exploit routine)
- If there exists at least one opponent j with cr_j ≥ ExploitHigh and that player is not classified as strongly retaliatory, then:
  - While that player’s cr_j ≥ ExploitLow and t ≤ r - Endgame:
    - Choose D (defect) to free‑ride on others’ contributions.
    - After each round re‑compute cr_j. If cr_j falls below ExploitLow, go to step 5 (punish/restore logic) or step 6 (conditional cooperation) as appropriate.
  - Rationale: one or more high‑rate cooperators provide a steady stream of public contributions I can periodically exploit. I stop exploiting when their cooperation visibly drops.

5) Punish and restore (short, credible punishment)
- If a previously exploitable player’s cr_j falls below ExploitLow (or group cooperation collapses after my defections), respond with short punishment:
  - Play D for PunishLength rounds (credible, predictable).
  - Then play C for ForgiveAfter rounds to test whether cooperation returns.
  - If cooperation from that player/group returns (cr_j rises back above ExploitLow), resume exploitation loop (step 4) but be more conservative (require cr_j ≥ ExploitHigh again).
  - If cooperation does not return after one punishment+forgiveness cycle, switch to conditional cooperation mode (step 6) or pure defection if group is hostile.

6) Conditional cooperation default (when no clear exploitable targets)
- If no reliably exploitable players exist (no cr_j ≥ ExploitHigh), use a conservative conditional rule:
  - If number of players who cooperated in the previous round ≥ ceil((n-1)/2) (i.e., a simple majority of others cooperated last round), play C this round.
  - Otherwise play D this round.
  - Exception: if a majority of opponents are classified as strongly retaliatory (they cut cooperation quickly after I defect), bias toward cooperating (choose C) to avoid being punished, because expected long‑run payoff is higher by keeping cooperation with retaliators.
  - Rationale: this rule tries to sustain cooperation when it is common, but avoids being the only cooperator.

7) Recovery from noise and randomness
- If opponents’ behavior is highly noisy (avg_others swinging widely and no stable cr_j), default to a slightly exploitative safe rule:
  - Cooperate once every (1 + floor(n/3)) rounds to probe; otherwise defect. This preserves some chance to elicit cooperation but limits exposure to prolonged exploitation.
- If almost everyone is defecting (avg_others very low, e.g., < 0.2), defect until a stable improvement appears.

8) Special handling for very short games
- If r ≤ ProbeRounds + Endgame (very short total length), shorten the probing window accordingly and bias earlier toward defection except the very first round where I still cooperate once to test reactions. Remember: last rounds are always D.

Why this is exploitative and robust
- Exploitative: the policy seeks out reliably cooperative opponents (cr_j ≥ 0.80), then defects repeatedly to free‑ride so long as they keep contributing; it only stops when their cooperation drops, maximizing immediate gains from naive cooperators.
- Robust: the policy probes early to classify opponents, uses short punishments (limiting losses from over‑punishing), and forgives to restore cooperation so conditional cooperators remain profitable. It detects retaliators and shifts toward cooperation with them (to avoid costly punishments). It defects in the final rounds to avoid being suckered by endgame behavior.
- Adaptive: decisions depend only on observed past actions and computed cooperation rates and responsiveness; no assumptions about norms or coordination are required.

Edge cases summary
- Round 1: cooperate (credibility probe).
- Last Endgame rounds: defect always.
- If a player is highly cooperative but strongly retaliatory (i.e., they stop cooperating after I defect), do not attempt extended exploitation; prefer conditional cooperation to avoid damage.
- If everyone defects persistently, defect too (no incentive to unilaterally cooperate).
- If behavior is noisy, limit exposure by probing infrequently and otherwise defecting.

Implementation notes (for clarity)
- All thresholds (ExploitHigh, ExploitLow, W, ProbeRounds, PunishLength, Endgame) are fixed given n,r,k; they can be tuned for specific tournament meta but are conservative defaults to balance exploitation and survival.
- The core mechanism is: probe → identify exploitable cooperators → free‑ride while cooperators remain reliable → punish briefly if cooperation collapses → forgive and try to restore. If no exploitable targets, use majority‑conditional cooperation with awareness of retaliators.

This strategy maximizes exploitation opportunities while preserving long‑run earnings against conditional cooperators and avoiding being trapped by punishing opponents.
'''

description_EXPLOITATIVE_121 = '''
Name: Selective Opportunistic Free‑rider (SOF)

Goal (exploitative mindset)
- Maximize my own cumulative payoff by free‑riding on others’ contributions whenever a high level of cooperation exists, while minimizing the chance that others permanently abandon cooperation or that I get “used” by conditional punishers. I will contribute rarely and only when it is likely to sustain or restore a high contribution environment that I can exploit.

Common helpers computed from parameters and history
- n, k, r: game parameters available to me.
- W = min(10, r) — lookback window (use short memory so I adapt quickly).
- For each opponent j, coop_rate_j = fraction of rounds in the last W rounds in which j contributed.
- group_rate G = average_{j ≠ me} coop_rate_j (average of opponents’ recent contribution rates).
- last_round_contribs L = number of opponents who contributed in the previous round.
- strong_cooperators = set of opponents with coop_rate_j ≥ 0.8.
- tolerant_thresholds (fixed, simple, interpretable):
  - HIGH = 0.8 (very cooperative population)
  - MED = 0.4 (mixed)
  - LOW = 0.2 (mostly defecting)

Decision rules (what I do each round t)
1. Endgame rule (last round(s))
   - If t = r (the final round): defect (D). No future to maintain, so always defect last round.
   - If t > r − min(3, r) (the very last few rounds, e.g., last 1–3 rounds): progressively reduce cooperation to zero. Concretely, for t in {r − 2, r − 1} treat as if group cooperation is LOW (defect).

2. Initial probing
   - Round 1: defect. Use early rounds to observe. (Contributing without future benefit is purely costly.)
   - Rounds 2..min(W, r): continue with cautious probing: defect unless an obvious sustained majority cooperated previously (L ≥ ceil(0.75*(n−1)) and group_rate G ≥ HIGH), in which case cooperate once to check for stable cooperation.

3. Main adaptive rule (for intermediate rounds)
   - If G ≤ LOW: defect. The population is too uncooperative; contributing is wasted and encourages further losses.
   - Else if G ≥ HIGH:
     - The population is highly cooperative. Exploit at low cost:
       - Contribute only occasionally to keep others believing the cooperative environment persists.
       - Contribute with probability p_high = 0.25 (i.e., one contribution in ~4 rounds on average). If you prefer deterministic behavior: contribute on one in every 4 rounds (e.g., when (t mod 4) == 0).
       - Exception (targeted exploitation): if last round had L < ceil(0.5*(n−1)) (a one‑round drop), do not contribute that round (wait for stability).
   - Else (LOW < G < HIGH): mixed environment — conditionally free‑ride and test responsiveness.
     - If last round had a clear majority contributing (L ≥ ceil(0.6*(n−1))), cooperate this round with small probability p_mid = 0.10 (try to sustain cooperation if it just appeared).
     - Otherwise defect.
   - Targeted cooperation option: if strong_cooperators contains at least ceil(0.6*(n−1)) distinct opponents, then when those specific players contributed last round, I may cooperate with slightly higher chance p_target = 0.3 to keep that cooperative subgroup engaged while excluding low‑rate players.

4. Punishment and forgiveness (avoid being exploited by conditional punishers)
   - If after I start contributing occasionally my group_rate G falls sharply (decrease by ≥ 0.15 over W rounds), interpret that as either punishment or instability — stop cooperating entirely for the next W rounds (defect) to avoid being milked.
   - If some opponents are reacting to my single defections by retaliating (their coop_rate_j drops sharply immediately after I defected), mark them as “reactive punishers.” Against reactive punishers I will not try to placate them by extra contributions; instead I will defect until they show sustained cooperation again (coop_rate_j ≥ 0.8 over W rounds). Do not try to out‑compete punishers in generosity; they reduce my leverage.

5. Recovery and re‑entry
   - After a punishment window or a period of defecting, re‑test the environment with one cooperative probe round only if group signals a recovery (G rises above MED and L last round ≥ ceil(0.6*(n−1))). If the probe is followed by increased cooperation, resume opportunistic contributions per the main rule.

6. Robustness checks and noise tolerance
   - Use moving averages (W rounds) to avoid over‑reacting to one noisy round.
   - When switching from defect to cooperate or back, do it gradually (probabilities above) rather than all‑or‑nothing so accidental single missteps do not collapse the exploitation regime.

Rationale and exploitative alignment (short)
- I defect by default because instantaneous individual incentives favor defection; I only pay the cost of contributing when it is likely to keep many opponents contributing in future rounds so I can free‑ride most of the time.
- I contribute rarely (small fixed probabilities) when others are highly cooperative — this preserves a cooperative environment without matching others’ effort, so I get above‑average payoff.
- I punish quickly and withdraw contributions permanently or for a window if cooperation collapses or if punishers exploit attempts to placate them.
- I always defect in the last round(s) to avoid being exploited without future leverage.

Edge cases covered
- First round: defect (probe).
- Very short games (r ≤ W): use smaller lookback, but still defect first round and defect last round; allow at most one cooperative probe if many opponents show immediate cooperation.
- Last round(s): defect always in final round; taper cooperation in last few rounds.
- Noisy opponents: moving average W and probabilistic cooperation avoid over‑reaction.
- Targeting: if a clear subgroup is very cooperative, I will selectively cooperate when they did, to profit from them while excluding low contributors.

Implementation notes (for an AI agent)
- Keep lightweight statistics (per‑opponent coop_rate over last W rounds and simple deltas).
- Use simple fixed thresholds above; they do not require knowing opponents’ strategies in advance.
- Use randomness to avoid being exploited by precise retaliatory strategies.

Summary (one‑line)
- Default defect; occasionally make low‑frequency contributions when the group is stably cooperative (or when a large subgroup is), withdraw immediately and permanently for a window if cooperation falters or punishers are detected, always defect in the last round — in short, be a cautious, conditional free‑rider that pays small costs only to sustain exploitable cooperation.
'''

description_EXPLOITATIVE_122 = '''
Summary (mindset)
- Aim to maximize our own lifetime payoff by taking tokens when safe and only paying the contribution cost when that sacrifice reliably produces enough extra future public-good benefit from others to more than compensate.
- Exploit unconditional and slow/uncaring cooperators; avoid provoking punishers; collaborate only as much as needed to keep conditional cooperators contributing.
- Use a short probing phase to learn rates and responsiveness, then adapt behavior every round based on classifications and observed population cooperation.

Notation used below
- n, r, k: game parameters (players, rounds, multiplier).
- t: current round (1..r). remaining = r − t + 1.
- history: full matrix of past actions and payoffs.
- For each opponent j:
  - coop_rate[j] = fraction of rounds (so far) in which j contributed.
  - resp_up[j] = estimated increase in j’s cooperation probability after we cooperated last round vs after we defected (responsiveness to our action).
- pop_coop = fraction of players who contributed in the previous round (or average over last few rounds).
- Default numeric constants (tunable): probe_rounds = min(6, max(2, floor(r/10))); high_coop = 0.85; low_coop = 0.2; resp_threshold = 0.2; punisher_resp = 0.4; punisher_count_threshold = 0.3; maintenance_min_prob = 0.05.

Phase A — Probing and estimation (rounds 1..probe_rounds)
1. Purpose: learn who reliably cooperates, who responds to our moves, and who punishes.
2. Action rule for probes:
   - In each probe round, cooperate with probability 0.6 (or cooperate in 60% of probe rounds; defect otherwise). This biases us slightly cooperative to attract conditional/unconditional cooperators while still collecting signal.
3. After probe_rounds compute for each opponent:
   - coop_rate[j] over probe rounds.
   - resp_up[j] = P(j cooperates | we cooperated in previous probe round) − P(j cooperates | we defected in previous probe round).
   - Identify simple patterns such as immediate retaliation (if j defects in the round following our defect significantly more than baseline).

Phase B — Classification (after probes and continuously updated)
Classify each opponent j as one of:
- Unconditional cooperator: coop_rate[j] ≥ high_coop and resp_up[j] < resp_threshold. (gives often regardless of our action)
- Conditional cooperator: coop_rate[j] between low_coop and high_coop and resp_up[j] ≥ resp_threshold. (adjusts to others)
- Defector: coop_rate[j] ≤ low_coop and resp_up[j] < resp_threshold. (rarely gives)
- Punisher / Retaliator: resp_up[j] ≤ −punisher_resp OR shows a pattern of sustained reduction in cooperation for ≥2 rounds after our single defection.
Update these classifications every round using all observed data (use exponential weighting to give recent rounds more weight if desired).

Decision rules (applied every round t)
Edge-cases first
- Last round (t = r): always defect. (Backward induction and no future to influence.)
- Final few rounds: for rounds t where remaining ≤ 2, default to defect (reduce risk of last-round exploitation). Optionally allow a 1-round maintenance cooperation if many unconditional cooperators remain and you estimate one last payoff benefit, but default is defect.

Core decision flow (for rounds not in the forced last-round defect region)
1. If proportion of punishers among players ≥ punisher_count_threshold (default 30%):
   - Risk of group retaliation is high. Play conservative conditional cooperation to avoid mass collapse:
     - If pop_coop (previous round) ≥ 0.6, cooperate this round (to preserve cooperation).
     - Else defect this round.
   - Rationale: defection will trigger punishers and collapse group benefits; better to extract value via staying inside cooperative stream.

2. Else (few punishers):
   - If many unconditional cooperators exist (fraction U ≥ 0.35):
     - Exploit mode: defect by default to collect private token while still enjoying others’ contributions.
     - But maintain the pool by occasional “maintenance” cooperation so that unconditional cooperators do not switch off:
       - Cooperate with a small maintenance probability p_maint = max(maintenance_min_prob, 1 / max(5, remaining)).
         - Concretely: in each round, cooperate with probability p_maint; otherwise defect.
       - Monitoring rule: if within two rounds we observe a drop in unconditional cooperators’ coop_rates by more than 0.15, increase p_maint (double it) for the next few rounds to rebuild trust, then return to exploitation.
     - If U is extremely high (≥ 0.7) and remaining rounds are many (> 10), increase p_maint slightly (e.g., to 0.1) to reduce risk of gradual decay.

   - Else if majority are conditional cooperators (largest category is conditional_cooperator):
     - Matching / minimal-sustain cooperation:
       - Cooperate this round iff pop_coop (previous round) ≥ 0.5 (or if the average cooperation over last 2 rounds ≥ 0.5).
       - If you cooperate and observe that conditional cooperators increase their cooperation next round (resp_up averaged positive), keep cooperating while the marginal benefit (observed gain in future expected returns from their extra contributions) seems to exceed 1 token cost spread over remaining rounds. Practically: if their average responsiveness is small, revert to defect unless pop_coop high.
       - If we defect and see that conditional cooperators retaliate by dropping cooperation for multiple rounds, switch to short “contrition” phase: cooperate for 2 consecutive rounds to restore cooperation, then resume minimal-sustain policy.

   - Else (mostly defectors/no cooperators):
     - Always defect — no benefit to giving away tokens.

Adaptivity and continuous update
- Recompute coop_rate and resp_up every round using the full history (optionally with decay to emphasize recent rounds).
- Adjust maintenance frequency p_maint upward if cooperators’ rates decline following our defection; reduce p_maint slowly when exploitation returns profits.
- If you detect a coordinated strategy that punishes anyone who defects (population-level retaliation after any single defection), immediately switch into the conservative mode of rule (1) above until such pattern disappears.

Recovery / forgiveness
- If a transient mistake or exploratory defection triggers retaliation, use a short forgiveness sequence:
  - Cooperate for S = min(3, remaining−1) consecutive rounds, then resume normal policy.
- Do not allow infinite forgiveness: if a player continues to punish despite consistent cooperation, relabel them a punisher and avoid exploiting.

Parameter sensitivity to k, n, r (how parameters affect aggressiveness)
- Larger k (bigger multiplier) and many remaining rounds increase the value of building/maintaining cooperation. Raise thresholds for defecting and increase maintenance frequency when k is relatively large and remaining rounds > probe_rounds*2.
- Small k or few remaining rounds → be more exploitative (defect more often), because each contributed token yields smaller marginal group benefit or little time to recover costs.
- If n is large, individual maintenance contribution buys a smaller share of the public good (k/n small), so prefer exploitation unless many players are highly responsive.

Summary pseudocode (high level)
- Initialize probes; run probe rounds with 60% cooperation.
- Compute coop_rate and resp_up for each player; classify players.
- Every round t:
  - If t = r or remaining ≤ 2: defect.
  - Else update classifications.
  - If many punishers: play conservative conditional cooperation (cooperate if recent pop_coop ≥ 0.6).
  - Else if many unconditional cooperators: default defect but cooperate occasionally with small maintenance probability p_maint; ramp up maintenance if cooperators decline.
  - Else if majority conditional cooperators: cooperate only when recent pop_coop ≥ 0.5, use contrition if retaliation occurs; otherwise defect.
  - Else (mostly defectors): defect.
  - Continuously update and adapt thresholds based on observed responsiveness and how k, n, remaining rounds affect the payoff calculus.

Why this is exploitative and robust
- It extracts value from unconditional cooperators by defecting as often as safe, using only minimal costly contributions to keep them contributing.
- It avoids costly tit-for-tat wars with punishers by detecting and switching to conservative play when retaliators are present.
- It coerces conditional cooperators to keep contributing at near-minimal cost by matching the minimal cooperation necessary to keep their expected cooperation high.
- Probing and continuous reclassification allow adaptation to a wide range of stranger strategies without requiring communication or shared norms.

Tuning notes (for tournament use)
- If you know tournaments reward stability, bias probe cooperation upward and lengthen maintenance; if tournaments reward pure payoff taking, reduce maintenance and probe shorter.
- Use small randomization in maintenance and probing to prevent easy exploitation by deterministic opponents that try to mimic cooperators.
'''

description_EXPLOITATIVE_123 = '''
Name: Adaptive Exploitative Conditional Strategy (AECS)

Overview (one-line): Start “nice” to learn how others respond, estimate how many others will contribute conditional on my move, then usually defect when it raises my expected payoff while cooperating occasionally and strategically to keep conditional cooperators contributing — switch to all-defect in the final rounds.

Variables I track (per game):
- r, n, k (given).
- t: current round (1..r).
- history: for each past round s I store my action my_s and total contributions by others others_s (or each player’s c_j,s if available).
- Counts and running averages with simple smoothing (pseudocount α = 1) to avoid division-by-zero:
  - avg_others_if_I_cooperated = (sum of others_s over rounds where my_s = C + α*prior) / (count_rounds_I_cooperated + α)
  - avg_others_if_I_defected = (sum of others_s over rounds where my_s = D + α*prior) / (count_rounds_I_defected + α)
- Unconditional group cooperation rate = overall average of others_s / (n-1).
- A short moving window (last W rounds, W = max(3, floor(r/6))) to detect change.
- Small exploration probability ε = min(0.08, 4/r) (probe/exploit noise).
- Endgame window E = min(3, floor(r/10)) (final guaranteed defect rounds).

Decision rule (each round):
1. Endgame: If t > r - E:
   - Defect (D). Rationale: last rounds have no future return for building cooperation.

2. Probing initialization (first few rounds): For t = 1..T_probe where T_probe = min(6, max(2, floor(r/6))):
   - Use a simple probing pattern to elicit responses:
     - Round 1: Cooperate (C) to appear non-hostile and measure baseline.
     - Alternate: If t is even, Defect (D); if odd, Cooperate (C). This yields some rounds of me cooperating and some defecting to estimate conditional responses.
   - (If exploration ε triggers, flip action with probability ε.)

3. After probe (t > T_probe):
   - Estimate expected number of other contributors next round under two hypothetical choices:
     - Exp_others_if_C = avg_others_if_I_cooperated (use moving window if recent change detected).
     - Exp_others_if_D = avg_others_if_I_defected.
   - Compute my expected payoffs:
     - Payoff_if_C = 0 + (k/n) * (1 + Exp_others_if_C)
     - Payoff_if_D = 1 + (k/n) * Exp_others_if_D
   - If Payoff_if_C >= Payoff_if_D + margin:
     - Cooperate. margin = 0.01 to prefer defection when payoffs close.
   - Else:
     - Defect.

   - Exception: If a sustained sharp drop in group cooperation occurs right after I defected (detected as average others in last W rounds much lower than longer-run average by threshold γ = 0.25), do a short “apology and rebuild”:
     - Cooperate for next R_rebuild rounds (R_rebuild = 1 or 2) to re-trigger conditional cooperators; then re-evaluate. This avoids permanent collapse against many conditional reciprocators.

4. Randomization & forgiveness:
   - With small probability ε each round (except last E rounds), flip the intended action. This does two things:
     - Prevents exploitable deterministic patterns by highly adaptive opponents.
     - Provides occasional forgiveness to avoid endless retaliation loops.

Intuition and exploitation mindset (how/why this exploits others):
- The game’s unilateral incentive is to defect; many strategies will still contribute either unconditionally or conditionally. My goal is to maximize my personal payoff by free-riding whenever doing so does not cause a big enough reduction in others’ contributions to make cooperation profitable.
- I actively estimate how many others are likely to contribute depending on my own choice. If others’ behavior is largely independent of my choice (unconditional cooperators), I defect almost always to harvest their contributions. If others respond to my defection (conditional cooperators), I will sometimes cooperate to sustain enough contribution from them but only when their additional contributions make cooperating personally worthwhile.
- Probing rounds create the data needed to classify the group response pattern. Short rebuild/punishment responses limit long-term retaliation while still using cooperation sparingly as a bargaining tool to maintain profitable exploitation.
- The small randomized moves and forgiveness avoid getting trapped by complex punishers and make my behavior harder to fully exploit.

Edge cases and robustness:
- Very short games: For r <= T_probe, probing uses minimal rounds; in the final rounds automatic defection dominates (endgame). I bias toward defection when future is small.
- Shifting opponents: Moving-window averages enable adaptation if opponents change behavior mid-tournament.
- Noisy opponents: Pseudocount smoothing and ε-randomization make estimates stable.
- All-defector groups: If others are basically defecting (avg_others very low), my expected payoff calculation will prefer defecting — avoid wasting tokens.
- All-cooperator groups: If the data show others always cooperate when I cooperate and even when I defect, Payoff_if_D will usually be higher and I defect repeatedly to exploit them.
- Sophisticated punishers: The rebuild/punish rule prevents long, costly mutual defection — I try short punishments where necessary but prefer measured recoveries so I don’t lose by over-punishing.

Summary pseudocode (compact):
- If t in last E rounds: D
- Else if t <= T_probe: follow alternating probe (start with C)
- Else:
  - Compute Exp_others_if_C and Exp_others_if_D (with smoothing and windowing)
  - Compute Payoff_if_C and Payoff_if_D
  - If Payoff_if_C >= Payoff_if_D + 0.01: choose C
  - Else choose D
  - If recent sharp collapse after my defections: do 1–2 cooperative rebuild rounds
  - With probability ε flip chosen action

This strategy is exploitative because it actively chooses defection whenever historical evidence shows doing so yields higher expected personal payoff, while remaining adaptive and minimally cooperative only when necessary to sustain others’ contributions that I can exploit.
'''

description_EXPLOITATIVE_124 = '''
Summary (mindset): Probe early to identify which opponents will reliably cooperate, then free-ride on them as often as possible while maintaining just enough cooperation to keep conditional cooperators (reciprocators) supplying contributions when it is profitable to do so. Defect against confirmed defectors and in the final round(s). Always maximize my expected payoff given the data I have; explore rarely to keep beliefs honest.

Notation used in the rules below:
- n, r, k: game parameters (players, rounds, multiplier).
- t: current round (1..r). R_rem = r - t is rounds remaining after this one.
- For each other player j maintain counts from rounds so far:
  - N_j = number of past rounds observed for j.
  - C_j = number of times j cooperated (overall cooperation rate p_j = C_j / N_j).
  - C_after_myC_j = number of times j cooperated in a round immediately following a round in which I cooperated.
  - N_after_myC_j = number of rounds in which I cooperated and j’s behavior was observed next round.
  - C_after_myD_j and N_after_myD_j defined similarly (behavior following my defection).
- Estimate conditional probabilities with Laplace smoothing (avoid zero-division): 
  - P_j(coop | myPrev=C) ≈ (C_after_myC_j + 1) / (N_after_myC_j + 2)
  - P_j(coop | myPrev=D) ≈ (C_after_myD_j + 1) / (N_after_myD_j + 2)
- Responsiveness r_j = P_j(coop | myPrev=C) − P_j(coop | myPrev=D). Positive r_j means j is more likely to cooperate after I cooperated (reciprocal/conditional); negative r_j means j punishes my cooperation.
- Short defaults (tunable): T_probe = min(6, max(4, floor(r/4))). high_coop = 0.85, low_coop = 0.15, resp_delta = 0.25. Small exploration probability p_explore = min(0.05, 5/r). Maximum horizon of influence L_effect = min(3, R_rem) (how many future rounds a cooperation today is assumed likely to influence).

Decision-rule skeleton

1. First round and probing phase
- For rounds t ≤ T_probe:
  - Follow a pre-set probing pattern that alternates cooperation and defection (example: C, D, C, D, ... starting with C). The goal is to gather data about how each opponent responds when I cooperate versus when I defect. (If r is very small such that T_probe ≥ r, use a shorter probe of at most floor(r/2) rounds.)
  - Update all counts after each round.

2. Classification (continually updated after probes)
- For each opponent j compute:
  - overall cooperation p_j.
  - conditional difference r_j as above.
- Label players:
  - Unconditional cooperator: p_j ≥ high_coop.
  - Defector: p_j ≤ low_coop.
  - Reciprocal/conditional cooperator: r_j ≥ resp_delta and P_j(coop | myPrev=C) ≥ 0.5.
  - Punisher/negative-responder: r_j ≤ −resp_delta (they cooperate less after I cooperate or punish my defection in a pattern).
  - Otherwise: neutral/mixed.

3. Round-by-round action for t > T_probe (main exploitative policy)
- If t == r (last round) → Defect. (No future to influence; always defect.)
- Otherwise, compute an expected-gain comparison for cooperating now vs defecting:
  a) Immediate-round estimates (what others will do this round):
     - Estimate others’ cooperation rate in this round p_others_now as the average p_j across opponents (or weighted by recent rounds). This is independent of my current simultaneous action.
     - Immediate payoff if I cooperate now: U_immediate_C = −1 + (k/n) * (p_others_now*(n−1) + 1).
     - Immediate payoff if I defect now: U_immediate_D = 0 + (k/n) * (p_others_now*(n−1)).
     - Note: immediate difference is (k/n − 1) < 0, so immediate-only incentive favors defection.
  b) Expected future benefit from cooperating now:
     - My cooperation today can raise the probability that each reciprocal opponent j cooperates in future rounds by approximately r_j.
     - Approximate expected extra contributions from others over the next L_effect rounds = sum_j max(0, r_j) * L_effect.
     - Expected future benefit in payoff units ≈ (k/n) * (sum_j max(0, r_j) * L_effect).
     - (Conservative option: cap r_j at 0.5 and/or use a decay factor; the formula above is the practical estimate.)
  c) Total expected net gain from cooperating now (relative to defecting):
     - Delta ≈ (U_immediate_C − U_immediate_D) + (k/n) * (sum_j max(0, r_j) * L_effect).
     - If Delta ≥ 0 (or ≥ a small positive threshold τ to avoid noise, e.g., τ = 0.01), choose C; else choose D.
- Rationale: cooperate only when the future boost in others’ cooperation you reliably expect to trigger (multiplied by k/n and the remaining short horizon) compensates the immediate cost of cooperating.

4. Exploitation of classified types
- Unconditional cooperators: treat them as a guaranteed source of contributions and defect whenever the general decision-rule above allows defecting. To be safe against possible reclassification errors, once every M rounds (M = max(10, floor(r/10))) take a single cooperation round with probability 1 to re-check whether they remain unconditional (or with small exploration probability p_explore).
- Reciprocal/conditional cooperators: these are the ones to invest in maintaining. The expected-gain rule will naturally drive occasional cooperation if their summed responsiveness makes it profitable. When the rule calls for C, give them cooperation; when it calls for D, defect and rely on the fact that a small level of cooperation will be used sometimes to rebuild cooperation when profitable.
- Punishers/negative-responders: avoid cooperating to try to placate them; they will reduce their cooperation if I cooperate so cooperate only if Delta shows clear long-term benefit (rare).
- Defectors: always defect.
- Neutrals: treat as noise; rely on the computed Delta using their observed rates.

5. Exploration and re-evaluation
- With small probability p_explore each round (decaying as rounds pass), take the opposite action of what you would choose to test whether classifications were incorrect. Increase probing if the population behavior changes.
- Periodically (every M rounds as above) re-run the classification and reset T_probe–style alternating mini-probes if many players’ behavior appears to have changed.

6. Endgame and receding-horizon behavior
- Last round t = r: always defect.
- If R_rem is small (≤ 2), reduce L_effect accordingly and therefore require a much larger immediate responsiveness to justify cooperation. Practically this causes the strategy to converge to defection in the last few rounds (standard exploitative endgame).
- If tournament history suggests many opponents are still cooperating late (unexpected), the expected-gain rule will occasionally permit cooperation in penultimate rounds only if Delta ≥ τ.

7. Robustness safeguards
- Use Laplace smoothing for low-sample estimates so you don’t overfit early noise.
- Cap assumed influence of one cooperation on the whole population (e.g., sum_j max(0, r_j) ≤ n−1) to avoid wildly optimistic estimates.
- Keep p_explore nonzero so opponents that condition on you cannot permanently trick you; this also prevents being locked into incorrect classifications.

Behavioral summary / how this is exploitative
- The strategy actively searches for and identifies cooperators and reciprocity patterns, then free-rides whenever doing so yields higher immediate or future net payoff.
- It defects against confirmed defectors and in the last round with no future to influence.
- It cooperates only when the expected future lift in group contributions that I can reliably trigger (given observed responsiveness) compensates the cost. That preserves exploited cooperators but withdraws support if their behavior changes.
- It includes occasional probing so it doesn’t become exploitable itself by a manipulative opponent.

Practical parameter suggestions (default, can be adjusted based on r, n):
- T_probe = min(6, max(4, floor(r/4)))
- T_recheck_interval M = max(10, floor(r/10))
- high_coop = 0.85, low_coop = 0.15, resp_delta = 0.25
- p_explore = min(0.05, 5/r), τ = 0.01
- L_effect = min(3, R_rem)

This strategy is adaptive (uses observed conditional probabilities), exploitative (free-rides on cooperators and defects in the endgame), and robust (smoothing, periodic probing, caps on optimistic assumptions).
'''

description_EXPLOITATIVE_125 = '''
Calculated Exploiter — adaptive, history‑based strategy for repeated PGG

Principles (exploitative mindset)
- Your one‑shot incentive is always to defect; exploit cooperators as long as doing so does not trigger sustained punishment that costs more than the gain.
- Learn opponents’ responsiveness and forgiveness quickly, then exploit forgiving/uncaring players aggressively and play cautiously with punishers.
- Preserve a tiny “payment schedule” of occasional cooperation to keep conditional cooperators contributing, but defect whenever safe. Always defect in the final round.

Notation / derived values
- n, r, k: game parameters (players, rounds, multiplier).
- m = k / n (your private return from your own 1 token; 0 < m < 1).
- immediate_gain_defect = 1 - m (constant per round you would gain by defecting rather than cooperating).
- t = current round index (1..r).
- history contains for each past round: each player’s action (C/D).
- Let others = set of other players (size n-1).

Phases
- Exploration phase: rounds 1 .. E (learn opponents).
  E = max(1, min(6, floor(0.1 * r))). (At small r this is at least 1; at long games it is modest.)
- Exploitation phase: rounds E+1 .. r - L.
- Endgame phase: last L rounds: always defect.
  L = max(1, floor(0.05 * r)). (Conservative endgame window to avoid futile cooperation near the end.)

Metrics computed after each round (use sliding window W = min(20, max(5, t-1)) of most recent rounds)
- coop_rate_j = fraction of rounds in window that player j contributed.
- group_coop_rate = average over others of coop_rate_j (fraction of contributions by others).
- responsiveness_j = P(j contributes | you cooperated previous round) - P(j contributes | you defected previous round), estimated in window (if insufficient data, treat as 0).
- forgiveness_j = average number of rounds until j returns to contributing after they stop cooperating because of your defect (estimate how quickly they resume).
- fraction_conditional = fraction of others with responsiveness_j >= 0.15.
- fraction_unconditional_coop = fraction of others with coop_rate_j >= 0.8 and responsiveness_j ≈ 0 (high unconditional cooperators; unresponsive but cooperative).
- fraction_punishers = fraction of others who reduce coop rate by >= 0.3 following any detected exploitation by you and fail to return within 3 rounds (tend to punish).

Decision rules (per round)
1. Endgame: if t > r - L (in the last L rounds): play D (defect). (No future to preserve via cooperation.)

2. Exploration (t <= E):
   - Round 1: play C (signal cooperativeness and collect info).
   - In rounds 2..E: if last round the group cooperated (majority C among others), play C; else play D. (Quickly learn who responds.)

3. After exploration (exploitation phase):
   Compute metrics above on the sliding window.

   A. If fraction_punishers >= 0.35 (many punishers detected):
      - Play conservatively: mimic majority of others in the previous round (if majority of others contributed last round, play C; otherwise play D).
      Rationale: avoid provoking a coordinated punishment that would reduce long‑run payoff. This preserves cooperative returns where punishers sustain cooperation and avoids needless exploitation.

   B. Else if fraction_unconditional_coop >= 0.25 (there are clear unconditional cooperators):
      - Exploit unconditional cooperators aggressively:
        - Default action: D (defect).
        - However, to avoid triggering fragile conditional cooperators, periodically “top up” cooperation: every Cycle rounds cooperate once.
          - Cycle = max(3, ceil( (immediate_gain_defect) * 10 )). Practically this means defect 2–6 rounds and then cooperate one round.
        - If in last observed window group_coop_rate drops below 0.4 or conditional players begin to punish, switch to cautious mode (case A) for at least W rounds.
      Rationale: unconditional cooperators will keep contributing; defect most rounds to collect 1-m per round; occasional cooperation prevents some conditional cooperators from abandoning the group entirely.

   C. Else if fraction_conditional >= 0.25 (many conditional reciprocators who are forgiving):
      - Use an “exploit-and-repair” cycle tuned to forgiveness:
        - Default: D.
        - If you have defected S consecutive rounds since your last cooperation and the conditional players remain cooperative, then play C to repair relations.
        - S = min(4, max(1, round(mean_forgiveness))) where mean_forgiveness is the average forgiveness_j (if not well estimated, use S = 2).
        - If any substantial drop in group cooperation follows your defection (group_coop_rate falls by >0.2), immediately play C next round and remain in cautious mode for W rounds.
      Rationale: conditional, forgiving players will restore cooperation after a short exploitation spell; exploit repeatedly but short enough to prevent long retaliations.

   D. Else (no clear pattern; opponents are mostly defectors or too noisy):
      - Default to D (defect). If you detect a stable minority of cooperators who continue to contribute despite your defection, optionally switch to pattern B to milk them; otherwise keep defecting.

4. Reactive safety net (always active):
   - If you observe, immediately after one of your defections, that a majority of others switch to permanent or prolonged defection (group_coop_rate drops by >0.4 and stays low for two rounds), assume coordinated punishment likely. Revert to cautious mode (case A) for at least W rounds: play majority‑mimic (cooperate only if majority of others contributed last round), to rebuild cooperation.
   - If you detect targeted punishers who reduce their contribution only in response to your defection but not to others’ defection, consider switching to more cooperative policy with them by cooperating for at least 2 consecutive rounds to demonstrate non‑exploitative intent (this reduces their incentive to punish you).

Edge cases and special handling
- Very small r (r <= 5): behave simply—cooperate first round, then defect every round except when the group clearly continues to cooperate and you can squeeze a single cooperation late to maintain them. In practice, for tiny horizons exploit opportunities are limited; favor defection except 1–2 probing cooperations.
- n = 2 (pairwise public good = prisoner’s dilemma): same rules apply, but responsiveness_j and punishers fraction are just for single opponent; be more conservative with punishers detection since punishment capacity is higher in dyad.
- If k/n (m) is extremely high (m close to 1): the immediate_gain_defect = 1-m is small; cooperating loses less and may be safer. In this case increase S (cooperate more often) and increase exploration length by one round to determine whether full cooperation can be sustained profitably.

Summary rule-of-thumb (one‑line actionable)
- Probe at start; learn who is unconditional/cooperative, conditional/forgiving, or punitive. If many punishers: mimic majority to avoid long punishment. If many unconditional cooperators or forgiving conditional cooperators: defect most rounds and “repair” occasionally by cooperating on a fixed short cycle (default: defect 2–4 rounds, then cooperate 1 round) so you keep milkable cooperators contributing while minimizing punishment risk. Always defect in the last few rounds.

Why this is exploitative yet robust
- Exploiters are taking advantage of unconditional and forgiving cooperators by defecting most rounds to capture the 1-m gain repeatedly.
- The algorithm continuously monitors for and responds to punishment; it retreats to conservative play when punishers threaten collective breakdown, preserving long‑run payoff.
- Occasional cooperation (repair cycles) prevents simple trigger strategies from permanently excluding you, permitting repeated exploitation over the game rather than a single short‑lived gain.

This description is implementable using only the public history of actions and payoffs, depends only on n, r, k and observed behavior, and balances aggressive exploitation with safety to avoid costly coordinated punishment.
'''

description_EXPLOITATIVE_126 = '''
Name: Adaptive Exploitative Conditional Cooperator (AECC)

Goal (exploitative mindset): Extract as much private payoff as possible by free‑riding on others’ contributions, while avoiding sustained punishment that would destroy future exploitation opportunities. The strategy learns who punishes and who is reliably cooperative and then opportunistically defects when it is safe (or very profitable) to do so; it reconciles quickly if defection provokes durable collapse.

Key computed quantities (computed each round from history and game parameters n, k, r)
- gamma = k / n (the per‑player return from one contribution).
- immediate_gain = 1 - gamma (the one‑round benefit of defecting instead of contributing, holding others’ actions fixed).
- Window W = min(8, number of past rounds) for recent statistics.
- Probe rounds P = min(4, r-1) (early rounds used to build reputation and probe responses).
- Last‑round cooperators L = number of other players who contributed last round.
- For each other player j, compute:
  - coop_rate_j = fraction of j’s C in the recent window W.
  - coop_after_myC_j = fraction of times j cooperated in rounds immediately following rounds when I cooperated.
  - coop_after_myD_j = fraction of times j cooperated in rounds immediately following rounds when I defected.
- Responsiveness Δ_j = coop_after_myC_j − coop_after_myD_j (positive values mean j tends to reduce cooperation after my defection — a retaliator).
- Proportion_retaliators = fraction of other players with Δ_j > delta, where delta = 0.3 (sensitivity threshold; see adaptation below).
- RetaliatorTolerance = 0.2 + 0.6 * immediate_gain (higher when defecting is more profitable); used to decide how many retaliators we will tolerate while exploiting.

Phases and decision rules

1) Endgame handling
- If t = r (final round): Defect. (No future rewards/punishments to fear.)
- If t = r − 1 (penultimate round): Defect unless ALL other players have never defected in the entire history (i.e., they are perfect unconditional cooperators). Rationale: little future to recover from punishment; exploit naive cooperators.

2) Very short games
- If r ≤ 3: Defect every round. (In tiny horizons punishment is ineffective; exploitation dominates.)

3) Probe / reputation build (rounds 1 .. P)
- If r > 3:
  - Cooperate for the first P−1 rounds to build a cooperative reputation and collect baseline statistics.
  - On round P perform one deliberate probe defection (play D). This single defection reveals who is responsive/retaliatory without immediately destroying long‑run trust if many are forgiving.

4) Main adaptive exploitation loop (rounds after probing, excluding endgame)
At each round t (after probes and not in endgame):
- Recompute the recent statistics above using window W.
- If L = 0 (no one cooperated last round): defect (no public good to free‑ride).
- Else if nearly everyone is unconditional defector (all coop_rate_j < 0.1): defect.
- Else compute proportion_retaliators.
  - If proportion_retaliators < RetaliatorTolerance AND L ≥ ceil((n−1)/2):
    - Exploit: Defect this round. Rationale: many others contributed last round and too few retaliate for defection to cause permanent collapse; take the one‑round gain.
    - Enter “opportunistic follow‑up”: continue to defect in subsequent rounds while the following conditions hold:
      - Others continue to contribute at roughly pre‑exploit levels (their coop_rate over the last W rounds remains within 15% of the baseline before we first exploited), AND
      - proportion_retaliators remains < RetaliatorTolerance, AND
      - we are not in endgame.
    - Stop opportunistic follow‑up and move to reconcile if others’ cooperation rates drop substantially or proportion_retaliators rises above RetaliatorTolerance.
  - Else (too many retaliators or fragile cooperation):
    - Cooperate this round. Rationale: maintaining cooperation yields higher long‑run exploitation than provoking a collapse to mutual defection.

5) Detecting and responding to punishment cycles (forgiveness policy)
- If after one of our defections a significant drop in others’ cooperation occurs (group average cooperation drops by > 20% from the round before our defection):
  - If drop appears to be targeted (high proportion_retaliators), immediately reconcile:
    - Cooperate for up to 2 consecutive rounds (or until group cooperation restores to within 10% of pre‑defection baseline) to re‑establish trust.
  - If drop is small or ephemeral, stay in opportunistic mode if other conditions permit.
- If reconciliation does not restore cooperation after 2 rounds (cooperation stays low), switch to default defection until you observe a sustained recovery (two rounds of increased cooperation), then start the probe cycle again.

6) Re‑probing and adaptation over long history
- Every T_reprobe = 10 rounds (or every time the group composition of behaviour shifts), perform a light re‑probe: defect one round after two consecutive cooperations to refresh estimates of responsiveness. Use observed responses to update Δ_j and proportion_retaliators and adjust RetaliatorTolerance behavior.

7) Special cases and safety net
- If you detect a player who is an unconditional cooperator (coop_rate_j > 0.95 and Δ_j ≈ 0): you can target exploitation more aggressively when that player is among the contributing majority; but never allow such exploitation to produce a high proportion of retaliators.
- If the group has a coalition of strong retaliators (proportion_retaliators > 0.6), switch to mostly cooperating to harvest steady mutual cooperation (it is more profitable long term than a punished defector trajectory).
- In the face of noisy or random opponents (high variance, no clear Δ_j pattern), favor defection (exploit randomness) unless group cooperation is very stable.

Why this is exploitative and robust
- Exploitative: the strategy actively defects when it detects safe opportunities to free‑ride (many contributors, few punishers), and it takes advantage of unconditional cooperators.
- Robust/adaptive: it does not blindly defect; it learns which players punish and which forgive, adapts thresholds based on immediate_gain = 1 − gamma (more aggressive when defection is more profitable), and reconciles quickly when defection provokes durable retaliation so as to restore future exploitation opportunities.
- Tournament‑safe: begins by building a cooperative reputation (so it can exploit naive cooperators), probes to detect punishers, and alternates exploitation and reconciliation to maximize cumulative payoff against a wide variety of independent strategies.

Concise pseudocode form (natural language)
1. Compute gamma = k/n, immediate_gain = 1 − gamma. Set P, W, delta = 0.3, RetaliatorTolerance = 0.2 + 0.6*immediate_gain.
2. If r ≤ 3: always D.
3. If t = r: play D. If t = r−1: play D unless everyone has never defected.
4. Rounds 1..P−1: play C (if r > 3). Round P: play D (probe).
5. For t > P and t < r−1:
   a. Update coop statistics using window W and compute proportion_retaliators.
   b. If L = 0 or all others are near‑defectors: play D.
   c. Else if proportion_retaliators < RetaliatorTolerance and L ≥ ceil((n−1)/2): play D and stay in opportunistic mode while group cooperation remains high.
   d. Else play C to preserve cooperation.
   e. If a defection is followed by a large drop in group cooperation, cooperate for up to 2 rounds to reconcile; if cooperation does not recover, switch to defection until recovery is observed.
6. Periodically re‑probe (every ~10 rounds) with a single defection after two cooperations to re‑estimate responsiveness.

Summary principle: Be cooperative long enough to be trusted and to identify who punishes; defect opportunistically when a sufficiently large cooperative majority exists and too few opponents are retaliatory to make defection costly in expectation; when defection generates punishment, reconcile quickly to restore long‑run exploitation opportunities.
'''

description_EXPLOITATIVE_127 = '''
Name: Adaptive Prober–Exploiter with Conditional Cooperation (APEC)

Summary goal: Extract surplus from players who keep contributing while avoiding sustained punishment from conditional cooperators. Use a short, deterministic probe early to detect whether the group contains punishers/conditional cooperators; if not, free-ride. Continuously monitor reactions to defections and switch to a reciprocity-preserving mode if defections provoke retaliation. Always defect in the final rounds when future retaliation loses credibility.

Parameters (computed from game parameters r, n, k)
- Probe length P = min(3, r). (Rounds 1–P form the probing phase when r>=3.)
- Endgame window E = min(3, r). In rounds t with t > r − E, always defect.
- Punisher detection threshold τ = 0.20 (20% of other players behaving as punishers is enough to treat the group as punisher-prone).
- Retaliation sensitivity δ = 0.20 (a ≥20% drop in average contributions by others after one of our defections counts as retaliation).
- Maintenance probing frequency S = max(6, floor(r/10)) (in exploit mode, perform occasional single cooperations at this cadence to re-test the environment).
- Forgiveness: when in reciprocal mode, allow a single missed contribution from the group without switching modes immediately.

Decision rules (round-by-round)
1. Endgame override
   - If current round t > r − E (i.e., in the last E rounds), play D (defect). The final round is always D.

2. Probing phase (rounds 1..P)
   - If r = 1: play D (single-shot game).
   - If P = 1 (r≥1 but P=1): play C in round 1 to avoid immediate universal defection and gather one data point.
   - If P = 3 (typical case when r≥3), use this deterministic pattern:
     Round 1: C
     Round 2: D (single explicit probe-defection)
     Round 3: C
   - After round 3 (or after whatever probe rounds exist), evaluate responses:
     - For each other player j, compare j's contribution in round 3 to j's contribution in round 1.
     - If j reduced contribution after our round-2 defection (i.e., j contributed in round 1 but not in round 3), count j as a punisher/conditional responder.
     - Let P_count = number of punishers among the n−1 others.
     - If P_count / (n−1) ≥ τ, set Mode := Reciprocal (punisher-prone group).
     - Otherwise set Mode := Exploit.

3. Exploit mode (Mode := Exploit)
   - Primary behavior: play D every round to maximize immediate payoff (free-ride on others).
   - Continuous monitoring:
     - After any round where we play D, compare average contribution of the others in the next round to their average contribution in the round before our defection (or to a recent baseline average). If the average contribution falls by ≥ δ, treat this as evidence of retaliation and immediately switch Mode := Reciprocal.
   - Maintenance probing:
     - To detect late-arriving punishers or changes in the group, occasionally play C (one round) every S rounds (one-shot cooperation) and observe whether that induces a detectable change; if that cooperation causes others to stop cooperating, switch to Reciprocal.
   - Exit condition: once switched to Reciprocal, stay in Reciprocal unless a long run (≥ max(5, floor(r/5)) rounds) shows no retaliation to a sequence of defections; then you may revert to Exploit.

4. Reciprocal mode (Mode := Reciprocal)
   - Purpose: avoid sustained punishment while preserving as much cooperative surplus as feasible.
   - Rule: in any non-endgame round, contribute (play C) if and only if at least half of the other players contributed in the previous round (majority cooperation), OR if the recent group cooperation rate (last 3 rounds) among others ≥ 0.6. Otherwise play D.
   - Forgiveness: if the group briefly falls below the cooperation threshold by a single round, do not immediately defect forever — treat one missed round as noise and continue to attempt cooperation for up to two rounds before switching to temporary punishment.
   - Punishment of persistent defectors: if the group cooperation rate drops and stays low (below 0.2 for ≥3 consecutive rounds), switch to permanent defection until a fresh probe (single cooperation after S rounds) shows recovery.
   - Monitoring: if in Reciprocal mode we detect that repeated defections by others are not followed by retaliatory reductions (i.e., others remain cooperative even when we defect), consider switching back to Exploit.

5. Miscellaneous operational rules
   - If multiple signals conflict, err on the side of self-protection: switch to Reciprocal rather than remaining in Exploit.
   - Use observed individual histories only to compute population aggregates (fractions of others cooperating). This strategy does not try to target or single-out individuals — decisions are based on group-level statistics.
   - Determinism: all thresholds and schedules are deterministic functions of (r, n, k) and observed history; there is no private randomness in the rule (except that occasional maintenance cooperation is deterministic in schedule).

Rationale and exploitative mindset
- Early probe (one explicit defection in a controlled setting) reveals whether the group contains conditional punishers who will lower their contributions in response. If the group contains few punishers, always defecting extracts the highest immediate surplus from cooperative others.
- Continuous monitoring and scheduled re-checks prevent getting trapped indefinitely in a destructive mutually-punishing equilibrium: if defections trigger retaliation, switch to a reciprocity-preserving strategy so punishment does not destroy long-run earnings.
- Endgame defection is explicit: in the last E rounds future retaliation is limited, so defect to grab one-shot gains.
- The strategy balances short-term exploitation (free-riding when safe) and protection (cooperating when necessary to avoid costly punishments), maximizing expected payoffs across a wide variety of opponent behaviors without relying on coordination or communication.
'''

description_EXPLOITATIVE_128 = '''
Adaptive Exploiter (natural-language / pseudocode description)

Goal summary (exploitative mindset)
- Elicit contributions from others when they are willing, then free‑ride (defect) to capture the larger share.
- Avoid being a stable sucker: punish persistent defectors or noisy nonresponders and withdraw cooperation from the group endgame.
- Be forgiving enough to re‑exploit if conditional cooperators return to cooperating.

Parameters computed from game inputs
- n, k, r are known.
- Endgame window E = min(3, ceil(r/6)). (In the final E rounds always defect.)
- Probe window W(t) = min(10, t-1) when computing recent history.
- Cooperator thresholds (tunable but fixed given no coordination):
  - StrongCooperator if player’s cooperation rate ≥ 0.9
  - LikelyCooperators fraction threshold TC_high = 0.6
  - Moderate cooperation threshold TC_mid = 0.4
  - Low cooperation threshold TC_low = 0.2

State tracked (from history)
- For each player j (excluding self): total times j played C, and cooperation rate p_j = (#C_j) / (rounds played so far).
- Recent average of others’ contributions P_recent = average number of contributions by others per round over the last W(t) rounds, normalized to [0,1] by dividing by (n-1).
- Count StrongCooperators = number of players with p_j ≥ 0.9.
- A simple “punishment memory” per player: last time we punished them (initially none); punishment lasts PunishLen = min(5, ceil(r/10)) rounds.

Initial and trivial-case rules
- If r = 1: always defect (single-shot).
- If r ≤ 3: play defect every round (short horizon — too risky to invest).
- First round (t = 1 and r > 3): play C once to signal willingness to cooperate and to probe for conditional cooperators.

Per-round decision (for round t, 1..r)
1. If t > r − E (final E rounds): play D (endgame defection).
2. Else if any StrongCooperator ≥ 1:
   - Exploit mode: always play D to extract maximum from identified unconditional cooperators.
     - Exception: if the group’s recent cooperation P_recent collapses to near zero (P_recent < TC_low), switch back to general mode (see step 3) because unconditional cooperators evidently stopped cooperating and continuing to cooperate rarely pays.
3. Else (no obvious unconditional sucker present):
   - Compute P_recent over the last W(t) rounds (average fraction of other players who contributed each recent round).
   - If P_recent ≥ TC_high:
     - Many others are reliably cooperating → defect (D) to free‑ride. Every few rounds (roughly 1 in 5; implementation: cooperate with probability 0.2 or on a deterministic schedule once every 5 rounds) play C to avoid provoking wholesale collapse from highly conditional cooperators. If you use a deterministic schedule, ensure occasional C spaced out to keep conditional cooperators responsive.
   - Else if TC_mid ≤ P_recent < TC_high:
     - Mixed group: attempt to tilt the group toward cooperation while keeping exploitation leverage.
       - Play D most rounds but cooperate occasionally to “nudge” conditional cooperators: play C with probability 0.4 (or deterministic: cooperate on 2 of every 5 rounds). If you observe that after cooperating others’ cooperation increases sustainably, shift toward the exploit mode above (defect more often).
   - Else if TC_low ≤ P_recent < TC_mid:
     - Low-to-moderate cooperation: be cautious and try to build a profitable pattern.
       - Play C with probability 0.25 for a short calibration phase of up to 5 rounds to test responsiveness; if others respond by increasing P_recent over that phase, move to the previous branch; if not, switch to defecting.
   - Else (P_recent < TC_low):
     - Others rarely cooperate → play D (protect yourself). During this phase, probe very rarely (probability 0.05 per round) by playing C to check whether conditional cooperators reappear.
4. Targeted punishment and forgiveness:
   - If in the previous round you played C and some player j played D while others cooperated (i.e., you were specifically taken advantage of), mark j as punished: for the next PunishLen rounds ignore j’s cooperative history when computing P_recent and lean toward defecting (this is a soft targeted punishment: it reduces the incentive to keep cooperating for that player's benefit).
   - If after punishment the punished player increases their cooperation rate for a sustained window (≥ W(t) rounds), clear their punishment status (forgiveness) and allow them to be counted in P_recent again.
5. Adaptation and momentum:
   - Continuously update player rates p_j and P_recent. If a short experiment (probing cooperations) succeeds in increasing others’ cooperation, employ the exploit pattern: at high group cooperation, defect most rounds and only cooperate occasionally to sustain others’ contributions.
   - If group cooperation falls sharply, immediately withdraw cooperation (binary switch to defect) and begin long-ish punishment/probing protocol described above.

Rationale and remarks (why this is exploitative and robust)
- Start with a small cooperative signal to identify conditional cooperators. When identified, the strategy free‑rides (defects) to maximize own payoff but uses occasional cooperation to maintain the conditional cooperators’ incentives — this extracts surplus from reciprocal strategies.
- StrongCooperator detection ensures persistent unconditional cooperators are exploited by consistent defection.
- Punishment of players who exploit our cooperations reduces risk of being a stable sucker; forgiveness rules allow re‑exploitation if they return to cooperation.
- Endgame defection prevents being exploited by last‑round free‑riding.
- Windowed statistics and occasional random probes protect against transient noise and allow adaptation to a wide range of behaviors.

Implementation notes (deterministic vs probabilistic)
- The policy can be implemented deterministically (cooperate on fixed spacing counts, e.g., “cooperate on rounds 1 and then every 5th round under high cooperation”) or probabilistically (specified probabilities above). Probabilistic choices make you harder to exploit by sophisticated opponents; deterministic schedules are simpler and acceptable if randomization is unavailable.

Summary one‑line rule
- Signal cooperation early to find conditional cooperators, then mostly defect to free‑ride when others cooperate, withdraw cooperation quickly when others stop, punish one-off exploitations, forgive after confirmed improvement, and always defect during the final small endgame window.
'''
