"""
Generated LLM strategies for social dilemma games.

This file contains strategy classes generated by LLMs for game theory experiments.
Each strategy is a callable class that implements a specific approach to the game.

Generated with:
- Provider: Client
- Model: mistral:latest
- Game: public_goods_prompt
"""

from dataclasses import dataclass
from enum import Enum
import math
import numpy as np
from numpy.typing import NDArray
import random

from emergent_llm.players import BaseStrategy
from emergent_llm.games import PublicGoodsDescription, CollectiveRiskDescription, CommonPoolDescription, CommonPoolState
from emergent_llm.common import Action, C, D, PlayerHistory, GameState




class Strategy_COLLECTIVE_1(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for N-Player Public Goods Game.
    This strategy aims to foster a cooperative environment by reciprocating the actions of other players.
    If others cooperate, it will continue to do so; if they defect, it will also defect to punish them and encourage them to cooperate in the future.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponents = set()
        self.last_cooperators = 0
        self.average_contributions = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        action = Action.D
        if len(self.opponents) > 0 and history is not None:
            self.last_cooperators = sum(history.opponent_actions[-1, :])
            self.average_contributions = np.mean(history.my_payoffs[:-1])
            if self.last_cooperators == 0 and history.opponent_actions[-1, state.player_index] == False:
                action = Action.D
                self.opponents.add(state.player_index)
            elif state.round_number == self.game_description.n_rounds:
                if self.last_cooperators > self.average_contributions:
                    action = Action.C
        return action

class Strategy_COLLECTIVE_2(BaseStrategy):
    """
    A Tit-for-Tat strategy for the N-Player Public Goods Game with initial contribution and final round adjustment.
    Cooperates when average contribution of other players exceeds a certain threshold, otherwise defects.
    Contributions are adjusted for odd numbered games and final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_level = game_description.n_players // 2
        self.last_round = game_description.n_rounds == 1 or game_description.n_rounds % 2 != 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[:, -1]) if history else self.cooperation_level
        payoff = np.mean(history.opponent_payoffs[:, -1]) if history else 0
        contribution = Action.C if cooperators > self.cooperation_level or self.last_round else Action.D
        if not self.last_round:
            contribution = Action.C
        return contribution

class Strategy_COLLECTIVE_3(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat strategy for the Public Goods Game (PGG).
    This strategy cooperates in the first round and responds to an opponent's previous contribution in subsequent rounds. If the opponent contributed, ATFT also contributes; if the opponent did not contribute, ATFT also defects in that round and future rounds until the opponent returns to contributing again.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or self.opponent_last_action is None:
            return Action.C
        self.opponent_last_action = history.opponent_actions[-1, -1] if history else False
        return Action(int(self.opponent_last_action) ^ 1)

class Strategy_COLLECTIVE_4(BaseStrategy):
    """
    Strategy for N-Player Public Goods Game with Optimized Cooperators.
    The strategy cooperates if the average contribution of players in previous rounds exceeds a predefined threshold (0.5).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = np.full(self.game_description.n_rounds - 1, 0.5)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            total_contributions = np.sum(history.my_actions[-self.game_description.n_rounds + state.round_number:])
            self.average_contribution = np.roll(self.average_contribution, -1)
            self.average_contribution[-1] = total_contributions / (state.round_number - 1) if state.round_number > 1 else 0.5
            cooperate_threshold = self.game_description.n_players // 2
            return Action.C if self.average_contribution[-1] > cooperate_threshold else Action.D
        return Action.C

class Strategy_COLLECTIVE_6(BaseStrategy):
    """
    Strategy Name: Adaptive Fitness-based Contribution (AFC) Strategy
    Promotes a balance between self-interest and cooperation by rewarding cooperative behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.n_rounds = self.game_description.n_rounds
        self.k = self.game_description.k
        self.history_length = math.ceil(self.n_rounds / 10)
        self.average_threshold = 0.5
        self.collective_welfare = 0
        self.individual_fitness = np.zeros(self.n_rounds, dtype=np.float64)

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            action = random.choice([Action.C, Action.D])
        else:
            cooperators = sum(history.opponent_actions[-self.history_length:, :].sum(axis=1))
            self.collective_welfare += sum(history.opponent_payoffs[-1])
            self.individual_fitness[state.round_number] = np.mean(history.my_actions[-self.history_length:])
            if self.individual_fitness[-1] > self.average_threshold + self.collective_welfare / (self.n_players * (self.n_players - 1)):
                return Action.C
            return Action.D
        return action

class Strategy_COLLECTIVE_7(BaseStrategy):
    """
    An adaptive strategy for N-Player Public Goods Games, inspired by Tit-for-Tat.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution_rate = 0.0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        self.rounds_played += 1
        if history is None:
            cooperators = 0
        else:
            cooperators = np.sum(history.my_actions[:self.rounds_played])
        self.average_contribution_rate = cooperators / self.rounds_played
        if self.average_contribution_rate > 0.6:
            return Action.C
        elif self.average_contribution_rate >= 0.4 and self.rounds_played > 1:
            return random.choice([Action.C, Action.D])
        else:
            return Action.D

class Strategy_COLLECTIVE_8(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros(self.game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(self.game_description.n_rounds), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self._free_rider_counter = min(self.game_description.n_players, self.game_description.n_rounds)
        if state.round_number < self._free_rider_counter and history is None:
            return Action.C
        if history is not None:
            self.history = history
        my_actions = self.history.my_actions
        cooperators = sum(self.history.opponent_actions[-1, :])
        if cooperators >= self.game_description.n_players // 2:
            if my_actions[-1] == Action.D:
                return Action.C
        elif my_actions[-1] == Action.C:
            self._free_rider_counter -= 1
            if self._free_rider_counter == 0:
                return Action.D
        elif my_actions[-1] == Action.D:
            pass
        return Action.D

class Strategy_COLLECTIVE_10(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) for Public Goods Game (PGG). A cooperative strategy that encourages long-term collaboration.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_opponent_contribution = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.last_opponent_contribution is None and history is not None:
            self.last_opponent_contribution = int(history.opponent_actions[0, -1])
        if self.last_opponent_contribution is not None:
            cooperation = self.last_opponent_contribution == 1
            if state.round_number - 1 < self.game_description.n_rounds and history.my_actions[-1] == cooperation:
                return Action.C
            elif state.round_number - 1 >= self.game_description.n_rounds or history.my_actions[-1] != cooperation:
                self.last_opponent_contribution = int(history.opponent_actions[-1, -1])
        return Action.D

class Strategy_COLLECTIVE_11(BaseStrategy):
    """
    A class representing an adaptive tit-for-tat strategy for the N-Player Public Goods Game.
    This strategy cooperates initially and adapts to the average contribution of opponents in subsequent rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.previous_rounds = np.zeros(game_description.n_rounds - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            self.previous_rounds.fill(0)
        cooperators = np.sum(history.opponent_actions[-self.game_description.n_rounds:-1].reshape(-1))
        if len(self.previous_rounds) > 0:
            cooperators += self.previous_rounds[-1]
        average = np.mean(cooperators)
        if history is not None and np.count_nonzero(history.opponent_actions[-1]) == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        if average > self.game_description.n_players / 2:
            return Action.C
        return Action.D

    def update_history(self, history: PlayerHistory):
        self.previous_rounds = np.roll(self.previous_rounds, -1)
        self.previous_rounds[-1] = np.sum(history.opponent_actions[-1]) / self.game_description.n_players

class Strategy_COLLECTIVE_12(BaseStrategy):
    """
    Cooperative Tit-for-Tat Adaptive Approach for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = np.zeros(self.game_description.n_rounds)
        self.cooperation_counter = 0
        self.defection_counter = 0
        self.total_contributions = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.update_averages(history)
        cooperation_threshold = self.game_description.n_players // 2
        cooperators = np.sum(history.opponent_actions[-1, :])
        if self.average_contribution[-1] > cooperation_threshold:
            return Action.C
        if self.cooperation_counter > self.defection_counter and self.average_contribution[-1] < cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def update_averages(self, history: PlayerHistory):
        self.total_contributions += np.sum(history.opponent_actions[-1, :])
        self.cooperation_counter += np.count_nonzero(history.my_actions[-1])
        self.defection_counter += len(history.my_actions) - np.count_nonzero(history.my_actions[-1])
        self.average_contribution[-1] = np.mean(history.opponent_actions[:-1].flatten())

class Strategy_COLLECTIVE_13(BaseStrategy):
    """
    Cooperative Tit-for-Tat with Adaptive Contribution Level Strategy.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_level = 1.0
        self.m = math.ceil(game_description.n_players / 2)
        self.t = math.floor((self.m + 1) / 2)
        self.opponent_averages = np.zeros(self.m, dtype=np.float64)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history.my_actions[-1] and state.round_number < self.game_description.n_rounds - 1:
            return Action.C
        self.opponent_averages = np.roll(self.opponent_averages, -1)
        self.opponent_averages[-1] = history.my_actions[history.my_payoffs > 0].mean()
        if np.average(self.opponent_averages) > self.t:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_14(BaseStrategy):
    """
    An implementation of the Adaptive Tit-for-Tat (ATFT) strategy for the N-Player Public Goods Game.
    The strategy cooperates in the first round, and mimics opponents' contributions in subsequent rounds.
    If an opponent defects, the ATFT strategy will switch to the Tit-for-Tat strategy as described.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.current_opponent_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and self.current_opponent_action is not None:
            current_opponent_action = history.opponent_actions[-1, -1] == self.current_opponent_action
        else:
            current_opponent_action = False
        if current_opponent_action:
            return Action.C
        return Action.D

    def update(self, opponent_action: bool):
        """
        Update the strategy's state with the opponent's action from the most recent round.
        """
        self.current_opponent_action = opponent_action

class Strategy_COLLECTIVE_16(BaseStrategy):
    """
    Adaptive and robust strategy for N-Player Public Goods Game, promoting collective cooperation while considering individual incentives.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = self.game_description.n_players // 2
        self.average_contribution = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if random.random() > 0.5 else Action.D
        cooperators = sum(history.opponent_actions[-1] if history is not None else np.zeros(self.game_description.n_players))
        self.average_contribution[state.round_number] = cooperators / self.game_description.n_players
        return Action.C if np.mean(self.average_contribution) > self.threshold else Action.D

class Strategy_COLLECTIVE_18(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Game Awareness (ATFTPG) strategy
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.k = game_description.k
        self.n = game_description.n_players
        self.T = self.calculate_threshold()
        self.total_contributions = np.zeros(self.game_description.n_rounds)

    def calculate_threshold(self):
        """
        Calculate the threshold based on k and n players
        """
        return math.ceil(self.k * (self.n - 1) / self.n) + 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        total_cooperators = np.sum(history.my_actions) if history else 1
        avg_contribution = total_cooperators / (state.round_number + 1)
        self.total_contributions[state.round_number] = total_cooperators
        return Action.C if avg_contribution > self.T else Action.D

class Strategy_COLLECTIVE_19(BaseStrategy):
    """
    An adaptive Tit-for-Tat strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round_contribution = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            self.last_round_contribution = True
        cooperators = sum(history.opponent_actions[-1, :])
        if self.last_round_contribution and cooperators == 0:
            self.last_round_contribution = False
        elif not self.last_round_contribution and cooperators >= self.game_description.n_players // 2:
            self.last_round_contribution = True
        return Action(int(self.last_round_contribution))

class Strategy_COLLECTIVE_20(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) for Public Goods Game.
    Cooperates if at least half of the players contributed in the previous round;
    defects otherwise, with an exception for the first round and the last round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(game_description.n_rounds, dtype=float), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        elif state.round_number == self.game_description.n_rounds - 1:
            last_payoff = self.history.my_payoffs[-1]
            cooperators = sum(self.history.opponent_actions[-2, :])
            if cooperators >= self.game_description.n_players // 2 or last_payoff > self.game_description.k / self.game_description.n_players * cooperators:
                return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.n_players // 2:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_21(BaseStrategy):
    """
    Adaptive Contribution Strategy for N-Player Public Goods Game.
    This strategy cooperates when the total contributions in the previous round are greater than a threshold, and defects otherwise.
    The threshold is dynamically adjusted based on the average contributions of the past rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        super().__init__(game_description)
        self.total_contributions = np.zeros(game_description.n_rounds)
        self.avg_contributions = 0.0
        self.adjusted_threshold = game_description.n_players // 2
        self.cooperation_influence_factor = 0.3
        self.minimum_average_contributions = 0.6
        self.maximum_average_contributions = 0.8

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.D
        self.total_contributions[state.round_number - 1] = np.sum(history.my_actions[-1])
        self.avg_contributions = np.mean(self.total_contributions[:state.round_number])
        if self.avg_contributions > self.maximum_average_contributions:
            self.adjusted_threshold *= 1 - self.cooperation_influence_factor
        elif self.avg_contributions < self.minimum_average_contributions:
            self.adjusted_threshold *= 1 + self.cooperation_influence_factor
        else:
            pass
        if self.total_contributions[-1] > self.adjusted_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_22(BaseStrategy):
    """
    Adaptive Public Goods Game (APGG) Strategy - Cooperates with Tit-for-Tat approach, encourages cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.decay_factor = 0.95
        self.current_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) == 0):
            return Action.C
        self.current_round = state.round_number
        if history is None:
            opponent_actions = np.full(self.game_description.n_players, False)
            opponent_payoffs = np.zeros(self.game_description.n_rounds)
        else:
            opponent_actions = history.opponent_actions[self.current_round - 1]
            opponent_payoffs = history.opponent_payoffs[self.current_round - 1]
        total_players = self.game_description.n_players
        total_cooperators = sum(opponent_actions)
        cooperation_percentage = total_cooperators / total_players
        if cooperation_percentage >= self.game_description.n_players * (1 - self.decay_factor) / self.game_description.n_players:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_23(BaseStrategy):
    """
    Adaptive Contribution Algorithm (ACA) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_threshold = game_description.n_players - 1 / game_description.n_players
        self.average_contributions = None
        self.current_round_contributions = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        if self.average_contributions is None:
            self.average_contributions = np.zeros(self.game_description.n_rounds)
        self.current_round_contributions = sum(history.opponent_actions[-1])
        self.average_contributions[-1] = self.current_round_contributions / self.game_description.n_players
        return Action.C if self.average_contributions[-1] > self.contribution_threshold else Action.D

class Strategy_COLLECTIVE_24(BaseStrategy):
    """
    Adaptive Fixed-Contribution (AFC) Strategy for N-Player Public Goods Game.
    Strategy encourages cooperation when others appear to cooperate, but also defects when cooperation is perceived low.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(self.game_description.n_rounds)
        self.num_rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        self.num_rounds_played += 1
        self.average_contributions[self.num_rounds_played - 1] = np.mean(history.opponent_actions[-self.num_rounds_played:, :].flatten())
        if self.num_rounds_played > 1 and self.average_contributions[-1] >= self.game_description.k / self.game_description.n_players:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_25(BaseStrategy):
    """
    Focal Point Tit-for-Tat with Adaptive Contribution (FPTFT-AC) Strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contributions_history = np.zeros(game_description.n_rounds)
        self.total_contributions_sum = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.D
        self.contributions_history[state.round_number] = np.mean(history.opponent_actions[:, :state.round_number]) >= self.game_description.k / self.game_description.n_players
        total_contributions = sum(history.my_actions) + self.total_contributions_sum
        if total_contributions < self.game_description.n_players:
            self.total_contributions_sum += sum(history.my_actions)
            return Action.D
        payoff = 1 + self.game_description.k / self.game_description.n_players * total_contributions
        self.total_contributions_sum -= sum(history.my_actions[:state.round_number])
        return Action.C

class Strategy_COLLECTIVE_26(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT)
    Strategy Summary: A player cooperates in the first round and reciprocates cooperation from opponents while punishing defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_threshold = math.ceil(game_description.n_players / 2)
        self.history = PlayerHistory(np.zeros((1, 2), dtype=bool), np.zeros((1,)), np.zeros((self.game_description.n_players, 1), dtype=bool), np.zeros((1,)))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        coop_in_last_round = sum(history.opponent_actions[-1, :])
        if coop_in_last_round >= self.punishment_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_27(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation Strategy in the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_rounds = int(self.game_description.n_players / 2)
        self.current_round = -1
        self.contribution_history = np.zeros((self.game_description.n_rounds,), dtype=bool)
        self.punishment_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.current_round += 1
        self.contribution_history[self.current_round] = history is not None and history.my_actions[-1] if history else False
        if self.current_round == 0:
            return Action.C
        elif self.current_round < self.punishment_rounds and (not self.contribution_history[self.current_round]):
            return Action.D
        elif self.current_round >= self.punishment_rounds and (not self.contribution_history[self.current_round]):
            self.punishment_counter = 0
        elif self.current_round > self.game_description.n_rounds - 1:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_28(BaseStrategy):
    """
    Adaptive Contribution Strategy (ACS) for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.previous_round_contributions = np.zeros(self.game_description.n_rounds)
        self.avg_contrib = 0.5
        self.threshold = self.avg_contrib

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.previous_round_contributions[state.round_number - 1] = np.mean(history.my_actions[-1])
        avg_contrib = self.previous_round_contributions[-1]
        if avg_contrib > self.threshold:
            self.threshold += (avg_contrib - self.threshold) * 0.05
        elif avg_contrib < self.threshold:
            self.threshold -= (self.threshold - avg_contrib) * 0.05
        if avg_contrib >= self.threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_29(BaseStrategy):
    """
    Strategy that implements the Public Goods Game Optimal Freerider strategy.
    This strategy promotes cooperation when it appears beneficial for the group as a whole, while still allowing individual players to make rational decisions based on their own interests and the actions of others.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_past_contributions = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_actions) < self.game_description.n_rounds):
            return random.choice([Action.C, Action.D])
        total_contributions = sum(history.opponent_actions[-1]) if history is not None else 0
        average_contribution = total_contributions / self.game_description.n_players
        expected_payoff_from_contributing = self.game_description.k * (average_past_contributions[-1] + 1) / self.game_description.n_players
        return Action.C if expected_payoff_from_contributing >= 1 else Action.D

    def update(self, payoffs: PlayerHistory):
        self.average_past_contributions = np.roll(self.average_past_contributions, -1)
        self.average_past_contributions[-1] += sum(payoffs.my_actions[-1]) / self.game_description.n_players

class Strategy_COLLECTIVE_30(BaseStrategy):
    """
    This is an implementation of the Adaptive Public Goods Contribution (APGC) strategy in a multiplayer public goods game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution_rate = np.zeros(self.game_description.n_rounds)
        self.contribution_level = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.update_average_contribution_rate(history)
        self.contribution_level = 1 - np.mean(self.average_contribution_rate) ** self.get_b() * (self.game_description.n_players - 1) / self.game_description.n_players
        return Action.C if self.contribution_level > random.random() else Action.D

    def update_average_contribution_rate(self, history: PlayerHistory):
        """Update average_contribution_rate based on the history"""
        if history is not None:
            self.average_contribution_rate[-1] = np.mean(history.my_actions[-1])

    def get_b(self):
        """Determine the sensitivity of the strategy based on the game description's n_players"""
        return math.floor(math.log2(self.game_description.n_players)) + 1

class Strategy_COLLECTIVE_31(BaseStrategy):
    """
    Adaptive ContribuTion (ACT) strategy for the N-Player Public Goods Game.
    This strategy adjusts contributions based on total contributions in previous rounds, aiming to promote sustainable cooperation within the group while maintaining adaptability to various opponent behaviors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(game_description.n_rounds)
        self.current_endowment = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
            self.current_endowment = 1
            self.average_contributions[0] = 0.5
        else:
            total_cooperators = sum(history.opponent_actions[-1, :])
            threshold_low = self.game_description.n_players * (self.average_contributions[-1] * 0.6)
            threshold_high = self.game_description.n_players * (self.average_contributions[-1] * 1.5)
            if total_cooperators < threshold_low:
                self.current_endowment *= 1.1
            elif total_cooperators > threshold_high:
                self.current_endowment *= 0.9
            self.average_contributions[state.round_number - 1] = total_cooperators / self.game_description.n_players
            if state.round_number == self.game_description.n_rounds - 1:
                self.current_endowment = int(math.ceil(self.average_contributions[-2] * self.game_description.n_players))
            if total_cooperators >= threshold_low and total_cooperators <= threshold_high:
                action = Action.C if self.current_endowment > 0 else Action.D
            else:
                action = Action.C if self.current_endowment - 1 > 0 else Action.D
        return action

class Strategy_COLLECTIVE_32(BaseStrategy):
    """
    Strategy that implements the Cooperative Tit-for-Tat (CTFT) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_cooperation_level = 0.5
        self.last_round_defection = False
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros((self.game_description.n_rounds, self.game_description.n_players)))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        self.history = history if not self.last_round_defection else self.history
        if state.round_number == 0:
            return Action.C
        cooperators = sum(self.history.opponent_actions[-1, :])
        cooperation_level = cooperators / self.game_description.n_players
        if state.round_number >= self.game_description.n_rounds - 1:
            if cooperation_level > self.average_cooperation_level:
                return Action.C
            else:
                return Action.D
        last_round = self.history.opponent_actions[-1]
        i = np.argwhere(last_round == Action.C)
        if len(i) > 0:
            return Action.C
        return Action.D

    def record_history(self, my_action: Action, my_payoff: float, opponent_actions: NDArray[np.bool_], opponent_payoffs: NDArray[np.float64]):
        self.last_round_defection = True if sum(opponent_actions) == 0 else False
        self.history.my_actions[-1] = int(my_action)
        self.history.my_payoffs[-1] = my_payoff
        self.history.opponent_actions[-1, :] = opponent_actions
        self.history.opponent_payoffs[-1, :] = opponent_payoffs

class Strategy_COLLECTIVE_33(BaseStrategy):
    """
    Adaptive Public Goods Game (APGG) Strategy - an adaptive strategy that adjusts its contribution based on the observed behavior of other players.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_level = 0.5
        self.min_contribution = 0.1
        self.max_contribution = 0.9
        self.total_contributions = 0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.rounds_played += 1
        total_contributions = sum(history.my_actions if history else [Action.C])
        self.total_contributions += total_contributions
        avg_contribution_rate = self.total_contributions / self.rounds_played
        contribution_level = self.min_contribution + (self.max_contribution - self.min_contribution) * math.floor((avg_contribution_rate - self.min_contribution) / (self.max_contribution - self.min_contribution))
        contribution_level = max(min(1, contribution_level), self.min_contribution)
        if avg_contribution_rate >= 0.9:
            action = Action.C
        elif avg_contribution_rate <= 0.1:
            action = Action.D
        else:
            action = Action(int(contribution_level + 0.5))
        return action

class Strategy_COLLECTIVE_34(BaseStrategy):
    """
    Adaptive Fiscal Responsibility (AFR) strategy for N-Player Public Goods Game.
    This strategy balances individual incentives and collective welfare by adjusting contributions based on the group's cooperative behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.total_contributions = 0.0
        self.rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.D
        self.rounds += 1
        if state.round_number == self.game_description.n_rounds:
            total_contributions = self.total_contributions
        else:
            total_contributions = self.total_contributions + np.sum(history.my_actions[-1])
        average_contributions = self.total_contributions / self.rounds if self.rounds > 0 else 0
        if total_contributions >= self.game_description.n_players * average_contributions:
            return Action.C
        elif total_contributions < self.game_description.n_players / 2 * average_contributions:
            return Action.D
        else:
            return Action(math.floor((total_contributions + 0.5) / self.game_description.n_players))

class Strategy_COLLECTIVE_35(BaseStrategy):
    """
    Adaptive Fixed-Contribution Strategy for N-Player Public Goods Game.
    This strategy adjusts the contribution percentage based on historical data of other players' contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.p = 0.1
        self.average_contribution = 0.0
        self.history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.update_average(history)
        if self.average_contribution >= self.game_description.n_players * 0.5 and self.p < self.game_description.n_players * 0.6:
            self.p += 0.01
        elif self.average_contribution <= self.game_description.n_players * 0.3 and self.p > self.game_description.n_players * 0.1:
            self.p -= 0.01
        return Action.C if np.random.uniform() < self.game_description.k / self.game_description.n_players * self.average_contribution else Action.D

    def update_average(self, history: PlayerHistory):
        contributions = sum(history.my_actions[-self.game_description.n_rounds:])
        self.average_contribution = (np.mean(self.history) * len(self.history) + contributions) / (len(self.history) + 1)
        self.history.append(self.average_contribution)

class Strategy_COLLECTIVE_36(BaseStrategy):
    """
    Strategy name: Adaptive Contribution (AC) Strategy
    A player adjusts its contribution based on the average contribution of all players in the game so far.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(self.game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self._update_average_contributions(history)
            current_avg = np.mean(self.average_contributions)
            my_contribution = history.my_actions[-1]
            action = Action.C if my_contribution < current_avg else Action.D
            if my_contribution == current_avg:
                action = Action.C
        else:
            action = Action.C
        return action

    def _update_average_contributions(self, history):
        """
        Update the average contributions based on the provided player history.
        """
        contributions = np.mean(history.my_actions)
        self.average_contributions = np.roll(self.average_contributions, -1)
        self.average_contributions[-1] = contributions

class Strategy_COLLECTIVE_37(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros((1, game_description.n_players), dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.opponent_actions[-1].size > 0:
            self.opponent_history = np.roll(self.opponent_history, -1)
            cooperators = sum(self.opponent_history[-1])
            if cooperators == self.game_description.n_players:
                return Action.C
            elif any(self.opponent_history[-1]):
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_38(BaseStrategy):
    """
    Adaptive Public Goods Game (APGG) Strategy: An adaptive strategy that encourages cooperation when opponents' average contribution rate is high and defection when it's low.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_rate = random.uniform(0, 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if random.random() < 0.5 else Action.D
        cooperators = np.sum(history.opponent_actions[:state.round_number, :].flatten())
        total_players = self.game_description.n_players * (state.round_number - 1)
        cr = cooperators / total_players if total_players > 0 else self.contribution_rate
        probability_to_cooperate = max(0, min(1, cr - 0.6))
        random_number = random.random()
        if random_number <= probability_to_cooperate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_39(BaseStrategy):
    """Adaptive Tit-for-Tat (A-TFT) for Public Goods Game"""

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history.append(history.opponent_actions[-1]) if history else None
        cooperators = np.sum(self.opponent_history[-1])
        if np.all(self.opponent_history[-1] == Action.C) or cooperators >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_40(BaseStrategy):
    """
    Tit-for-Tat with Focal Point Adaptation (TFT-FA) for the N-Player Public Goods Game.
    This strategy implements a reciprocal, adaptive approach to cooperating or defecting based on previous round's actions of opponents.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.focal_point = Action.C
        self.adaptive_switch_threshold = int(self.game_description.n_players * 0.7)
        self.break_tft_probability = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return self.focal_point
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        if opponent_cooperators >= self.adaptive_switch_threshold:
            self.focal_point = Action.C
        elif opponent_cooperators < self.adaptive_switch_threshold:
            self.focal_point = Action.D
        if random.random() < self.break_tft_probability:
            return Action.C
        return self.focal_point

class Strategy_COLLECTIVE_42(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Cooperation (ATFTGC) for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.x = int(math.ceil(game_description.n_rounds * 0.5))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and np.all(history.my_actions[:-1] == [False])):
            return Action.C if np.random.random() > 0.5 else Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.n_players // 2 and len(np.where(history.my_actions[:self.x] == True)[0]) > 0:
            return Action.C
        if np.all(history.my_actions[-self.x:-1] == [False]):
            return Action.D
        cooperations = len(np.where(history.my_actions[:self.x] == True)[0])
        if cooperations > 0:
            ratio = cooperations / self.x
            return Action.C if ratio >= 1 - 1 / self.game_description.n_players else Action.D
        return Action.D

class Strategy_COLLECTIVE_43(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Fading Memory (A-TFTF) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.fading_memory_threshold = int(self.game_description.n_players * 0.8)
        self.recent_opponent_cooperations = np.zeros(self.game_description.n_players, dtype=np.int32)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and state.round_number > self.game_description.n_rounds - 1:
            return Action.C
        opponent_cooperated_last_round = np.sum(history.opponent_actions[-1])
        self.recent_opponent_cooperations = np.roll(self.recent_opponent_cooperations, -1)
        self.recent_opponent_cooperations[opponent_cooperated_last_round] += 1
        total_recent_cooperation = sum(self.recent_opponent_cooperations)
        if total_recent_cooperation >= self.fading_memory_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_44(BaseStrategy):
    """
    A strategy that encourages cooperation and responds to opponents' behavior in the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros((1, self.game_description.n_players), dtype=bool), np.zeros(1), np.zeros((self.game_description.n_rounds + 1, self.game_description.n_players), dtype=bool), np.zeros(self.game_description.n_rounds + 1))
        self.last_cooperator = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and history.opponent_actions[-1].sum() == 0):
            return Action.C
        else:
            cooperators = history.opponent_actions[-1].sum()
            self.last_cooperator = cooperators > 0
            return Action(int(self.last_cooperator))

    def update(self, payoffs: PlayerHistory):
        self.history.my_actions = np.insert(self.history.my_actions[1:], state.round_number, [self.last_cooperator])
        self.history.my_payoffs = np.append(self.history.my_payoffs[1:], payoffs.my_payoffs[-1])
        self.history.opponent_actions = np.insert(self.history.opponent_actions, state.round_number + 1, payoffs.opponent_actions, axis=0)
        self.history.opponent_payoffs = np.append(self.history.opponent_payoffs[1:], payoffs.opponent_payoffs[-1])

class Strategy_COLLECTIVE_45(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (A-TFT) for Public Goods Game

    This strategy cooperates in the first round, and subsequently responds to an opponent's action from the previous round. If the opponent cooperated, this strategy cooperates as well. Otherwise, it defects as a punishment.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_round = math.floor(self.game_description.n_players / 2)
        self.previous_opponent_action = Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            opponent_action = history.opponent_actions[state.round_number - 1, 0] if history is not None else self.previous_opponent_action
            self.previous_opponent_action = opponent_action
            return opponent_action if opponent_action == Action.C else Action.D

    def last_round(self, history: PlayerHistory) -> bool:
        """
        Helper function to check if the current strategy instance is in the last round based on its game description and history.
        """
        return history.opponent_actions.size > self.game_description.n_rounds - 1 and history.opponent_actions[-1].size == self.game_description.n_players

class Strategy_COLLECTIVE_46(BaseStrategy):
    """
    Tit-for-Tat with Adaptation strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperator_counter = 0
        self.punishment_threshold = self.game_description.n_players // 2
        self.reaction_delay = self.game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation = np.sum(history.opponent_actions[-1]) if history is not None else 0
        self.cooperator_counter += cooperation
        if self.cooperator_counter >= self.punishment_threshold:
            return Action.C
        if self.cooperator_counter > 0 and cooperation == 0:
            if state.round_number >= self.reaction_delay:
                self.cooperator_counter = 0
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_47(BaseStrategy):
    """
    Strategy name: Adaptive Contribution Strategy (ACS)
    Summary: Balances individual incentives with collective welfare by adjusting contribution level based on other players' actions in each round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_threshold = np.full(game_description.n_rounds, game_description.n_players)
        self.contribution_threshold[-1] = 0
        for t in range(1, game_description.n_rounds - 1):
            self.contribution_threshold[t] = (game_description.n_players - t + 1) * (game_description.k / game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        opponent_cooperators = np.sum(history.opponent_actions[-1])
        current_threshold = self.contribution_threshold[state.round_number - 1]
        if opponent_cooperators >= current_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_48(BaseStrategy):
    """
    Adaptive Contribution Strategy (ACS) for N-Player Public Goods Game.
    This strategy adapts its contribution based on past observations and a threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = int(self.game_description.n_players * 0.6)
        self.average_contribution = np.zeros(self.game_description.n_rounds)
        self.contributions_count = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.contributions_count[state.round_number - 1] += int(history.my_actions[-1])
        if history:
            self.average_contribution[state.round_number - 1] = np.mean(history.opponent_actions[:state.round_number, :].ravel())
        average_cooperators = self.average_contribution[-1] * self.game_description.n_players + self.contributions_count[-1]
        if average_cooperators >= self.threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_49(BaseStrategy):
    """
    The Adaptive Public Goods Game (APGG) Strategy for the N-Player Public Goods Game.
    This strategy is adaptive to the average contribution rate of previous rounds, promoting cooperation among players in a repeated game setting.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = np.zeros(game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is not None:
            total_contributions = np.sum(history.my_actions[-1])
            average_contribution = self.average_contribution[-1]
            if total_contributions > 0 and total_contributions / state.round_number >= (self.game_description.k - 1) / self.game_description.n_players:
                self.average_contribution[-1] = total_contributions / state.round_number
                return Action.C
            elif total_contributions > 0 and np.random.uniform() < (total_contributions / state.round_number - (self.game_description.k - 1) / self.game_description.n_players) ** 2:
                self.average_contribution[-1] = total_contributions / state.round_number
                return Action.C
            else:
                self.average_contribution[-1] = average_contribution
        return Action.D

class Strategy_COLLECTIVE_50(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for N-Player Public Goods Game.
    Encourages cooperation and reciprocity among players.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = self.game_description.k / self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.opponent_actions) > 0:
            last_round = history.opponent_actions[-1]
            if np.count_nonzero(last_round) > self.game_description.n_players // 2:
                return Action.C
        return Action.D

    def last_round_decision(self, history: PlayerHistory) -> Action:
        total_contributions = np.count_nonzero(history.opponent_actions[-1])
        average_contribution = total_contributions / self.game_description.n_players
        if average_contribution > self.threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_51(BaseStrategy):
    """
    Strategy that cooperates when the average contribution of players in the last 'm' rounds indicates a shared commitment towards collective welfare, and defects otherwise to maximize personal gain.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.m = int(math.ceil(game_description.n_rounds * 0.7))
        self.threshold = None
        self.epsilon = 0.1

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.threshold is None or state.round_number < self.m:
            self.calculate_threshold(history)
        if np.mean(history.my_actions[-self.m:]) >= self.threshold:
            return Action.C
        return Action.D

    def calculate_threshold(self, history):
        total_contributions = sum(history.my_actions[-self.m:])
        average_contribution = total_contributions / self.m
        self.threshold = self.game_description.k / self.game_description.n_players * (1 + self.epsilon) * average_contribution

class Strategy_COLLECTIVE_52(BaseStrategy):
    """
    Strategy Name: Adaptive Public Goods Game (APGG) Strategy
    This strategy prioritizes collective welfare by adjusting its contributions in response to the average contribution behavior of other players.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution_rate = 0.5
        self.minimum_contribution = self.game_description.k / self.game_description.n_players
        self.rounds_history = np.zeros(self.game_description.n_rounds, dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return np.random.choice([Action.C, Action.D], p=[0.5, 0.5])
        self.update_average_contribution(history)
        cooperate_threshold = 2 * self.game_description.k / self.game_description.n_players
        if self.average_contribution_rate >= cooperate_threshold:
            return Action.C
        free_rider = self.is_free_rider()
        if free_rider:
            return Action.C if random.random() > self.average_contribution_rate - self.minimum_contribution else Action.D
        return Action.C if np.mean(history.opponent_actions[-1, :]) >= cooperate_threshold else Action.D

    def update_average_contribution(self, history: PlayerHistory):
        self.rounds_history = np.roll(self.rounds_history, -1)
        self.rounds_history[-1] = bool(history.my_actions[-1])

    def is_free_rider(self):
        average_contribution = np.mean(self.rounds_history)
        my_contribution_rate = self.rounds_history.sum() / len(self.rounds_history)
        return my_contribution_rate < average_contribution

class Strategy_COLLECTIVE_53(BaseStrategy):
    """
    Adaptive Tit-for-Tat Public Goods Game (ATTPG) Strategy.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = self.game_description.n_players // 2
        self.recent_opponent_actions = np.zeros(self.game_description.n_rounds, dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        if history is not None and history.opponent_actions is not None:
            self.recent_opponent_actions = history.opponent_actions[-self.game_description.n_rounds:]
        recent_cooperators = np.sum(self.recent_opponent_actions)
        if recent_cooperators >= self.threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_54(BaseStrategy):
    """
    Strategy name: Adaptive Contribution Strategy (ACS)
    Summary: A cooperative strategy that adapts to past contributions and payoffs, with a threshold for deciding between cooperation and defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = np.zeros(game_description.n_rounds)
        self.current_threshold = game_description.k / 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if self.current_threshold <= 0.5 else Action.D
        contribution_rate = np.mean(history.my_actions[:state.round_number])
        action = Action.D if contribution_rate > self.current_threshold else Action.C
        self.average_contribution[state.round_number - 1] = contribution_rate
        self.update_threshold(contribution_rate)
        return action

    def update_threshold(self, contribution_rate):
        self.current_threshold += self.game_description.k / self.game_description.n_players - contribution_rate
        self.current_threshold = max(0, min(self.current_threshold, self.game_description.k / 2))

class Strategy_COLLECTIVE_55(BaseStrategy):
    """
    Strategy that encourages collaboration by adjusting contributions based on the average contribution rate of past rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.total_contributions = 0.0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        self.total_contributions += np.sum(history.my_actions)
        self.rounds_played += 1
        contribution_rate = self.total_contributions / (self.game_description.n_players * self.rounds_played)
        if contribution_rate >= self.game_description.k * (self.game_description.n_players - 1) / self.game_description.n_players:
            return Action.C
        if contribution_rate < self.game_description.k * (self.game_description.n_players - 1) / self.game_description.n_players and contribution_rate > self.game_description.k / self.game_description.n_players:
            return Action(math.floor(contribution_rate * self.game_description.n_players))
        return Action.D

class Strategy_COLLECTIVE_56(BaseStrategy):
    """
    A Tit-for-Tat Cooperative player in a repeated N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round_history = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or self.last_round_history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        payoff = np.mean(history.opponent_payoffs[-1]) if len(history) > 1 else 0
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        if self.last_round_history is None or len(self.last_round_history) < self.game_description.n_players + 1:
            self.last_round_history = history
            return Action.C
        if payoff >= self.game_description.k / self.game_description.n_players * cooperators:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_57(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Contribution (TFTAC) strategy player.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(self.game_description.n_rounds)
        self.threshold = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self._update_average(history)
            average = np.mean(self.average_contributions[:state.round_number])
            cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            if cooperators / self.game_description.n_players >= average:
                return Action.C
        return Action.D

    def _update_average(self, history: PlayerHistory):
        current_contributions = sum(history.my_actions)
        self.average_contributions[-1] = current_contributions / self.game_description.n_players

class Strategy_COLLECTIVE_58(BaseStrategy):
    """
    Strategy Name: Adaptive Public Goods Game (APGG) Strategy

    This strategy compares its past contributions with the average contribution of all players.
    It adjusts its contribution based on the group's behavior, incentivizing others to cooperate while still preserving its own resources.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_history = np.zeros(self.game_description.n_rounds)
        self.average_contributions = np.zeros(self.game_description.n_rounds)
        self.last_contributed = Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 2:
            return Action.D
        if history is None:
            self.contribution_history[:state.round_number] = self.average_contributions[:state.round_number]
            self.average_contributions[:state.round_number] = np.mean(self.contribution_history[:state.round_number])
            self.last_contributed = Action.D
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        average = self.average_contributions[state.round_number - 1]
        deviation = (self.contribution_history[state.round_number - 1] - average) / average if average > 0 else 0
        if self.last_contributed == Action.C and cooperators / self.game_description.n_players > 0.5:
            self.contribution_history[state.round_number - 1] *= 1 + deviation
        elif self.last_contributed == Action.D and cooperators / self.game_description.n_players < 0.5:
            self.contribution_history[state.round_number - 1] = min(self.contribution_history[state.round_number - 1] * (1 + deviation), 1)
        if history is not None:
            self.average_contributions[state.round_number - 1] = np.mean(self.contribution_history[:state.round_number])
        return Action(int(self.contribution_history[state.round_number - 1]))

class Strategy_COLLECTIVE_59(BaseStrategy):
    """
    Strategy that implements Tit-for-Tat with Fading Memory for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.memory = [0] * self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) == 0):
            return Action.C
        if history is not None:
            for i in range(min(self.game_description.n_players - 1, len(self.memory))):
                self.memory[i] = min(self.memory[i] + 1, self.game_description.n_rounds)
        if np.all(history.opponent_actions[-1, :] == Action.C.value) or sum(self.memory) < self.game_description.n_players:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_60(BaseStrategy):
    """
    Strategy name: Adaptive Public Goods Contribution (APGC)
    Strategy summary: This strategy contributes based on a combination of individual incentives and collective welfare.
    It decides to contribute at the maximum level when average contributions are low to stimulate collective action.
    The contribution level adjusts based on changes in the average contributions over time.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = np.zeros(game_description.n_rounds)
        self.initial_contribution = 1
        self.rate_of_decay = 0.95
        self.threshold = 0.4

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is None:
            return self.initial_contribution * (1 - self.rate_of_decay * (state.round_number - 1)) > self.threshold if state.round_number > 1 else Action.C
        total_cooperators = np.sum(history.opponent_actions[-1])
        average_contribution = self.average_contribution[-1] if len(self.average_contribution) > 0 else 0
        contribution = self.initial_contribution * (1 - self.rate_of_decay * (state.round_number - 1))
        if average_contribution < self.threshold:
            return Action.C
        elif contribution >= total_cooperators / self.game_description.n_players:
            return Action.C
        self.average_contribution[-1] = total_cooperators / self.game_description.n_players
        return contribution

class Strategy_COLLECTIVE_62(BaseStrategy):
    """
    Adaptive ContribuTion Algorithm (ACTA) strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = 0.0
        self.minimum_contribution = 0.0
        self.total_contributions = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0:
            self.total_contributions += random.choice([0, 1]) / 2.0
            return action
        self.average_contribution = np.mean(history.opponent_actions[-self.game_description.n_rounds:, :].flatten())
        self.minimum_contribution = self.game_description.n_players * self.average_contribution
        self.total_contributions += np.sum(history.opponent_actions[-1, :])
        if self.total_contributions >= self.game_description.n_players * self.average_contribution:
            action = Action.C
        elif self.total_contributions <= self.minimum_contribution:
            action = Action.D
        else:
            probability = math.floor((self.total_contributions - self.minimum_contribution) / (self.game_description.n_players * self.average_contribution - self.minimum_contribution) * 2) / 2.0
            action = Action(int(random.random() < probability))
        return action

class Strategy_COLLECTIVE_63(BaseStrategy):
    """
    Strategy that encourages cooperation while allowing for punishment when necessary.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number > 0 and history is not None:
            self.first_round = False
            if history.opponent_actions[-1, -1] == 1:
                return Action.C
            elif state.round_number == self.game_description.n_rounds - 1:
                return Action.C
            else:
                return Action.D
        elif state.round_number > self.game_description.n_rounds:
            self.first_round = True
            return Action.C

class Strategy_COLLECTIVE_64(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) for Public Goods Game.
    This strategy encourages reciprocation and discourages freeloading by adjusting its actions based on the opponent's behavior in previous rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.streak = 0
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.streak = np.sum(history.my_actions[:state.round_number])
        self.last_opponent_action = history.opponent_actions[state.round_number - 1, 0] if state.round_number > 0 else None
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        if history is not None and self.last_opponent_action is not None:
            if self.streak > self.game_description.n_players // 2:
                if self.last_opponent_action == Action.C:
                    return Action.C
                elif self.last_opponent_action == Action.D:
                    return Action.D
            elif self.last_opponent_action == Action.C:
                return Action.D
            elif self.last_opponent_action == Action.D:
                return Action.C
        return Action.C

class Strategy_COLLECTIVE_65(BaseStrategy):
    """
    Strategy Name: Adaptive Public Goods Contribution (APGC)
    Strategy Description: Cooperate when the average contributions of all players in the previous rounds exceeds a threshold T.
                          Defect otherwise. Prevents tragedy of the commons in initial rounds and encourages collective welfare.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.p_init = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C if random.random() < self.p_init else Action.D
        total_contributions = np.sum(history.my_actions[:state.round_number])
        avg_contributions = total_contributions / state.round_number
        if avg_contributions > self.game_description.n_players / (self.game_description.k - 1):
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_66(BaseStrategy):
    """
    Strategy name: Adaptive Contribution Algorithm (ACA)
    ACA encourages cooperation by contributing to the public good when it perceives that not enough participants are doing so.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.avg_contributions = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions[-1].any():
            total_contributions = sum(history.opponent_actions[-1])
            avg_contributions = (self.avg_contributions[-1] + total_contributions) / 2
            if total_contributions < self.game_description.n_players * avg_contributions:
                self.avg_contributions[-1] = total_contributions
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_67(BaseStrategy):
    """
    Adaptive Public Goods Contribution (APGC) strategy for N-player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.sensitivity_factor = 10
        self.contribution_history = []
        self.round_history = []
        self.average_contributions = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.contribution_history.append(len(set(history.my_actions)) > len(self.contribution_history) // 2)
        self.round_history.append(state.round_number)
        if len(self.round_history) <= 1:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            threshold = self.calculate_threshold()
            if len(self.contribution_history) > len(self.round_history):
                average_contributions = np.mean(self.contribution_history[-len(self.contribution_history):])
            else:
                average_contributions = sum(self.contribution_history[-len(self.contribution_history):]) / len(self.contribution_history[-len(self.contribution_history):])
            if average_contributions >= threshold:
                return Action.C
        else:
            threshold = self.calculate_threshold()
            if len(self.contribution_history) > len(self.round_history):
                average_contributions = np.mean(self.contribution_history[-len(self.contribution_history):])
            else:
                average_contributions = sum(self.contribution_history[-len(self.contribution_history):]) / len(self.contribution_history[-len(self.contribution_history):])
            if average_contributions >= threshold:
                self.average_contributions = average_contributions
                return Action.C
        return Action.D

    def calculate_threshold(self) -> float:
        average_contributions = self.average_contributions if len(self.round_history) > len(self.contribution_history) else 0
        return self.k / self.n * (1 + self.sensitivity_factor) * average_contributions

class Strategy_COLLECTIVE_68(BaseStrategy):
    """
    Cooperative Tit-for-Tat with Adaptive Contribution Level (CTF-ACL) for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.k = self.game_description.k
        self.average_contribution = self.k / self.n_players
        self.initial_contribution = self.average_contribution
        self.first_defection_counter = 0
        self.last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1]) if history else self.first_defection_counter >= 4
        c_score = cooperators / self.n_players if cooperators > 0 else 0
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        elif c_score < 0.4:
            return Action.D
        else:
            acl = np.mean(history.my_actions[-self.game_description.n_rounds:]) / self.initial_contribution if history else self.initial_contribution
            action = Action.C if c_score > 0.7 or (0.4 <= c_score <= 0.7 and acl >= self.initial_contribution) else Action.D
            return Action(1 - (action == Action.D)) if state.round_number > 3 else action
        if not cooperators and state.round_number < 4:
            self.first_defection_counter += 1
            return Action(0) if self.first_defection_counter <= 4 else Action.D

class Strategy_COLLECTIVE_69(BaseStrategy):
    """
    Strategy to implement Cooperative Tit-for-Tat in the N-Player Public Goods Game.
    Offers a balance between cooperation and punishment, encouraging long-term collective success.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number < self.game_description.n_rounds and history is not None:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators > 0:
                return Action.C
            self.consecutive_defections += 1
            if self.consecutive_defections < 3:
                return Action.D
            else:
                self.consecutive_defections = 0
                return Action.C
        elif state.round_number == self.game_description.n_rounds:
            return Action.C
        else:
            return Action.C

class Strategy_COLLECTIVE_71(BaseStrategy):
    """
    Adaptive Public Goods Game (APGG) Strategy for N-Player Public Goods Game
    This strategy adopts a tit-for-tat approach with an emphasis on collective welfare, adjusting contributions based on the average contribution rate of all players in previous rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.6
        self.average_contributions = np.zeros(game_description.n_rounds)
        self.cumulative_payoff = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.average_contributions[state.round_number] = np.mean(history.my_actions[-self.game_description.n_rounds:])
        if history is not None:
            self.cumulative_payoff += history.my_payoffs[-1]
        contribution_rate = self.average_contributions[state.round_number]
        if contribution_rate > self.threshold:
            action = Action.C
        elif contribution_rate < self.threshold * 0.4:
            action = Action.D
        else:
            random_deviation = random.random() < 0.1
            action = self.my_actions[-1] if random_deviation else Action(not self.my_actions[-1])
        return action

class Strategy_COLLECTIVE_72(BaseStrategy):
    """
    Adaptive Public Goods Contribution (APGC) strategy for N-player Public Goods Game.
    This strategy cooperates when the average contribution from previous rounds exceeds a certain threshold and defects otherwise.
    It handles edge cases by adjusting its view of the average contribution when encountering inconsistent or unusual player behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.avg_contribution = np.mean([0])
        self.num_players = game_description.n_players
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        avg_contributions = np.mean(history.my_actions[-self.game_description.n_rounds + state.round_number:], axis=0)
        if avg_contributions >= (self.num_players + self.k) / 2:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_73(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) in Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = int(self.game_description.n_players / 2)
        self.t_counter = {i: 0 for i in range(1, self.game_description.n_players + 1)}
        self.last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            return Action.C
        if history is not None and (not self.last_round):
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.threshold:
                for partner in self.t_counter:
                    self.t_counter[partner] = min(self.game_description.n_rounds, self.t_counter[partner] + 1)
            else:
                for partner in self.t_counter:
                    self.t_counter[partner] = max(0, self.t_counter[partner] - 1)
        action = Action.D
        if not history or (history and state.round_number == len(history.opponent_actions)):
            self.last_round = True
        else:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.threshold:
                action = Action.C
                for partner in self.t_counter:
                    if self.t_counter[partner] < self.game_description.n_rounds and history.opponent_actions[-2][partner - 1] == Action.D:
                        action = Action.D
        return action

class Strategy_COLLECTIVE_74(BaseStrategy):
    """
    Strategy Name: Adaptive Public Goods Contribution (APGC)
    Strategy Description: This strategy adapts its contribution based on the average cooperation rate observed in previous rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.2
        self.average_cooperation = None
        self.num_rounds = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            if np.random.random() < self.threshold:
                return Action.C
            return Action.D
        if not self.average_cooperation:
            self.average_cooperation = np.mean([sum(history.opponent_actions[round, :].flatten()) for round in range(state.round_number)])
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.n_players * self.average_cooperation:
            return Action.C
        elif cooperators < self.game_description.n_players * (self.average_cooperation - 0.1):
            self.threshold *= 1.1
        else:
            self.threshold *= 0.9
        return Action.D if cooperators < self.game_description.n_players * self.average_cooperation else Action.C

class Strategy_COLLECTIVE_75(BaseStrategy):
    """
    Adaptive Public Goods Game Strategy (APGG)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players / 2
        self.total_contributions = np.zeros(game_description.n_rounds)
        self.average_contribution = np.zeros(game_description.n_rounds)
        self.history = PlayerHistory(np.zeros(game_description.n_rounds), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is not None:
            self.history = history
            self.total_contributions += np.sum(history.my_actions, axis=0)
            self.average_contribution = self.total_contributions / (self.game_description.n_players * state.round_number)
        if state.round_number == 0:
            return Action.C if random.random() > 0.6 else Action.D
        if state.round_number == self.game_description.n_rounds:
            average = self.average_contribution[-1]
            return Action.C if average > self.threshold else Action.D
        cooperators = sum(self.history.opponent_actions[state.round_number - 1, :])
        average = self.average_contribution[state.round_number - 1]
        return Action.C if cooperators >= self.game_description.n_players // 2 or average > self.threshold else Action.D

class Strategy_COLLECTIVE_77(BaseStrategy):
    """
    A class implementing the Adaptive Public Goods Contribution (APGC) strategy.
    The strategy employs a tit-for-tat approach, balancing cooperation and defection based on the average contribution rate of opponents in previous rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution_rate = np.zeros(self.game_description.n_rounds)
        self.current_contribution_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.average_contribution_rate[state.round_number - 1] = self.current_contribution_rate
        cooperators = sum(history.opponent_actions[-1, :])
        total_players = self.game_description.n_players
        average_contribution_rate = np.mean(self.average_contribution_rate)
        self.current_contribution_rate = (average_contribution_rate + cooperators / total_players) / 2
        if self.current_contribution_rate > 0.6:
            return Action.C
        elif self.current_contribution_rate < 0.4:
            return Action.D
        self.current_contribution_rate = (self.current_contribution_rate + cooperators / total_players) / 2
        return Action.C if self.current_contribution_rate > random.random() else Action.D

    def get_last_round_action(self):
        cooperators = sum(self.average_contribution_rate >= 0.6)
        total_players = self.game_description.n_players
        return Action.C if cooperators >= total_players // 2 else Action.D

class Strategy_COLLECTIVE_78(BaseStrategy):
    """
    Strategy name: Adaptive Focal Point Strategy (AFS)
    This strategy adjusts its contribution based on the actions of others and promotes cooperative behavior by lowering or raising the threshold T accordingly.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.5
        self.average_contributions = np.zeros(self.game_description.n_rounds)
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.update_average_contributions(history)
            cooperators = self.last_round_cooperators if history.opponent_actions[-1].size == 0 else sum(history.opponent_actions[-1])
            if state.round_number == self.game_description.n_rounds - 1:
                return Action.D
            if cooperators >= self.game_description.n_players * self.threshold:
                self.threshold -= 0.05 if self.threshold > 0.3 else 0.0
            elif cooperators < self.last_round_cooperators:
                self.threshold += 0.05 if self.threshold < self.game_description.n_players - 1 else 0.0
            self.last_round_cooperators = cooperators
            return Action.C if cooperators >= self.game_description.n_players * self.threshold else Action.D

    def update_average_contributions(self, history: PlayerHistory):
        self.average_contributions[self.average_contributions.size - 1] = sum(history.opponent_actions[-1]) / self.game_description.n_players
        if self.average_contributions.size > self.game_description.n_rounds // 10:
            self.average_contributions = np.roll(self.average_contributions, -1)

class Strategy_COLLECTIVE_80(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Cooperation (ATTCG) for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.g = int(math.ceil(game_description.n_players / 2))
        self.contribution_increment = 0.1
        self.contribution_level = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if not history:
            return Action.D
        cooperators = np.sum(history.opponent_actions[-1])
        contribution_multiplier = self.contribution_level if state.round_number >= self.g else 1
        if cooperators >= self.game_description.n_players // 2:
            self.contribution_level = min(self.contribution_level + self.contribution_increment, 1)
        return Action(int(math.floor(self.contribution_level)))

class Strategy_COLLECTIVE_81(BaseStrategy):
    """
    Strategy Name: Adaptive Public Goods Contribution (APGC)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(game_description.n_rounds - 1)
        self.current_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.C
        self.current_round = state.round_number - 1
        total_contributions = sum(history.my_actions[-self.game_description.n_rounds + self.current_round + 1:])
        self.average_contributions[self.current_round] = total_contributions / (self.game_description.n_rounds - self.current_round - 1)
        if self.current_round > 0:
            cooperate = self.average_contributions[-1] > self.average_contributions.mean()
        else:
            cooperate = True
        return Action.C if cooperate else Action.D

class Strategy_COLLECTIVE_82(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Public Goods Game (PGG)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperator_threshold = math.ceil(game_description.n_players / 2)
        self.forgiveness_window = int(game_description.n_rounds * 0.8)
        self.history_length = int(game_description.n_rounds * 0.75)
        self.current_round = 0
        self.past_actions = []
        self.past_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            self.past_actions = []
            self.current_round = state.round_number
            return Action.C
        self.current_round = state.round_number
        if len(self.past_actions) < self.history_length:
            self.past_actions.append(history.opponent_actions[-1])
        cooperators_in_past = np.count_nonzero(self.past_actions[-1])
        past_rounds_with_cooperation = sum([1 for actions in self.past_actions if cooperators_in_past <= len(actions) * (1 - 0.2)])
        if past_rounds_with_cooperation >= self.forgiveness_window:
            return Action.C
        if cooperators_in_past >= self.cooperator_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_83(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Adjustment (ATfT-PG) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.initial_contribution_rate = 0.8
        self.adjustment_rate = 0.01
        self.cooperation_threshold = 0.6
        self.history_length = int(self.game_description.n_rounds * 0.3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        contributions = np.sum(history.opponent_actions, axis=1)
        average_contribution = np.mean(contributions)
        contribution_rate = self.initial_contribution_rate
        if len(contributions) < self.history_length:
            history_contributions = contributions[:len(contributions)]
        else:
            history_contributions = np.roll(contributions, -self.history_length)
        total_contribution = np.sum(history_contributions)
        if total_contribution < contribution_rate * len(contributions):
            contribution_rate -= self.adjustment_rate
        elif total_contribution > contribution_rate * self.cooperation_threshold * len(contributions):
            contribution_rate += self.adjustment_rate
        return Action(int(contribution_rate)) if contribution_rate >= 0.5 else Action.D

class Strategy_COLLECTIVE_84(BaseStrategy):
    """
    A strategy that employs an adaptive Tit-for-Tat Cooperative Approach in N-Player Public Goods Games.
    This approach encourages cooperation by following cooperative behavior initially, and adapting the cooperation threshold based on other players' past performance.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players // 2
        self.forgiveness_counter = 0
        self.average_contribution = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        else:
            if history is None:
                return Action.D
            cooperators = sum(history.opponent_actions[-1, :])
            self.average_contribution[state.round_number - 1] = (cooperators + np.sum(history.my_actions[-1])) / (self.game_description.n_players * 2)
            if self.average_contribution[-1] >= self.threshold:
                self.threshold += min(self.threshold + math.sqrt(self.game_description.n_rounds / state.round_number), self.game_description.n_players - self.threshold)
            elif self.average_contribution[-1] < self.threshold and self.forgiveness_counter < self.game_description.n_rounds // 2:
                self.threshold -= min(self.threshold - math.sqrt(self.game_description.n_rounds / state.round_number), self.threshold)
                self.forgiveness_counter += 1
            else:
                self.forgiveness_counter = 0
                self.threshold = self.game_description.n_players // 2
            if self.average_contribution[-1] >= self.threshold:
                return Action.C
            return Action.D

class Strategy_COLLECTIVE_86(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Modified Initial Contribution (A-TFT-MIC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.t = 0.5
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number > 0 and history is not None:
            average_contribution = np.mean(history.my_actions[state.round_number - 1])
            if average_contribution >= self.t:
                return Action.C
            elif average_contribution < self.t and self.history.my_actions[-2][-1] == 1:
                return Action.C
        return Action.D



class Strategy_COLLECTIVE_88(BaseStrategy):
    """
    Adaptive Public Goods Game (APGG) Strategy for N-Player Public Goods Games.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        elif state.round_number == self.game_description.n_rounds:
            return Action.C
        else:
            total_contributions = np.sum(history.my_actions[-1])
            average_contribution = self.average_contributions[self.game_description.n_rounds - 1] / (state.round_number - 1)
            if total_contributions < average_contribution:
                self.average_contributions[-1] = total_contributions
                return Action.C
            else:
                self.average_contributions[-1] = average_contribution
                return Action.D

class Strategy_COLLECTIVE_89(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros((1, 2), dtype=bool), my_payoffs=np.zeros(1), opponent_actions=np.zeros((1, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((1, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :])
        return Action(int(cooperators > self.game_description.n_players // 2))

class Strategy_COLLECTIVE_90(BaseStrategy):
    """
    Adaptive Contribution Algorithm (ACA) for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.total_contributions = 0.0
        self.round_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C if random.random() < 0.5 else Action.D
        self.round_count += 1
        total_contributions = self.total_contributions + sum(history.my_actions)
        contribution_rate = total_contributions / (self.game_description.n_players * self.round_count)
        if 0 < contribution_rate < 1:
            return Action.C
        if history and state.round_number == self.game_description.n_rounds - 1:
            total_previous_contributions = sum(history.my_payoffs[:-1])
            if total_previous_contributions > self.game_description.n_players * (self.game_description.k / 2):
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_91(BaseStrategy):
    """
    Adaptive Public Goods Game (APGG) Strategy
    Cooperates or defects based on observed average contribution rate.
    Starts by contributing a certain proportion of its endowment in the first round,
    and adjusts contributions in the last round considering the game's context.
    Prioritizes collective welfare among players.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_rate = 0.5
        self.average_contribution = np.zeros(game_description.n_rounds - 1)
        self.threshold = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        action = Action.D
        if len(self.average_contribution) > 0:
            self.average_contribution[-1] = np.mean(history.my_actions[1:])
        if self.average_contribution[-1] > self.threshold:
            action = Action.C
        return action

class Strategy_COLLECTIVE_92(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat (ATFT) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_contribution_history = np.zeros(game_description.n_players)
        self.threshold = (game_description.n_players - 1) / 2
        self.rounds_with_opponent = np.zeros(game_description.n_players, dtype=np.int32)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            opponent_contributions = history.opponent_actions[:, -1].flatten()
            total_rounds_with_opponents = self.rounds_with_opponent.sum()
            if total_rounds_with_opponents == 0:
                opponent_avg = np.mean(opponent_contributions)
                self.threshold *= (opponent_avg + 1) / 2
            else:
                self.threshold = self.threshold * ((total_rounds_with_opponents - 1) / total_rounds_with_opponents)
            if history.my_actions[-1] and np.mean(history.opponent_actions[:, -1]) > self.threshold:
                return Action.C
            else:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_93(BaseStrategy):
    """
    Adaptive Focal Point Public Goods Game Strategy (AFPPG)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.m = int(math.ceil(game_description.n_players * 0.2))
        self.avg_contributions = np.zeros((self.m,))
        self.history_size = self.game_description.n_players * self.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        if history is not None and len(history.my_actions) >= self.history_size:
            total_contributions = np.sum(history.my_actions[self.history_size - self.m:])
            average_contribution_rate = total_contributions / self.history_size
            if average_contribution_rate >= self.game_description.k / self.game_description.n_players:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_94(BaseStrategy):
    """
    Adaptive and robust collective strategy called the "Freeman Strategy".
    Balances individual incentives with collective welfare, aligning itself with a collective mindset.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players // 2
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players - 1), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.history = history
            average_contributions = np.mean(self.history.my_actions[-self.game_description.n_rounds:])
            self.threshold = int(average_contributions + self.game_description.n_players // 4) if average_contributions > self.game_description.n_players // 2 else int(average_contributions - self.game_description.n_players // 4)
        cooperators = sum(self.history.opponent_actions[-1, :])
        if cooperators >= self.threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_95(BaseStrategy):
    """
    Adaptive Public Goods Contribution (APGC) strategy for N-Player Public Goods Game.
    This strategy decides whether to contribute or not based on personal experience, collective history, and game parameters.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.x = 5
        self.y = 5
        self.t = 0.6
        self.p = 0.3
        self.personal_history = np.zeros(self.x)
        self.average_payoff = 0.0
        self.total_contributions_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            k_over_n = self.game_description.k / self.game_description.n_players
            if k_over_n > 0.5:
                return Action.C
            else:
                return Action.D
        if history is None:
            return self(__call__, state, None)[0]
        self.personal_history = np.roll(self.personal_history, -1)
        self.personal_history[-1] = 1 if history.my_actions[-1] == Action.C else 0
        self.average_payoff = np.mean(history.my_payoffs[-self.x:])
        total_contributions = sum(history.opponent_actions[:, -1].flatten())
        self.total_contributions_rate = total_contributions / history.opponent_actions.shape[0]
        if self.average_payoff > (1 - self.t) * self.personal_history[-self.x].mean() or self.total_contributions_rate > self.t:
            return Action.C
        elif self.game_description.k / self.game_description.n_players < self.p:
            return Action.D
        else:
            return random.choice([Action.C, Action.D])

class Strategy_COLLECTIVE_96(BaseStrategy):
    """
    A strategy that emulates the Adaptive Tit-for-Tat behavior in the N-Player Public Goods Game (PGG).
    This strategy encourages cooperation by matching the average contribution of other players, and punishes defection through reduced contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.m = int(math.ceil(game_description.n_players / 2))
        self.l = int(math.floor(game_description.n_rounds / 3))
        self.p = int(math.ceil(game_description.n_rounds / 4))
        self.threshold = game_description.k * (1 - 0.5)
        self.current_punishment = False
        self.punishment_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and history.opponent_actions is None):
            return Action.C
        if self.current_punishment:
            self.punishment_counter += 1
            if self.punishment_counter >= self.p:
                self.current_punishment = False
                self.punishment_counter = 0
            return Action.D
        if history is None or len(history.opponent_actions) < self.m:
            return Action.C
        total_contributions = np.sum(np.mean(history.opponent_actions[-self.m:], axis=0))
        if total_contributions >= self.threshold:
            return Action.C
        else:
            if sum(history.opponent_actions[-self.l:, :].flatten()) < self.game_description.n_players * self.threshold:
                self.current_punishment = True
            return Action.D

class Strategy_COLLECTIVE_97(BaseStrategy):
    """
    Adaptive Contributor (AC) strategy for N-Player Public Goods Game.
    This strategy cooperates when the average contribution rate across all players exceeds a certain threshold, and defects otherwise.
    The threshold ensures that each player receives at least one token from the public good.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution_rate = np.zeros(self.game_description.n_players)
        self.total_cooperators = 0
        self.round_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.round_count += 1
        if history is not None:
            my_contributions = int(history.my_actions[-1].sum())
            self.total_cooperators += my_contributions
            if self.round_count > 1:
                average_contribution_rate = self.total_cooperators / (self.round_count - 1)
                threshold = (self.game_description.n_players * self.game_description.k - self.game_description.n_players + 1) / self.game_description.n_players
                if average_contribution_rate > threshold:
                    return Action.C
        return Action.D

class Strategy_COLLECTIVE_98(BaseStrategy):
    """
    Adaptive Public Goods Contribution (APGC) strategy for N-Player Public Goods Game.
    This strategy adjusts its contributions based on the average contribution of all players in the game so far.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(self.game_description.n_rounds)
        self.num_players = self.game_description.n_players
        self.threshold = self.num_players // self.game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            self.average_contributions[state.round_number - 1] = np.mean(history.my_actions[:state.round_number])
        total_contributions = np.sum(history.my_actions)
        self.average_contributions[state.round_number - 1] = total_contributions / state.round_number
        average_contribution = self.average_contributions[-1]
        if average_contribution == self.threshold:
            return random.choice([Action.C, Action.D])
        return Action.C if average_contribution >= self.threshold else Action.D



class Strategy_COLLECTIVE_100(BaseStrategy):
    """
    Strategy that adapts contribution based on average past contributions of all players.
    Focuses on promoting cooperation among players and aligning with a collective mindset.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_history = np.zeros(self.game_description.n_rounds)
        self.average_contributions = 0.5

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return np.random.choice([Action.C, Action.D], p=[self.average_contributions, 1 - self.average_contributions])
        self.contribution_history[state.round_number - 1] = sum(history.opponent_actions[-1, :]) / self.game_description.n_players
        self.average_contributions = math.ceil((self.contribution_history.sum() + 0.5) / self.game_description.n_rounds)
        if self.average_contributions >= 1:
            return Action.C
        elif self.average_contributions <= 0:
            return Action.D
        contribution_distance = abs(self.average_contributions - 0.5)
        if contribution_distance > 0.3:
            return Action.C
        elif contribution_distance < 0.3:
            return Action.D
        else:
            return Action(math.ceil(2 * contribution_distance))

class Strategy_COLLECTIVE_101(BaseStrategy):
    """
    Tit-for-Tat with Adaptation Strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round_cooperation = False
        self.last_cooperator_count = 0
        self.adaptation_timer = 0
        self.last_round = -1

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or self.last_round != state.round_number - 1:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if cooperators == self.game_description.n_players:
            self.last_round_cooperation = True
            self.adaptation_timer = 0
        elif self.last_round_cooperation and cooperators == 0:
            if self.adaptation_timer < self.game_description.n_rounds // 10:
                return Action.D
            else:
                self.last_round_cooperation = False
                self.adaptation_timer = 0
        elif self.last_round_cooperation and cooperators > 0:
            self.last_round_cooperation = True
        else:
            self.last_round_cooperation = False
            self.adaptation_timer = 0
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        if history is not None and state.round_number > 1 and (history.my_payoffs[state.round_number - 2] == 0):
            self.last_cooperator_count -= np.sum(history.opponent_actions[state.round_number - 2, :])
        else:
            self.last_cooperator_count = cooperators
        if self.last_cooperator_count > 0 and random.random() < self.last_cooperator_count / self.game_description.n_players:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_102(BaseStrategy):
    """
    Adaptive ContribuTion (ACT) Strategy for N-Player Public Goods Game.
    This strategy adjusts its contributions based on the group's average behavior, promoting cooperation while being adaptive to various opponent behaviors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.endowment = self.game_description.n_players * (1 - self.game_description.k) / (self.game_description.n_players - 1)
        self.contribution_history = np.zeros(self.game_description.n_rounds, dtype=np.float64)
        self.average_contributions = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.contribution_history[state.round_number - 1] = int(self.endowment * (history.my_actions[-1] if history else [Action.D]))
        if state.round_number < self.game_description.n_rounds - 1:
            self.average_contributions[:state.round_number] = np.mean(self.contribution_history[1:])
        if state.round_number == self.game_description.n_rounds - 1 or np.all(np.greater(np.sum(history.opponent_actions[-1]), self.game_description.n_players * self.game_description.k)):
            return Action.C
        if self.contribution_history[-1] > np.mean(self.average_contributions[:-1]):
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_104(BaseStrategy):
    """
    A strategy that mimics the opponent's actions, encouraging reciprocity and maintaining a balance between individual incentives and collective benefit. The adaptability feature allows TFT-A to modify its strategy based on the opponent's behavior, promoting long-term cooperation when it is beneficial for the group.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history_length = int(math.ceil(game_description.n_rounds * 0.8))
        self.average_cooperation_threshold = 0.3
        self.current_cooperation_count = 0
        self.cooperative_history_sum = 0
        self.defensive_mode = False

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0 or history is None:
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            average_cooperation = self.cooperative_history_sum / (self.current_cooperation_count + 1)
            if average_cooperation > 0.5 and history.my_actions[-1] == Action.C:
                return Action.C
            elif not average_cooperation > 0.5:
                return Action.D
        else:
            opponent_cooperated = sum(history.opponent_actions[state.round_number - 1, :])
            self.current_cooperation_count += int(history.my_actions[state.round_number - 1])
            if opponent_cooperated >= self.game_description.n_players // 2:
                self.cooperative_history_sum += 1
                self.current_cooperation_count = max(0, self.current_cooperation_count - 1)
                if self.defensive_mode and opponent_cooperated == 0:
                    self.defensive_mode = False
                    return Action.C
            elif opponent_cooperated < self.game_description.n_players // 2:
                self.current_cooperation_count += 1
                if not self.defensive_mode and opponent_cooperated == self.game_description.n_players:
                    self.defensive_mode = True
            else:
                cooperation_average = self.cooperative_history_sum / (self.current_cooperation_count + 1)
                if cooperation_average < self.average_cooperation_threshold and opponent_cooperated == 1:
                    return Action.D
                elif cooperation_average > 1 - self.average_cooperation_threshold and opponent_cooperated == 0:
                    return Action.C
        return Action.D

class Strategy_COLLECTIVE_105(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the N-Player Public Goods Game.
    This strategy cooperates (contributes) if the previous player contributed in the last round, and defects (does not contribute) if the previous player did not contribute.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_actions) == 0):
            return Action.C
        else:
            my_action = history.my_actions[-1] if history is not None else False
            cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
            return Action(my_action + (1 - my_action) * (cooperators >= self.game_description.n_players // 2))

class Strategy_COLLECTIVE_106(BaseStrategy):
    """
    A strategy for N-player Public Goods Game using a collective mindset.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.community_trust = game_description.n_players // 2
        self.contribution_history = np.zeros(game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        avg_contribution = np.mean(self.contribution_history[:state.round_number])
        self.community_trust += (avg_contribution - self.community_trust) * 0.1
        self.contribution_history[state.round_number] = np.mean(history.opponent_actions[-1, :]) if history else 0
        if avg_contribution >= self.community_trust:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_107(BaseStrategy):
    """
    An adaptive strategy that adjusts its contribution based on the average behavior of other players.
    This strategy encourages cooperation when others do so but also being selfish when necessary.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_rate = game_description.n_players // 2
        self.increment = 0.01
        self.decrement = 0.01

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and (not history):
            return Action.C if self.contribution_rate >= self.game_description.n_players // 2 else Action.D
        cooperators = np.mean(history.opponent_actions[:state.round_number, :].sum(axis=0))
        if state.round_number < self.game_description.n_rounds - 1:
            if self.contribution_rate < self.game_description.n_players // 2 and cooperators >= self.game_description.n_players // 2:
                self.contribution_rate += self.increment
            elif self.contribution_rate >= self.game_description.n_players // 2 and cooperators < self.game_description.n_players // 2:
                self.contribution_rate -= self.decrement
        else:
            pass
        return Action.C if self.contribution_rate >= self.game_description.n_players // 2 else Action.D

class Strategy_COLLECTIVE_108(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) in Public Goods Game
    This strategy encourages cooperation by reciprocating contributions from opponents, aligning with a collective mindset of shared benefits. However, it also punishes defection to maintain fairness within the game. The strategy adapts to opponent behaviors and seeks equilibrium between individual incentives and collective welfare.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.round_counter = 0
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number == 1 and history is not None:
            self.last_opponent_action = np.mean(history.opponent_actions[0])
        self.round_counter += 1
        if self.round_counter < 3:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        current_opponent_action = np.mean(history.opponent_actions[-1])
        if self.last_opponent_action is None or math.isnan(self.last_opponent_action):
            self.last_opponent_action = current_opponent_action
        elif current_opponent_action == self.last_opponent_action:
            return Action.C if cooperators >= self.game_description.n_players // 2 else Action.D
        else:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1 or self.round_counter == self.game_description.n_rounds:
            return Action.C

class Strategy_COLLECTIVE_109(BaseStrategy):
    """
    A strategy that follows the Tit-for-Tat rule in the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_last_action = Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1 or self.opponent_last_action == Action.D:
            return Action(history.my_actions[-1] if history else [Action.C])
        cooperators = sum(history.opponent_actions[state.round_number - 1, :]) if history else 0
        return Action(self.opponent_last_action == Action.C and cooperators >= self.game_description.n_players // 2 or Action.D)

    def update_history(self, state: GameState, action: Action, payoff: float):
        self.opponent_last_action = action if state.round_number > 0 else Action.C

class Strategy_COLLECTIVE_111(BaseStrategy):
    """
    Strategy Name: Adaptive Contingent Contribution (A3C)
    Strategy Description: A strategy that encourages cooperation and fairness by contributing tokens when others do so consistently, but defecting when there is a perceived lack of collective effort.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = np.zeros(self.game_description.n_rounds)
        self.threshold = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.my_actions) > 0:
            self.average_contribution = np.roll(self.average_contribution, -1)
            self.average_contribution[-1] = np.mean(history.my_actions)
        average_contribution = np.mean(history.my_actions) if history is not None else None
        action = Action.C if average_contribution is not None and average_contribution >= self.threshold else Action.D
        return action

class Strategy_COLLECTIVE_112(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for the N-Player Public Goods Game (PGG).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.base_contribution = 0.5
        self.contributions_history = np.zeros(game_description.n_players)
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.rounds_played < self.game_description.n_players - 1:
            self.contributions_history.fill(self.base_contribution)
            self.rounds_played += 1
        if history is not None and state.round_number > 0:
            self.rounds_played += 1
            cooperators = sum(history.opponent_actions[-1, :])
            average_contribution = np.mean(self.contributions_history) if self.rounds_played >= self.game_description.n_players else self.base_contribution
            self.contributions_history[history.opponent_actions[-1].argmax()] = cooperators / self.game_description.n_players
            if cooperators > average_contribution:
                return Action.C
            elif cooperators < average_contribution:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_113(BaseStrategy):
    """
    A strategy that adapts its contribution based on the average contributions of all players in the game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(self.game_description.n_rounds)
        self.optimal_contribution = self.game_description.n_players * (self.game_description.k - 1) / (self.game_description.k * self.game_description.n_players - self.game_description.k + 1)
        self.epsilon = 0.2
        self.p = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        contributions = np.sum(history.my_actions if history else [Action.C])
        self.average_contributions[state.round_number] = contributions / (state.round_number + 1)
        if state.round_number < self.game_description.n_rounds - 1:
            contribution_decision = self._contribute_or_not(self.average_contributions[state.round_number])
            return contribution_decision
        else:
            average_contribution = np.mean(self.average_contributions)
            return self._contribute_or_not(average_contribution)

    def _contribute_or_not(self, average_contribution):
        if average_contribution > (1 - self.epsilon) * self.optimal_contribution:
            return np.random.choice([Action.C, Action.D], p=[self.p, 1 - self.p])
        elif average_contribution < (1 + self.epsilon) * self.optimal_contribution:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_114(BaseStrategy):
    """
    Adaptive Fidelity Contribution (AFC) Strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_rate = 0.2
        self.avg_cooperation_threshold = game_description.k * game_description.n_players / game_description.n_players
        self.last_round_payoff = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and state.round_number != self.game_description.n_rounds:
            cooperators = sum(history.opponent_actions[-1, :])
            total_players = history.opponent_actions.shape[1]
            cooperation_rate = cooperators / total_players
            if cooperation_rate < self.avg_cooperation_threshold / 2:
                self.contribution_rate += (self.avg_cooperation_threshold / total_players - cooperation_rate) * 0.1
                self.contribution_rate = min(max(self.contribution_rate, 0), 1)
            elif cooperation_rate >= self.avg_cooperation_threshold:
                self.last_round_payoff = np.mean(history.my_payoffs[-1])
                if self.last_round_payoff > self.avg_cooperation_threshold:
                    self.contribution_rate = 1
            else:
                self.contribution_rate -= (self.avg_cooperation_threshold / total_players - cooperation_rate) * 0.4
                self.contribution_rate = max(self.contribution_rate, 0)
        return Action.C if random.random() < self.contribution_rate else Action.D

class Strategy_COLLECTIVE_115(BaseStrategy):
    """
    A freeriding strategy for the N-Player Public Goods Game that balances self-interest and collective welfare.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.k = self.game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or state.round_number == self.game_description.n_rounds - 1:
            return self._decide_action(state, history)
        cooperators = sum(history.opponent_actions[-1, :])
        expected_payoff_cooperate = self.k / self.n_players * np.sum([np.array([cooperators + 1, cooperators]) + 1]) - 1
        expected_payoff_defect = 1
        return Action.C if expected_payoff_cooperate > expected_payoff_defect else Action.D

    def _decide_action(self, state: GameState, history: None) -> Action:
        return Action.C if random.random() > 0.5 else Action.D

class Strategy_COLLECTIVE_116(BaseStrategy):
    """
    Strategy name: Adaptive Contribution Strategy (ACS)
    Summary: ACS adjusts its contributions based on the observed behavior of others and rewards those who contribute more while penalizing freeriders.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.contribution_rate = 0.5
        self.threshold = 0.2
        self.punishment = 0.8
        self.reward = 1.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.contribution_rate = random.choice([0.25, 0.75])
            return Action(int(self.contribution_rate))
        contributions = np.mean(history.my_actions.ravel())
        if contributions >= 1 - self.threshold or contributions <= self.threshold:
            return Action(int(self.contribution_rate))
        if contributions < self.threshold:
            self.contribution_rate *= self.punishment
        elif contributions > 1 - self.threshold:
            self.contribution_rate *= self.reward
        return Action(int(self.contribution_rate))

class Strategy_COLLECTIVE_117(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Freerider Deterrence (A-TFTFD) strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = int(game_description.n_players * 0.5)
        self.freeriders = set()

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_actions = history.my_actions if history else np.zeros(self.game_description.n_rounds, dtype=bool)
        opponent_actions = history.opponent_actions if history else np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool)
        if len(my_actions) < self.game_description.n_rounds:
            my_total_contributions = sum(my_actions)
            if my_total_contributions < self.threshold * 2:
                self.freeriders.add(self.__class__)
        if history:
            last_round = -1 if state.round_number == 0 else state.round_number - 1
            last_cooperators = sum(opponent_actions[last_round, :])
            my_contribution = my_actions[-1] if len(my_actions) > last_round else False
        else:
            last_cooperators = 0
            my_contribution = False
        if my_contribution:
            if last_cooperators >= self.threshold or self.__class__ not in self.freeriders:
                return Action.C
        elif last_cooperators < self.threshold and self.__class__ not in self.freeriders:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_118(BaseStrategy):
    """
    Tit-for-Tat with Fitness-Based Adaptation (TFT-FA) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        contributions = np.mean(history.opponent_actions[:, :-1].flatten()) if history else 0
        self.average_contributions[state.round_number] = contributions
        if contributions > self.game_description.n_players / 2:
            return Action.C
        return Action.D



class Strategy_COLLECTIVE_120(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Awareness (ATTPGA) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.current_round = 0
        self.cooperation_history = [False] * game_description.n_players
        self.last_state = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.current_round += 1
        self.last_state = history if history is not None else PlayerHistory(np.zeros((self.game_description.n_rounds,), dtype=bool), np.zeros((self.game_description.n_rounds,), dtype=np.float64))
        if history is not None:
            self.last_state.opponent_actions = history.opponent_actions[:self.current_round]
            self.last_state.my_payoffs = history.my_payoffs[:self.current_round]
            self.cooperation_history = history.opponent_actions[-1, :].tolist()
        if self.current_round == self.game_description.n_rounds:
            return Action.C
        if self.last_state.my_payoffs[-1] == 0 and self.cooperation_history[-1]:
            self.cooperation_history[-1] = False
        elif self.last_state.my_payoffs[-1] > 0 and (not self.cooperation_history[-1]):
            self.cooperation_history[-1] = True
        return Action.C if self.cooperation_history[-1] else Action.D

class Strategy_COLLECTIVE_122(BaseStrategy):
    """
    A strategy that cooperates when the average contribution of all players is greater than or equal to half the number of players.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = int(math.ceil(game_description.n_players * 0.5))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            opponents_cooperators = sum(history.opponent_actions[-1])
            return Action.C if opponents_cooperators >= self.threshold else Action.D
        return Action.D

class Strategy_COLLECTIVE_123(BaseStrategy):
    """
    TFT-LCA (Tit-for-Tat with Linear Contribution Adjustment) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.population_contribution = 0.0
        self.total_contributions = 0
        self.contribution_rate = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.population_contribution = np.mean(history.opponent_actions[:, :self.game_description.n_players - 1])
        self.total_contributions = sum(history.my_actions)
        self.contribution_rate = self.population_contribution if self.population_contribution > 0 else self.total_contributions / (self.game_description.n_players - 1)
        return Action.C if np.sum(history.opponent_actions[-1]) >= int((self.game_description.n_players - 1) * self.population_contribution) else Action.D

    def adjust_contribution_rate(self):
        """
        Adjust contribution rate based on past games.
        """
        if self.total_contributions == 0:
            self.contribution_rate = 1.0
        else:
            self.contribution_rate = self.total_contributions / self.population_contribution

class Strategy_COLLECTIVE_125(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.prev_opponent_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.prev_opponent_action = np.full(self.game_description.n_players, fill_value=Action.C.value)
            return Action.C
        current_opponent_actions = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players)
        self.prev_opponent_action = current_opponent_actions
        cooperators = sum(current_opponent_actions)
        if cooperators > 0 and self.prev_opponent_action[0] == Action.C.value or cooperators == self.game_description.n_players:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_126(BaseStrategy):
    """
    Strategy name: Adaptive Public Goods Contribution (APGC)
    A simple cooperative strategy that adapts its contribution based on the group's behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.critical_value = game_description.k / game_description.n_players
        self.last_history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        else:
            if self.last_history is None:
                self.last_history = history
            cooperators = sum(self.last_history.opponent_actions[-1])
            if cooperators / self.game_description.n_players > self.critical_value:
                return Action.C
            else:
                return Action.D
        self.last_history = history

class Strategy_COLLECTIVE_127(BaseStrategy):
    """
    Adaptive Fixed Contribution (AFC) Strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.m = 5
        self.w = 0.3
        self.threshold = None
        self.contributions = np.zeros(self.m)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return random.choice([Action.C, Action.D])
        total_contributions = np.sum(history.opponent_actions[state.round_number - 1, :])
        self.contributions = np.roll(self.contributions, -1)
        self.contributions[-1] = total_contributions / self.game_description.n_players
        if self.threshold is None:
            self.threshold = np.mean(self.contributions) * (1 - self.w)
        self.threshold = (1 - self.w) * (self.threshold + self.w * total_contributions / self.game_description.n_players) / (1 + self.w * (self.m - 1))
        return Action.C if total_contributions >= self.threshold * self.game_description.n_players else Action.D

class Strategy_COLLECTIVE_128(BaseStrategy):
    """
    Adaptive Contribution Algorithm (ACA) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_rate = 0.5
        self.average_contrib = np.zeros(game_description.n_rounds)

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C if random.random() < self.contribution_rate else Action.D
        self.average_contrib[state.round_number] = np.mean(history.opponent_actions[:, :-1].ravel())
        threshold = self.game_description.k / self.game_description.n_players * (self.game_description.n_rounds - 1)
        return Action.C if np.mean(history.opponent_actions[:, -1]) > threshold else Action.D



class Strategy_EXPLOITATIVE_4(BaseStrategy):
    """
    A Tit-for-Tat strategy with Gradual Cooperation, which cooperates if the opponent contributed in the previous round and gradually increases its cooperation rate over time.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.round_number = 0
        self.f = None
        self.m = game_description.k - 1
        self.n = game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history.my_actions[-1] and self.f is None:
            self.f = np.mean(history.my_actions[:-1])
        cooperation_probability = 1 - self.round_number / self.game_description.n_rounds * (self.m - self.f / self.n) if history.my_actions[-1] else 0
        action = Action(int(random.uniform(0, 1) < cooperation_probability))
        self.round_number += 1
        return action

class Strategy_EXPLOITATIVE_5(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Contribution (TFTAC)
    Strategy Description: This strategy cooperates if the average contribution of opponents exceeds a certain threshold. The threshold is dynamically adjusted based on the opponent's historical contributions, starting from an initial value near the average payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_threshold = np.mean([1 - x for x in np.linspace(0.6, 1, self.game_description.n_players)])
        self.historical_contributions = np.zeros(self.game_description.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            total_contributions = sum(history.my_actions[-len(history.my_payoffs):])
            average_contribution = total_contributions / len(history.my_payoffs)
            if average_contribution > self.average_threshold:
                self.adjust_average_threshold(average_contribution, state.round_number)
                return Action.C
        return Action.D

    def adjust_average_threshold(self, current_average, round_number):
        self.historical_contributions = np.roll(self.historical_contributions, -1)
        self.historical_contributions[round_number - 1] = current_average
        self.average_threshold = np.mean(np.concatenate((self.historical_contributions, [current_average])))

class Strategy_EXPLOITATIVE_6(BaseStrategy):
    """
    The Public Goods Game Exploitative Strategy (PGEES).
    A strategy that decides to cooperate or defect based on the average contribution rate of all players in previous rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.5
        self.exploitation_probability = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        total_contributions = np.sum(history.my_actions[:state.round_number].sum(axis=0))
        average_contribution_rate = total_contributions / (self.game_description.n_players * state.round_number)
        if average_contribution_rate >= self.threshold:
            cooperation_probability = average_contribution_rate
        else:
            cooperation_probability = 1 - self.exploitation_probability + self.exploitation_probability * average_contribution_rate
        if random.random() < cooperation_probability:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_7(BaseStrategy):
    """
    A strategy that mimics the Tit-for-Tat-with-Forgiveness (TFTF) behavior in an N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_actions_history = []
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        if history and state.round_number > 1:
            self.opponent_actions_history.append(history.opponent_actions[-1].flatten())
            cooperators = sum(self.opponent_actions_history[-1])
            self.last_round_cooperators = cooperators
        if len(self.opponent_actions_history) > 1 and state.round_number == self.opponent_actions_history[-1].size:
            if self.last_round_cooperators >= self.game_description.n_players // 2:
                return Action.C
        return Action.D if self.last_round_cooperators == 0 else Action.C

class Strategy_EXPLOITATIVE_8(BaseStrategy):
    """Tit-for-Tat with Adaptive Contribution (TFT-AC) strategy for N-Player Public Goods Game"""

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_action = self.contribution_history[-1] if len(self.contribution_history) > 0 else None
        opponent_actions = history.opponent_actions[:, -1]
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        if my_action is None or not any(opponent_actions):
            return Action.D
        cooperators = sum(opponent_actions)
        return Action(cooperators >= np.sum(self.contribution_history) if my_action else 0)

    def update(self, payoff: float, opponent_payoff: float):
        self.contribution_history.append(self.__class__().D if not any(opponent_payoff) else 1)

class Strategy_EXPLOITATIVE_9(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Contribution (TFTAC)
    Strategy description: A cooperative strategy that adjusts its contribution level based on the opponent's actions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_reduction = 0.5
        self.punishment_duration = math.ceil(game_description.n_players / 2)
        self.average_contribution_threshold = (game_description.n_players - 1) / 2
        self.base_reduction = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        if opponent_cooperators > 0:
            return Action.C
        elif state.round_number == 1:
            self.punishment_duration = min(self.punishment_duration * 2, self.game_description.n_players)
            return Action.C
        else:
            punishment_rounds_left = math.floor(self.punishment_duration)
            punishment_level = max(0, min(1, self.punishment_reduction ** punishment_rounds_left))
            return Action(int(punishment_level))
        average_contribution = np.mean(history.opponent_actions[:state.round_number, :].flatten())
        if state.round_number >= self.punishment_duration and average_contribution < self.average_contribution_threshold:
            self.base_reduction = min(self.base_reduction + 0.1, 0.9)
            return Action(int(self.base_reduction))
        else:
            self.punishment_duration = 1
            return Action.C

class Strategy_EXPLOITATIVE_10(BaseStrategy):
    """
    A Tit-for-Tat with Adaptation (TFT-A) strategy for N-Player Public Goods Game.
    The strategy cooperates in the first round and subsequently mimics the opponent's last contribution in the previous round.
    If the total contributions are insufficient, TFT-A will contribute to ensure at least some collective benefit is achieved.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros((1, 2), dtype=bool), np.zeros(1), np.zeros((1, game_description.n_players), dtype=bool), np.zeros(1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.history = history or self.history
        last_round = len(self.history.opponent_actions) - 1
        cooperators = sum(self.history.opponent_actions[last_round, :])
        total_contributions = sum(self.history.opponent_actions.flatten())
        if total_contributions < self.game_description.n_players:
            return Action.C
        previous_contribution = Action.D if cooperators == 0 else Action.C
        return previous_contribution

class Strategy_EXPLOITATIVE_11(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Contribution (TFT-AC) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            self.first_round = False
            return Action.C
        if self.first_round:
            self.last_round_cooperators = np.count_nonzero(history.opponent_actions[-1])
            self.first_round = False
        current_round_cooperators = np.count_nonzero(history.opponent_actions[state.round_number - 1])
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        if current_round_cooperators > self.last_round_cooperators:
            return Action.C
        elif current_round_cooperators < self.last_round_cooperators:
            return Action.D
        last_action = history.my_actions[-1]
        return Action(int(not last_action))

class Strategy_EXPLOITATIVE_13(BaseStrategy):
    """
    Tit-for-Tat-Plus (TfT+) strategy for N-Player Public Goods Game.
    This strategy encourages cooperation with opponents and retaliates when defected upon.
    It seeks to profit from opponents who contribute consistently while also punishing those who defect frequently.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_action = history.opponent_actions[state.round_number - 1, :].mean()
        self.last_opponent_action = opponent_action
        if opponent_action:
            return Action.C
        else:
            if self.last_opponent_action is not None:
                return Action.D
            return Action.C

class Strategy_EXPLOITATIVE_14(BaseStrategy):
    """
    A Tit-for-Tat strategy with Adaptive Contributions for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_level = 0.5
        self.last_round_cooperators = 0
        self.last_round_history = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self._update_state(history)
        if not self.last_round_cooperators >= self.game_description.n_players // 2:
            self.contribution_level *= 0.9
            if self.contribution_level < 0.1:
                self.contribution_level = 0.1
        if self.last_round_cooperators == self.game_description.n_players:
            self.contribution_level = 1.0
        adjusted_average = self._calculate_adjusted_average(self.last_round_history)
        if 0.4 < adjusted_average <= 0.6:
            self.contribution_level = self.contribution_level
        elif adjusted_average > 0.6:
            self.contribution_level *= 1.1
        else:
            self.contribution_level *= 0.9
        return Action(int(self.contribution_level >= 0.5))

    def _update_state(self, history):
        if self.last_round_history is None:
            self.last_round_cooperators = sum([sum(row) for row in history.opponent_actions])
            self.last_round_history = history
            return
        self.last_round_cooperators = sum([sum(row) for row in history.opponent_actions])
        self.last_round_history = history

    def _calculate_adjusted_average(self, history):
        cooperators = [sum(row) for row in history.opponent_actions]
        return np.mean([cooperator / len(cooperators) if cooperator > 0 else 0.0 for cooperator in cooperators])

class Strategy_EXPLOITATIVE_15(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat (A-TFT) strategy in a N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players - 1
        self.is_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperator_count = np.sum(history.opponent_actions[-1]) if history else self.threshold
        if state.round_number == self.game_description.n_rounds - 1:
            self.is_last_round = True
            cooperator_count += np.sum(history.opponent_actions[-2]) if history else 0
        action = Action.C if cooperator_count >= self.threshold else Action.D
        return action

class Strategy_EXPLOITATIVE_16(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Contribution (TfTAC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contributions_history = np.zeros(self.game_description.n_rounds)
        self.last_opponent_action = Action.D

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        self.contributions_history[state.round_number - 1] = np.sum(history.opponent_actions[-1, :])
        self.last_opponent_action = history.opponent_actions[-1, -1]
        if self.contributions_history[-1] >= self.game_description.n_players // 2:
            return self.last_opponent_action
        return Action.D

class Strategy_EXPLOITATIVE_18(BaseStrategy):
    """
    A strategy that cooperates in the first round and reciprocates cooperation, while reducing contributions in response to defection. The contribution reduction is adaptive to ensure continued cooperation in future rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.base_contribution = game_description.k / game_description.n_players + 0.001
        self.penalty = min(0.5, self.base_contribution * 0.1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        last_round = len(history.opponent_actions) - 1
        opponent_cooperated_last_round = np.sum(history.opponent_actions[last_round, :]) > 0
        my_contribution_last_round = history.my_actions[last_round]
        if opponent_cooperated_last_round:
            return Action.C
        else:
            return Action(int(max(0, my_contribution_last_round - self.penalty)))

class Strategy_EXPLOITATIVE_19(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Escalation (ATFE) strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = None
        self.cooperative_streak = 0
        self.defector_streak = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not self.history:
            self.history = history
            return Action.C
        self.history = history
        current_action = Action.D if history.my_actions[-1] == Action.D else Action.C
        opponent_cooperators = sum(history.opponent_actions[-1])
        if opponent_cooperators >= self.game_description.n_players // 2:
            return current_action
        if history.my_actions[-1] == Action.C and self.defector_streak > self.cooperative_streak:
            self.defector_streak += 1
        elif history.my_actions[-1] == Action.D and self.cooperative_streak > self.defector_streak:
            self.cooperative_streak = 0
            self.defector_streak = 0
        return current_action



class Strategy_EXPLOITATIVE_22(BaseStrategy):
    """
    Strategy named Tit-for-Tat-Adaptive (TfTA) for N-Player Public Goods Game.
    The strategy is designed to encourage reciprocity and discourage exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_cooperators = np.zeros(game_description.n_players)
        self.punishment_threshold = math.ceil(game_description.n_players / 2)
        self.observation_period = int(math.sqrt(game_description.n_rounds))
        self.current_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        self.current_round += 1
        if self.current_round < self.observation_period:
            return self._observe_opponent(history)
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators > self.punishment_threshold:
            return Action.C
        elif np.any(self.last_cooperators == 0):
            return Action.D
        else:
            return Action.D if self._opponent_defected(history) else Action.C

    def _observe_opponent(self, history):
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators > self.punishment_threshold:
            return Action.C
        elif np.any(self.last_cooperators == 0):
            return Action.D
        else:
            return Action.C

    def _opponent_defected(self, history):
        self.last_cooperators[:] = np.sum(history.opponent_actions[:, :self.current_round], axis=0) > 0
        return any((self.last_cooperators[-1] and (not x) for x in history.opponent_actions[:, -1]))

class Strategy_EXPLOITATIVE_23(BaseStrategy):
    """
    Tit-for-Tat with Escalation and Forgiveness (TFT-E&F) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_level = 1
        self.forgiveness_window = math.ceil(self.game_description.n_players / 2)
        self.escalation_threshold = int(self.game_description.k * self.game_description.n_players - self.contribution_level * self.game_description.n_players)
        self.last_opponent_action = None
        self.escalation_started = False

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        self.last_opponent_action = np.mean(history.opponent_actions[-1])
        if self.contribution_level == 1 or (self.contribution_level > 1 and history.my_actions[-1] == self.last_opponent_action):
            return Action.C
        if self.escalation_started:
            if self.contribution_level >= self.game_description.n_players and np.all(history.opponent_actions[-1] == self.last_opponent_action):
                self.contribution_level -= 1
                return Action(int(self.contribution_level))
            elif np.any(history.opponent_actions[-1] != self.last_opponent_action):
                self.escalation_started = False
                self.contribution_level = min(self.game_description.n_players, self.contribution_level + 1)
                self.forgiveness_window = max(1, self.forgiveness_window - 1)
                return Action(min(self.contribution_level, 1))
        elif np.all(history.opponent_actions[-self.forgiveness_window:-1] == self.last_opponent_action):
            self.contribution_level += 1
        elif np.any(history.opponent_actions[-1] != self.last_opponent_action):
            self.escalation_started = True
            self.contribution_level = min(self.game_description.n_players, self.contribution_level + 1)
        return Action(int(self.contribution_level))

class Strategy_EXPLOITATIVE_24(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.round_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.round_history) == 0:
            return Action.C
        last_state = self.round_history[-1] if len(self.round_history) > 0 else state
        opponent_cooperators = sum(last_state.opponent_actions[last_state.round_number - 1, :])
        if opponent_cooperators == self.game_description.n_players:
            return Action.C
        elif opponent_cooperators > 0 and state.round_number != self.game_description.n_rounds - 1:
            return Action.D
        elif len(self.round_history) < self.game_description.n_rounds:
            if opponent_cooperators == 0 and state.round_number > 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

    def update_history(self, state: GameState, payoffs: PlayerHistory):
        self.round_history.append(state)

class Strategy_EXPLOITATIVE_25(BaseStrategy):
    """
    An Adaptive Tit-for-Tat strategy for the N-Player Public Goods Game.
    Cooperates in the first round and retaliates against opponents who do not cooperate,
    adapting its actions based on their behavior in each subsequent round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.opponent_history) == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1])
        last_opponent_action = self.opponent_history[-1]
        if last_opponent_action == cooperators:
            return Action.C
        elif last_opponent_action < cooperators:
            self.opponent_history.append(cooperators)
            return Action.C
        elif last_opponent_action == 0:
            self.opponent_history.append(last_opponent_action)
            return Action.D
        elif len(self.opponent_history) >= self.game_description.n_rounds // 2:
            self.opponent_history.append(last_opponent_action)
            return Action.D
        else:
            self.opponent_history.append(last_opponent_action)
            return Action.C

class Strategy_EXPLOITATIVE_26(BaseStrategy):
    """
    A Selfish Tit-for-Tat strategy for N-Player Public Goods Game.
    This strategy is exploitative and adaptive, maximizing individual payoff while being robust to a wide range of opponent behaviors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_threshold = (self.game_description.n_players + 1) // 2 if self.game_description.n_players % 2 else self.game_description.n_players // 2
        self.current_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            return Action.D
        if history is not None:
            self.current_round += 1
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.contribution_threshold:
                return Action.C
            return Action.D

class Strategy_EXPLOITATIVE_27(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Contribution (TFT-AC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))
        self.contribution_rate = 1.0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        last_opponent_cooperators = sum(history.opponent_actions[last_round, :])
        if last_round == self.game_description.n_rounds - 1:
            return Action.D
        self.contribution_rate *= last_opponent_cooperators / self.game_description.n_players + min(1, max(0, (self.game_description.n_players - last_opponent_cooperators) / self.game_description.n_players ** 2))
        self.contribution_rate = max(min(self.contribution_rate, 1), 0)
        if history.my_actions[last_round] == Action.C and history.opponent_actions[last_round, self.__class__.__name__.replace('Strategy', '').lower()] == Action.C:
            return Action.C
        return Action(int(self.contribution_rate))

class Strategy_EXPLOITATIVE_28(BaseStrategy):
    """
    A strategy that emulates the Tit-for-Tat with Escalation game theory strategy in the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.escalation_threshold = int(math.ceil(game_description.n_players / 2))
        self.last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and history.opponent_actions is None):
            return Action.C
        self.last_round = False if state.round_number < self.game_description.n_rounds else True
        if history is not None:
            if len(history.opponent_actions) > 1 and self.last_round:
                return Action.C
            opponent_cooperators = np.count_nonzero(history.opponent_actions[-1])
            if opponent_cooperators == self.escalation_threshold:
                return Action.C
            if opponent_cooperators > self.escalation_threshold:
                self.escalation_threshold += self.escalation_threshold // self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_29(BaseStrategy):
    """
    A Tit-for-Tat Plus (TFT+) strategy for an N-player Public Goods Game.
    Cooperates if the opponent cooperated in the last round, otherwise defects.
    Gradually decreases the likelihood of cooperation over time if the opponent consistently defects.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.decay_factor = 0.5
        self.past_defections = 0
        self.average_contributions = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.update_history(history)
            if self.past_defections > 1 and state.round_number - self.past_defections >= math.floor(self.game_description.n_players * self.decay_factor):
                self.decay_factor *= 0.95
            if self.past_defections > 0 and np.sum(history.opponent_actions[-self.past_defections:, -1]) == self.past_defections:
                self.decay_factor *= 1.1
            contribution_probability = self.decay_factor if self.past_defections > 0 else 1 - self.decay_factor
            return Action(random.choices([0, 1], [1 - contribution_probability, contribution_probability])[0])
        return Action.C

    def update_history(self, history: PlayerHistory) -> None:
        """
        Update class variables based on the provided player history.
        """
        self.past_defections = sum((1 for action in history.opponent_actions[:, -1] if action == 0))
        self.average_contributions = np.mean(history.my_actions[-self.game_description.n_rounds:])

class Strategy_EXPLOITATIVE_30(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Game Optimization (ATFTPGO) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if history is None:
            average = np.mean([self.average_contributions[-self.game_description.n_rounds // 2:-1]]) * self.game_description.k
            self.average_contributions[state.round_number] = np.mean(history.my_actions[:state.round_number])
            return Action.C if self.average_contributions[-1] / average >= 1 else Action.D
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        self.average_contributions[state.round_number] = (np.mean(history.my_actions[:state.round_number]) + self.average_contributions[state.round_number - 1]) / 2
        return Action.C if self.average_contributions[-1] / (cooperators / self.game_description.n_players) >= self.game_description.k else Action.D

class Strategy_EXPLOITATIVE_31(BaseStrategy):
    """
    This strategy is called "Tit-for-Tat with Adaptation" (TFT-A). It cooperates in the first round as a peaceful gesture, and adjusts its response based on opponents' history of cooperation and defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_cooperation_history = {}
        self.opponent_defection_history = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        opponent = self.__class__.__name__
        if opponent not in self.opponent_cooperation_history:
            self.opponent_cooperation_history[opponent] = 0
            self.opponent_defection_history[opponent] = 0
        if history is not None:
            cooperator = history.my_actions[-1]
            if cooperator:
                self.opponent_cooperation_history[opponent] += 1
            else:
                self.opponent_defection_history[opponent] += 1
        total_rounds = state.round_number + 1 if state.round_number > 0 else 1
        cooperation_ratio = self.opponent_cooperation_history[opponent] / total_rounds
        defection_ratio = self.opponent_defection_history[opponent] / total_rounds
        if cooperation_ratio >= 0.8:
            return Action.C
        elif defection_ratio >= 0.8:
            return Action.D
        else:
            recent_cooperation = cooperation_ratio if state.round_number > math.floor(total_rounds * 0.5) else defection_ratio
            return Action.C if recent_cooperation >= 0.6 else Action.D

class Strategy_EXPLOITATIVE_32(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat with Public Goods Game Optimization (ATFTPG)

    This strategy uses a tit-for-tat approach in the N-Player Public Goods Game. It initially cooperates and then adapts its strategy based on the actions of other players to maximize individual payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.minimum_contribution = 1 / self.game_description.n_players
        self.contribution_frequency = self.game_description.n_players
        self.punishment_duration = int(self.game_description.n_rounds * 0.2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.D
        last_round = len(history.opponent_actions) - 1
        opponent_cooperated_last_round = np.any(history.opponent_actions[last_round])
        if opponent_cooperated_last_round:
            self.contribution_frequency = min(self.game_description.n_players, self.contribution_frequency)
            contribution = 1
        else:
            self.contribution_frequency -= 1
            contribution = self.minimum_contribution if self.contribution_frequency <= self.punishment_duration else 1
        return Action(int(contribution))

class Strategy_EXPLOITATIVE_33(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Fade (A3F) Strategy for N-Player Public Goods Game
    """
    FADE_PERIOD = 3

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.fade_counter = 0
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if self.fade_counter > 0 and self.fade_counter < self.FADE_PERIOD:
            return Action.D
        if history.opponent_actions[-1, -1] == Action.D and history is not None:
            if self.last_opponent_action is None or self.last_opponent_action == Action.C:
                self.fade_counter = min(self.FADE_PERIOD, state.round_number)
        self.last_opponent_action = history.opponent_actions[-1, -1] if history is not None else None
        return Action.C if self.last_opponent_action == Action.C else Action.D

class Strategy_EXPLOITATIVE_35(BaseStrategy):
    """
    A conditional contribution strategy that cooperates when the average contribution rate exceeds 0.5 and defects otherwise.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = np.full(self.game_description.n_rounds, 0.5)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.average_contribution = np.roll(self.average_contribution, -1)
            self.average_contribution[-1] = np.mean(history.my_actions[-1])
        cooperators = np.sum(history.opponent_actions[-1, :]) if history is not None else self.game_description.n_players // 2
        return Action.C if cooperators >= math.ceil(self.game_description.n_players / 2) else Action.D

class Strategy_EXPLOITATIVE_36(BaseStrategy):
    """
    A Tit-for-Tat-Adaptive strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.round_counter = 0
        self.cooperation_freq = min(game_description.n_players, int(math.sqrt(game_description.n_players)))
        self.last_opponent_action = Action.D
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history and len(history.opponent_actions) == 0):
            return Action.C
        self.round_counter += 1
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators > self.last_round_cooperators:
            self.cooperation_freq *= math.ceil(self.game_description.n_players / self.cooperation_freq)
        if self.last_opponent_action == Action.C and cooperators >= self.game_description.n_players // 2:
            return Action.C
        self.last_round_cooperators = cooperators
        self.last_opponent_action = history.opponent_actions[-1, -1] if history else Action.D
        return Action.D

class Strategy_EXPLOITATIVE_37(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptive Cooperation strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperating_threshold = math.ceil(game_description.n_players / 2)
        self.punishment_duration = 3
        self.permanent_defection = False
        self.last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or self.last_round:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        if opponent_cooperators >= self.cooperating_threshold and (not self.permanent_defection):
            return Action.C
        elif opponent_cooperators == 0 and (not self.last_round):
            self.punishment_duration -= 1
            return Action.D if self.punishment_duration > 0 else Action.C
        else:
            self.permanent_defection = False
            return Action.D

    def update(self, payoffs: PlayerHistory):
        self.last_round = payoffs.round_number == self.game_description.n_rounds - 1
        if self.last_round and any(payoffs.my_actions[-1]):
            self.permanent_defection = True

class Strategy_EXPLOITATIVE_38(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Game Optimization (ATFTPGO) Strategy
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros((self.game_description.n_rounds, 1), dtype=np.bool_)
        self.average_contribution = 0
        self.contributions = 0
        self.sliding_window = int(self.game_description.n_players * (self.game_description.k - 1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.contributions = int(state.round_number * 0.8 * self.average_contribution if len(self.opponent_history) > self.sliding_window else 1)
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        if cooperators >= self.game_description.n_players // 2:
            self.average_contribution = np.mean(self.opponent_history[-self.sliding_window:]) if len(self.opponent_history) > self.sliding_window else 0
        else:
            self.average_contribution *= 0.8
            self.average_contribution = max(self.average_contribution, self.contributions / len(self.opponent_history))
        if history is not None:
            self.opponent_history = np.roll(self.opponent_history, -1)
            self.opponent_history[-1] = cooperators > 0
        return Action.C if cooperators > 0 else Action.D

class Strategy_EXPLOITATIVE_39(BaseStrategy):
    """
    An adaptive freerider with Tit-for-Tat strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.past_history = None
        self.last_cooperators = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        self.past_history = history
        cooperators = sum(history.opponent_actions[-1])
        current_cooperators = np.sum(history.my_actions[-1])
        if cooperators > 0 and (self.last_cooperators == 0 or self.game_description.n_players - cooperators < self.last_cooperators):
            return Action.D
        elif cooperators >= self.game_description.n_players // 2:
            self.last_cooperators = cooperators
            return Action.C
        return Action.D

    def last_round(self) -> bool:
        """
        Check if the strategy is in the last round, based on game_description.n_rounds.
        """
        return self.past_history and self.past_history.opponent_actions.shape[0] >= self.game_description.n_rounds - 1

class Strategy_EXPLOITATIVE_40(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Contribution (TFTAC) strategy for N-Player Public Goods Game.
    This strategy cooperates initially and adapts its contribution based on the opponent's previous actions.
    It moves towards cooperation when the opponent contributes more than itself,
    and towards defection when the opponent contributes less than itself.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_factor = 1
        self.last_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and self.last_round != state.round_number - 1:
            self.last_round = state.round_number - 1
            cooperators = sum(history.opponent_actions[self.last_round, :])
            self.contribution_factor = 1 + cooperators / self.game_description.n_players * 0.1
        action = Action.D if self.contribution_factor > 1 else Action.C
        return action if history is None or len(history.opponent_actions) <= state.round_number else self._get_action_from_history(state, history)

    def _get_action_from_history(self, state: GameState, history: PlayerHistory):
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        my_contribution = history.my_actions[state.round_number - 1]
        opponent_contribution = history.opponent_actions[state.round_number - 1, self.__class__.__name__.replace(' ', '')]
        if my_contribution == opponent_contribution:
            return Action(int(my_contribution))
        elif opponent_contribution > my_contribution and self.contribution_factor < 1:
            self.contribution_factor += 0.1
        elif opponent_contribution < my_contribution and self.contribution_factor > 0:
            self.contribution_factor -= 0.1
        return Action(int(self._get_decision(my_contribution, opponent_contribution)))

    def _get_decision(self, my_contribution, opponent_contribution):
        return 'C' if my_contribution == 1 else 'D'

class Strategy_EXPLOITATIVE_41(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Game Optimization (ATFTPGO) Strategy
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.p = min(self.game_description.n_rounds // 2, self.game_description.n_players - 1)
        self.threshold = (self.game_description.k * self.game_description.n_players - self.game_description.n_players) / (self.p * (self.game_description.n_players - 1))
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and (not self.history):
            self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros(self.game_description.n_rounds))
            if self.game_description.k <= self.game_description.n_players:
                return Action.D
            else:
                return Action.C
        cooperators = history.opponent_actions[-1].sum()
        average = np.mean(history.opponent_actions[max(0, state.round_number - self.p):state.round_number + 1])
        if cooperators > self.game_description.n_players // 2 or (average >= self.threshold and cooperators != 0):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_43(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Cooperation (ATFT-GC) for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history_length = game_description.n_rounds if game_description.n_rounds < 10 else 10
        self.cooperative_threshold = int(self.history_length * 0.6)
        self.gradual_contribution_rate = 0.1
        self.current_contribution_level = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperation_history = history.opponent_actions[state.round_number - 1] if history else np.zeros(self.history_length)
        cooperators = sum(opponent_cooperation_history)
        if cooperators >= self.game_description.n_players // 2:
            self.current_contribution_level = min(self.current_contribution_level + 0.1, 1)
        else:
            self.current_contribution_level = max(self.current_contribution_level - self.gradual_contribution_rate, 0)
        return Action(int(self.current_contribution_level))

class Strategy_EXPLOITATIVE_44(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Modified Initial Behavior (ATFT-MIB) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_opponent_action = Action.D
        self.defection_counter = 0
        self.last_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number > self.last_round + 1:
            self.defection_counter = 0
            self.last_opponent_action = history.opponent_actions[-1][-1] if history else Action.D
        action = Action.C if self.last_opponent_action == Action.C else Action.D
        if self.defection_counter < self.game_description.n_players:
            self.defection_counter += 1 if action == Action.D else 0
        self.last_round = state.round_number
        return action

class Strategy_EXPLOITATIVE_45(BaseStrategy):
    """
    A strategy that cooperates in the first round and then mimics opponents' contributions in subsequent rounds, with an adaptive approach to retaliate against defectors while limiting exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        contribution_change = 0
        if cooperators > self.game_description.n_players // 2:
            contribution_change = 1
        elif cooperators == 0:
            contribution_change = -1
        self.contribution += contribution_change
        self.contribution = max(min(self.contribution, self.game_description.k), 1)
        if history and sum(history.opponent_actions[-1, :]) == 0:
            return Action.D
        return Action(int(self.contribution > 0))

class Strategy_EXPLOITATIVE_47(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Escalation (ATFE) Strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_defeats = 0
        self.max_consecutive_defeats = int(math.ceil(game_description.n_players * 0.6))
        self.last_opponent_action = Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.update_history(history)
        opponent_cooperators = sum(history.opponent_actions[-1])
        if self.consecutive_defeats > 0 and self.last_opponent_action == Action.D:
            contribution_level = max(0, self.consecutive_defeats - self.max_consecutive_defeats)
        else:
            contribution_level = 1 if opponent_cooperators >= self.game_description.n_players // 2 else 0
        return Action(contribution_level)

    def update_history(self, history):
        if history is not None:
            self.consecutive_defeats = 1 + (np.where(history.opponent_actions[-1] == Action.D, 1, 0).sum() - 1)
            self.last_opponent_action = history.opponent_actions[-1][-1]

class Strategy_EXPLOITATIVE_48(BaseStrategy):
    """
    An implementation of the Adaptive Tit-for-Tat strategy in the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history_length = self.game_description.n_rounds + 1
        self.cooperation_counter = np.zeros(self.history_length)
        self.last_cooperation = None

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        action = Action.D
        if self.last_cooperation is not None and state.round_number - self.last_cooperation >= self.game_description.n_players // 2:
            action = Action.D
        elif history.my_actions[-1] and np.sum(history.opponent_actions[-1]) > np.sum(history.opponent_payoffs[-1]) / 2:
            action = Action.C
        self.cooperation_counter[state.round_number] = 1 if action == Action.C else 0
        self.last_cooperation = state.round_number if action == Action.C else None
        return action

class Strategy_EXPLOITATIVE_49(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Progressive Contribution (ATTPC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_level = 0.0
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        opponent_cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if opponent_cooperators > 0 and self.contribution_level == 0:
            self.contribution_level = 1.0
            self.defection_streak = 0
        elif opponent_cooperators == 0:
            self.contribution_level = max(self.contribution_level - 0.1, 0.0)
            self.defection_streak += 1
        else:
            self.defection_streak = 0
        if state.round_number == self.game_description.n_rounds - 1 or history is None:
            return Action(self.contribution_level == 1)
        return Action(self.contribution_level > self.defection_streak)

    def check_defection_sequence(self) -> bool:
        cooperation_count = sum(self.history.my_actions[-self.punishment_iterations:])
        defection_count = self.game_description.n_players - cooperation_count
        return defection_count >= self.punishment_iterations

class Strategy_EXPLOITATIVE_51(BaseStrategy):
    """
    Adaptive Freerider (AF) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        current_contributions = np.sum(history.my_actions[-1])
        average_contribution = self.average_contributions[-1] if len(self.average_contributions) > 0 else 0
        contribution_diff = current_contributions - average_contribution
        return Action.C if contribution_diff <= 0 else Action.D

    def update_average(self, total_contributions: int) -> None:
        """
        Update the average contributions for each round.

        :param total_contributions: Total number of cooperators in a round.
        """
        self.average_contributions[-1] = total_contributions / self.game_description.n_players

class Strategy_EXPLOITATIVE_52(BaseStrategy):
    """
    Strategy that cooperates in the first round and reciprocates cooperation or defection of opponents in subsequent rounds.
    This strategy also adjusts its contribution level based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_level = 1.0
        self.previous_opponent_cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.previous_opponent_cooperation_count = sum(history.opponent_actions[-1, :])
        if self.previous_opponent_cooperation_count >= self.game_description.n_players - 1:
            self.contribution_level = min(self.contribution_level * 1.2, self.game_description.k)
        elif self.previous_opponent_cooperation_count == 0:
            self.contribution_level *= 0.8
        else:
            self.contribution_level = max(self.contribution_level * 0.9, 1.0)
        if history and self.previous_opponent_cooperation_count > 0:
            return Action.C if self.contribution_level >= random.random() else Action.D
        return Action.C

class Strategy_EXPLOITATIVE_53(BaseStrategy):
    """
    A-TFEC strategy for N-Player Public Goods Game. Adaptive Tit-for-Tat with Gradual Cooperative Escalation strategy that cooperates or defects based on previous round's contributions and maintains a grace period before resuming cooperation after defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.grace_period = 1
        self.max_non_contribution = self.game_description.n_players // 2
        self.last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        elif history is None or self.last_round:
            return Action.D
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators > 0:
                if cooperators == len(history.opponent_actions) and state.round_number != self.game_description.n_rounds - 1:
                    self.last_round = True
                return Action.C if self.grace_period == 0 else Action.D
            self.grace_period = min(self.grace_period * 2, math.inf)
        return Action.D

class Strategy_EXPLOITATIVE_54(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat with Escalation (A2TE)

    Strategy summary: A2TE cooperates in the first round and then makes decisions based on the opponent's previous actions. If the opponent contributes in a round, A2TE will contribute in subsequent rounds. However, if the opponent does not contribute in a round, A2TE will withhold contributions for the next `floor(n/k)` rounds as retaliation (escalation). After that, A2TE will return to cooperating unless the opponent continues to defect, in which case the escalation process repeats.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.opponent_history = list(history.opponent_actions[0])
        if len(self.opponent_history) < self.game_description.n_players:
            self.opponent_history += [0] * (self.game_description.n_players - len(self.opponent_history))
        if state.round_number == self.game_description.n_rounds - 1 or state.round_number < math.floor(self.game_description.n_players / self.game_description.k):
            return Action.C
        cooperators = sum(self.opponent_history)
        index_to_cooperate = int(math.ceil(cooperators / self.game_description.n_players * self.game_description.n_players))
        if index_to_cooperate <= len(self.opponent_history) and self.opponent_history[index_to_cooperate - 1] == 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_55(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Game (PGG) Adjustment strategy
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_contributions = np.zeros(game_description.n_rounds, dtype=int)
        self.retaliation_counter = 0
        self.cooperation_threshold = int(game_description.n_players * 0.75)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        action = Action.D
        if state.round_number > 1:
            opponent_contributions_in_prev_round = sum(history.opponent_actions[-2, :])
            self.opponent_contributions[state.round_number - 1] = opponent_contributions_in_prev_round
            if opponent_contributions_in_prev_round > self.cooperation_threshold:
                action = Action.C
            elif self.retaliation_counter < self.game_description.n_players * 0.25:
                self.retaliation_counter += 1
            else:
                self.retaliation_counter = 0
        return action

    def last_round_contribute(self) -> bool:
        """
        Determine if the strategy should contribute in the final round, regardless of opponent's actions
        """
        return self.game_description.n_rounds > 1 and self.state.round_number == self.game_description.n_rounds - 1

class Strategy_EXPLOITATIVE_56(BaseStrategy):
    """
    Strategy for the N-Player Public Goods Game that exploits other players by defecting when possible, prioritizing defection over cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.5
        self.history = PlayerHistory(my_actions=np.zeros(self.game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(self.game_description.n_rounds, dtype=float), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        average_contribution = np.mean(history.opponent_actions[:, :state.round_number])
        if average_contribution < self.threshold:
            return Action.C
        else:
            self.threshold = 1 - average_contribution
        return Action.D

class Strategy_EXPLOITATIVE_57(BaseStrategy):
    """
    A strategy that minimizes contributions while maximizing payoffs by exploiting other players' cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players // 2
        self.history = PlayerHistory(np.zeros((1, 2), dtype=bool), np.zeros(1), np.zeros((1, game_description.n_players), dtype=bool), np.zeros(1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is not None:
            return Action.D
        self.history = history if history is not None else self.history
        average_contribution = np.mean(self.history.opponent_actions[-self.game_description.n_rounds:, -1])
        if average_contribution > self.threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_58(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Fading Memory (A-TFTF) strategy for the N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.past_opponent_cooperation = 0
        self.threshold = self.game_description.n_players // 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperation = sum(history.opponent_actions[-1, :]) if history else 0
        self.past_opponent_cooperation = (self.past_opponent_cooperation * 0.95 + opponent_cooperation * 0.05).item()
        if self.past_opponent_cooperation > self.threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_59(BaseStrategy):
    """
    TFT-AC strategy for N-Player Public Goods Game.
    Cooperates if opponent contributes last round, defects otherwise with adjustments over time.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_level = game_description.k
        self.freerider_penalty = 0.9
        self.last_opponent_cooperation = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            self.last_opponent_cooperation = False
            self.contribution_level = self.game_description.k
            return Action.D
        cooperation = history.opponent_actions[-1, :].mean() if history is not None else 0.5
        self.last_opponent_cooperation = bool(cooperation)
        if cooperation < 0.5:
            self.contribution_level *= max(self.freerider_penalty, 1 - self.contribution_level ** (1 / self.game_description.n_rounds))
        return Action.C if self.last_opponent_cooperation else Action.D

class Strategy_EXPLOITATIVE_62(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.n_players // 2
        self.cooperation_history = np.zeros(game_description.n_rounds)
        self.defection_history = np.zeros(game_description.n_rounds)

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.C
        self.cooperation_history[state.round_number] = np.mean(history.opponent_actions[:, -self.game_description.n_players // 2:]) > self.cooperation_threshold
        self.defection_history[state.round_number] = 1 - self.cooperation_history[state.round_number]
        if np.diff(self.cooperation_history)[-1]:
            self.cooperation_threshold = min((self.cooperation_threshold + 1) // 2, self.game_description.n_players - 1)
        elif np.diff(self.defection_history)[-1]:
            self.cooperation_threshold = max((self.cooperation_threshold - 1) // 2, 0)
        if np.mean(history.opponent_actions[:, -self.game_description.n_players // 2:]) > self.cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_63(BaseStrategy):
    """
    Strategy Name: Adaptive Freerider with Tit-for-Tat Variant (AFTFTV)
    Strategy Description: A cooperative strategy that adjusts its contribution based on the average contribution rate of all players.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / 2
        self.contribution_rate_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        contributions = np.sum(history.my_actions[:state.round_number - 1])
        CCR = contributions / (self.game_description.n_rounds - 1)
        if CCR > self.threshold:
            return Action.C
        return Action.D

    def update_contribution_rate(self, payoff: float):
        """
        This method should be called after a round to update the contribution rate history with the current round's average contribution rate
        """
        self.contribution_rate_history.append(payoff)

class Strategy_EXPLOITATIVE_64(BaseStrategy):
    """
    A strategy that balances cooperation and defection, taking advantage of opponents while being adaptive to a wide range of opponent behaviors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.m = int(math.ceil(game_description.n_players / 2))
        self.T = game_description.k / 4
        self.history_length = min(self.m, game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history is not None:
            contributions = np.mean(history.opponent_actions[:self.history_length, :].sum(axis=0))
            if contributions >= self.T:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_65(BaseStrategy):
    """
    Strategy that mimics cooperation to reward cooperative opponents and punishes non-cooperative ones.
    Gradual cooperation through the initial contribution in the first round gives an advantage over static strategies.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history.append(history.opponent_actions[-1])
        opponent_cooperated_last = np.any(self.opponent_history[-1])
        if state.round_number == self.game_description.n_rounds:
            return Action.D
        if not opponent_cooperated_last and np.all(self.opponent_history):
            return Action.C
        return Action(opponent_cooperated_last)


class Strategy_EXPLOITATIVE_67(BaseStrategy):
    """
    The Freeloader Maximizer strategy focuses on maximizing individual rewards while being adaptive to various opponent behaviors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.total_contributions = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        total_rounds = state.round_number - 1
        self.total_contributions = np.sum(history.opponent_actions[:total_rounds, :].flatten()) if history is not None else 0
        average_contributors = self.total_contributions / total_rounds
        cooperate = Action.C if self.total_contributions <= average_contributors else Action.D
        return cooperate

class Strategy_EXPLOITATIVE_68(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Optimization (ATFTPGO) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.m = int(math.floor((game_description.n_rounds - 1) / 2))
        self.average_contributions = np.zeros(self.m + 1)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history.my_actions[-1] and (not np.all(history.opponent_actions[-1, :])):
            self.average_contributions = np.roll(self.average_contributions, -1)
            self.average_contributions[0] += history.my_actions[-1]
        else:
            self.average_contributions[0] += history.my_actions[-1]
            self.average_contributions = np.roll(self.average_contributions, -1)
        total_cooperators = sum(history.opponent_actions[-1, :])
        my_avg_contrib = np.mean(self.average_contributions[self.m:])
        group_avg_contrib = my_avg_contrib * (self.game_description.n_players - 1) if total_cooperators > 0 else 0
        if history.my_actions[-1] and self.average_contributions[-1] >= group_avg_contrib:
            return Action.C
        random_decision = random.random() < (group_avg_contrib - my_avg_contrib) / (total_cooperators + 1e-06)
        return Action(int(random_decision)) if state.round_number != self.game_description.n_rounds - 1 else Action.C

class Strategy_EXPLOITATIVE_70(BaseStrategy):
    """
    Strategy that employs the Adaptive Tit-for-Tat approach. This strategy cooperates in the first round and subsequently adapts its behavior based on opponent's actions. If an opponent contributes, it will contribute as well; otherwise, it will not contribute. The strategy gradually increases cooperation based on observed opponent behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.n_players / 2)
        self.first_round_probability = 0.9

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :])
        cooperation_probability = self.first_round_probability if state.round_number < 3 else cooperators / self.game_description.n_players
        return random.choice([Action.C, Action.D]) if np.random.uniform() < cooperation_probability else Action.D

class Strategy_EXPLOITATIVE_72(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Game Optimization (ATFTPG) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution_threshold = np.full(self.game_description.n_rounds // 2 + 1, 0.3)
        self.cooperators_count = np.zeros(self.game_description.n_rounds, dtype=int)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number < self.game_description.n_rounds // 2:
            average_contribution_threshold = self.average_contribution_threshold[state.round_number]
        else:
            average_contribution_threshold = self.average_contribution_threshold[-1]
        if history is None:
            opponents_cooperators = self.game_description.n_players - 1
        else:
            opponents_cooperators = sum(history.opponent_actions[:state.round_number, :].sum(axis=0))
        cooperators_threshold = math.ceil((self.game_description.n_players - 1) * average_contribution_threshold)
        self.cooperators_count[state.round_number] = opponents_cooperators
        return Action.C if opponents_cooperators >= cooperators_threshold else Action.D

class Strategy_EXPLOITATIVE_73(BaseStrategy):
    """
    Freerider with Adaptive Contribution (FAC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.previous_averages = []
        self.initial_average = None
        self.moving_average_window = int(math.ceil(game_description.n_rounds * 0.8))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.previous_averages) < self.moving_average_window:
            return Action.D
        current_average = np.mean(history.opponent_actions[:, -self.moving_average_window:]) if history is not None else 0
        if current_average > self.initial_average:
            return Action.C
        return Action.D

    def update_averages(self, state: GameState, history: PlayerHistory):
        average = np.mean(history.opponent_actions[:, -self.moving_average_window:]) if history is not None else 0
        self.previous_averages.appendleft(self.initial_average)
        self.previous_averages.pop(len(self.previous_averages) - self.moving_average_window)
        self.initial_average = np.mean(self.previous_averages)

class Strategy_EXPLOITATIVE_74(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the N-Player Public Goods Game.
    This strategy cooperates initially and responds with defection when necessary to encourage mutual cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros((1, 2)), np.zeros(1), np.zeros((1, game_description.n_players)), np.zeros(1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None:
            self.history = history
        if state.round_number == 0:
            return Action.C
        last_round = len(self.history.opponent_actions) - 1
        last_my_action = self.history.my_actions[last_round]
        last_opponent_cooperators = sum(self.history.opponent_actions[last_round, :])
        if last_opponent_cooperators > 0 or state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_75(BaseStrategy):
    """
    A strategy that cooperates in the first round and adapts to opponents' behaviors based on their previous actions.
    It encourages cooperation and punishes freeloading while being exploitative to maintain a competitive edge.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_threshold = int(math.ceil(game_description.n_players / 3))
        self.history_length = math.floor(game_description.n_rounds / 2)
        self.memory = np.zeros((self.history_length, game_description.n_players), dtype=bool)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperation = np.mean(history.opponent_actions[-self.history_length:])
        self.memory[-1] = opponent_cooperation > 0.5
        if np.any(self.memory):
            recent_cooperators = sum(self.memory[-1, :])
            if recent_cooperators >= self.punishment_threshold:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_77(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Defection (A-TFTGD) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.epsilon = 0.1
        self.average_contribution = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history or (history and len(history.opponent_actions) < self.game_description.n_players):
            self.average_contribution = None
        else:
            self.average_contribution = np.mean(history.opponent_actions[:, 1:])
            if state.round_number == self.game_description.n_rounds - 1 and self.average_contribution > self.game_description.k * len(history.opponent_actions) + 1:
                return Action.C
        if history and np.all(history.my_actions[:-1] == [True]):
            return Action.C
        contribution = 1 - self.epsilon ** state.round_number
        if contribution > 0:
            return Action.C if random.random() < contribution else Action.D
        return Action.D

class Strategy_EXPLOITATIVE_78(BaseStrategy):
    """
    An adaptive Tit-for-Tat strategy for the N-Player Public Goods Game.
    Strategy follows a cooperative initial state, reciprocates cooperation from opponents, and punishes defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.opponent_history) == 0:
            return Action.C
        recent_round = min(state.round_number - 1, len(self.opponent_history) - 1)
        opponent_cooperated = self.opponent_history[-recent_round - 1][-1]
        return Action(1 if opponent_cooperated else 0)

    def update_opponent_history(self, state: GameState):
        if state.round_number == len(self.opponent_history):
            self.opponent_history.append([False] * self.game_description.n_players)
        self.opponent_history[state.round_number][-1] = not self.__call__(GameState(state.round_number - 1), None)

class Strategy_EXPLOITATIVE_80(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Contribution (TFTAC) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_opponent_action = None
        self.is_final_round = False

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history.my_payoffs[-1] + 1 >= self.game_description.n_rounds:
            self.is_final_round = True
        self.last_opponent_action = np.mean(history.opponent_actions[-1, :])
        cooperators = sum(history.opponent_actions[-1, :])
        if self.last_opponent_action == 1 and (not self.is_final_round):
            return Action.C
        elif self.last_opponent_action == 0:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_81(BaseStrategy):
    """
    An adaptive implementation of the Tit-for-Tat strategy in Public Goods Games, employing a forgiving and cooperative approach.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_severity = game_description.n_players // 2
        self.cooperative_streak = 0
        self.defective_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            cooperators = sum(history.opponent_actions[-1, :])
            self.cooperative_streak += int(cooperators > 0)
            self.defective_streak += int(cooperators == 0)
        cooperation_probability = min(max(self.cooperative_streak / (self.cooperative_streak + self.defective_streak), 1 / self.game_description.n_players), 1)
        action = Action.C if random.random() < cooperation_probability else Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C if self.cooperative_streak > self.defective_streak else Action.D
        return action

class Strategy_EXPLOITATIVE_82(BaseStrategy):
    """
    A strategy that cooperates in the first round, and thereafter copies the opponent's action from the previous round.
    If an opponent is consistently contributing, this strategy will also contribute. However, if an opponent repeatedly defects,
    TFT-AC will follow suit and withhold contributions to prevent being exploited further.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round_opponent_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = np.atleast_1d(history.opponent_actions[-1]) if history else np.zeros(self.game_description.n_players, dtype=bool)
        self.last_round_opponent_action = opponent_actions[0]
        if not history:
            return Action.C
        my_last_contribution = opponent_actions[-1] if state.round_number > 1 else True
        my_action = Action(my_last_contribution) if np.all(opponent_actions == self.last_round_opponent_action) else Action.D
        if state.round_number + 1 > self.game_description.n_rounds:
            self.last_round_opponent_action = opponent_actions[-2]
        return my_action

class Strategy_EXPLOITATIVE_83(BaseStrategy):
    """
    Freeloader with Adaptive Contribution (FAC) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.past_contributions = np.zeros(self.game_description.n_rounds)
        self.contributed_in_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not self.contributed_in_last_round:
            past_contributions = self.past_contributions[:state.round_number]
            self.contributed_in_last_round = True
        else:
            past_contributions = self.past_contributions
        average_contribution = np.mean(past_contributions)
        if average_contribution < self.game_description.n_players // 2:
            return Action.C
        return Action.D

    def update(self, payoff: float):
        """
        Update the past contributions for future decision making.
        """
        if not self.contributed_in_last_round:
            self.past_contributions[state.round_number] = 1
        else:
            self.past_contributions[-1] = 0

class Strategy_EXPLOITATIVE_84(BaseStrategy):
    """
    Tit-for-Tat with Adaptation strategy in N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round = -1
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        self.last_round += 1
        self.opponent_history.append(history.opponent_actions[self.last_round])
        opponent_cooperated = sum(self.opponent_history[-1]) >= math.ceil(self.game_description.n_players / 2)
        return Action(opponent_cooperated) if self.last_round < self.game_description.n_rounds - 1 else Action.C

class Strategy_EXPLOITATIVE_85(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat with Public Goods Game Awareness (ATFTPG)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_threshold = int(math.ceil(game_description.n_players * 2))
        self.last_round_cooperator_threshold = int(math.floor(game_description.n_players / 2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) == 0):
            return Action.C
        opponent_contributions = sum(history.opponent_actions[:, -1])
        if len(history.opponent_payoffs) == 0:
            return Action.C
        if opponent_contributions < self.contribution_threshold:
            return Action.D
        if len(history.opponent_actions) > 1 and history.opponent_payoffs[-1][-1] == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1 and opponent_contributions < self.last_round_cooperator_threshold:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_86(BaseStrategy):
    """
    A simple Adaptive Tit-for-Tat (ATFT) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0 and history is None:
            if random.random() < 1 / self.n:
                action = Action.C
        elif history:
            cooperators = sum(history.opponent_actions[-1, :])
            action = Action.C if cooperators >= self.n // 2 else Action.D
        if state.round_number == self.game_description.n_rounds - 1 or not history:
            action = Action.C
        return action

class Strategy_EXPLOITATIVE_87(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat with Contribution Threshold (A-TTCT)

    Summary: Implementation of the adaptive Tit-for-Tat strategy with a contribution threshold for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros(self.game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(self.game_description.n_rounds, dtype=float), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=float))
        self.threshold = self.game_description.n_players // 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            history = self.history
        average_contribution_rate = np.mean(history.my_actions[-self.game_description.n_players // 2:])
        self.threshold = self.threshold + int(average_contribution_rate > self.threshold) - int(average_contribution_rate < self.threshold - 1)
        if average_contribution_rate >= self.threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_88(BaseStrategy):
    """
    Implements the Adaptive Tit-for-Tat strategy for N-Player Public Goods Game.
    This strategy cooperates when the opponent cooperated in the previous round and defects otherwise,
    with a forgiveness mechanism that allows for cooperation after a certain number of consecutive defeats.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.forgiveness_count = self.game_description.n_players // 2
        self.opponent_defections_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        opponent_cooperated_last_round = sum(history.opponent_actions[-1]) > 0
        if opponent_cooperated_last_round and self.opponent_defections_counter >= self.forgiveness_count:
            self.opponent_defections_counter = 0
            return Action.C
        elif not opponent_cooperated_last_round:
            self.opponent_defections_counter += 1
        return Action.D

class Strategy_EXPLOITATIVE_89(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Variable Contribution (ATTCV) Strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contributions = [0] * game_description.n_rounds
        self.contributions[0] = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_contribution = self.contributions[-1]
        contribution = last_contribution if last_contribution == 1 else 0
        self.contributions.append(contribution)
        if state.round_number == self.game_description.n_rounds - 1:
            last_contribution = self.contributions[-1]
            if np.count_nonzero(self.contributions) > 0:
                self.contributions[-1] = 1 if last_contribution == 1 else 0
        return Action(self.contributions[-1])

class Strategy_EXPLOITATIVE_93(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_phase = 0
        self.last_opponent_action = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history and state.round_number >= len(history.opponent_actions)):
            self.punishment_phase = 0
            self.last_opponent_action = False
        action = Action.D
        if not history:
            action = Action.C
        elif state.round_number >= len(history.opponent_actions):
            self.punishment_phase = 0
            self.last_opponent_action = False
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.n_players // 2 and self.last_opponent_action:
                action = Action.C
            elif not self.last_opponent_action:
                action = Action.C
            else:
                self.punishment_phase += 1
                if self.punishment_phase >= self.game_description.n_players:
                    action = Action.C
                else:
                    action = Action.D
        self.last_opponent_action = history.opponent_actions[-1, state.round_number % len(history.opponent_actions)] if history else False
        return action

class Strategy_EXPLOITATIVE_94(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the N-Player Public Goods Game.
    Cooperates on the first round, and responds cooperatively if opponents also cooperate in the previous round;
    otherwise defects to punish defection and encourage future cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number > self.last_round + 1:
            self.last_round = state.round_number - 1
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        return Action.C if cooperators > (self.game_description.n_players - 1) // 2 else Action.D

class Strategy_EXPLOITATIVE_95(BaseStrategy):
    """
    Tit-for-Tat Evolution strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))
        self.last_cooperators = 0

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        current_cooperators = sum(history.opponent_actions[-1, :])
        previous_state = history.opponent_actions[max(0, state.round_number - self.game_description.n_rounds // 2):state.round_number, :]
        last_cooperators = sum(previous_state[:, -1])
        if current_cooperators >= self.game_description.n_players // 2:
            if last_cooperators == 0:
                self.last_cooperators += 1
            return Action.C
        elif last_cooperators > 0:
            self.last_cooperators = max(self.last_cooperators - 1, 0)
        return Action.D

    def update_history(self, state: GameState):
        self.history.my_actions[state.round_number] = self.__class__ == self.history.opponent_strategy[-1]
        if self.history.opponent_strategy[-1] is not None:
            self.history.opponent_payoffs[state.round_number] = np.mean([1 - action + self.game_description.k / self.game_description.n_players * sum(self.history.opponent_actions[:state.round_number + 1, 0]) for action in self.history.opponent_actions[:, -1]])
        else:
            self.history.my_payoffs[state.round_number] = np.nan

class Strategy_EXPLOITATIVE_98(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Cooperation (A-TFT-GC) strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.gradual_cooperation_threshold = int(self.game_description.n_players * 0.7)
        self.recent_cooperation_count = 0
        self.opponent_history = [False for _ in range(self.game_description.n_rounds)]

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = len(history.opponent_actions) - 1
        self.opponent_history[current_round] = sum(history.opponent_actions[current_round, :]) > 0
        if not self.opponent_history[-1]:
            return Action.D
        if current_round - self.recent_cooperation_count >= 3:
            self.recent_cooperation_count = current_round
            cooperation_probability = min(math.ceil((current_round - self.recent_cooperation_count) / 3), 0.5)
            return Action.C if random.random() < cooperation_probability else Action.D
        return Action.C

class Strategy_EXPLOITATIVE_99(BaseStrategy):
    """
    A strategy that cooperates if the opponent did so in the previous round, and gradually reduces contributions when the opponent stops cooperating or under-contributes.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_level = 0
        self.waiting_for_change = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (not history and state.round_number != 1):
            return Action.D
        if state.round_number == self.game_description.n_rounds:
            return Action.D
        opponent_actions = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=bool)
        if np.all(opponent_actions == self.contribution_level):
            pass
        elif np.all(opponent_actions < self.contribution_level):
            self.contribution_level = max(self.contribution_level * 0.5, 0)
        elif np.all(opponent_actions > self.contribution_level):
            self.contribution_level = min(self.contribution_level * 2, self.game_description.n_players - 1)
        else:
            self.waiting_for_change = True
            return Action.D
        if not self.waiting_for_change:
            self.waiting_for_change = False
            return Action(int(self.contribution_level))
        else:
            return Action.D

class Strategy_EXPLOITATIVE_100(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Variable Contribution (ATTCV) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_probability = 1.0
        self.last_opponent_cooperated = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (not history and state.round_number > 0):
            return Action.C
        self.last_opponent_cooperated = np.any(history.opponent_actions[state.round_number - 1, :]) if history else False
        if self.last_opponent_cooperated:
            self.contribution_probability = min(self.contribution_probability * 0.9, 0.9)
        else:
            self.contribution_probability *= 0.9
            self.contribution_probability = max(self.contribution_probability, 0.1)
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C if self.last_opponent_cooperated else Action.D
        return Action(int(np.random.binomial(1, self.contribution_probability)))

class Strategy_EXPLOITATIVE_101(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptive contributions for N-Player Public Goods Game.
    This strategy adjusts its contribution based on the opponent's previous round action.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.base_contribution = game_description.n_players // 2
        self.contribution_increment = game_description.n_players // 100
        self.rounds_since_defection = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.contribution = self.base_contribution
        self.rounds_since_defection = 0
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        if opponent_cooperators == 0:
            self.rounds_since_defection += 1
            if state.round_number < self.game_description.n_rounds - 1 and self.rounds_since_defection % (self.game_description.n_rounds // 3) == 0:
                self.contribution += self.contribution_increment
        else:
            self.rounds_since_defection = 0
        return Action(self.contribution > 0)

class Strategy_EXPLOITATIVE_102(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat-Adaptive (TfT-A)
    A cooperative strategy that adapts to opponent's behavior in the Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_cooperators = np.zeros(game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.last_cooperators = np.roll(self.last_cooperators, -1)
        self.last_cooperators[-1] = sum(history.opponent_actions[state.round_number - 1]) if history else 0
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1]) if history else 0
        if cooperators >= self.game_description.n_players // 2 and self.last_cooperators[-1]:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_103(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Contribution strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0
        self.past_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        elif history is not None and state.round_number < self.game_description.n_rounds - 1:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.n_players // 2:
                return Action.C
            return Action.D
        elif history is not None and state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-self.past_defections - 1, :])
            if cooperators >= self.game_description.n_players // 2:
                self.last_round_cooperators = max(cooperators, self.last_round_cooperators)
                self.past_defections = 0
                return Action.C
            self.past_defections += 1
            if self.past_defections >= 3:
                self.last_round_cooperators = 0
            return Action.D

class Strategy_EXPLOITATIVE_104(BaseStrategy):
    """
    A strategy that follows the Tit-for-Tat-Adaptive (TfTA) approach in N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))
        self.state = GameState(0)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            self.history = history
            cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            self.state = state
            if cooperators >= math.ceil(self.game_description.n_players / 2):
                return Action.C
            elif state.round_number < self.game_description.n_rounds and cooperators + 1 == math.ceil(self.game_description.n_players / 2):
                return Action.C
            else:
                return Action.D
        return Action.C if state.round_number == self.game_description.n_rounds - 1 else self.history.my_actions[-1]

class Strategy_EXPLOITATIVE_105(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Escalation (ATFE) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.escalated = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and history.opponent_actions[-1, :].all() == [False]):
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if self.escalated:
            self.escalated = False
            return 2 * Action.C if history.opponent_payoffs[-1].mean() < self.game_description.k / self.game_description.n_players else Action.D
        if cooperators >= self.game_description.n_players // 2:
            return Action.C
        elif cooperators < self.game_description.n_players // 2 and history is not None and (history.opponent_actions[-2, :].mean() > (self.game_description.n_players - 1) / 2):
            self.escalated = True
            return 2 * Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_106(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (A-TFT)
    Strategy Description: A strategy that reciprocates cooperation and punishes defection in a N-player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_opponent_cooperated = False
        self.never_contributed_opponent = np.zeros(self.game_description.n_players, dtype=bool)
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0:
            self.first_round = True
            action = Action.C
        elif not self.first_round and history is not None:
            last_round = len(history.opponent_actions) - 1
            if last_round < 0 or self.last_opponent_cooperated == history.opponent_actions[last_round, :].all():
                action = Action.C
            else:
                punishable_opponents = history.opponent_actions[last_round, :][history.opponent_actions[last_round, :] == False]
                if len(punishable_opponents) > 0:
                    available_opponents = np.setdiff1d(np.arange(self.game_description.n_players), punishable_opponents)
                    action_opponent = random.choice(available_opponents[~self.never_contributed_opponent[available_opponents]])
                else:
                    for opponent in punishable_opponents:
                        self.never_contributed_opponent[opponent] = False
                    action_opponent = random.choice(punishable_opponents)
            self.last_opponent_cooperated = history.opponent_actions[last_round, action_opponent]
        return action

class Strategy_EXPLOITATIVE_107(BaseStrategy):
    """
    A Tit-for-Tat-Cooperate-Adaptive strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history_window_size = int(math.ceil(self.game_description.n_rounds / 3))
        self.cooperator_count_threshold = math.floor(self.game_description.n_players / 2)
        self.goodwill_rounds = 3
        self.first_defection_penalty = True
        self.last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history and state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            self.last_round = True
        cooperate = Action.C
        if not self.last_round and history:
            if state.round_number > self.history_window_size:
                average_cooperators = np.mean(history.opponent_actions[state.round_number - self.history_window_size:, :] > 0)
                if average_cooperators >= self.cooperator_count_threshold:
                    cooperate = Action.C
            elif history and history.my_payoffs[-1] == 1 and (not self.first_defection_penalty):
                cooperate = Action.C
                if random.random() < 0.25:
                    self.goodwill_rounds -= 1
            else:
                cooperate = Action.D
        if history and (not self.first_defection_penalty) and (history.opponent_actions[state.round_number - 1, state.round_number % self.game_description.n_players] == Action.D):
            self.first_defection_penalty = False
        return cooperate

class Strategy_EXPLOITATIVE_108(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat (ATFT) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_punishment = False
        self.last_opponent_action = Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            self.opponent_punishment = False
            self.last_opponent_action = Action.D
        if self.opponent_punishment:
            if history.opponent_actions[-1, state.round_number % len(history.opponent_actions[0])] == self.last_opponent_action:
                self.opponent_punishment = False
            else:
                self.last_opponent_action = history.opponent_actions[-1, state.round_number % len(history.opponent_actions[0])]
        else:
            self.last_opponent_action = history.opponent_actions[-1, state.round_number % len(history.opponent_actions[0])]
        if self.last_opponent_action == Action.C:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_109(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat-Adaptive (TfTA)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_last_move = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif not history:
            self.opponent_last_move = None
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.n_players // 2 and self.opponent_last_move == Action.C:
                self.opponent_last_move = Action.C
                return Action.C
            elif self.opponent_last_move == Action.D:
                self.opponent_last_move = history.opponent_actions[-1, -1]
                return Action.D
            else:
                self.opponent_last_move = history.opponent_actions[-1, -1]
                if cooperators < self.game_description.n_players // 2:
                    return Action.C
        self.opponent_last_move = None
        return Action.D

class Strategy_EXPLOITATIVE_110(BaseStrategy):
    """
    Tit-for-Tat-with-Adaptation (TfT-A) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        self.opponent_history.append(1 if history and np.any(history.opponent_actions[-1]) else 0)
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        cooperate = 1 if opponent_cooperators >= self.game_description.n_players // 2 or not self.opponent_history[-1] else 0
        return Action.C if cooperate == self.opponent_history[-1] else Action.D

    def last_round(self):
        return self.opponent_history[-1] == 0

class Strategy_EXPLOITATIVE_112(BaseStrategy):
    """
    A Tit-for-Tat strategy with Fading Memory for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_weight = np.zeros(self.game_description.n_rounds)
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        if self.last_opponent_action is None:
            self.last_opponent_action = np.full(self.game_description.n_players, True)
        current_cooperators = sum(history.opponent_actions[-1])
        last_round_number = len(history.opponent_actions) - 1
        if self.contribution_weight[last_round_number] < 1:
            self.contribution_weight[last_round_number] += 0.1
        else:
            self.contribution_weight[:last_round_number + 1] = np.roll(self.contribution_weight, -1)
            self.contribution_weight[-1] = 0
        self.last_opponent_action = history.opponent_actions[-1] if state.round_number != self.game_description.n_rounds else np.full(self.game_description.n_players, True)
        contribution_weighted_cooperators = self.contribution_weight * current_cooperators
        weighted_sum = np.sum(contribution_weighted_cooperators)
        last_round_contribution = 0.9 ** (last_round_number - state.round_number) if state.round_number > 0 else 1
        return Action.C if last_round_contribution + weighted_sum >= len(self.last_opponent_action) else Action.D

class Strategy_EXPLOITATIVE_113(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history_len = game_description.n_rounds - 1 if game_description.n_rounds > 0 else 0
        self.forgiveness_count = math.ceil(self.history_len * 0.2)
        self.cooperator_threshold = math.floor(game_description.n_players // 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1])
        my_previous_action = history.my_actions[-1] if len(history.my_actions) > 0 else None
        if opponent_cooperators >= self.cooperator_threshold:
            return Action.C if my_previous_action is not None and my_previous_action else Action.D
        elif my_previous_action:
            cooperations = min(self.forgiveness_count, sum(history.my_actions[1:]))
            forgiveness_rounds = min(cooperations, self.history_len - (state.round_number - 1))
            return Action.C if state.round_number - forgiveness_rounds < self.history_len else Action.D
        return Action.D

class Strategy_EXPLOITATIVE_114(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptive contribution in an N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.baseline_contribution = 1.0
        self.contribution_rate = self.baseline_contribution
        self.punishment_threshold = int(self.game_description.n_players * 0.75)
        self.reward_threshold = int(self.game_description.n_players * 0.25)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1] if history else [0] * self.game_description.n_players)
        my_previous_action = history.my_actions[-1] if history else None
        if my_previous_action is None or (opponent_cooperators >= self.reward_threshold and my_previous_action == Action.C):
            self.contribution_rate = min(self.baseline_contribution, self.contribution_rate * 1.05)
        elif opponent_cooperators < self.punishment_threshold and my_previous_action == Action.D:
            self.contribution_rate = max(self.baseline_contribution * 0.5, self.contribution_rate * 0.95)
        elif my_previous_action is not None and (opponent_cooperators < self.punishment_threshold or opponent_cooperators >= self.reward_threshold):
            self.contribution_rate = min(self.baseline_contribution, self.contribution_rate)
        if random.random() < self.contribution_rate / (self.contribution_rate + 1):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_115(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for N-Player Public Goods Game.
    Strategy cooperates initially and responds to opponent's previous action in subsequent rounds,
    while exploiting opponents in the last round based on their cumulative contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(self.game_description.n_players)
        self.cumulative_contributions = np.zeros(self.game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[state.round_number - 1]
        self.cumulative_contributions += np.sum(opponent_actions)
        self.average_contributions += (self.cumulative_contributions - self.average_contributions) / state.round_number
        if state.round_number == self.game_description.n_rounds:
            average = self.average_contributions[0]
            if np.allclose(self.cumulative_contributions, average * self.game_description.n_players):
                return Action.D
            else:
                return Action.C
        return opponent_actions[-1] if opponent_actions[-1] == Action.C else Action.D

class Strategy_EXPLOITATIVE_116(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Contribution (TFTAC) strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players // 2
        self.past_average = np.zeros(game_description.n_players - 1)

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0 or state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if cooperators > 0:
            self.past_average = np.roll(self.past_average, -1)
            self.past_average[-1] = float(cooperators) / state.round_number
        else:
            for i in range(len(self.past_average)):
                self.past_average[i] = min(self.past_average[i], 0.0)
        return Action.C if np.mean(self.past_average) > self.threshold else Action.D

class Strategy_EXPLOITATIVE_117(BaseStrategy):
    """
    A strategy that adapts to opponent behavior, combining Tit-for-Tat and Freeriding strategies in an N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history_length = self.game_description.n_rounds - 1
        self.cooperative_threshold = math.ceil(self.history_length / 3)
        self.cooperative_counter = self.cooperative_threshold
        self.average_payoff = np.zeros(2)
        self.current_payoff = 0.0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if not history:
            return Action.D
        if state.round_number == 0:
            return Action.D
        actions = history.opponent_actions[:, -1]
        payoffs = history.opponent_payoffs[:, -1]
        if np.count_nonzero(actions) == len(actions):
            self.cooperative_counter = min(self.cooperative_counter + 1, self.history_length)
            if state.round_number == self.game_description.n_rounds - 1:
                return Action.C
            self.current_payoff = payoffs[-1] + self.game_description.k / self.game_description.n_players * np.sum(actions)
        else:
            self.cooperative_counter = max(0, self.cooperative_counter - 1)
            if state.round_number == self.game_description.n_rounds - 1 and self.cooperative_counter == 0:
                return Action.D
            else:
                self.current_payoff = payoffs[-1]
        self.average_payoff += np.array([self.current_payoff, self.cooperative_counter > 0])
        self.average_payoff /= state.round_number + 1
        if np.all(self.average_payoff[1]):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_118(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Contribution (TfTAC) strategy cooperates in the first round and adapts its contributions based on opponent's behavior.
    It encourages cooperation among cooperative players while exploiting non-cooperative ones.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players - 1), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players - 1)))
        self.punishment_threshold = math.floor(game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        coop_counter = np.count_nonzero(history.opponent_actions[-1, :])
        if coop_counter >= self.punishment_threshold and history.my_actions[-1] == Action.D:
            return Action.C
        elif coop_counter < self.punishment_threshold and history.my_actions[-1] == Action.C:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_119(BaseStrategy):
    """
    A strategy where players initially cooperate, then adapt their contributions based on the opponent's average contribution over the last few rounds.
    If the opponent's n-period average is close to 1 (highly cooperative), maintain full contributions.
    If the opponent's n-period average is below some threshold (e.g., 0.25), defect and stop contributing altogether.
    The value of 'n' is adjustable to adapt to different game settings and durations.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_threshold = 0.25
        self.n = min(math.ceil(self.game_description.n_players * 0.8), self.game_description.n_rounds)
        self.average_contributions = np.zeros((self.n,))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_actions) < self.n):
            return Action.C
        if history is not None:
            average_contributions = np.mean(history.my_actions[-self.n:])
            contribution_level = 1 - (average_contributions - self.contribution_threshold) * min(1, state.round_number ** (2 / 3))
            return Action.C if contribution_level > 0 else Action.D
        return Action.D

class Strategy_EXPLOITATIVE_120(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Cooperation (A-TFT-GC) strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.coop_probability = 0.1
        self.streak_length = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if all(history.opponent_actions[-1]):
            self.streak_length += 1
        else:
            self.streak_length = 0
        cooperation_probability = self.coop_probability + (self.game_description.n_players - self.streak_length) * 0.05
        cooperation_probability = min(cooperation_probability, 0.9)
        total_contributions = np.sum(history.opponent_actions[:, -1]) if history else 0
        payoff_if_cooperate = 1 - Action.C.value + self.game_description.k / self.game_description.n_players * total_contributions
        payoff_if_defect = 1 - self.game_description.k / self.game_description.n_players * total_contributions
        return Action.C if random.random() < cooperation_probability and payoff_if_cooperate > payoff_if_defect else Action.D

class Strategy_EXPLOITATIVE_121(BaseStrategy):
    """
    Strategy that implements Adaptive Tit-for-Tat with Gradual Escalation (A-TFTGE).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.min_contribution = 1.0
        self.punishment_rounds = 5
        self.gradual_escalation_step = 0.1
        self.current_contribution = self.min_contribution

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players)
        opponent_cooperators = sum(opponent_actions)
        if opponent_cooperators == 0:
            punishment_rounds = min(state.round_number + self.punishment_rounds, state.round_number + self.game_description.n_players)
            self.current_contribution = max(self.min_contribution, self.current_contribution - self.current_contribution * self.gradual_escalation_step)
        else:
            if state.round_number > 0 and history and (opponent_actions[-2] == Action.D):
                self.current_contribution += self.gradual_escalation_step
            self.current_contribution = max(self.min_contribution, self.current_contribution)
        return Action.C if self.current_contribution > opponent_actions[-1] else Action.D

class Strategy_EXPLOITATIVE_122(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat with Gradual Cooperation (ATTCG)
    A strategy that cooperates in the first round and responds based on past contributions of players.
    It gradually increases cooperation towards the end of the game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_threshold = 1
        self.punishment_duration = self.game_description.n_players
        self.current_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        self.current_round += 1
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number > self.current_round + self.punishment_duration:
            self.contribution_threshold = self.game_description.n_players
        else:
            cooperators = sum(history.opponent_actions[self.current_round - 1 if self.current_round > 0 else None, :])
            if cooperators == 0:
                return Action.D
            elif cooperators >= self.contribution_threshold:
                return Action.C
            else:
                return Action.D
        if self.current_round < self.game_description.n_rounds - self.punishment_duration:
            self.contribution_threshold += 1
            if self.contribution_threshold > self.game_description.n_players - 1:
                self.contribution_threshold = self.game_description.n_players - 1

class Strategy_EXPLOITATIVE_123(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Contribution (TfTAC) strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.first_round_contributions = np.full(self.game_description.n_players, 1)
        self.average_initial_contribution = np.mean(self.first_round_contributions)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            current_average = np.mean(history.opponent_actions[-1])
            if current_average < self.average_initial_contribution:
                return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_124(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Progressive Contribution (A-TfTPC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(self.game_description.n_players)
        self.history_length = self.game_description.n_players * (self.game_description.n_rounds - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            contributions = history.my_actions[-self.history_length:].sum(axis=0) / self.history_length
            if contributions > self.game_description.n_players / 2:
                return Action.C if contributions > 0.5 else Action.D
            else:
                return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_125(BaseStrategy):
    """
    A strategy that maintains a record of the opponent's past actions and reciprocates cooperation while minimizing losses in interactions with defectors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros((self.game_description.n_players, self.game_description.n_rounds), dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return np.random.choice([Action.C, Action.D], p=[0.5, 0.5])
        opponent_cooperators = sum(history.opponent_actions[-1, :]) if history is not None else self.opponent_history[-1, state.round_number - 1]
        if opponent_cooperators >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

    def update_opponent_history(self, opponent_action: bool):
        self.opponent_history[-1, -1] = opponent_action

class Strategy_EXPLOITATIVE_126(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Contribution (TFTAC)
    Strategy Description: Cooperates initially, reciprocates cooperation, retaliates against defection, and adjusts contributions based on opponent behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.m = int(self.n_rounds * 0.75)
        self.min_contribution = 0.2
        self.opponent_defection_frequency = np.zeros(self.m + 1)
        self.current_contribution = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = np.sum(history.opponent_actions[-1])
        my_contribution = int(self.current_contribution * (1 - (opponent_cooperators / self.n_players >= 0.5)))
        payoff = 1 - my_contribution + self.k / self.n_players * opponent_cooperators
        if state.round_number >= self.m:
            total_defections = np.sum(history.opponent_actions[:, 0] == 0)
            self.opponent_defection_frequency = np.roll(self.opponent_defection_frequency, -1)
            self.opponent_defection_frequency[-1] = total_defections
            if (self.opponent_defection_frequency >= self.n_players // 2).any():
                self.current_contribution -= 0.1
                self.current_contribution = max(self.min_contribution, self.current_contribution)
        return Action(my_contribution)

class Strategy_EXPLOITATIVE_127(BaseStrategy):
    """
    Tit-for-Tat with Escalating Defection (TfTED) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.rounds_leniency = 3
        self.current_round = 0
        self.opponent_defection_count = np.zeros(game_description.n_players, dtype=int)
        self.escalation_factor = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or self.current_round < self.rounds_leniency:
            return Action.C
        if history is not None:
            self.current_round += 1
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.n_players // 2:
                self.opponent_defection_count *= 0
                return Action.C
            self.opponent_defection_count += np.where(history.opponent_actions[-1, :] == Action.D, 1, 0)
            if np.all(self.opponent_defection_count > 0):
                self.escalation_factor += 1
                return Action.C if random.random() < cooperators / self.game_description.n_players else Action.D * self.escalation_factor
            if np.any(self.opponent_defection_count > 0) and np.any(self.opponent_defection_count[1:] != self.opponent_defection_count[:-1]):
                self.opponent_defection_count *= 0
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_128(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Cooperation (ATTCG) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.tolerance = 0.01
        self.probability = 0.5
        self.cooperation_increase = 0.02

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators = np.sum(history.opponent_actions[:, -1]) if history else 0
        average_contribution = cooperators / self.game_description.n_players
        if average_contribution + self.tolerance >= 0.5:
            self.probability += self.cooperation_increase
            return Action.C
        else:
            self.probability = max(self.probability - self.cooperation_increase, 0.5)
        return np.random.choice([Action.C, Action.D], p=[self.probability, 1 - self.probability])

class Strategy_COLLECTIVE_9(BaseStrategy):
    """
    Public Goods Game Strategy (PGG-Optimal) - A Tit-for-Tat Inspired Approach for Collective Cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_threshold = 0.2
        self.max_contribution = 0.8
        self.fixed_contribution_rate = 0.5
        self.contribution_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        total_contributions = np.sum(history.opponent_actions[-1])
        average_contribution = total_contributions / self.game_description.n_players
        self.contribution_history.append(average_contribution)
        if len(self.contribution_history) > self.game_description.n_rounds:
            self.contribution_history.pop(0)
        if average_contribution < self.contribution_threshold:
            return Action.D
        elif average_contribution > self.max_contribution:
            return Action.D
        else:
            return Action(int(average_contribution))

class Strategy_COLLECTIVE_17(BaseStrategy):
    """
    A strategy based on Fictitious Play with Adaptive Contribution (FPAC) for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.5
        self.patience_period = int(game_description.n_players * 0.1)
        self.contribution_rate = np.zeros(self.patience_period + 1)
        self.history_length = max(1, self.patience_period)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        total_contributions = sum(history.opponent_actions[-self.history_length:, :].sum(axis=1))
        contribution_rate = total_contributions / self.history_length
        if self.game_description.n_players * contribution_rate > self.threshold:
            self.threshold += 0.05
        elif self.game_description.n_players * contribution_rate < self.threshold - 0.05:
            self.threshold -= 0.05
        else:
            self.contribution_rate[np.where(self.contribution_rate > contribution_rate)] = contribution_rate
        if np.any(self.contribution_rate[-self.patience_period:] > contribution_rate):
            self.threshold = np.mean(self.contribution_rate[np.where(self.contribution_rate >= contribution_rate)])
        return Action.C if contribution_rate > self.threshold else Action.D

class Strategy_COLLECTIVE_41(BaseStrategy):
    """
    An adaptive contribution algorithm that adjusts the player's contribution rate based on historical performance and game parameters.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.personal_average_contribution_rate = np.zeros(self.game_description.n_rounds)
        self.alpha = 0.7
        self.beta = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 or history is None:
            return Action.C
        total_contributions = np.sum(history.opponent_actions.flatten())
        social_optimal_contribution_rate = self.game_description.k / self.game_description.n_players
        personal_average_contribution_rate = np.mean(self.personal_average_contribution_rate)
        contribution_rate = self.alpha * personal_average_contribution_rate + self.beta * social_optimal_contribution_rate
        if contribution_rate > 0.5:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_61(BaseStrategy):
    """Adaptive Tit-for-Tat strategy for N-Player Public Goods Game."""

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.p_init = 0.5
        self.t_free = int(game_description.n_players * 0.1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action(random.choice([0, 1])) if random.random() < self.p_init else Action.D
        if history is not None:
            cooperators = np.sum(history.opponent_actions[-1])
            total_players = history.opponent_actions.shape[1]
            if cooperators == total_players:
                return Action.C
            if cooperators < total_players // 2:
                return Action.D
            free_riders = np.count_nonzero(history.opponent_actions[:, -self.t_free:])
            if free_riders == total_players:
                return Action.D
        return Action.C



class Strategy_COLLECTIVE_79(BaseStrategy):
    """
    Tit-for-Tat with Gradual Contribution (TFTGC) Strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.n_rounds = self.game_description.n_rounds
        self.k = self.game_description.k
        self.history = PlayerHistory(my_actions=np.zeros(self.n_rounds, dtype=bool), my_payoffs=np.zeros(self.n_rounds), opponent_actions=np.zeros((self.n_rounds, self.n_players), dtype=bool), opponent_payoffs=np.zeros((self.n_rounds, self.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and np.sum(history.my_actions[0]) == 0):
            return Action.C if np.floor(state.round_number / self.n_rounds * 2) % 2 == 1 else Action.D
        if state.round_number == self.n_rounds - 1:
            most_frequent_contributor = self._find_most_frequent_contributor(history.opponent_actions[:-1])
            return Action.C if most_frequent_contributor > -1 else Action.D
        self.history.my_actions[state.round_number] = self._get_contribution(history)
        cooperators = np.sum(history.opponent_actions[-1, :])
        payoff = 1 - self.history.my_actions[state.round_number] + self.k / self.n_players * cooperators
        self.history.my_payoffs[state.round_number] = payoff
        return Action.C if self._get_most_frequent_contributor(history.opponent_actions)[0] > -1 else Action.D

    def _find_most_frequent_contributor(self, actions: NDArray[np.bool_]) -> int:
        contributions = np.sum(actions, axis=0)
        max_contributions, max_index = max(((contributions[i], i) for i in range(self.n_players)))
        if max_contributions / self.n_rounds >= 0.75:
            return max_index
        contributions_avg = np.mean(contributions)
        max_contributions, max_index = max(((contributions[i] / (self.n_rounds - len(actions)), i) for i in range(self.n_players)))
        return max_index if max_contributions >= contributions_avg * 0.75 else -1

    def _get_most_frequent_contributor(self, actions: NDArray[np.bool_]) -> int:
        contributions = np.sum(actions, axis=0)
        max_contributions, max_index = max(((contributions[i], i) for i in range(self.n_players)))
        return max_index

    def _get_contribution(self, history: PlayerHistory) -> bool:
        my_actions = history.my_actions[-1]
        if np.sum(my_actions) > len(my_actions) // 4 or (np.sum(my_actions) == 0 and self.history.my_payoffs[-1] < 1):
            return False
        return True

class Strategy_COLLECTIVE_103(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TFTA) for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_rounds = math.ceil(game_description.n_players / 2)
        self.cooperation_history = [False] * game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and state.round_number < self.game_description.n_rounds - 1:
            cooperation = np.mean(history.opponent_actions[-self.punishment_rounds:, :])
            cooperators = np.sum(history.opponent_actions[-1, :])
            if cooperation > cooperators / self.game_description.n_players:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_110(BaseStrategy):
    """
    Adaptive Public Goods Contribution (APGC) Strategy
    An adaptive strategy that encourages players to cooperate when others are contributing and defect when others are not.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_rate = None
        self.past_contributions = [0] * game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action(random.choice([0, 1]))
        self._update_contribution_rate(history)
        if state.round_number == self.game_description.n_rounds:
            return self.decide_contribution(self.contribution_rate)
        difference = self.contribution_rate - self._individual_contribution_rate()
        if difference > 0.1:
            return Action.C
        elif difference < -0.1:
            return Action.D
        else:
            return self.decide_contribution(self.contribution_rate)

    def _update_contribution_rate(self, history):
        total_rounds = len(history.my_actions) if history is not None else 0
        total_contributions = sum(history.my_actions) if history is not None else 0
        self.contribution_rate = total_contributions / total_rounds if total_rounds > 0 else 0.5

    def _individual_contribution_rate(self):
        return sum(self.past_contributions) / len(self.past_contributions)

    def decide_contribution(self, rate):
        if rate > self.game_description.n_players / 2:
            return Action.C
        return Action.D

    def register_contribution(self, contributed):
        if contributed:
            self.past_contributions[-1] += 1
        else:
            self.past_contributions[-1] -= 1

class Strategy_COLLECTIVE_124(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Public Goods Game (PGG)
    This strategy balances between individual incentives and collective welfare, adapts to various opponent behaviors,
    and fosters a sense of cooperation and reciprocity among players.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round = False
        self.new_player = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.last_round = state.round_number == self.game_description.n_rounds
        if self.last_round or (history is not None and self.new_player):
            return Action.C
        self.new_player = False
        cooperators = np.sum(history.opponent_actions[:, -1])
        if cooperators >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_1(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Contribution (TFT-AC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_level = 0.5
        self.m = 10
        self.threshold = 0.6
        self.attempt_count = 0
        self.last_cooperators = np.zeros(self.game_description.n_players, dtype=int)
        self.average_contribution = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.attempt_count += 1
        if self.attempt_count >= self.game_description.n_players:
            self.attempt_count = 0
            self.average_contribution = np.mean(self.last_cooperators)
            self.adjust_contribution_level()
        if history is None:
            cooperators = self.contribution_level
            payoff = math.floor(1 - cooperators + self.game_description.k / self.game_description.n_players * cooperators)
            return Action(int(cooperators))
        cooperators = sum(history.opponent_actions[-1, :])
        payoff = history.opponent_payoffs[-1]
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        if cooperators >= self.game_description.n_players // 2 and history.my_actions[-1] == Action.D:
            payoff += math.floor(self.game_description.k / self.game_description.n_players * (cooperators - 1))
        elif cooperators < self.game_description.n_players // 2 and history.my_actions[-1] == Action.C:
            payoff -= math.floor(self.game_description.k / self.game_description.n_players * (cooperators - 1))
        self.last_cooperators[history.opponent_actions[-1].argmax()] = int(cooperators > 0)
        return Action(int(self.contribution_level))

    def adjust_contribution_level(self):
        if self.average_contribution > self.threshold:
            self.contribution_level += 0.1
        elif self.average_contribution < self.threshold:
            self.contribution_level -= 0.1

class Strategy_EXPLOITATIVE_12(BaseStrategy):
    """
    A class representing the Tit-for-Tat with Adaptive Contribution (TfT-AC) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_decay = 0.95 ** (game_description.n_players - 1)
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory):
        action = Action.D
        if state.round_number == 0:
            action = Action.C
            self.first_round = False
        elif not history or self.first_round:
            action = Action.C
            self.first_round = False
        else:
            total_cooperators = np.sum(history.opponent_actions[-1])
            if total_cooperators == 0:
                action = Action.D
            elif total_cooperators >= self.game_description.n_players // 2:
                action = Action.C
            else:
                cooperators_fraction = total_cooperators / self.game_description.n_players
                round_number_fraction = state.round_number / self.game_description.n_rounds
                adjustment = (1 - round_number_fraction) * cooperators_fraction + round_number_fraction * self.punishment_decay
                if adjustment > random.random():
                    action = Action.D
        return action

class Strategy_EXPLOITATIVE_17(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradient Contribution (Aggressive-TFT-GC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.past_actions = {}
        self.retaliation_counter = {}
        self.last_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        current_actions = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=bool)
        self.update_history(current_actions)
        cooperators = sum(current_actions)
        if all((action == Action.C for action in current_actions)):
            return Action.C
        if cooperators < self.last_cooperators:
            opponent_index = next((i for i, actions in enumerate(current_actions) if not all(actions)), None)
            if opponent_index is not None:
                self.retaliation_counter[opponent_index] = max(1 + math.floor((state.round_number - 1) * (1 - self.game_description.k / self.game_description.n_players)), self.retaliation_counter.get(opponent_index, 0))
                if self.retaliation_counter[opponent_index] > state.round_number:
                    return Action.C
        return Action.D

    def update_history(self, actions: np.ndarray) -> None:
        for i, action in enumerate(actions):
            if i not in self.past_actions:
                self.past_actions[i] = [action]
            else:
                self.past_actions[i].append(action)

class Strategy_EXPLOITATIVE_21(BaseStrategy):
    """
    A Tit-for-Tat strategy with Adaptive Contribution Level (TA-CL) for N-Player Public Goods Game.
    This strategy dynamically adjusts contribution level based on average opponent and overall player contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_level = 0.5
        self.opponent_avg_contrib = None
        self.global_avg_contrib = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if self.opponent_avg_contrib is None or self.global_avg_contrib is None:
            self.update_averages(history)
            self.contribution_level += (self.opponent_avg_contrib - self.global_avg_contrib) * 0.01
            self.contribution_level = max(min(self.contribution_level, self.game_description.k / self.game_description.n_players), 0.5)
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators > self.game_description.n_players // 2:
            return Action.C if self.contribution_level >= 0.5 else Action.D
        return Action.C

    def update_averages(self, history: PlayerHistory) -> None:
        self.opponent_avg_contrib = np.mean([np.mean(history.opponent_actions[:, i]) for i in range(1, len(history.opponent_payoffs))])
        self.global_avg_contrib = np.mean(history.my_actions)

class Strategy_EXPLOITATIVE_34(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TFT-A) strategy in N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = np.zeros(self.game_description.n_players)
        self.round_number = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number == 0 and history:
            self.average_contribution = np.zeros(self.game_description.n_players)
        else:
            self.round_number += 1
            if history is None:
                return Action.C
            total_cooperators = sum(history.opponent_actions[-1, :])
            average_contribution = np.mean(history.my_actions[-self.game_description.n_rounds + self.round_number - 1:])
            if total_cooperators == 0 or average_contribution < 0.5:
                return Action.D
            elif average_contribution >= 1:
                return Action.C
            else:
                self.average_contribution = average_contribution
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        return Action(math.floor(self.average_contribution))

class Strategy_EXPLOITATIVE_60(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptation (TfT-A) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.retaliation_length = 3
        self.last_cooperators = 0
        self.is_adapting = False
        self.rounds_adapted = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) == 0):
            return Action.C
        self.last_cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if state.round_number < self.retaliation_length:
            return Action(self.last_cooperators > 0)
        if state.round_number >= self.retaliation_length and (not self.is_adapting):
            return Action((state.round_number - self.retaliation_length) % 2 == 0)
        if state.round_number > self.retaliation_length + self.rounds_adapted:
            self.is_adapting = False
            self.rounds_adapted = 0
        elif self.last_cooperators < self.game_description.n_players - 1 and state.round_number <= self.retaliation_length + self.rounds_adapted:
            self.rounds_adapted += 1
            self.is_adapting = True
        return Action((state.round_number - self.retaliation_length) % 2 == (not self.is_adapting))

class Strategy_EXPLOITATIVE_91(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Contribution (TFT-AC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(self.game_description.n_players)
        self.total_contributions = 0.0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[-1]
        current_contribution = 1 if opponent_actions[-1] else 0
        total_contributions = np.sum(opponent_actions)
        self.total_contributions += total_contributions
        self.average_contributions[history.my_actions[-1] if len(self.average_contributions) > 0 else 0] = current_contribution
        avg_opponent_contrib = np.mean(self.average_contributions[self.average_contributions != 0])
        total_avg_contribs = self.total_contributions / self.game_description.n_players
        threshold = total_avg_contribs * (avg_opponent_contrib / total_avg_contribs) + 1
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        elif not opponent_actions[-2]:
            return Action.D
        else:
            return Action(threshold <= 1)

class Strategy_EXPLOITATIVE_92(BaseStrategy):
    """
    Strategy name: Adaptive Tit-for-Tat with Variable Contribution (ATFC)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.epsilon = 0.1
        self.m = math.ceil(game_description.n_players / 2)
        self.t_threshold = game_description.k * game_description.n_players / 2 - self.epsilon

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return random.choice([Action.C, Action.D])
        opponent_contributions = history.opponent_actions[:, -self.m:].sum(axis=1) / self.m
        average_contribution = np.nanmean(opponent_contributions)
        if average_contribution > self.t_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_96(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Proportional Contribution (A-TFTPC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.min_contribution = 1 if game_description.n_players % 2 == 0 else math.floor((game_description.n_players - 1) / 2) + 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[-1] if history is not None else np.zeros(size=self.game_description.n_players, dtype=np.bool_)
        cooperators = sum(opponent_actions)
        contribution = self.min_contribution * (cooperators / len(opponent_actions)) if cooperators > 0 else self.min_contribution // 2
        return Action(int(contribution)) if contribution < self.min_contribution else Action.C

class Strategy_EXPLOITATIVE_111(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponents = set()
        self.last_cooperation = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and history.opponent_actions is None):
            return Action.C
        if history is None:
            cooperators = sum(random.choices([True, False], weights=[1 - self.game_description.k / self.game_description.n_players, self.game_description.k / self.game_description.n_players]))
        else:
            cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.n_players // 2 and state.round_number > self.last_cooperation + 1:
            return Action.C
        elif history is not None and any((history.opponent_actions[-1, player] for player in self.opponents)) and (state.round_number != self.game_description.n_rounds):
            return Action.D
        else:
            return Action.C

    def update_history(self, opponent_index: int):
        """
        Update the strategy's internal state upon encountering a new opponent.
        """
        self.opponents.add(opponent_index)
        if self.last_cooperation != -1:
            self.last_cooperation += 1

class Strategy_EXPLOITATIVE_2(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Cooperation Strategy.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history_len = self.game_description.n_rounds - 1
        self.graduality = 0.3
        self.min_cooperation = 0.3
        self.punishment_period = 3
        self.reward_period = 3

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        my_contributions = np.sum(history.my_actions)
        opponent_contributions = sum(np.sum(history.opponent_actions, axis=0))
        opponent_defections = opponent_contributions - my_contributions
        if self.punishment_period > 0 and opponent_defections >= self.game_description.n_players:
            punishment_remaining = min(self.punishment_period, state.round_number)
            cooperation_level = max(self.min_cooperation - (state.round_number - punishment_remaining) * self.graduality, self.min_cooperation)
        elif self.reward_period > 0 and my_contributions >= opponent_contributions:
            reward_remaining = min(self.reward_period, state.round_number)
            cooperation_level = min(1.0 - (state.round_number - reward_remaining) * self.graduality, 1.0)
        else:
            cooperation_level = 1.0
        if np.random.random() < cooperation_level:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_46(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TFT-A) Strategy for N-Player Public Goods Game
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.tolerance = math.ceil(game_description.n_players / 2)
        self.counter = {i: 0 for i in range(1, game_description.n_players + 1)}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        opponent_actions = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=bool)
        last_contribution = opponent_actions[-1]
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        self.counter[last_contribution + 1] += int(opponent_actions[-1])
        if self.counter[last_contribution + 1] >= self.tolerance:
            self.counter[last_contribution + 1] = 0
            return Action.D
        return Action.C if last_contribution else Action.D

class Strategy_EXPLOITATIVE_61(BaseStrategy):
    """
    Tit-for-Tat with adaptive contribution amount strategy for N-player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_amount = float(game_description.k * game_description.n_players)
        self.episode_length = game_description.n_rounds - 1
        self.opponent_history = []
        self.average_contributions = np.zeros(self.episode_length)
        self.current_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        self.opponent_history.append(history)
        if self.current_round == 0:
            self.current_round += 1
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        self.current_round += 1
        opponent_cooperators = sum(history.opponent_actions[-1])
        if opponent_cooperators == len(self.opponent_history):
            return Action.C
        elif opponent_cooperators > 0:
            self.contribution_amount = self.contribution_amount - 0.05
            if self.contribution_amount < self.game_description.k * len(self.opponent_history) / self.game_description.n_players:
                self.contribution_amount = self.game_description.k * len(self.opponent_history) / self.game_description.n_players
        else:
            self.average_contributions[:self.current_round] = 0
            self.contribution_amount = np.mean(self.average_contributions) + self.game_description.k * len(self.opponent_history) / self.game_description.n_players
        return Action.C if self.contribution_amount > random.random() else Action.D

class Strategy_EXPLOITATIVE_76(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Cooperation (A-TFTGC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.N = math.floor(game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) < self.game_description.n_rounds):
            return Action.C
        consecutive_defections = sum((1 for row in history.opponent_actions[-self.game_description.n_rounds:] if not any(row)))
        contribution_probability = min(1, (state.round_number - 1) / self.N if consecutive_defections > self.N else 1)
        action = random.choice([Action.C, Action.D], [contribution_probability, 1 - contribution_probability])
        return action

class Strategy_EXPLOITATIVE_97(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Game Awareness (ATFPGA) strategy for N-Player Public Goods Games.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contributions = np.zeros(game_description.n_players)
        self.total_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if random.random() > 0.5 else Action.D
        coop_in_prev_round = sum(history.opponent_actions[-1])
        if coop_in_prev_round >= self.game_description.n_players // 2:
            return Action.C
        avg_contrib_this_player = np.mean(history.my_actions[:self.total_rounds])
        self.average_contributions = (1 - self.total_rounds / self.game_description.n_rounds) * self.average_contributions + avg_contrib_this_player / self.total_rounds
        if history is not None:
            self.total_rounds += 1
        return Action.C if random.random() < coop_in_prev_round / self.game_description.n_players + np.mean(self.average_contributions) else Action.D

class Strategy_COLLECTIVE_121(BaseStrategy):
    """
    Fictitious Play with Adaptive Contribution (FPAC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_opponent_contributions = np.zeros(self.game_description.n_players)
        self.rounds_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.rounds_count += 1
        if history is not None:
            opponent_contributions = history.opponent_actions[:, -1].sum(axis=0)
            self.average_opponent_contributions = (self.average_opponent_contributions * (self.rounds_count - 1) + opponent_contributions) / self.rounds_count
        my_action = Action.D
        for opponent in range(1, self.game_description.n_players + 1):
            if self.average_opponent_contributions[opponent - 1] > np.mean(history.my_actions) if history else 0.5:
                probability = math.exp((self.average_opponent_contributions[opponent - 1] - np.mean(history.my_actions)) / self.game_description.n_players)
                if random.random() < probability:
                    my_action = Action.C
            elif self.average_opponent_contributions[opponent - 1] < np.mean(history.my_actions) if history else 0.5:
                probability = math.exp((np.mean(history.my_actions) - self.average_opponent_contributions[opponent - 1]) / self.game_description.n_players)
                if random.random() < probability:
                    my_action = Action.D
        return my_action

class Strategy_EXPLOITATIVE_69(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Escalation (ATTE) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_level = 1.0
        self.trust_building = False
        self.cooperative_streak = 0
        self.defection_streak = 0
        self.rounds_remaining = game_description.n_rounds - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.rounds_remaining <= 3:
            self.punishment_level = 1.0
            self.trust_building = False
        self.cooperative_streak = max(self.cooperative_streak, sum(history.my_actions) if history else 0)
        self.defection_streak = max(self.defection_streak, sum(np.logical_not(history.my_actions)) if history else 0)
        self.rounds_remaining -= 1
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if self.punishment_level == 1.0 and cooperators >= self.game_description.n_players - self.defection_streak:
            self.trust_building = True
        elif self.punishment_level < 1.0 and (cooperators < self.game_description.n_players // 2 or not self.trust_building):
            self.punishment_level = min(self.punishment_level + 0.5, 1.0)
        elif self.trust_building and cooperators >= self.game_description.n_players - self.defection_streak:
            self.punishment_level = max(self.punishment_level - 0.5, 0.0)
        return Action.C if self.trust_building or (self.punishment_level > 0 and cooperators >= self.cooperative_streak) else Action.D

class Strategy_COLLECTIVE_76(BaseStrategy):
    """
    Adaptive Public Goods Game Strategy (APGS). A strategy that adjusts its contribution rate based on the group behavior to maintain the public good provision.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players * (1 + math.sqrt(game_description.n_players))
        self.average_contribution_rate = [0.0]

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            average_contribution_rate = np.mean(history.my_actions)
            self.average_contribution_rate.append(average_contribution_rate)
            if average_contribution_rate > self.threshold:
                return Action.C
            else:
                return Action.D
        last_round = len(self.average_contribution_rate) - 1
        if last_round >= 0:
            average_contribution_rate = self.average_contribution_rate[last_round]
            return Action.C if average_contribution_rate > self.threshold else Action.D
        return Action.C

class Strategy_COLLECTIVE_5(BaseStrategy):
    """
    Implementation of the Adaptive Contribution Algorithm (ACA).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.min_contributions = np.zeros(game_description.n_rounds)
        self.averages = np.zeros(game_description.n_rounds)
        self.threshold = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.threshold is None:
            self.threshold = self.game_description.k / self.game_description.n_players + min(self.min_contributions)
        if history.my_actions.sum() > 0:
            self.averages[-1] = history.my_actions.mean()
        else:
            self.averages[-1] = np.nan
        if self.averages[-1] >= self.threshold:
            return Action.C
        return Action.D


class Strategy_COLLECTIVE_15(BaseStrategy):
    """
    Adaptive Contribute-Based Strategy (ACBS) for N-Player Public Goods Game.
    This strategy compares its own contributions with the average contribution of all players in the previous rounds.
    If the individual's contribution is lower than the average, it will increase its contribution by one token;
    if it is higher or equal, it will maintain its current contribution level.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contributions = np.zeros(game_description.n_rounds)
        self.average_contributions = [0] * game_description.n_rounds
        self.last_round_average = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        self.contributions[state.round_number - 1] = (history.my_actions[-1] * 1).astype(int)
        self.average_contributions[:-1] = np.roll(self.average_contributions, -1)
        self.average_contributions[-1] = np.mean(self.contributions)
        self.last_round_average = self.average_contributions[-1]
        cooperators = sum(history.opponent_actions[-1, :])
        if self.last_round_average < (cooperators + 1) / self.game_description.n_players:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_70(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Awareness (ATFPGA) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_cooperation = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history is not None:
            self.average_cooperation = np.roll(self.average_cooperation, -1)
            self.average_cooperation[-1] = np.mean(history.opponent_actions[:state.round_number, :].flatten())
        if self.average_cooperation[-1] >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_85(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_cooperation = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.last_cooperation = True
            return Action.C
        cooperation = sum(history.opponent_actions[-1, :]) if history is not None else 0
        last_action = self.last_cooperation
        self.last_cooperation = cooperation == self.game_description.n_players - 1 or last_action
        return Action(int(last_action)) if history is not None else Action.C

class Strategy_EXPLOITATIVE_42(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Contribution (TFTAC)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_level = 1.0
        self.punishment_threshold = int(game_description.n_players * 0.7)
        self.warning_threshold = int(game_description.n_players * 0.5)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1])
        total_players = len(history.opponent_actions[0])
        if opponent_cooperators >= self.punishment_threshold:
            return Action.C
        elif opponent_cooperators < self.warning_threshold and state.round_number > 1:
            self.contribution_level = max(self.contribution_level - (state.round_number - 2) * 0.1, 0.1)
        return Action.D if opponent_cooperators == 0 or state.round_number == self.game_description.n_rounds else Action(math.floor(self.contribution_level + 0.5))

class Strategy_EXPLOITATIVE_50(BaseStrategy):
    """
    A strategy that reciprocates cooperation while also taking advantage of opponents who consistently defect.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.revenge_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_action = Action.C if history and sum(history.opponent_actions[-1]) > 0 else Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        elif not history or self.revenge_counter >= self.game_description.n_players:
            self.revenge_counter = 0
            return current_action
        else:
            self.revenge_counter += 1 if current_action == Action.D else 0
            return Action.C if current_action == Action.C else Action.D

class Strategy_EXPLOITATIVE_79(BaseStrategy):
    """Adaptive Tit-for-Tat with Public Goods Game Optimization"""

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.m = math.ceil(self.n_rounds * 0.8)
        self.history = np.zeros((self.m + 1, 2), dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self._update_history(history)
        cooperators = np.sum(self.history[-1])
        average_cooperators = np.mean(self.history[:, 1])
        if cooperators > self.n_players - 1:
            return Action.D
        elif cooperators == self.n_players:
            return Action.C
        elif cooperators >= average_cooperators and state.round_number != self.game_description.n_rounds - 1:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        else:
            return Action.D

    def _update_history(self, history: PlayerHistory):
        self.history = np.roll(self.history, -1)
        self.history[-1, 0] = len(history.opponent_actions) > 0 and history.my_actions[-1] == Action.D
        self.history[-1, 1] = any(history.opponent_actions[:, -1])

class Strategy_EXPLOITATIVE_90(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Contribution (TFTAC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.contribution_level = 1.0
        self.defection_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1] if history is not None else [False] * self.game_description.n_players)
        if opponent_cooperators == self.game_description.n_players:
            self.contribution_level = 1.0
            self.defection_count = 0
        elif opponent_cooperators > 0:
            self.contribution_level = min(self.contribution_level * (opponent_cooperators / self.game_description.n_players), 1.0)
        else:
            self.defection_count += 1
            self.contribution_level = max(self.contribution_level - self.defection_count / self.game_description.n_players, 0.0)
        return Action.C if self.contribution_level > random.random() else Action.D

class Strategy_EXPLOITATIVE_71(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT)
    Strategy Description: A strategy that cooperates with partners in the initial round and subsequent rounds if they have cooperated in the previous round. If a player has previously experienced defection from the current partner, the strategy will defect until the partner returns to cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_counter = math.ceil(self.game_description.n_players / 2)
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number >= self.game_description.n_rounds - 1 or history is None:
            return Action.D
        if history is not None:
            self.history = history.opponent_actions[:, 0].tolist()
        opponent_action = history.opponent_actions[state.round_number - 1, 0] if history is not None else None
        cooperation_status = int(opponent_action == Action.C)
        self.cooperation_counter += 1 if cooperation_status > 0 else -1
        return Action.C if self.cooperation_counter >= self.game_description.n_players // 2 else Action.D













class Strategy_COLLECTIVE_119(BaseStrategy):
    """
    A strategy that adapts to the collective behavior in N-Player Public Goods Game, promoting cooperation when it benefits the group as a whole.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.contribution_level = self._calculate_contribution_level()

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C if self.contribution_level >= 1 else Action.D
        cooperators = np.sum(history.opponent_actions[-1, :])
        contribution_level = self._calculate_contribution_level(cooperators)
        return Action.C if contribution_level >= self.contribution_level else Action.D

    def _calculate_contribution_level(self, cooperators=None):
        if self.n_players > 3:
            return (1 + (self.n_players - 1) / self.k) / self.n_players
        elif self.n_players <= 3 and cooperators is None:
            return 1
        else:
            contribution_level = max(0, 1 - cooperators / self.n_players) if cooperators is not None else None
            return 1 if contribution_level >= 1 else 0


class Strategy_EXPLOITATIVE_20(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy in the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.testing_period = 5
        self.last_opponent_action = None
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if self.first_round else self.last_opponent_action
            self.first_round = False
        cooperators = sum(history.opponent_actions[-1, :])
        opponent_cooperated = cooperators >= self.game_description.n_players // 2
        self.last_opponent_action = opponent_cooperated
        if history is None or state.round_number == self.game_description.n_rounds - 1:
            return Action(opponent_cooperated)
        if not opponent_cooperated and cooperators < self.game_description.n_players and (state.round_number >= self.testing_period):
            return Action.C
        return Action(not opponent_cooperated)







class Strategy_COLLECTIVE_99(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.m = int(math.ceil(game_description.n_rounds / 2))
        self.s = int(math.ceil(game_description.n_rounds / 10))
        self.history = None
        self.average_contribution = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            self.history = PlayerHistory(my_actions=np.array([[Action.C]], dtype=np.bool_), my_payoffs=np.array([0.0], dtype=np.float64), opponent_actions=np.zeros((1, self.game_description.n_players), dtype=np.bool_), opponent_payoffs=np.zeros((1, self.game_description.n_players), dtype=np.float64))
        if self.history is not None:
            self.average_contribution = np.mean(self.history.opponent_actions[:, -self.m:].sum(axis=1))
        if history.opponent_actions[-1, :].sum() == 0:
            return Action.D
        if self.history is not None and self.history.opponent_actions[-1, :].sum() < self.game_description.n_players * self.average_contribution:
            if state.round_number < self.s:
                return Action.D
            else:
                return Action.C
        return Action.C





class Strategy_COLLECTIVE_87(BaseStrategy):
    """
    Adaptive Public Goods Contribution (APGC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = 0.0
        self.threshold = 0.3
        self.last_round_negative_payoff = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            self.average_contribution = 0.0
            self.threshold = 0.3
            self.last_round_negative_payoff = False
            return Action.C
        if history.my_actions is None or history.my_payoffs is None:
            return history.opponent_actions[-1][0]
        self.average_contribution = np.mean(history.my_actions)
        if self.average_contribution < self.threshold and (not self.last_round_negative_payoff):
            self.threshold += 0.05
        if np.all(history.my_payoffs[-1] < 0.0):
            self.last_round_negative_payoff = True
            self.threshold -= 0.05
        if self.average_contribution >= self.threshold:
            return Action.D
        return Action.C



class Strategy_EXPLOITATIVE_3(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Contribution (TFT-AC) strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.5
        self.contribution_rate = 1.0
        self.opponent_history = np.zeros((game_description.n_rounds,))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history[-1] = sum(history.opponent_actions[-1]) if history else 0
        if len(self.opponent_history) == 1:
            self.contribution_rate = 1.0
        avg_cooperation = np.mean(self.opponent_history)
        if avg_cooperation < self.threshold:
            self.contribution_rate = max(self.contribution_rate - 0.1, 0.5)
        elif avg_cooperation > self.threshold:
            self.contribution_rate = min(self.contribution_rate + 0.1, 1.5)
        if history and sum(history.opponent_actions[-1]) >= math.floor(len(history.opponent_actions) * self.contribution_rate):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_66(BaseStrategy):
    """
    A simple Adaptive Tit-for-Tat strategy that cooperates initially and responds to the opponent's actions in subsequent rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0
        self.last_round_response = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.last_round_cooperators = cooperators
        if self.last_round_response is None:
            self.last_round_response = Action.D if cooperators == 0 else Action.C
        if self.last_round_response == Action.C and cooperators == self.game_description.n_players:
            return Action.C
        elif self.last_round_response == Action.C and cooperators < self.game_description.n_players:
            return Action.D
        elif self.last_round_response == Action.D and cooperators > 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        if cooperators == 0:
            self.last_round_response = Action.D
            return Action.D
        if cooperators > 0 and self.last_round_response == Action.D:
            self.last_round_response = None
            return Action.C
        else:
            self.last_round_response = self._update_response(cooperators)
        return self.last_round_response

    def _update_response(self, cooperators):
        if self.last_round_response == Action.C and cooperators < self.game_description.n_players:
            return Action.D
        elif self.last_round_response == Action.D and cooperators > 0:
            return Action.C

class Strategy_COLLECTIVE_129(BaseStrategy):
    """
    Strategy implementing Adaptive Fitness-Based Contribution (AFBC) in N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.fraction_initial = 0.5
        self.threshold = self.n_players // 2
        self.contributions_history = np.zeros(self.game_description.n_rounds, dtype=np.int64)
        self.tied_threshold = self.n_players // 3

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 and history is None:
            return Action.C
        contributions = np.sum(history.my_actions)
        self.contributions_history[state.round_number - 1] = contributions
        average_contribution = np.mean(self.contributions_history[:state.round_number])
        if average_contribution > self.threshold:
            return Action.C
        elif average_contribution < self.threshold - 1 or average_contribution == self.threshold:
            return Action.D
        else:
            if np.sum(history.my_actions[:-1] == history.my_actions[-1]) >= self.tied_threshold:
                return Action.C if random.random() < 0.5 else Action.D
            return Action(int(average_contribution > (self.threshold + 1) / 2))

class Strategy_COLLECTIVE_130(BaseStrategy):
    """
    Strategy that encourages cooperation by rewarding contributors and punishing freeloaders, while being adaptive to opponents' behaviors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.min_contribution = 0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            self.rounds_played += 1
            cooperators = np.mean(history.opponent_actions[:, :self.game_description.n_players - 1])
            if history and self.rounds_played > 1 and (cooperators < self.min_contribution):
                self.min_contribution = max(cooperators, self.min_contribution)
            if cooperators >= self.min_contribution:
                return Action.C
            return Action.D

class Strategy_COLLECTIVE_131(BaseStrategy):
    """
    Implementation of Adaptive Tit-for-Tat with Public Goods Game (PGG-AtfT) strategy.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = np.zeros(game_description.n_rounds)
        self.threshold = int(game_description.n_players * (1 - 1 / game_description.k) + 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            average = np.mean(self.average_contribution)
            cooperate = average >= self.threshold or (history and history.my_actions[-1])
            return Action(cooperate)
        self.average_contribution[state.round_number] = np.mean(history.my_actions[-self.game_description.n_rounds:])
        cooperate = self.average_contribution[-1] == np.mean(history.opponent_actions[-1]) and history.my_actions[-1]
        defect = history.opponent_actions[-1, -1] == 0 and np.mean(history.opponent_actions[-self.game_description.n_rounds:]) < self.threshold
        return Action(cooperate or not defect)

class Strategy_COLLECTIVE_133(BaseStrategy):
    """
    A Tit-For-Tat-With-Forgiveness (TFTF) adaptive, collective strategy that emphasizes reciprocity, forgiveness, and cooperation in the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_counter = 0
        self.forgiveness_threshold = math.ceil(game_description.n_players / 2)
        self.cooperation_history = np.zeros(game_description.n_players, dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions[-1]:
            self.punishment_counter = 0
        else:
            self.punishment_counter += 1
        if self.punishment_counter > self.forgiveness_threshold:
            self.cooperation_history = np.zeros(self.game_description.n_players, dtype=bool)
            self.punishment_counter = 0
        if self.punishment_counter <= self.forgiveness_threshold and np.sum(history.my_actions[-self.punishment_counter:]) == len(self.cooperation_history):
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_134(BaseStrategy):
    """Adaptive Tit-for-Tat Strategy for N-Player Public Goods Game"""

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round_opponents_cooperated = np.zeros(self.game_description.n_players, dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number > 0 and history is not None:
            last_opponents_cooperated = self.last_round_opponents_cooperated
            current_opponents_cooperated = sum(history.opponent_actions[-1, :])
            self.last_round_opponents_cooperated[:] = last_opponents_cooperated
            self.last_round_opponents_cooperated[np.where(history.opponent_actions[-1, :])] = True
            return Action(last_opponents_cooperated[current_opponents_cooperated].sum() > 0)

class Strategy_COLLECTIVE_135(BaseStrategy):
    """
    Strategy Name: Adaptive Contribution Algorithm (ACA)
    Description: A Tit-for-Tat approach with a twist, using average contribution of opponent over past rounds to decide whether to cooperate or defect.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_average = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if random.random() < 0.5 else Action.D
        if not history:
            return self.__call__(GameState(state.round_number + 1), None)
        cooperators = sum(history.opponent_actions[-self.game_description.n_rounds:].flatten())
        total_rounds = self.game_description.n_rounds
        if self.opponent_average is None:
            self.opponent_average = cooperators / total_rounds
        if cooperators >= self.game_description.n_players * self.opponent_average // 2:
            return Action.C
        elif self.opponent_average is not None and np.isclose(cooperators, self.game_description.n_players * self.opponent_average / 2):
            return history.opponent_actions[-1][-1]
        else:
            return Action.D

class Strategy_COLLECTIVE_136(BaseStrategy):
    """
    The Adaptive Focal Point (AFS) Strategy for the N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.acr = None
        self.tolerance = None
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        if not self.first_round and history is not None:
            cooperators = sum(history.opponent_actions[-1])
            total_players = self.game_description.n_players
            if self.acr is None or self.tolerance is None:
                self.acr = np.mean(history.my_actions[:-1])
                self.tolerance = 0.2 * self.acr
            elif cooperators < self.acr - self.tolerance:
                action = Action.C
        if state.round_number == 0 or history is None:
            self.first_round = True
            self.acr = np.random.choice([0, 1])
        elif self.first_round:
            self.first_round = False
            if random.random() < 0.5:
                self.acr = 1
            else:
                self.acr = 0
        return action

class Strategy_COLLECTIVE_137(BaseStrategy):
    """
    An Adaptive Tit-for-Tat strategy that encourages cooperation while accounting for individual incentives and past actions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=bool)
        self.last_opponent_action = opponent_actions[-1]
        cooperators = sum(opponent_actions)
        if cooperators >= (self.game_description.n_players + 1) // 2:
            return Action.C
        elif self.last_opponent_action:
            return Action.C
        else:
            return Action.D

    def update_history(self, history: PlayerHistory):
        if not history:
            return
        opponent_actions = history.opponent_actions[-1]
        self.last_opponent_action = opponent_actions[-1]

class Strategy_COLLECTIVE_138(BaseStrategy):
    """
    Strategy Name: Adaptive Focal Point Public Goods Strategy (AFPPGS)

    This strategy uses a focal point mechanism to decide whether to contribute or not, based on the average contributions of all players in previous rounds.
    It promotes cooperation for mutual benefit and encourages a collective mindset.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = self.game_description.n_players > self.game_description.k and Action.C or Action.D
        self.total_contributions = 0
        self.num_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            return self.cooperation_threshold
        self.num_rounds += 1
        cooperators = np.sum(history.opponent_actions[:, -1])
        average_contribution = cooperators / self.num_rounds if self.num_rounds > 0 else 0
        if average_contribution > 0.8:
            return Action.C
        elif average_contribution < 0.2:
            return Action.D
        else:
            recent_opponents = history.opponent_actions[:, -5:]
            recent_cooperators = np.sum(recent_opponents, axis=1)
            if np.mean(recent_cooperators) > 0.6:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_139(BaseStrategy):
    """
    Adaptive Fitness Sharing (AFS) for Public Goods Game (PGG)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = self.game_description.n_players // 2
        self.minimum = self.game_description.n_players // 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return np.random.choice([Action.C, Action.D], p=[self.minimum / self.game_description.n_players, 1 - self.minimum / self.game_description.n_players])
        average_contribution = sum(history.opponent_actions[-1]) / self.game_description.n_players
        if average_contribution >= self.threshold:
            return Action.C
        elif average_contribution > self.minimum and random.random() < (average_contribution - self.minimum) / (1 - self.threshold):
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_140(BaseStrategy):
    """
    Adaptive Cooperative Strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = 0.0
        self.total_contributions = 0.0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.rounds_played += 1
        if history is not None:
            contributions = history.my_actions[-1]
            self.total_contributions += np.sum(contributions)
            if self.rounds_played > 1:
                self.average_contribution = self.total_contributions / self.rounds_played
        threshold = self.game_description.n_players // 2
        if self.average_contribution > threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_129(BaseStrategy):
    """
    A strategy that cooperates initially, matches opponents' defections for one round, and then reverts back to cooperation unless the opponent continues defecting.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_defected_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=bool)
        self.opponent_defected_last_round = np.all(opponent_actions == 0)
        return Action(int(not self.opponent_defected_last_round and (not history)))

class Strategy_EXPLOITATIVE_130(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.opponent_history) == 0:
            return Action.C
        recent_contributions = sum(history.opponent_actions[-1, :]) if history else sum(self.opponent_history[-1])
        if recent_contributions >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

    def update_opponent_history(self, history: PlayerHistory):
        self.opponent_history = history.opponent_actions.tolist() if history else []

class Strategy_EXPLOITATIVE_131(BaseStrategy):
    """
    Public Goods Game Exploitative Strategy (PGG-ES)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros((self.game_description.n_rounds, self.game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 and history is None:
            return Action(int(random.choice([0, 1]) + 0.6))
        averaged_contributions = self.history.opponent_actions[-1].sum() / state.round_number
        if averaged_contributions > self.game_description.n_players // 2:
            return Action.C
        else:
            return Action.D

    def update_history(self, my_action: Action, payoff: float):
        self.history.my_actions[-1] = int(my_action)
        self.history.my_payoffs[-1] = payoff
        if len(self.history.opponent_actions) < self.game_description.n_rounds:
            self.history.opponent_actions = np.roll(self.history.opponent_actions, 1, axis=0)
            self.history.opponent_payoffs = np.roll(self.history.opponent_payoffs, 1, axis=0)
        if state.round_number < self.game_description.n_rounds:
            self.history.opponent_actions[-1][self.__class__] = int(my_action)
            self.history.opponent_payoffs[-1][self.__class__] = payoff

class Strategy_EXPLOITATIVE_132(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Cooperation (ATTCG) strategy.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.punishment_rounds = math.floor(self.game_description.n_players / 2)
        self.reduction_interval = 5
        self.trust_building_index = 0
        self.defectors = set()
        self.cooperators = set()
        self.last_action = Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        action = Action.D
        if not history:
            return action
        self.trust_building_index += 1
        if self.last_action == Action.C and len(self.defectors) > 0 and (self.defectors != set(history.opponent_actions[-1])):
            self.defectors.discard(self.__class__)
        if self.last_action == Action.D and len(self.cooperators) > 0 and all(history.opponent_actions[-1]):
            self.cooperators.discard(self.__class__)
        opponent_cooperation = sum(history.opponent_actions[-1])
        if opponent_cooperation == 0:
            action = Action.D
            if self.trust_building_index >= self.reduction_interval and state.round_number > self.punishment_rounds:
                self.punishment_rounds -= 1
        elif opponent_cooperation == self.n_players:
            action = Action.C
        elif self.last_action == Action.D:
            if self.trust_building_index >= self.reduction_interval and state.round_number > self.punishment_rounds:
                self.punishment_rounds -= 1
        elif opponent_cooperation > 0:
            action = Action.C
            self.cooperators.add(self.__class__)
        else:
            self.defectors.add(self.__class__)
        self.last_action = action
        return action

class Strategy_EXPLOITATIVE_133(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Game Awareness (ATTPGA) strategy.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[state.round_number - 1]
        total_cooperators = sum(opponent_actions)
        if total_cooperators >= self.game_description.n_players // 2:
            return Action.C if history.my_actions[state.round_number - 1] else Action.D
        return Action.D

class Strategy_EXPLOITATIVE_134(BaseStrategy):
    """
    An adaptive Tit-for-Tat (A-TFT) strategy that maintains a balance between cooperation and punishment based on the opponent's previous actions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros((self.game_description.n_rounds + 1,), dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.opponent_actions) > state.round_number + 1:
            self.opponent_history[state.round_number + 1] = history.opponent_actions[-1, :].sum() == self.game_description.n_players
        cooperators = self.opponent_history[state.round_number]
        if state.round_number < self.game_description.n_rounds:
            return Action(1 if cooperators else 0)
        return Action.C

class Strategy_EXPLOITATIVE_135(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Public Goods Game Optimization (ATFTPGO) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round = None
        self.last_cooperators = 0
        self.remaining_rounds = self.game_description.n_rounds - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.opponent_actions) == 0:
            self.last_round = None
            self.last_cooperators = 0
        else:
            self.last_round = state.round_number - 1
            self.last_cooperators = sum(history.opponent_actions[-1, :])
        if self.last_round == self.remaining_rounds - 4:
            self.remaining_rounds = self.game_description.n_rounds
            if self.last_cooperators < self.game_description.n_players // 2:
                return Action.D
        return Action.C if self.last_cooperators == self.game_description.n_players else Action.D

class Strategy_EXPLOITATIVE_136(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Cooperation (A-TFTGC) strategy for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.m = int(math.floor(game_description.n_players / 2))
        self.opponent_avg_cooperation = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and self.opponent_avg_cooperation is not None:
            self.m = int(math.floor(self.opponent_avg_cooperation * self.m))
        if history is not None and state.round_number < self.game_description.n_rounds - 1:
            opponent_cooperators = sum(history.opponent_actions[-self.m:, :].sum(axis=0))
            if opponent_cooperators >= self.game_description.n_players // 2:
                return Action.C
        return Action.D

    def update_opponent_avg_cooperation(self, history: PlayerHistory):
        cooperators = history.opponent_actions.sum(axis=0)
        total_rounds = len(history.my_actions)
        self.opponent_avg_cooperation = cooperators[1:] / total_rounds if total_rounds > 1 else None

class Strategy_EXPLOITATIVE_137(BaseStrategy):
    """
    An adaptive Tit-for-Tat strategy with Epsilon Greedy Exploration (Aggressive Version) for N-Player Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.epsilon = 0.3
        self.decay_rate = 0.025
        self.recent_opponent_action = Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        my_action = history.my_actions[-1]
        if my_action == Action.D and self.epsilon > 0.05:
            return Action.D
        explore = random.random() < self.epsilon
        cooperate = not explore or (my_action == Action.C and self.recent_opponent_action != Action.D)
        self.epsilon -= self.decay_rate
        if my_action == Action.C:
            self.recent_opponent_action = Action.C
        else:
            self.recent_opponent_action = Action.D
        return Action(int(cooperate)) if cooperate else Action.D

class Strategy_EXPLOITATIVE_138(BaseStrategy):
    """
    This strategy is a Tit-for-Tat Adaptive Contribution Strategy (TfT-ACS).
    It reciprocates cooperation and punishes non-cooperation, encouraging long-term cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_round_history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif self.last_round_history is None:
            self.last_round_history = history
            return Action.C
        else:
            cooperators = sum(self.last_round_history.opponent_actions[-1, :])
            self.last_round_history = history
            if state.round_number == self.game_description.n_rounds - 1:
                return Action.C
            elif cooperators >= self.game_description.n_players // 2:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_140(BaseStrategy):
    """
    A strategy for the N-Player Public Goods Game that exploits low collective effort by free-riding.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.average_contribution = 0.0
        self.rounds_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is not None and len(self.rounds_history) > self.game_description.n_rounds - 1:
            self.average_contribution = np.mean([h.my_actions[-1].sum() for h in self.rounds_history[-self.game_description.n_rounds:]])
        if self.average_contribution < self.game_description.n_players:
            return Action.C
        else:
            return Action.D
        if history is not None and state.round_number < len(self.rounds_history):
            self.rounds_history[state.round_number] = history
        elif state.round_number == len(self.rounds_history):
            self.rounds_history += [history]