"""
Generated LLM strategies for social dilemma games.

This file contains strategy classes generated by LLMs for game theory experiments.
Each strategy is a callable class that implements a specific approach to the game.

Generated with:
- Provider: Anthropic
- Model: claude-opus-4-5
- Game: CollectiveRiskDescription
"""

from emergent_llm.players import BaseStrategy
from emergent_llm.games import PublicGoodsDescription, CollectiveRiskDescription, CommonPoolDescription, CommonPoolState
from emergent_llm.common import Action, C, D, PlayerHistory, GameState
import numpy as np
from numpy.typing import NDArray
import math
import random



class Strategy_COLLECTIVE_1(BaseStrategy):
    """
    Adaptive Threshold Guardian: A collectively-minded strategy that assumes
    responsibility as one of m needed cooperators while adapting to observed
    cooperation levels in the group.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        prev_round_idx = history.round_number - 1
        prev_opponent_coop = np.sum(history.opponent_actions[prev_round_idx, :])
        prev_self_coop = 1 if history.my_actions[prev_round_idx] else 0
        prev_coop = int(prev_opponent_coop) + prev_self_coop
        if current_round == self.r - 1:
            avg_coop = self._calculate_average_cooperators(history)
            if avg_coop >= self.m - 0.5:
                return Action.C
            else:
                return Action.D
        if prev_coop >= self.m + 2:
            defect_prob = (prev_coop - self.m) / self.n
            if random.random() < defect_prob:
                return Action.D
            else:
                return Action.C
        elif prev_coop == self.m + 1:
            return Action.C
        elif prev_coop == self.m:
            return Action.C
        elif prev_coop == self.m - 1:
            return Action.C
        else:
            trend = self._calculate_trend(history, window=3)
            if trend >= 0:
                return Action.C
            elif prev_coop < self.m / 2:
                return Action.D
            else:
                return Action.C

    def _calculate_average_cooperators(self, history: PlayerHistory) -> float:
        """Calculate average total cooperators over all previous rounds."""
        total_coop = 0.0
        n_rounds = history.round_number
        for r in range(n_rounds):
            opponent_coop = np.sum(history.opponent_actions[r, :])
            self_coop = 1 if history.my_actions[r] else 0
            total_coop += opponent_coop + self_coop
        return total_coop / n_rounds if n_rounds > 0 else 0.0

    def _calculate_trend(self, history: PlayerHistory, window: int=3) -> float:
        """
        Calculate cooperation trend over the last `window` rounds.
        Returns positive if increasing, negative if decreasing, zero if stable.
        """
        n_rounds = history.round_number
        if n_rounds < 2:
            return 0.0
        actual_window = min(window, n_rounds)
        coop_counts = []
        for r in range(n_rounds - actual_window, n_rounds):
            opponent_coop = np.sum(history.opponent_actions[r, :])
            self_coop = 1 if history.my_actions[r] else 0
            coop_counts.append(opponent_coop + self_coop)
        if len(coop_counts) < 2:
            return 0.0
        if len(coop_counts) == 2:
            return coop_counts[1] - coop_counts[0]
        else:
            n = len(coop_counts)
            x_mean = (n - 1) / 2.0
            y_mean = sum(coop_counts) / n
            numerator = sum(((i - x_mean) * (coop_counts[i] - y_mean) for i in range(n)))
            denominator = sum(((i - x_mean) ** 2 for i in range(n)))
            if denominator == 0:
                return 0.0
            return numerator / denominator

class Strategy_COLLECTIVE_2(BaseStrategy):
    """
    Adaptive Threshold Guardian: A probabilistic cooperation strategy that aims
    to achieve exactly m cooperators by adaptively adjusting cooperation probability
    based on observed history, gaps from threshold, trends, and pivotal situations.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p_previous = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        if history is None:
            k_adjustment = min(0.15, math.log(max(k, 1.01)) / 10)
            if k <= 1.1:
                k_adjustment = -0.1
            p = m / n + 0.1 + k_adjustment
            p = max(0.1, min(0.95, p))
            self.p_previous = p
            return Action.C if random.random() < p else Action.D
        current_round = history.round_number
        my_last_action = history.my_actions[-1]
        opponent_cooperators_last = np.sum(history.opponent_actions[-1, :])
        c_last = int(opponent_cooperators_last) + (1 if my_last_action else 0)
        gap = m - c_last
        if self.p_previous is None:
            self.p_previous = m / n + 0.1
        if gap > 0:
            p_base = min(1.0, self.p_previous + gap / n * 0.5)
        elif gap == 0:
            p_base = self.p_previous
        else:
            p_base = max(0.1, self.p_previous + gap / n * 0.3)
        p_adjusted = p_base
        if current_round >= 3:
            c_t = c_last
            my_action_t_minus_2 = history.my_actions[-3]
            opponent_coop_t_minus_2 = np.sum(history.opponent_actions[-3, :])
            c_t_minus_2 = int(opponent_coop_t_minus_2) + (1 if my_action_t_minus_2 else 0)
            trend = (c_t - c_t_minus_2) / 2
            if trend < -0.5:
                p_adjusted = p_base + 0.15
            elif trend > 0.5:
                p_adjusted = p_base - 0.05
        i_cooperated_last = my_last_action
        if i_cooperated_last and c_last == m:
            p_adjusted += 0.1
        if not i_cooperated_last and c_last == m - 1:
            p_adjusted += 0.2
        if current_round >= 3:
            consecutive_failures = 0
            for i in range(1, min(current_round + 1, 4)):
                my_act = history.my_actions[-i]
                opp_coop = np.sum(history.opponent_actions[-i, :])
                total_coop = int(opp_coop) + (1 if my_act else 0)
                if total_coop < m:
                    consecutive_failures += 1
                else:
                    break
            if consecutive_failures >= 3:
                p_adjusted += 0.15 * (consecutive_failures - 2)
        is_final_round = current_round + 1 == r
        if is_final_round:
            total_cooperators = 0
            for i in range(current_round):
                my_act = history.my_actions[i]
                opp_coop = np.sum(history.opponent_actions[i, :])
                total_cooperators += int(opp_coop) + (1 if my_act else 0)
            avg_coop_rate = total_cooperators / (current_round * n) if current_round > 0 else m / n
            if avg_coop_rate >= m / n:
                p_final = max(p_adjusted, m / n)
            else:
                p_final = p_adjusted * 0.7
            p_adjusted = p_final
        p = max(0.1, min(0.95, p_adjusted))
        self.p_previous = p
        return Action.C if random.random() < p else Action.D

class Strategy_COLLECTIVE_3(BaseStrategy):
    """
    Adaptive Threshold Guardian: A collectively-minded strategy that cooperates
    with probability based on the group's need, adjusting based on observed behavior
    to maintain threshold cooperation while avoiding exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.base_prob = self.m / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.n
        r = self.r
        m = self.m
        base_prob = self.base_prob
        if history is None:
            if m >= n - 1:
                coop_prob = 0.9
            else:
                coop_prob = max(base_prob, 0.6)
            if random.random() < coop_prob:
                return Action.C
            else:
                return Action.D
        current_round = state.round_number
        rounds_played = history.round_number
        my_last_action = 1 if history.my_actions[-1] else 0
        opponent_cooperators_last = np.sum(history.opponent_actions[-1, :])
        last_cooperators = my_last_action + opponent_cooperators_last
        gap = m - last_cooperators
        if gap > 0:
            adjustment = 0.15 * (gap / m)
        elif gap < 0:
            denominator = n - m if n - m > 0 else 1
            adjustment = -0.1 * (abs(gap) / denominator)
        else:
            adjustment = 0
        rounds_threshold_met = 0
        for r_idx in range(rounds_played):
            my_action_r = 1 if history.my_actions[r_idx] else 0
            opponent_coop_r = np.sum(history.opponent_actions[r_idx, :])
            total_coop_r = my_action_r + opponent_coop_r
            if total_coop_r >= m:
                rounds_threshold_met += 1
        trust = rounds_threshold_met / rounds_played if rounds_played > 0 else 0.5
        trust_modifier = 0.1 * (trust - 0.5)
        coop_prob = base_prob + adjustment + trust_modifier
        coop_prob = max(0.3, min(0.95, coop_prob))
        if m >= n - 1:
            coop_prob = max(coop_prob, 0.9)
        if current_round == r - 1:
            coop_prob *= 0.85
            coop_prob = max(0.3, min(0.95, coop_prob))
        if random.random() < coop_prob:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_4(BaseStrategy):
    """
    Adaptive Threshold Guardian: A strategy that aims to be one of exactly m cooperators
    when possible, maximizing group welfare while being responsive to actual behavior patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.n
        m = self.m
        r = self.r
        k = self.k

        def cooperate_with_probability(p):
            p = max(0.0, min(1.0, p))
            return Action.C if random.random() < p else Action.D
        if n == m:
            return Action.C
        if history is None:
            base_prob = m / n
            if k > n:
                base_prob = min(base_prob * min(k / n, 2), 1.0)
            return cooperate_with_probability(base_prob)
        current_round = state.round_number
        prev_round_idx = current_round - 1
        my_prev_action_bool = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        prev_cooperators = int(my_prev_action_bool) + int(np.sum(opponent_prev_actions))
        my_prev_action = Action.C if my_prev_action_bool else Action.D
        if m == 1:
            if current_round == 1:
                if prev_cooperators >= 1 and (not my_prev_action_bool):
                    return Action.D
                elif prev_cooperators >= 1:
                    other_cooperators = prev_cooperators - (1 if my_prev_action_bool else 0)
                    if other_cooperators >= 1:
                        return Action.D
                    else:
                        return Action.C
            else:
                other_cooperators = prev_cooperators - (1 if my_prev_action_bool else 0)
                if other_cooperators >= 1:
                    return Action.D
                else:
                    return Action.C
        if current_round == r - 1:
            recent_rounds = min(3, current_round)
            total_cooperators = 0
            for rd in range(current_round - recent_rounds, current_round):
                my_action_rd = history.my_actions[rd]
                opp_actions_rd = history.opponent_actions[rd, :]
                total_cooperators += int(my_action_rd) + int(np.sum(opp_actions_rd))
            avg_cooperators = total_cooperators / recent_rounds
            if avg_cooperators >= m - 1:
                if my_prev_action == Action.C:
                    return Action.C
                elif avg_cooperators < m:
                    prob = m - avg_cooperators
                    return cooperate_with_probability(prob)
                else:
                    return Action.D
            else:
                return Action.D
        if prev_cooperators == m:
            return my_prev_action
        elif prev_cooperators > m:
            if my_prev_action == Action.C:
                excess = prev_cooperators - m
                p_defect = excess / prev_cooperators
                if random.random() < p_defect:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.D
        elif prev_cooperators > 0:
            if my_prev_action == Action.C:
                return Action.C
            else:
                shortfall = m - prev_cooperators
                non_cooperators = n - prev_cooperators
                if non_cooperators > 0:
                    p_coop = shortfall / non_cooperators
                    return cooperate_with_probability(p_coop)
                else:
                    return Action.C
        else:
            base_prob = m / n
            if k > n:
                base_prob = min(base_prob * min(k / n, 2), 1.0)
            return cooperate_with_probability(base_prob)

class Strategy_COLLECTIVE_5(BaseStrategy):
    """
    Adaptive Threshold Guardian: A collectively-minded strategy for the Collective Risk Dilemma.
    
    Aims to be one of the m cooperators needed, adapts based on history, and avoids exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def _cooperate_with_prob(self, prob: float) -> Action:
        """Return Action.C with given probability, else Action.D"""
        if random.random() < prob:
            return Action.C
        return Action.D

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in a given round"""
        my_coop = 1 if history.my_actions[round_idx] else 0
        others_coop = int(np.sum(history.opponent_actions[round_idx, :]))
        return my_coop + others_coop

    def _count_successes(self, history: PlayerHistory) -> int:
        """Count rounds where threshold was met"""
        successes = 0
        for r in range(len(history.my_actions)):
            if self._count_cooperators_in_round(history, r) >= self.m:
                successes += 1
        return successes

    def _total_cooperations(self, history: PlayerHistory) -> int:
        """Count total cooperations by all players across all rounds"""
        my_coops = int(np.sum(history.my_actions))
        others_coops = int(np.sum(history.opponent_actions))
        return my_coops + others_coops

    def _my_cooperations(self, history: PlayerHistory) -> int:
        """Count my cooperations"""
        return int(np.sum(history.my_actions))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None or len(history.my_actions) == 0:
            return self._cooperate_with_prob(self.m / self.n)
        rounds_played = len(history.my_actions)
        success_rate = self._count_successes(history) / rounds_played
        total_actions = self.n * rounds_played
        coop_rate = self._total_cooperations(history) / total_actions
        my_coop_rate = self._my_cooperations(history) / rounds_played
        last_round_idx = rounds_played - 1
        last_round_coops = self._count_cooperators_in_round(history, last_round_idx)
        my_last_action = 1 if history.my_actions[last_round_idx] else 0
        others_last = last_round_coops - my_last_action
        if current_round == self.r - 1:
            if success_rate >= 0.7:
                return self._cooperate_with_prob(min(0.9, (self.m + 1) / self.n))
            elif success_rate < 0.4:
                return Action.D
            else:
                return self._cooperate_with_prob(self.m / self.n)
        if last_round_coops < self.m:
            return self._cooperate_with_prob(min(0.9, self.m / self.n + 0.2))
        if others_last < self.m:
            return self._cooperate_with_prob(0.8)
        if my_coop_rate > coop_rate + 0.15:
            return self._cooperate_with_prob(0.3)
        if success_rate < 0.4 and rounds_played > 2:
            return self._cooperate_with_prob(0.85)
        if success_rate > 0.8:
            lower_bound = self.m / self.n - 0.1
            upper_bound = self.m / self.n + 0.2
            if lower_bound <= coop_rate <= upper_bound:
                return self._cooperate_with_prob(my_coop_rate)
        return self._cooperate_with_prob(self.m / self.n)

class Strategy_COLLECTIVE_6(BaseStrategy):
    """
    Threshold Guardian Strategy for Collective Risk Dilemma.
    
    Acts as a reliable cooperator who helps meet the collective threshold,
    but adaptively reduces cooperation when the group consistently fails
    to coordinate or when free-riding becomes exploitative.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        others_C_last = self._count_others_cooperated_last(history)
        my_last_action = history.my_actions[-1]
        threshold_met_last = self._was_threshold_met_last(history)
        HSR = self._historical_success_rate(history)
        if self.n == 2 and self.m == 2:
            if not history.opponent_actions[-1, 0]:
                return Action.D
            return Action.C
        if not my_last_action and others_C_last >= self.m - 1:
            return Action.C
        if round_num == self.r - 1:
            return self._final_round_decision(history, HSR, others_C_last)
        if threshold_met_last:
            return Action.C
        elif others_C_last >= self.m - 1:
            return Action.C
        elif HSR > 0.5:
            return Action.C
        elif HSR > 0.3 and others_C_last >= (self.m - 1) / 2:
            return Action.C
        else:
            return Action.D

    def _count_others_cooperated_last(self, history: PlayerHistory) -> int:
        """Count how many other players cooperated in the last round."""
        return int(np.sum(history.opponent_actions[-1, :]))

    def _was_threshold_met_last(self, history: PlayerHistory) -> bool:
        """Check if threshold was met in the last round."""
        others_C = int(np.sum(history.opponent_actions[-1, :]))
        my_C = 1 if history.my_actions[-1] else 0
        total_C = others_C + my_C
        return total_C >= self.m

    def _historical_success_rate(self, history: PlayerHistory) -> float:
        """Calculate proportion of past rounds where threshold was met."""
        n_rounds = len(history.my_actions)
        if n_rounds == 0:
            return 0.0
        successes = 0
        for r in range(n_rounds):
            others_C = int(np.sum(history.opponent_actions[r, :]))
            my_C = 1 if history.my_actions[r] else 0
            total_C = others_C + my_C
            if total_C >= self.m:
                successes += 1
        return successes / n_rounds

    def _expected_others_cooperation(self, history: PlayerHistory) -> float:
        """Calculate expected cooperation from others based on recent rounds."""
        n_rounds = len(history.my_actions)
        lookback = min(3, n_rounds)
        if lookback == 0:
            return 0.0
        total = 0.0
        for r in range(n_rounds - lookback, n_rounds):
            total += np.sum(history.opponent_actions[r, :])
        return total / lookback

    def _final_round_decision(self, history: PlayerHistory, HSR: float, others_C_last: int) -> Action:
        """Make decision for the final round."""
        expected_others_C = self._expected_others_cooperation(history)
        if HSR >= 0.6:
            if expected_others_C >= self.m:
                if random.random() < 0.7:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        elif HSR >= 0.4:
            if expected_others_C >= self.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_7(BaseStrategy):
    """
    Adaptive Threshold Guardian: A collectively-minded strategy that defaults to cooperation
    and adapts based on observed cooperation levels to help ensure the group reaches threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if self.n == self.m:
            return Action.C
        buffer = math.ceil(self.n / 4)
        buffer = min(buffer, self.n - self.m - 1) if self.n - self.m > 1 else 1
        my_last_action = 1 if history.my_actions[-1] else 0
        opponent_cooperators_last = int(np.sum(history.opponent_actions[-1, :]))
        prev_cooperators = my_last_action + opponent_cooperators_last
        total_rounds_completed = len(history.my_actions)
        total_my_cooperations = int(np.sum(history.my_actions))
        total_opponent_cooperations = int(np.sum(history.opponent_actions))
        total_cooperations = total_my_cooperations + total_opponent_cooperations
        total_possible = self.n * total_rounds_completed
        cumulative_rate = total_cooperations / total_possible if total_possible > 0 else 0
        if current_round == self.r - 1:
            if cumulative_rate >= self.m / self.n:
                prob = max(self.m / self.n, 0.5)
                return Action.C if random.random() < prob else Action.D
            elif prev_cooperators >= self.m:
                prob = max(self.m / self.n, 0.5)
                return Action.C if random.random() < prob else Action.D
            else:
                return Action.C if random.random() < 0.4 else Action.D
        if prev_cooperators < self.m:
            return Action.C
        elif prev_cooperators == self.m:
            return Action.C
        elif prev_cooperators <= self.m + buffer:
            prob = (self.m + buffer - prev_cooperators + 1) / (buffer + 1)
            return Action.C if random.random() < prob else Action.D
        else:
            return Action.C if random.random() < 0.3 else Action.D

class Strategy_COLLECTIVE_8(BaseStrategy):
    """
    Adaptive Threshold Guardian: A strategy that aims to be one of the m cooperators
    needed, but not redundant beyond that threshold. Balances reliability with efficiency.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None or current_round == 0:
            p = self.m / self.n
            if self.m >= self.n - 1:
                p = min(1, p + 0.2)
            return Action.C if random.random() < p else Action.D
        prev_my_action = 1 if history.my_actions[-1] else 0
        prev_opponent_coop = int(np.sum(history.opponent_actions[-1, :]))
        prev_coop = prev_my_action + prev_opponent_coop
        if current_round == self.r - 1:
            successful_rounds = 0
            for t in range(len(history.my_actions)):
                my_action_t = 1 if history.my_actions[t] else 0
                opp_coop_t = int(np.sum(history.opponent_actions[t, :]))
                total_coop_t = my_action_t + opp_coop_t
                if total_coop_t >= self.m:
                    successful_rounds += 1
            success_rate = successful_rounds / len(history.my_actions) if len(history.my_actions) > 0 else 0
            if success_rate >= 0.7:
                p = self.m / self.n
                return Action.C if random.random() < p else Action.D
            else:
                return Action.D
        if prev_coop < self.m:
            denominator = self.n - prev_coop
            if denominator <= 0:
                p = 1.0
            else:
                p = min(1, (self.m - prev_coop + 1) / denominator)
        elif prev_coop == self.m:
            return Action.C if history.my_actions[-1] else Action.D
        else:
            p = self.m / prev_coop
        if len(history.my_actions) >= 3:
            coop_counts = []
            for t in range(-3, 0):
                my_act = 1 if history.my_actions[t] else 0
                opp_coop = int(np.sum(history.opponent_actions[t, :]))
                coop_counts.append(my_act + opp_coop)
            if coop_counts[0] > coop_counts[1] > coop_counts[2]:
                p = min(1, p + 0.15)
        if prev_coop == 0:
            p = min(1, (self.m + 1) / self.n)
        if prev_coop == self.n:
            p = self.m / self.n
        if self.m >= self.n - 1:
            p = min(1, p + 0.2)
        return Action.C if random.random() < p else Action.D

class Strategy_COLLECTIVE_9(BaseStrategy):
    """
    Adaptive Threshold Guardian: A conditional cooperator with a cooperative bias.
    Cooperates by default and only defects when evidence strongly suggests 
    the threshold cannot be met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.consecutive_low_cooperation = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        rounds_played = history.round_number
        current_round = state.round_number
        my_last_action = 1 if history.my_actions[-1] else 0
        opponent_cooperators_last = np.sum(history.opponent_actions[-1, :])
        recent_cooperators = my_last_action + opponent_cooperators_last
        threshold_met_count = 0
        for r_idx in range(rounds_played):
            my_coop = 1 if history.my_actions[r_idx] else 0
            opp_coop = np.sum(history.opponent_actions[r_idx, :])
            total_coop = my_coop + opp_coop
            if total_coop >= self.m:
                threshold_met_count += 1
        threshold_met_rate = threshold_met_count / rounds_played
        total_cooperations = np.sum(history.my_actions) + np.sum(history.opponent_actions)
        cooperation_rate = total_cooperations / (self.n * rounds_played)
        if recent_cooperators < self.m / 2:
            self.consecutive_low_cooperation += 1
        else:
            self.consecutive_low_cooperation = 0
        if self.consecutive_low_cooperation >= 3:
            if self.consecutive_low_cooperation == 3:
                return Action.C
            return Action.D
        if self.n == 2 and self.m == 2:
            if rounds_played >= 2:
                partner_defected_count = 0
                for r_idx in range(max(0, rounds_played - 2), rounds_played):
                    if not history.opponent_actions[r_idx, 0]:
                        partner_defected_count += 1
                if partner_defected_count >= 2:
                    return Action.D
            return Action.C
        if self.m <= self.n / 3:
            met_without_me = 0
            defect_rounds = 0
            for r_idx in range(rounds_played):
                if not history.my_actions[r_idx]:
                    defect_rounds += 1
                    opp_coop = np.sum(history.opponent_actions[r_idx, :])
                    if opp_coop >= self.m:
                        met_without_me += 1
            if defect_rounds >= 2 and met_without_me == defect_rounds:
                return Action.D
        is_last_round = current_round == self.r - 1
        if is_last_round:
            if recent_cooperators >= self.m:
                return Action.C
            if recent_cooperators == self.m - 1:
                return Action.C
            if threshold_met_rate >= 0.6 and cooperation_rate >= self.m / self.n:
                return Action.C
            return Action.D
        if recent_cooperators == self.m - 1:
            return Action.C
        if recent_cooperators >= self.m:
            return Action.C
        if threshold_met_rate >= 0.5:
            return Action.C
        if cooperation_rate >= (self.m - 1) / self.n:
            return Action.C
        if self.m >= self.n - 1:
            return Action.C
        if self.k > 2 and cooperation_rate >= (self.m - 2) / self.n:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_10(BaseStrategy):
    """
    Adaptive Threshold Guardian: A collective-minded strategy for the Collective Risk Dilemma.
    
    Aims to be one of exactly m cooperators needed, distributing cooperation burden fairly
    over time while maintaining threshold safety.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.solo_cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        rounds_played = history.round_number
        my_last_action = history.my_actions[-1]
        opponent_coop_last = int(np.sum(history.opponent_actions[-1, :]))
        last_round_coop_count = opponent_coop_last + (1 if my_last_action else 0)
        my_coop_count = int(np.sum(history.my_actions))
        my_rate = my_coop_count / rounds_played
        fair_rate = self.m / self.n
        total_opponent_coops = int(np.sum(history.opponent_actions))
        group_coop_rate = total_opponent_coops / ((self.n - 1) * rounds_played)
        if my_last_action and opponent_coop_last == 0:
            self.solo_cooperation_count += 1
        else:
            self.solo_cooperation_count = 0
        if self.solo_cooperation_count >= 3:
            if random.random() < group_coop_rate:
                return Action.C
            return Action.D
        danger_threshold = self.m / self.n - 0.1
        if group_coop_rate < danger_threshold:
            return Action.C
        if last_round_coop_count < self.m:
            return Action.C
        if last_round_coop_count == self.m:
            if my_last_action:
                return Action.C
            else:
                if state.round_number == self.r - 1:
                    return Action.C
                return Action.D
        my_debt = fair_rate - my_rate
        if my_debt > 0.05:
            return Action.C
        if last_round_coop_count >= self.n - 1:
            return Action.D
        if self.m >= self.n - 1:
            if random.random() < 0.7:
                return Action.C
            return Action.D
        excess_ratio = (last_round_coop_count - self.m) / max(1, self.n - self.m)
        if state.round_number == self.r - 1:
            excess_ratio *= 0.7
        if random.random() < excess_ratio:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_11(BaseStrategy):
    """
    Adaptive Threshold Guardian: Aims to be one of the m cooperators needed,
    but not a surplus cooperator. Dynamically estimates cooperation levels
    and fills gaps to reach the threshold while avoiding exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number

        def cooperate_with_prob(p):
            return Action.C if random.random() < p else Action.D
        if history is None:
            p = min(1.0, self.m / self.n + 0.1)
            return cooperate_with_prob(p)
        rounds_played = history.round_number
        total_opponent_cooperations = np.sum(history.opponent_actions)
        total_opponent_opportunities = rounds_played * (self.n - 1)
        if total_opponent_opportunities > 0:
            coop_rate = total_opponent_cooperations / total_opponent_opportunities
        else:
            coop_rate = self.m / self.n
        expected_others_cooperating = coop_rate * (self.n - 1)
        gap = self.m - expected_others_cooperating
        fair_share = rounds_played * self.m / self.n
        my_cooperations = np.sum(history.my_actions)
        debt = fair_share - my_cooperations
        last_round_cooperators = np.sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
        threshold_met_last = last_round_cooperators >= self.m
        boost = 0.3 if not threshold_met_last else 0.0
        reduce = 0.0
        if rounds_played >= 3:
            all_surplus = True
            for i in range(max(0, rounds_played - 3), rounds_played):
                round_coops = np.sum(history.opponent_actions[i, :]) + (1 if history.my_actions[i] else 0)
                if round_coops <= self.m:
                    all_surplus = False
                    break
            if all_surplus:
                reduce = 0.1
        rounds_remaining = self.r - current_round
        if self.m >= self.n - 1:
            return Action.C
        if np.sum(history.opponent_actions[-1, :]) == 0:
            return cooperate_with_prob(0.4)
        if np.sum(history.opponent_actions[-1, :]) == self.n - 1:
            return Action.D
        k_boost = 0.2 if self.k > 3 else 0.0
        if self.r <= 3:
            boost += 0.15
        if current_round == self.r - 1:
            if expected_others_cooperating >= self.m:
                return Action.D
            elif expected_others_cooperating >= self.m - 1:
                return cooperate_with_prob(0.7 + k_boost)
            elif expected_others_cooperating >= self.m - 2 and debt > 0:
                return Action.C
            else:
                return Action.D

        def clamp(x, low, high):
            return max(low, min(high, x))
        if gap >= 1:
            return Action.C
        elif gap > 0:
            p = gap + 0.2 * max(0, debt) + boost - reduce + k_boost
            return cooperate_with_prob(clamp(p, 0, 1))
        elif debt > 0.5:
            if rounds_remaining > 0:
                p = min(0.3, debt / rounds_remaining) + boost - reduce + k_boost
            else:
                p = 0.3 + boost - reduce + k_boost
            return cooperate_with_prob(clamp(p, 0, 1))
        else:
            return Action.D

class Strategy_COLLECTIVE_12(BaseStrategy):
    """
    Adaptive Threshold Guardian: A collectively-minded strategy that adapts
    cooperation probability based on observed cooperation rates and game phase.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.n
        m = self.m
        r = self.r
        k = self.k

        def clamp(value, min_val, max_val):
            return max(min_val, min(max_val, value))

        def cooperate_with_probability(prob):
            return Action.C if random.random() < prob else Action.D
        if history is None:
            base_prob = m / n
            if n <= 3:
                base_prob += 0.15
            if m > n / 2:
                base_prob += (m / n - 0.5) * 0.3
            if k > 2:
                base_prob += min(0.2, (k - 2) * 0.1)
            base_prob = clamp(base_prob, 0.15, 0.95)
            return cooperate_with_probability(base_prob)
        total_rounds_played = history.round_number
        total_opponent_cooperations = np.sum(history.opponent_actions)
        total_opponent_actions = (n - 1) * total_rounds_played
        if total_opponent_actions > 0:
            obs_coop_rate = total_opponent_cooperations / total_opponent_actions
        else:
            obs_coop_rate = m / n
        current_round = state.round_number
        if current_round == r - 1:
            if obs_coop_rate >= m / n:
                prob = 0.7
            elif obs_coop_rate >= (m - 1) / n:
                prob = 0.8
            else:
                prob = 0.3
            if n <= 3:
                prob += 0.15
            if k > 2:
                prob += min(0.2, (k - 2) * 0.1)
            prob = clamp(prob, 0.15, 0.95)
            return cooperate_with_probability(prob)
        expected_others_cooperating = obs_coop_rate * (n - 1)
        cooperation_gap = m - expected_others_cooperating
        if cooperation_gap <= 0:
            base_prob = 0.3
        else:
            base_prob = min(1.0, cooperation_gap)
        if obs_coop_rate > m / n:
            reciprocity_bonus = 0.2
        else:
            reciprocity_bonus = -0.1
        consistency_bonus = 0.0
        if total_rounds_played > 0:
            i_cooperated_last = history.my_actions[-1]
            others_cooperated_last = np.sum(history.opponent_actions[-1])
            my_coop_last = 1 if i_cooperated_last else 0
            total_cooperators_last = others_cooperated_last + my_coop_last
            threshold_met_last = total_cooperators_last >= m
            if i_cooperated_last and threshold_met_last:
                consistency_bonus = 0.1
        final_prob = clamp(base_prob + reciprocity_bonus + consistency_bonus, 0.2, 0.95)
        if n <= 3:
            final_prob += 0.15
        if m > n / 2:
            final_prob += (m / n - 0.5) * 0.3
        if k > 2:
            final_prob += min(0.2, (k - 2) * 0.1)
        if obs_coop_rate > 0.8:
            final_prob = max(final_prob, 0.85)
        if obs_coop_rate < 0.2:
            final_prob = max(final_prob, 0.25)
        final_prob = clamp(final_prob, 0.15, 0.95)
        return cooperate_with_probability(final_prob)

class Strategy_COLLECTIVE_13(BaseStrategy):
    """
    Adaptive Threshold Guardian strategy for Collective Risk Dilemma.
    
    Aims to be one of the m cooperators needed to secure the collective reward,
    but not a redundant cooperator being exploited by free-riders. Adapts based
    on observed cooperation levels and trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None or current_round == 0:
            prob = self.m / self.n
            return Action.C if random.random() < prob else Action.D
        last_round_idx = current_round - 1
        my_prev_action = history.my_actions[last_round_idx]
        others_coop_last = int(np.sum(history.opponent_actions[last_round_idx, :]))
        my_contribution = 1 if my_prev_action else 0
        prev_cooperators = others_coop_last + my_contribution
        others_cooperating = others_coop_last
        trend = self._calculate_trend(history, current_round)
        base_prob = self._calculate_base_probability(others_cooperating)
        adjusted_prob = base_prob + self._trend_adjustment(trend)
        adjusted_prob = self._apply_parameter_adjustments(adjusted_prob, current_round)
        if current_round == self.r - 1:
            adjusted_prob = self._final_round_adjustment(adjusted_prob, others_cooperating)
        adjusted_prob = max(0.1, min(0.95, adjusted_prob))
        return Action.C if random.random() < adjusted_prob else Action.D

    def _calculate_base_probability(self, others_cooperating: int) -> float:
        """Calculate base cooperation probability based on others' cooperation."""
        if others_cooperating >= self.m:
            return 0.2
        elif others_cooperating == self.m - 1:
            return 0.9
        else:
            gap = self.m - 1 - others_cooperating
            if gap == 1:
                return 0.7
            elif gap == 2:
                return 0.5
            else:
                return 0.3

    def _calculate_trend(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate cooperation trend over last 3 rounds."""
        rounds_to_check = min(3, current_round)
        if rounds_to_check < 2:
            return 0.0
        coop_counts = []
        for i in range(rounds_to_check):
            round_idx = current_round - 1 - i
            others_coop = int(np.sum(history.opponent_actions[round_idx, :]))
            my_coop = 1 if history.my_actions[round_idx] else 0
            coop_counts.append(others_coop + my_coop)
        if len(coop_counts) >= 2:
            recent_avg = coop_counts[0]
            older_avg = np.mean(coop_counts[1:])
            return (recent_avg - older_avg) / max(1, self.n)
        return 0.0

    def _trend_adjustment(self, trend: float) -> float:
        """Adjust probability based on cooperation trend."""
        if trend > 0.05:
            return 0.1
        elif trend < -0.05:
            return -0.1
        return 0.0

    def _apply_parameter_adjustments(self, prob: float, current_round: int) -> float:
        """Apply adjustments based on game parameters."""
        adjusted = prob
        if self.m >= self.n - 1:
            adjusted += 0.15
        if self.m <= self.n * 0.3:
            adjusted -= 0.1
        if self.k > 3:
            adjusted += 0.1
        if self.r > 20 and current_round < self.r * 0.2:
            adjusted += 0.1
        return adjusted

    def _final_round_adjustment(self, prob: float, others_cooperating: int) -> float:
        """Adjust probability for the final round."""
        if others_cooperating >= self.m:
            return 0.0
        elif others_cooperating == self.m - 1:
            return 0.85
        else:
            gap = self.m - others_cooperating
            return min(0.5, gap / self.n)

class Strategy_COLLECTIVE_14(BaseStrategy):
    """
    Adaptive Threshold Guardian: Aims to be one of exactly m cooperators needed,
    using history to estimate cooperation rates and fill gaps as needed.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.n
        m = self.m
        k = self.k
        r = self.r

        def cooperate_with_prob(prob: float) -> Action:
            prob = max(0.0, min(1.0, prob))
            return Action.C if random.random() < prob else Action.D
        if history is None:
            if m >= n - 1:
                return Action.C
            base_prob = m / n
            if r <= 3:
                base_prob += 0.2
            if k > 3:
                base_prob += 0.1
            return cooperate_with_prob(base_prob)
        current_round = state.round_number
        rounds_played = history.round_number
        my_coop_count = np.sum(history.my_actions)
        opponent_coop_count = np.sum(history.opponent_actions)
        total_actions = rounds_played * n
        total_coops = my_coop_count + opponent_coop_count
        coop_rate = total_coops / total_actions if total_actions > 0 else m / n
        expected_others = coop_rate * (n - 1)
        if expected_others >= m:
            base_prob = 0.2
        elif expected_others >= m - 1:
            base_prob = 0.8
        else:
            base_prob = 1.0

        def threshold_met_in_round(round_idx: int) -> bool:
            my_coop = 1 if history.my_actions[round_idx] else 0
            other_coops = np.sum(history.opponent_actions[round_idx, :])
            total_coops = my_coop + other_coops
            return total_coops >= m
        recent_failures = 0
        if rounds_played >= 1 and (not threshold_met_in_round(rounds_played - 1)):
            recent_failures += 1
        if rounds_played >= 2 and (not threshold_met_in_round(rounds_played - 2)):
            recent_failures += 1
        if recent_failures >= 2:
            base_prob = 1.0
        elif recent_failures == 1:
            base_prob += 0.3
        if rounds_played >= 1:
            last_round_coops = (1 if history.my_actions[-1] else 0) + np.sum(history.opponent_actions[-1, :])
            if last_round_coops == 0:
                base_prob = 1.0
            elif last_round_coops == n:
                base_prob = m / n
        if rounds_played >= 3:
            last_3_met = all((threshold_met_in_round(rounds_played - 1 - i) for i in range(3)))
            if last_3_met:
                total_coops_last_3 = 0
                for i in range(3):
                    round_idx = rounds_played - 1 - i
                    my_coop = 1 if history.my_actions[round_idx] else 0
                    other_coops = np.sum(history.opponent_actions[round_idx, :])
                    total_coops_last_3 += my_coop + other_coops
                avg_coops = total_coops_last_3 / 3
                if avg_coops > m + 1:
                    base_prob -= 0.15
                    base_prob = max(base_prob, m / n)
        if m >= n - 1:
            base_prob = 1.0
        if k > 3:
            base_prob += 0.1
        if r <= 3:
            base_prob += 0.2
        if current_round == r - 1:
            my_coop_rate = np.mean(history.my_actions) if rounds_played > 0 else 0
            if my_coop_rate > m / n:
                base_prob = 0.5
            else:
                base_prob = 0.9
        base_prob = max(0.0, min(1.0, base_prob))
        return cooperate_with_prob(base_prob)

class Strategy_COLLECTIVE_15(BaseStrategy):
    """
    Adaptive Threshold Guardian: A collectively-minded strategy that acts as one of m guardians
    responsible for ensuring the threshold is met, while adapting to the behavior of others.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        if n == 2 and m == 2:
            return Action.C
        if m >= n - 1:
            if random.random() < 0.9:
                return Action.C
            return Action.D
        if history is None:
            if random.random() < m / n:
                return Action.C
            return Action.D
        current_round = state.round_number
        rounds_played = history.round_number
        my_coop_count = np.sum(history.my_actions)
        my_coop_rate = my_coop_count / rounds_played
        opponent_coop_counts = np.sum(history.opponent_actions, axis=0)
        opponent_coop_rates = opponent_coop_counts / rounds_played
        all_coop_rates = np.concatenate([[my_coop_rate], opponent_coop_rates])
        last_round_my_coop = history.my_actions[-1]
        last_round_opponent_coops = np.sum(history.opponent_actions[-1])
        last_round_total_coops = int(last_round_my_coop) + last_round_opponent_coops
        threshold_met_last_round = last_round_total_coops >= m
        if not threshold_met_last_round:
            self.consecutive_failures += 1
        else:
            self.consecutive_failures = 0
        if last_round_total_coops == 0:
            return Action.C
        if rounds_played >= 3:
            solo_cooperator_count = 0
            for rd in range(max(0, rounds_played - 3), rounds_played):
                my_coop = history.my_actions[rd]
                others_coop = np.sum(history.opponent_actions[rd])
                if my_coop and others_coop == 0:
                    solo_cooperator_count += 1
            if solo_cooperator_count >= 3:
                return Action.D
        my_rank = 1
        for i, rate in enumerate(opponent_coop_rates):
            if rate > my_coop_rate:
                my_rank += 1
            elif rate == my_coop_rate and i + 1 < 0:
                my_rank += 1
        if my_rank <= m:
            action = Action.C
        else:
            action = Action.D
        if current_round < r - 1:
            if not threshold_met_last_round:
                increase_prob = 0.3 * self.consecutive_failures
                if random.random() < increase_prob:
                    action = Action.C
            if threshold_met_last_round and last_round_total_coops > m + 2:
                avg_coop_rate = np.mean(all_coop_rates)
                if my_coop_rate > avg_coop_rate + 0.2:
                    if random.random() < 0.3:
                        action = Action.D
            if not history.my_actions[-1] and threshold_met_last_round:
                if random.random() < 0.2:
                    action = Action.C
            if k > n and action == Action.D:
                if random.random() < 0.2:
                    action = Action.C
        else:
            likely_cooperators = np.sum(all_coop_rates > 0.5)
            if likely_cooperators >= m:
                if my_rank <= m:
                    action = Action.C
                else:
                    action = Action.D
            elif likely_cooperators + 1 >= m and my_coop_rate > 0.3:
                action = Action.C
            elif likely_cooperators <= m / 2:
                action = Action.D
            else:
                pivot_prob = (m - likely_cooperators) / max(1, n - likely_cooperators)
                if random.random() < pivot_prob:
                    action = Action.C
                else:
                    action = Action.D
        return action

class Strategy_COLLECTIVE_16(BaseStrategy):
    """
    Adaptive Threshold Guardian: A strategy that aims to be part of the minimum
    viable coalition achieving the threshold, adapting based on observed behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        p_base = self.m / self.n
        if history is None or len(history.my_actions) == 0:
            p = p_base
            if self.m >= self.n - 1:
                p = min(0.85, p + 0.1)
            if self.k > 2:
                p += 0.1
            if self.r <= 3:
                p += 0.1
            p = max(0.1, min(0.9, p))
            return Action.C if random.random() < p else Action.D
        rounds_played = len(history.my_actions)
        cooperators_per_round = []
        for round_idx in range(rounds_played):
            my_coop = 1 if history.my_actions[round_idx] else 0
            opp_coops = np.sum(history.opponent_actions[round_idx, :])
            total_coop = my_coop + opp_coops
            cooperators_per_round.append(total_coop)
        avg_coop = np.mean(cooperators_per_round)
        deficit = self.m - avg_coop
        if current_round == self.r - 1:
            recent_rounds = min(3, rounds_played)
            recent_coop = cooperators_per_round[-recent_rounds:]
            recent_avg = np.mean(recent_coop)
            if recent_avg >= self.m - 0.5 and recent_avg < self.m + 0.5:
                return Action.C
            elif recent_avg >= self.m + 0.5:
                return Action.D
            else:
                return Action.C if random.random() < 0.3 else Action.D
        adjustment_factor = 1.5
        p = p_base + deficit / self.n * adjustment_factor
        if self.m >= self.n - 1:
            p += 0.1
        if self.k > 2:
            p += 0.1
        if self.r <= 3:
            p += 0.1
        if self.m <= self.n / 3:
            p = max(0.2, p - 0.05)
        p = max(0.1, min(0.9, p))
        return Action.C if random.random() < p else Action.D

class Strategy_COLLECTIVE_17(BaseStrategy):
    """
    Adaptive Threshold Guardian: A collectively-minded strategy for the Collective Risk Dilemma.
    
    Uses probabilistic commitment calibrated to achieve exactly m cooperators, with adaptive
    responsiveness based on observed cooperation levels in previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            prob = min(1.0, (self.m + 0.5) / self.n)
            if self.r <= 3:
                prob = min(1.0, prob * 1.2)
            if self.m >= self.n - 1:
                boost = 1 + (self.m - self.n / 2) / self.n
                prob = min(1.0, prob * boost)
            return Action.C if random.random() < prob else Action.D
        prev_round_idx = history.round_number - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_coops = np.sum(history.opponent_actions[prev_round_idx, :])
        my_coop = 1 if my_prev_action else 0
        prev_cooperators = int(opponent_coops) + my_coop
        threshold_met = prev_cooperators >= self.m
        if not threshold_met:
            self.consecutive_failures += 1
        else:
            self.consecutive_failures = 0
        if self.consecutive_failures >= 3:
            return Action.C if random.random() < 0.8 else Action.D
        if current_round == self.r - 1:
            if threshold_met:
                return Action.C if my_prev_action else Action.D
            else:
                defectors = self.n - prev_cooperators
                prob = min(1.0, self.m / max(1, defectors + 1))
                return Action.C if random.random() < prob else Action.D
        if threshold_met:
            if prev_cooperators == self.m:
                return Action.C if my_prev_action else Action.D
            elif my_prev_action:
                quit_prob = (prev_cooperators - self.m) / prev_cooperators
                return Action.D if random.random() < quit_prob else Action.C
            else:
                if self.m <= 2:
                    return Action.D
                return Action.D
        elif my_prev_action:
            return Action.C
        else:
            gap = self.m - prev_cooperators
            defectors = self.n - prev_cooperators
            prob = min(1.0, gap / max(1, defectors) + 0.2)
            if self.m >= self.n - 1:
                boost = 1 + (self.m - self.n / 2) / self.n
                prob = min(1.0, prob * boost)
            return Action.C if random.random() < prob else Action.D

class Strategy_COLLECTIVE_18(BaseStrategy):
    """
    Adaptive Threshold Guardian: A strategy that aims to be one of the m cooperators
    needed while distributing cooperation burden fairly based on reputation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None or current_round == 0:
            prob = self.m / self.n
            return Action.C if random.random() < prob else Action.D
        rounds_played = history.round_number
        my_coop_count = np.sum(history.my_actions)
        my_score = (my_coop_count + 1) / (rounds_played + 2)
        n_opponents = history.opponent_actions.shape[1]
        opponent_coop_counts = np.sum(history.opponent_actions, axis=0)
        opponent_scores = (opponent_coop_counts + 1) / (rounds_played + 2)
        all_scores = [my_score] + list(opponent_scores)
        indexed_scores = [(all_scores[i], i) for i in range(len(all_scores))]
        indexed_scores.sort(key=lambda x: (-x[0], x[1]))
        my_rank = 1
        for i, (score, idx) in enumerate(indexed_scores):
            if idx == 0:
                my_rank = i + 1
                break
        if my_rank <= self.m:
            if self.m > 0:
                base_prob = 0.7 + 0.2 * (self.m - my_rank) / self.m
            else:
                base_prob = 0.7
        elif self.n - self.m > 0:
            base_prob = 0.3 * (1 - (my_rank - self.m) / (self.n - self.m))
        else:
            base_prob = 0.3
        window = min(3, rounds_played)
        recent_successes = 0
        for t in range(rounds_played - window, rounds_played):
            my_action_t = history.my_actions[t]
            opponent_actions_t = history.opponent_actions[t, :]
            total_cooperators = int(my_action_t) + np.sum(opponent_actions_t)
            if total_cooperators >= self.m:
                recent_successes += 1
        recent_success_rate = recent_successes / window if window > 0 else 0.5
        if recent_success_rate < 0.5:
            prob = min(1.0, base_prob + 0.3)
        elif recent_success_rate == 1.0:
            prob = base_prob * 0.9
        else:
            prob = base_prob
        if current_round == self.r - 1:
            my_coop_rate = my_score
            if my_coop_rate > 0.5:
                prob = 0.85
            else:
                prob = self.m / self.n + 0.1
        if self.m >= self.n - 1:
            prob = max(prob, 0.8)
        if self.n <= 3:
            prob = max(prob, 0.7)
        if self.r <= 3:
            prob = max(prob, self.m / self.n + 0.15)
        consecutive_failures = 0
        for t in range(rounds_played - 1, -1, -1):
            my_action_t = history.my_actions[t]
            opponent_actions_t = history.opponent_actions[t, :]
            total_cooperators = int(my_action_t) + np.sum(opponent_actions_t)
            if total_cooperators < self.m:
                consecutive_failures += 1
            else:
                break
        if consecutive_failures >= 3:
            prob = 0.9
        prob = max(0.1, min(0.95, prob))
        return Action.C if random.random() < prob else Action.D

class Strategy_COLLECTIVE_19(BaseStrategy):
    """
    Adaptive Threshold Guardian: A strategy that aims to be one of exactly m cooperators
    using probabilistic cooperation that adapts based on observed group behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.n
        m = self.m
        r = self.r
        p_base = m / n
        if history is None:
            p = p_base
            return Action.C if random.random() < p else Action.D
        current_round = state.round_number
        cooperators_per_round = []
        for round_idx in range(len(history.my_actions)):
            my_coop = 1 if history.my_actions[round_idx] else 0
            opponent_coops = np.sum(history.opponent_actions[round_idx, :])
            total_coops = my_coop + opponent_coops
            cooperators_per_round.append(total_coops)
        C_prev = cooperators_per_round[-1] if cooperators_per_round else m
        C_avg = np.mean(cooperators_per_round) if cooperators_per_round else m
        gap = m - C_avg
        p = p_base + gap / n * 0.5
        if C_prev < m:
            p = p + 0.2
        if C_prev > m + 1:
            p = p - 0.1
        consecutive_met = 0
        for coops in reversed(cooperators_per_round):
            if coops >= m:
                consecutive_met += 1
            else:
                break
        if consecutive_met >= 3:
            recent_avg = np.mean(cooperators_per_round[-3:])
            if m <= recent_avg <= m + 1:
                p = p_base + gap / n * 0.3
        is_last_round = current_round == r - 1
        if is_last_round:
            if C_avg >= m * 0.6:
                p_final = min((m + 0.5) / n + 0.1, 0.85)
                p = p_final
            else:
                p = p_base
        if m >= n - 1:
            p = max(p, 0.7)
        if len(cooperators_per_round) > 0 and all((c < m for c in cooperators_per_round)):
            rounds_failed = len(cooperators_per_round)
            p = min(p + 0.05 * rounds_failed, 0.8)
        if len(cooperators_per_round) > 2 and all((c > m + 1 for c in cooperators_per_round)):
            p = max(p - 0.05, m / (n + 1))
        p = max(0.1, min(0.95, p))
        return Action.C if random.random() < p else Action.D

class Strategy_COLLECTIVE_20(BaseStrategy):
    """
    Threshold Guardian strategy for Collective Risk Dilemma.
    
    Embraces a collective mindset: cooperates optimistically at start,
    persists when close to threshold, and gradually withdraws if the group
    chronically fails to coordinate, while always leaving room for recovery.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        completed_rounds = history.round_number
        prev_my_action = history.my_actions[-1]
        prev_opponent_actions = history.opponent_actions[-1, :]
        prev_cooperators = int(prev_my_action) + int(np.sum(prev_opponent_actions))
        threshold_met = prev_cooperators >= self.m
        cooperation_deficit = max(0, self.m - prev_cooperators)
        consec_fail = 0
        for i in range(completed_rounds - 1, -1, -1):
            round_coop = int(history.my_actions[i]) + int(np.sum(history.opponent_actions[i, :]))
            if round_coop >= self.m:
                break
            consec_fail += 1
        successes = 0
        for i in range(completed_rounds):
            round_coop = int(history.my_actions[i]) + int(np.sum(history.opponent_actions[i, :]))
            if round_coop >= self.m:
                successes += 1
        success_rate = successes / completed_rounds if completed_rounds > 0 else 0.0
        if threshold_met:
            p = 0.85
        elif cooperation_deficit <= 2:
            p = 0.7 + 0.1 * (prev_cooperators / self.m) if self.m > 0 else 0.7
        else:
            p = max(0.25, 0.5 - 0.05 * consec_fail)
        if success_rate > 0.7:
            p += 0.1
        elif success_rate < 0.3 and completed_rounds > 3:
            p -= 0.1
        if prev_cooperators == self.m or prev_cooperators == self.m + 1:
            p += 0.15
        if self.m >= self.n - 1:
            p += 0.1
        if self.n == 2 and self.m == 2 and threshold_met:
            p = 0.9
        is_final_round = current_round == self.r - 1
        if is_final_round:
            if success_rate > 0.5:
                p *= 0.7
            elif threshold_met:
                p *= 0.6
            else:
                p *= 0.5
        p = max(0.15, min(0.95, p))
        if random.random() < p:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_21(BaseStrategy):
    """
    Adaptive Threshold Guardian: A probabilistic cooperation strategy that aims to be
    one of the m cooperators needed, adapting based on observed cooperation patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            p_initial = self.m / self.n
            if self.m >= self.n - 1:
                p_initial = min(1.0, p_initial + 0.15)
            if self.k > 2:
                p_initial = min(1.0, p_initial + 0.1)
            if random.random() < p_initial:
                return Action.C
            else:
                return Action.D
        current_round = state.round_number
        my_last_action = history.my_actions[-1]
        opponent_cooperators_last = np.sum(history.opponent_actions[-1, :])
        prev_cooperators = int(opponent_cooperators_last) + (1 if my_last_action else 0)
        my_cooperation_rate = np.mean(history.my_actions)
        threshold_met_rounds = 0
        for i in range(len(history.my_actions)):
            total_coop = int(np.sum(history.opponent_actions[i, :])) + (1 if history.my_actions[i] else 0)
            if total_coop >= self.m:
                threshold_met_rounds += 1
        consistency = threshold_met_rounds / len(history.my_actions)
        exploitation_count = 0
        for i in range(len(history.my_actions)):
            if history.my_actions[i]:
                others_coop = int(np.sum(history.opponent_actions[i, :]))
                if others_coop < self.m - 1:
                    exploitation_count += 1
        if current_round == self.r - 1:
            if consistency >= 0.7:
                p_final = max(self.m / self.n - 0.1, 0.2)
            else:
                p_final = 0.15
            if my_cooperation_rate > 0.6:
                p_final = min(p_final + 0.2, self.m / self.n)
            if random.random() < p_final:
                return Action.C
            else:
                return Action.D
        gap = self.m - prev_cooperators
        if gap > 0:
            p_base = min(1.0, self.m / self.n + gap / self.n * 0.5)
        elif gap < 0:
            p_base = max(0.1, self.m / self.n - abs(gap) / self.n * 0.3)
        else:
            p_base = self.m / self.n
        p_adjusted = p_base
        if len(history.my_actions) >= 3:
            recent_coop = []
            for i in range(-3, 0):
                total_coop = int(np.sum(history.opponent_actions[i, :])) + (1 if history.my_actions[i] else 0)
                recent_coop.append(total_coop)
            if recent_coop[-1] < recent_coop[-2] < recent_coop[-3]:
                p_adjusted = p_base + 0.15
            elif recent_coop[-1] > self.m and recent_coop[-2] > self.m:
                p_adjusted = p_base - 0.1
        if my_last_action and prev_cooperators >= self.m:
            p_adjusted = max(p_adjusted, 0.6)
        if prev_cooperators == 0:
            p_adjusted = 0.7
        elif prev_cooperators == self.n:
            p_adjusted = max(self.m / self.n - 0.1, 0.2)
        if exploitation_count >= 2 and my_cooperation_rate > 0.5:
            p_adjusted = min(p_adjusted, 0.3)
        if prev_cooperators == self.m:
            if my_last_action:
                p_adjusted = max(p_adjusted, 0.65)
            else:
                p_adjusted = min(p_adjusted, 0.3)
        if self.m >= self.n - 1:
            p_adjusted = min(1.0, p_adjusted + 0.15)
        if self.m == 2:
            p_adjusted = max(p_adjusted, 0.2)
        if self.k > 2:
            p_adjusted = min(1.0, p_adjusted + 0.1)
        p_adjusted = max(0.0, min(1.0, p_adjusted))
        if random.random() < p_adjusted:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_22(BaseStrategy):
    """
    Adaptive Threshold Guardian: A probabilistic cooperation strategy that aims to
    be part of a reliable coalition meeting the threshold m, while adapting to
    observed behavior. Uses a responsibility score for implicit coordination.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        if self.m == self.n - 1:
            self.base_probability = (self.m + 0.5) / self.n
        elif self.m == 2:
            self.base_probability = (self.m + 0.3) / self.n
        else:
            self.base_probability = (self.m + 1) / self.n
        self.base_probability = max(0.1, min(0.95, self.base_probability))

    def _deterministic_hash(self, player_id: int, round_num: int) -> float:
        """Generate a deterministic pseudo-random score in [0, 1] for coordination."""
        hash_val = (player_id * 73856093 + round_num * 19349663) % 1000
        return hash_val / 1000.0

    def _clamp(self, value: float, min_val: float, max_val: float) -> float:
        """Clamp a value between min and max."""
        return max(min_val, min(max_val, value))

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators in a given round (including self)."""
        my_coop = 1 if history.my_actions[round_idx] else 0
        opponent_coops = int(np.sum(history.opponent_actions[round_idx, :]))
        return my_coop + opponent_coops

    def _get_historical_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all players and rounds."""
        rounds_played = history.round_number
        if rounds_played == 0:
            return self.m / self.n
        total_cooperations = int(np.sum(history.my_actions)) + int(np.sum(history.opponent_actions))
        total_decisions = rounds_played * self.n
        return total_cooperations / total_decisions

    def _get_my_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate my personal cooperation rate."""
        if history.round_number == 0:
            return 0.5
        return float(np.mean(history.my_actions))

    def _get_player_cooperation_rates(self, history: PlayerHistory) -> tuple:
        """Get cooperation rates for all players, returns (my_rate, opponent_rates)."""
        rounds_played = history.round_number
        if rounds_played == 0:
            return (0.5, [])
        my_rate = float(np.mean(history.my_actions))
        opponent_rates = [float(np.mean(history.opponent_actions[:, i])) for i in range(self.n - 1)]
        return (my_rate, opponent_rates)

    def _final_round_logic(self, history: PlayerHistory) -> Action:
        """Logic for the final round."""
        my_rate, opponent_rates = self._get_player_cooperation_rates(history)
        reliable_count = 1 if my_rate > 0.6 else 0
        for rate in opponent_rates:
            if rate > 0.6:
                reliable_count += 1
        if reliable_count < self.m:
            if random.random() < 0.85:
                return Action.C
            return Action.D
        elif reliable_count == self.m:
            if my_rate > 0.6:
                return Action.C
            else:
                if random.random() < 0.4:
                    return Action.C
                return Action.D
        elif my_rate > 0.6:
            if random.random() < 0.5:
                return Action.C
            return Action.D
        else:
            return Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        player_id = 0
        resp_score = self._deterministic_hash(player_id, current_round)
        if history is None or history.round_number == 0:
            if resp_score < self.base_probability:
                return Action.C
            return Action.D
        if self.r == 2 and current_round == 1:
            return self._final_round_logic(history)
        if current_round == self.r - 1:
            return self._final_round_logic(history)
        last_round_idx = history.round_number - 1
        last_round_coops = self._count_cooperators_in_round(history, last_round_idx)
        deficit = self.m - last_round_coops
        adjusted_prob = self.base_probability
        if deficit > 0:
            urgency = min(deficit / self.m, 1.0)
            adjusted_prob = self.base_probability + (1 - self.base_probability) * urgency * 0.5
        elif deficit < 0:
            surplus = -deficit
            adjusted_prob = self.base_probability - surplus / self.n * 0.3
        hist_rate = self._get_historical_cooperation_rate(history)
        expected_rate = self.m / self.n
        if hist_rate < expected_rate * 0.8:
            adjusted_prob = adjusted_prob + 0.15
        elif hist_rate > expected_rate * 1.3:
            adjusted_prob = adjusted_prob - 0.1
        final_prob = self._clamp(adjusted_prob, 0.1, 0.95)
        if resp_score < final_prob:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_23(BaseStrategy):
    """
    Adaptive Threshold Guardian: A collectively-minded strategy that aims to be
    one of the m cooperators needed while fairly sharing the cooperation burden.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        if history is None:
            base_prob = m / n
            return Action.C if random.random() < base_prob else Action.D
        current_round = state.round_number
        my_coop_count = np.sum(history.my_actions)
        rounds_played = len(history.my_actions)
        my_coop_rate = my_coop_count / rounds_played if rounds_played > 0 else 0
        total_coops = my_coop_count + np.sum(history.opponent_actions)
        total_actions = rounds_played * n
        group_coop_rate = total_coops / total_actions if total_actions > 0 else 0
        last_round_others_coops = np.sum(history.opponent_actions[-1, :])
        i_cooperated_last = history.my_actions[-1]
        last_round_total_coops = last_round_others_coops + (1 if i_cooperated_last else 0)
        if last_round_total_coops < m:
            self.consecutive_failures += 1
        else:
            self.consecutive_failures = 0
        opponent_coop_rates = np.mean(history.opponent_actions, axis=0)
        chronic_defector_count = np.sum(opponent_coop_rates < 0.2)
        if current_round == r - 1:
            expected_others = np.sum(opponent_coop_rates)
            if expected_others < m - 1:
                return Action.D
            elif expected_others >= m:
                if my_coop_rate < group_coop_rate:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        base_prob = m / n
        if last_round_total_coops < m:
            prob = min(1.0, base_prob * (m / max(last_round_total_coops, 1)))
            prob = min(1.0, prob + 0.1 * self.consecutive_failures)
        elif last_round_total_coops == m:
            if i_cooperated_last:
                prob = 0.9
            else:
                prob = base_prob
        elif my_coop_rate > group_coop_rate:
            prob = max(0.3, base_prob - 0.1)
        else:
            prob = min(0.9, base_prob + 0.2)
        effective_n = n - chronic_defector_count
        if effective_n >= m and chronic_defector_count > 0:
            adjusted_prob = m / effective_n
            prob = (prob + adjusted_prob) / 2
        elif effective_n < m:
            prob = 1.0
        if m >= n - 1:
            prob = max(prob, 0.85)
        if k > 3:
            prob = min(1.0, prob + 0.1)
        return Action.C if random.random() < prob else Action.D

class Strategy_COLLECTIVE_24(BaseStrategy):
    """
    Adaptive Threshold Guardian: A conditional cooperation strategy that aims to be
    one of the m cooperators needed while adapting to observed cooperation rates.
    Uses probabilistic commitment based on game phase and cooperation trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.n
        r = self.r
        m = self.m
        k = self.k

        def clamp(value, min_val, max_val):
            return max(min_val, min(max_val, value))
        if history is None:
            p0 = m / n
            if n == m:
                p0 = 0.8
            elif m == 2:
                p0 = max(2 / n, 0.4)
            if r <= 3:
                p0 = 0.7
            if k > 2:
                p0 = p0 * min(k / 2, 1.3)
                p0 = clamp(p0, 0, 0.95)
            return Action.C if random.random() < p0 else Action.D
        current_round = state.round_number
        last_round_idx = history.round_number - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_cooperators = np.sum(history.opponent_actions[last_round_idx, :])
        prev_cooperators = int(opponent_cooperators) + (1 if my_last_action else 0)
        i_cooperated_last_round = my_last_action
        target_rate = m / n
        if current_round == r - 1:
            if prev_cooperators >= m:
                p_final = 0.4 if i_cooperated_last_round else 0.2
            else:
                p_final = 0.15
            return Action.C if random.random() < p_final else Action.D
        if prev_cooperators >= m:
            if i_cooperated_last_round:
                p_base = 0.85
            else:
                p_base = 0.3
        elif prev_cooperators == m - 1:
            if i_cooperated_last_round:
                p_base = 0.95
            else:
                p_base = 0.7
        elif i_cooperated_last_round:
            p_base = 0.6
        else:
            p_base = target_rate * 1.2
        if history.round_number >= 2:
            prev_prev_idx = last_round_idx - 1
            my_prev_prev_action = history.my_actions[prev_prev_idx]
            opponent_cooperators_prev = np.sum(history.opponent_actions[prev_prev_idx, :])
            prev_prev_cooperators = int(opponent_cooperators_prev) + (1 if my_prev_prev_action else 0)
            trend = prev_cooperators - prev_prev_cooperators
            if trend > 0:
                p_adjust = 0.1
            elif trend < 0:
                p_adjust = -0.1
            else:
                p_adjust = 0
            p_base = clamp(p_base + p_adjust, 0.1, 0.95)
        if n == m:
            p_base = clamp(p_base + 0.1, 0.1, 0.95)
        if k > 2:
            p_base = p_base * min(k / 2, 1.3)
            p_base = clamp(p_base, 0.1, 0.95)
        return Action.C if random.random() < p_base else Action.D

class Strategy_COLLECTIVE_25(BaseStrategy):
    """
    Adaptive Threshold Guardian: A probabilistic cooperation strategy that aims to be
    part of a reliable coalition meeting threshold m, while adapting to observed behavior.
    Uses baseline probability m/n, adjusted based on cooperation success rates and trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.n
        r = self.r
        m = self.m
        p_base = m / n
        p_base = max(0.15, p_base)
        if history is None:
            if n == 2 and m == 2:
                return self._cooperate_with_probability(0.7)
            if m >= n - 1:
                return self._cooperate_with_probability(0.9)
            if r <= 3:
                p = min(0.95, p_base * 1.2)
                return self._cooperate_with_probability(p)
            return self._cooperate_with_probability(p_base)
        current_round = state.round_number
        rounds_played = history.round_number
        coop_rate = self._calculate_overall_cooperation_rate(history)
        threshold_met_rate = self._calculate_threshold_success_rate(history)
        recent_trend = self._calculate_recent_trend(history, window=3)
        if n == 2 and m == 2:
            return self._handle_two_player_case(history)
        if threshold_met_rate >= 0.7:
            if coop_rate > (m + 1) / n:
                p = max(0.3, p_base - 0.1)
            else:
                p = p_base
        elif threshold_met_rate >= 0.4:
            p = min(0.9, p_base + 0.2)
        elif threshold_met_rate > 0:
            p = min(0.95, p_base + 0.3)
        elif rounds_played <= r / 3:
            p = 0.8
        else:
            p = 0.2
        if recent_trend == 'increasing' and threshold_met_rate < 0.7:
            p = min(1.0, p + 0.15)
        elif recent_trend == 'decreasing' and threshold_met_rate >= 0.4:
            p = min(1.0, p + 0.1)
        if current_round == r - 1:
            if threshold_met_rate >= 0.6:
                p = p_base
            elif self._threshold_met_last_round(history):
                p = p_base
            elif threshold_met_rate < 0.5:
                p = 0.1
        if r <= 3:
            p = min(0.95, p * 1.2)
        if r > 20 and rounds_played < r * 0.2:
            if threshold_met_rate >= 0.7 and random.random() < 0.15:
                p = max(0.2, p - 0.3)
        if m >= n - 1:
            p = max(p, 0.85)
        return self._cooperate_with_probability(p)

    def _cooperate_with_probability(self, p: float) -> Action:
        if random.random() < p:
            return Action.C
        return Action.D

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        rounds_played = history.round_number
        if rounds_played == 0:
            return 0.0
        my_coops = np.sum(history.my_actions)
        opp_coops = np.sum(history.opponent_actions)
        total_actions = rounds_played * self.n
        total_coops = my_coops + opp_coops
        return total_coops / total_actions

    def _calculate_threshold_success_rate(self, history: PlayerHistory) -> float:
        rounds_played = history.round_number
        if rounds_played == 0:
            return 0.0
        successes = 0
        for r in range(rounds_played):
            total_coops = int(history.my_actions[r]) + np.sum(history.opponent_actions[r])
            if total_coops >= self.m:
                successes += 1
        return successes / rounds_played

    def _calculate_recent_trend(self, history: PlayerHistory, window: int=3) -> str:
        rounds_played = history.round_number
        if rounds_played < 2:
            return 'stable'
        actual_window = min(window, rounds_played)
        rates = []
        for r in range(rounds_played - actual_window, rounds_played):
            total_coops = int(history.my_actions[r]) + np.sum(history.opponent_actions[r])
            rates.append(total_coops / self.n)
        if len(rates) < 2:
            return 'stable'
        mid = len(rates) // 2
        if mid == 0:
            mid = 1
        first_half_avg = np.mean(rates[:mid])
        second_half_avg = np.mean(rates[mid:])
        diff = second_half_avg - first_half_avg
        if diff > 0.1:
            return 'increasing'
        elif diff < -0.1:
            return 'decreasing'
        return 'stable'

    def _threshold_met_last_round(self, history: PlayerHistory) -> bool:
        if history.round_number == 0:
            return False
        last_round = history.round_number - 1
        total_coops = int(history.my_actions[last_round]) + np.sum(history.opponent_actions[last_round])
        return total_coops >= self.m

    def _handle_two_player_case(self, history: PlayerHistory) -> Action:
        rounds_played = history.round_number
        partner_ever_cooperated = np.any(history.opponent_actions)
        if partner_ever_cooperated:
            return self._cooperate_with_probability(0.9)
        consecutive_defections = 0
        for r in range(rounds_played - 1, -1, -1):
            if not history.my_actions[r] and (not history.opponent_actions[r, 0]):
                consecutive_defections += 1
            else:
                break
        if consecutive_defections >= 3:
            return self._cooperate_with_probability(0.1)
        return self._cooperate_with_probability(0.7)

class Strategy_COLLECTIVE_26(BaseStrategy):
    """
    Adaptive Threshold Guardian: A collectively-minded strategy that aims to meet
    the cooperation threshold while adapting based on group behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.escalation_start = None
        self.escalation_rounds = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if self.n == self.m:
            return Action.C
        if history is None or current_round == 0:
            base_probability = self.m / self.n
            cooperation_premium = 0.15
            p_cooperate = min(1.0, base_probability + cooperation_premium)
            return Action.C if random.random() < p_cooperate else Action.D
        rounds_played = history.round_number
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_plays = self.n * rounds_played
        cooperation_rate = total_cooperations / total_plays if total_plays > 0 else 0
        expected_fair_rate = self.m / self.n
        health_ratio = cooperation_rate / expected_fair_rate if expected_fair_rate > 0 else 1.0
        last_round_my_action = 1 if history.my_actions[-1] else 0
        last_round_opponent_coops = np.sum(history.opponent_actions[-1, :])
        last_round_coops = last_round_my_action + last_round_opponent_coops
        if health_ratio >= 0.9:
            base_p = self.m / self.n + 0.1
        elif health_ratio >= 0.5:
            base_p = min(1.0, self.m / self.n + 0.3 * (1 - health_ratio))
        else:
            in_escalation = False
            if self.escalation_start is not None:
                if current_round - self.escalation_start < self.escalation_rounds:
                    in_escalation = True
                else:
                    self.escalation_start = None
            if health_ratio < 0.5 and self.escalation_start is None:
                self.escalation_start = current_round
                in_escalation = True
            if in_escalation:
                base_p = 0.7
            else:
                base_p = self.m / self.n
        if last_round_coops >= self.m:
            adjust = -0.05
        elif last_round_coops == self.m - 1:
            adjust = 0.15
        else:
            adjust = 0.1
        if current_round == self.r - 1:
            adjust = 0
            if cooperation_rate >= expected_fair_rate - 0.1:
                base_p = self.m / self.n + 0.1
            else:
                base_p = self.m / self.n
        final_p = max(0.1, min(0.95, base_p + adjust))
        if self.m == 1:
            missed_count = sum((1 for r_idx in range(rounds_played) if history.my_actions[r_idx] + np.sum(history.opponent_actions[r_idx, :]) < 1))
            if missed_count > 0:
                final_p = min(0.95, final_p + 0.1 * missed_count)
        if last_round_coops == self.m - 1:
            final_p = min(0.95, final_p + 0.05)
        return Action.C if random.random() < final_p else Action.D

class Strategy_COLLECTIVE_27(BaseStrategy):
    """
    Adaptive Threshold Guardian: Aims to be one of exactly m cooperators,
    adapts based on group behavior, and maintains fair burden sharing.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            prob = self.m / self.n
            return Action.C if random.random() < prob else Action.D
        current_round = state.round_number
        total_rounds = self.r
        prev_round_idx = history.round_number - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        prev_cooperators = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        base_prob = self._calculate_base_prob(prev_cooperators, my_prev_action)
        my_coop_rate = self._calculate_my_coop_rate(history)
        others_coop_rate = self._calculate_others_avg_coop_rate(history)
        reliability = self._calculate_threshold_hit_rate(history)
        fairness_adj = (others_coop_rate - my_coop_rate) * 0.3
        reliability_adj = (1 - reliability) * 0.2
        adjusted_prob = base_prob + fairness_adj + reliability_adj
        adjusted_prob = max(0.1, min(0.95, adjusted_prob))
        if current_round == total_rounds - 1:
            adjusted_prob = self._final_round_adjustment(adjusted_prob, reliability, my_coop_rate, others_coop_rate)
        return Action.C if random.random() < adjusted_prob else Action.D

    def _calculate_base_prob(self, prev_cooperators: int, my_prev_action: bool) -> float:
        m = self.m
        n = self.n
        if prev_cooperators < m:
            shortfall = m - prev_cooperators
            base_prob = min(1.0, (m + shortfall) / n)
        elif prev_cooperators == m:
            if my_prev_action:
                base_prob = (m - 0.5) / n
            else:
                base_prob = (m + 0.5) / n
        else:
            surplus = prev_cooperators - m
            if my_prev_action:
                base_prob = max(0.1, (m - surplus) / n)
            else:
                base_prob = m / n
        return base_prob

    def _calculate_my_coop_rate(self, history: PlayerHistory) -> float:
        if history.round_number == 0:
            return 0.5
        return float(np.mean(history.my_actions))

    def _calculate_others_avg_coop_rate(self, history: PlayerHistory) -> float:
        if history.round_number == 0:
            return 0.5
        return float(np.mean(history.opponent_actions))

    def _calculate_threshold_hit_rate(self, history: PlayerHistory) -> float:
        if history.round_number == 0:
            return 0.5
        threshold_hits = 0
        for round_idx in range(history.round_number):
            my_coop = int(history.my_actions[round_idx])
            opponent_coops = int(np.sum(history.opponent_actions[round_idx, :]))
            total_coops = my_coop + opponent_coops
            if total_coops >= self.m:
                threshold_hits += 1
        return threshold_hits / history.round_number

    def _final_round_adjustment(self, current_prob: float, reliability: float, my_coop_rate: float, others_coop_rate: float) -> float:
        m = self.m
        n = self.n
        if reliability >= 0.7:
            final_prob = m / n
        elif reliability >= 0.4:
            final_prob = (m + 1) / n
        else:
            final_prob = min(0.9, (m + 2) / n)
        if my_coop_rate < others_coop_rate:
            final_prob = min(1.0, final_prob + 0.15)
        return max(0.1, min(0.95, final_prob))

class Strategy_COLLECTIVE_28(BaseStrategy):
    """
    Adaptive Threshold Guardian: A probabilistic cooperation strategy that aims to be
    one of the m cooperators needed without being a surplus cooperator who enables free-riding.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.n
        m = self.m
        k = self.k
        r = self.r

        def clip(val, low, high):
            return max(low, min(high, val))
        base_rate = min(0.95, (m + 0.5) / n)
        if k > 2:
            base_rate += 0.1
        elif k < 1.5:
            base_rate -= 0.1
        base_rate = clip(base_rate, 0.1, 0.95)
        if n == 2 and m == 2:
            if history is None:
                p = 0.8
            else:
                opponent_coop_rate = np.mean(history.opponent_actions)
                p = 0.5 + 0.4 * opponent_coop_rate
                p = clip(p, 0.3, 0.95)
            return Action.C if random.random() < p else Action.D
        if history is None:
            p = min(1.0, (m + 1) / n)
            return Action.C if random.random() < p else Action.D
        current_round = state.round_number
        rounds_played = history.round_number
        total_opponent_actions = history.opponent_actions.size
        if total_opponent_actions > 0:
            obs_coop_rate = np.sum(history.opponent_actions) / total_opponent_actions
        else:
            obs_coop_rate = m / n

        def count_cooperators_per_round():
            my_coop = history.my_actions.astype(int)
            opponent_coop = np.sum(history.opponent_actions, axis=1)
            return my_coop + opponent_coop
        cooperators_per_round = count_cooperators_per_round()
        threshold_met_count = np.sum(cooperators_per_round >= m)
        threshold_met_rate = threshold_met_count / rounds_played if rounds_played > 0 else 0.5

        def threshold_met_recently(window=3):
            if rounds_played == 0:
                return False
            recent_rounds = min(window, rounds_played)
            recent_cooperators = cooperators_per_round[-recent_rounds:]
            return np.sum(recent_cooperators >= m) >= recent_rounds / 2
        if threshold_met_rate >= 0.8:
            coop_mult = 0.9
            if m <= n / 3 and threshold_met_rate >= 0.9:
                coop_mult = 0.85
        elif threshold_met_rate >= 0.5:
            coop_mult = 1.0
        elif obs_coop_rate >= (m - 1) / n:
            coop_mult = 1.2
        else:
            coop_mult = max(0.3, obs_coop_rate * n / m) if m > 0 else 0.3
        rounds_remaining = r - current_round - 1
        recent_success = threshold_met_recently(window=3)
        if rounds_remaining <= 3 and recent_success:
            urgency = 0.85
        elif rounds_remaining <= 3 and (not recent_success):
            urgency = 1.15
        else:
            urgency = 1.0
        p = clip(base_rate * coop_mult * urgency, 0.1, 0.95)
        if current_round == r - 1:
            if threshold_met_rate >= 0.7:
                p *= 1.1
            else:
                avg_opponent_coop = np.mean(np.sum(history.opponent_actions, axis=1))
                if abs(avg_opponent_coop - (m - 1)) < 0.5:
                    p = 0.85
                else:
                    p *= 0.8
            p = clip(p, 0.1, 0.95)
        if m >= n - 1:
            p = max(p, 0.85)
        return Action.C if random.random() < p else Action.D

class Strategy_COLLECTIVE_29(BaseStrategy):
    """
    Adaptive Threshold Guardian: A strategy that aims to be one of the m cooperators
    needed while minimizing exploitation. Uses probabilistic fair-share cooperation
    with responsive adjustments based on group performance.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def _clamp(self, value, min_val, max_val):
        """Clamp value between min and max."""
        return max(min_val, min(max_val, value))

    def _cooperate_with_prob(self, prob, round_num, seed_offset=0):
        """Deterministic pseudo-random decision based on round and seed."""
        combined = (round_num * 31 + seed_offset * 17) % 1000
        threshold = prob * 1000
        return combined < threshold

    def _count_cooperators(self, my_action, opponent_actions):
        """Count total cooperators including self."""
        opp_coop = np.sum(opponent_actions)
        my_coop = 1 if my_action else 0
        return opp_coop + my_coop

    def _count_cooperators_round(self, history, round_idx):
        """Count cooperators in a specific round."""
        my_coop = 1 if history.my_actions[round_idx] else 0
        opp_coop = np.sum(history.opponent_actions[round_idx, :])
        return my_coop + opp_coop

    def _threshold_met(self, cooperator_count):
        """Check if threshold was met."""
        return cooperator_count >= self.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        base_prob = self.m / self.n
        if history is None:
            if self.m == self.n - 1:
                base_prob = base_prob + 0.1
            if random.random() < base_prob:
                return Action.C
            return Action.D
        current_round = state.round_number
        num_completed = history.round_number
        threshold_met_count = 0
        total_cooperators = 0
        for r in range(num_completed):
            c_count = self._count_cooperators_round(history, r)
            total_cooperators += c_count
            if self._threshold_met(c_count):
                threshold_met_count += 1
        threshold_met_rate = threshold_met_count / num_completed if num_completed > 0 else 0
        avg_coop = total_cooperators / num_completed if num_completed > 0 else self.m
        c_prev = self._count_cooperators_round(history, -1)
        my_last_action = history.my_actions[-1]
        if c_prev < self.m:
            urgency_boost = (self.m - c_prev) / self.m * 0.3
        else:
            urgency_boost = 0
        if threshold_met_rate < 0.5:
            history_adj = 0.2
        elif threshold_met_rate > 0.8 and avg_coop > self.m + 1:
            history_adj = -0.15
        else:
            history_adj = 0
        if my_last_action and c_prev > self.m:
            personal_adj = -0.2
        elif not my_last_action and c_prev < self.m:
            personal_adj = 0.25
        else:
            personal_adj = 0
        consecutive_failures = 0
        for r in range(num_completed - 1, -1, -1):
            c_count = self._count_cooperators_round(history, r)
            if not self._threshold_met(c_count):
                consecutive_failures += 1
            else:
                break
        if consecutive_failures >= 3:
            prob = 0.8
        else:
            if current_round == self.r - 1:
                personal_adj = 0
                if threshold_met_rate < 0.4:
                    history_adj = -0.1
                elif threshold_met_rate >= 0.7:
                    history_adj = 0
                else:
                    history_adj = 0.1
            if self.m == self.n - 1:
                base_prob = base_prob + 0.1
            k_multiplier = min(self.k / 2, 1.5)
            if self.k > 2:
                urgency_boost *= k_multiplier
                if history_adj > 0:
                    history_adj *= k_multiplier
            if threshold_met_rate > 0.9 and avg_coop > self.m + 1.5:
                surplus_adj = -0.05 * min(num_completed, 3)
                surplus_adj = max(surplus_adj, -(base_prob - (self.m / self.n - 0.15)))
            else:
                surplus_adj = 0
            prob = base_prob + urgency_boost + history_adj + personal_adj + surplus_adj
        prob = self._clamp(prob, 0.1, 0.9)
        if random.random() < prob:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_30(BaseStrategy):
    """
    Adaptive Threshold Guardian: A strategy that aims to be one of the m cooperators needed,
    using observable history to coordinate implicitly and adapt to population behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.player_index = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.n
        m = self.m
        k = self.k
        r = self.r
        round_num = state.round_number

        def clamp(val, min_val, max_val):
            return max(min_val, min(max_val, val))
        if n == m:
            return Action.C
        if history is None:
            base_prob = m / n
            if m == 1:
                base_prob = 1.5 / n
            if k > 2:
                base_prob += 0.1
            elif k < 1.2:
                base_prob -= 0.1
            base_prob = clamp(base_prob, 0.1, 0.9)
            return Action.C if random.random() < base_prob else Action.D
        rounds_played = history.round_number
        player_index = hash(tuple(history.my_actions.tolist())) % n
        window = min(3, rounds_played)
        total_coop_per_round = []
        my_coop_list = []
        for i in range(rounds_played - window, rounds_played):
            my_coop = 1 if history.my_actions[i] else 0
            opp_coop = int(np.sum(history.opponent_actions[i, :]))
            total_coop_per_round.append(my_coop + opp_coop)
            my_coop_list.append(my_coop)
        avg_coop = np.mean(total_coop_per_round) if total_coop_per_round else m
        my_coop_rate = np.mean(my_coop_list) if my_coop_list else 0.5
        all_total_coop = []
        for i in range(rounds_played):
            my_coop = 1 if history.my_actions[i] else 0
            opp_coop = int(np.sum(history.opponent_actions[i, :]))
            all_total_coop.append(my_coop + opp_coop)
        success_count = sum((1 for tc in all_total_coop if tc >= m))
        success_rate = success_count / rounds_played if rounds_played > 0 else 0
        my_coop_when_failed = sum((1 for i, tc in enumerate(all_total_coop) if tc < m and history.my_actions[i]))
        if avg_coop < m:
            base_prob = min(1.0, m / n + 0.2)
        elif avg_coop <= m + 1:
            base_prob = m / n
        else:
            base_prob = max(0.1, m / n - 0.15)
        fair_share = avg_coop / n
        if my_coop_rate > fair_share + 0.2:
            base_prob -= 0.15
        elif my_coop_rate < fair_share - 0.2:
            base_prob += 0.15
        slot = (player_index + round_num) % n
        if slot < m:
            base_prob += 0.2
        else:
            base_prob -= 0.1
        if m == 1:
            base_prob = max(base_prob, 1.5 / n)
        if k > 2:
            base_prob += 0.1
        elif k < 1.2:
            base_prob -= 0.1
        if rounds_played >= 3 and success_rate == 0:
            base_prob = 0.8
        if my_coop_when_failed >= 3:
            base_prob = min(base_prob, 0.4)
        if round_num == r - 1:
            if success_rate >= 0.7:
                base_prob = m / n + 0.1
            else:
                base_prob = min(0.8, m / n + 0.25)
        final_prob = clamp(base_prob, 0.1, 0.95)
        return Action.C if random.random() < final_prob else Action.D

class Strategy_COLLECTIVE_31(BaseStrategy):
    """
    Adaptive Threshold Guardian: A collectively-minded strategy that uses
    probabilistic cooperation calibrated to achieve the threshold, with
    adaptive responsiveness to observed group behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.n
        m = self.m
        k = self.k
        total_rounds = self.r
        target_rate = m / n
        if history is None:
            p = target_rate
            if n <= 4:
                p += 0.1
            if m > n / 2:
                p += 0.1
            if k > 2:
                p = max(p, 0.3)
            p = min(1.0, max(0.0, p))
            return Action.C if random.random() < p else Action.D
        round_num = state.round_number
        rounds_played = history.round_number
        my_coops = np.sum(history.my_actions)
        opp_coops = np.sum(history.opponent_actions)
        total_coops = my_coops + opp_coops
        total_plays = n * rounds_played
        if total_plays > 0:
            cooperation_rate = total_coops / total_plays
        else:
            cooperation_rate = target_rate

        def get_player_coop_rate(player_idx):
            if player_idx == -1:
                if rounds_played == 0:
                    return 0.0
                return np.sum(history.my_actions) / rounds_played
            else:
                if rounds_played == 0:
                    return 0.0
                return np.sum(history.opponent_actions[:, player_idx]) / rounds_played
        reliable_count = 0
        if get_player_coop_rate(-1) >= 0.6:
            reliable_count += 1
        n_opponents = n - 1
        for i in range(n_opponents):
            if get_player_coop_rate(i) >= 0.6:
                reliable_count += 1
        if round_num == total_rounds - 1:
            if reliable_count >= m:
                p = 0.3
            elif reliable_count == m - 1:
                p = 0.8
            else:
                uncertain_players = n - reliable_count
                needed = m - reliable_count
                if uncertain_players > 0:
                    p = min(1.0, needed / uncertain_players)
                else:
                    p = 1.0
            p = min(1.0, max(0.0, p))
            return Action.C if random.random() < p else Action.D
        shortfall = target_rate - cooperation_rate
        alpha = 1.5
        if n > 1:
            p = target_rate + alpha * shortfall * (n / (n - 1))
        else:
            p = target_rate + alpha * shortfall
        if m > 0:
            adjustment = (m - reliable_count) / m
            p = p * (1 + 0.3 * adjustment)
        if n <= 4:
            p += 0.1
        if m > n / 2:
            p = max(p, target_rate + 0.1)
        if k > 2:
            p = max(p, 0.3)
        if cooperation_rate < 0.2 and rounds_played > 0:
            p = max(p, target_rate)
        floor = max(0.1, (m - reliable_count) / n) if n > 0 else 0.1
        p = max(floor, p)
        p = min(1.0, max(0.0, p))
        return Action.C if random.random() < p else Action.D

class Strategy_COLLECTIVE_32(BaseStrategy):
    """
    Adaptive Threshold Guardian: Cooperates when cooperation is likely needed
    to reach the threshold, and defects when cooperation is futile or redundant.
    Uses history-based adjustment and priority rotation for fair burden sharing.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def _deterministic_hash(self, round_num: int, player_index: int) -> float:
        """Generate a deterministic pseudo-random value between 0 and 1."""
        seed = (round_num * 31 + player_index * 17 + 13) % 10000
        value = (seed * 1103515245 + 12345) % 2 ** 31 / 2 ** 31
        return value

    def _get_my_index(self, history: PlayerHistory) -> int:
        """Estimate player index based on history patterns."""
        if history is not None and len(history.my_actions) > 0:
            pattern_hash = sum((int(a) * (i + 1) for i, a in enumerate(history.my_actions[:min(3, len(history.my_actions))])))
            return pattern_hash % self.n
        return 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        my_index = (current_round * 3 + hash(str(current_round)) % 100) % self.n
        if history is not None:
            my_index = self._get_my_index(history)
        base_rate = self.m / self.n
        if history is None or current_round == 0:
            adjusted_rate = base_rate + 0.05
            round_seed = 0 * 7 % self.n
            priority = (my_index + round_seed) % self.n
            priority_bonus = 0.2 if priority < self.m else -0.1
            k_bonus = min(0.15, (self.k - 1) / 10) if self.k > 2 else 0
            if self.m >= self.n - 1:
                adjusted_rate = min(0.9, base_rate + 0.15)
            final_rate = adjusted_rate + priority_bonus + k_bonus
            final_rate = max(0.05, min(0.95, final_rate))
            threshold = self._deterministic_hash(0, my_index)
            if threshold < final_rate:
                return Action.C
            else:
                return Action.D
        cooperators_per_round = []
        for r in range(len(history.my_actions)):
            my_coop = 1 if history.my_actions[r] else 0
            opponent_coops = np.sum(history.opponent_actions[r, :])
            total_coops = my_coop + opponent_coops
            cooperators_per_round.append(total_coops)
        avg_cooperators = np.mean(cooperators_per_round) if cooperators_per_round else self.m
        if avg_cooperators < self.m:
            adjusted_rate = base_rate + (self.m - avg_cooperators) / self.n
        elif avg_cooperators > self.m + 1:
            adjusted_rate = base_rate - (avg_cooperators - self.m - 1) / (2 * self.n)
        else:
            adjusted_rate = base_rate
        round_seed = current_round * 7 % self.n
        priority = (my_index + round_seed) % self.n
        priority_bonus = 0.2 if priority < self.m else -0.1
        k_bonus = min(0.15, (self.k - 1) / 10) if self.k > 2 else 0
        last_round_adj = 0
        if current_round == self.r - 1:
            threshold_met_count = sum((1 for c in cooperators_per_round if c >= self.m))
            success_rate = threshold_met_count / len(cooperators_per_round) if cooperators_per_round else 0
            if success_rate > 0.7:
                last_round_adj = 0
            else:
                last_round_adj = -0.1
        if self.m >= self.n - 1:
            adjusted_rate = min(0.9, adjusted_rate + 0.15)
        final_rate = adjusted_rate + priority_bonus + k_bonus + last_round_adj
        final_rate = max(0.05, min(0.95, final_rate))
        threshold = self._deterministic_hash(current_round, my_index)
        if threshold < final_rate:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_1(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that free-rides when possible,
    cooperates only when pivotal, and defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_counts = None
        self.rounds_played = 0
        self.cooperation_boost = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        n_opponents = self.n - 1
        if self.cooperation_counts is None:
            self.cooperation_counts = np.zeros(n_opponents)
        if history.round_number > 0:
            last_round_idx = history.round_number - 1
            last_opponent_actions = history.opponent_actions[last_round_idx, :]
            self.cooperation_counts += last_opponent_actions.astype(float)
            self.rounds_played = history.round_number
            last_total_cooperators = np.sum(last_opponent_actions) + (1 if history.my_actions[last_round_idx] else 0)
            my_last_action = history.my_actions[last_round_idx]
            if last_total_cooperators == self.m - 1 and (not my_last_action):
                self.cooperation_boost = min(self.cooperation_boost + 0.2, 0.8)
            elif last_total_cooperators >= self.m + 2 and my_last_action:
                self.cooperation_boost = max(self.cooperation_boost - 0.1, 0.0)
            else:
                self.cooperation_boost = max(self.cooperation_boost - 0.05, 0.0)
        if current_round == self.r - 1:
            return Action.D
        if self.k < 1:
            return Action.D
        if self.r <= 2:
            return Action.D
        if self.m == 2 and self.n >= 4:
            expected_coop = self._estimate_cooperators()
            if expected_coop >= 2:
                return Action.D
        if self.m >= self.n - 1:
            return Action.C
        if history.round_number > 0:
            last_round_idx = history.round_number - 1
            total_last_round = np.sum(history.opponent_actions[last_round_idx, :]) + (1 if history.my_actions[last_round_idx] else 0)
            if total_last_round == 0:
                return Action.D
        expected_coop = self._estimate_cooperators()
        if self.cooperation_boost > 0 and random.random() < self.cooperation_boost:
            expected_coop -= 0.5
        if expected_coop >= self.m:
            return Action.D
        elif expected_coop >= self.m - 1:
            return Action.C
        else:
            return Action.D

    def _estimate_cooperators(self) -> float:
        """Estimate how many opponents will cooperate based on their history."""
        if self.rounds_played == 0:
            return (self.n - 1) * 0.5
        cooperation_rates = self.cooperation_counts / self.rounds_played
        expected_coop = np.sum(cooperation_rates)
        return expected_coop

class Strategy_EXPLOITATIVE_2(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that free-rides on others' cooperation
    while minimizing personal contribution. Cooperates only when mathematically necessary
    to avoid collective disaster.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if history is None:
            if self.m <= self.n / 2:
                return Action.D
            else:
                return Action.C if random.random() < self.m / self.n else Action.D
        n_opponents = self.n - 1
        rounds_played = history.round_number
        reliable_count = 0
        conditional_count = 0
        for i in range(n_opponents):
            coop_count = np.sum(history.opponent_actions[:, i])
            coop_rate = coop_count / rounds_played
            if coop_rate >= 0.8:
                reliable_count += 1
            elif coop_rate >= 0.4:
                conditional_count += 1
        expected_coop = reliable_count + 0.5 * conditional_count
        last_round_coop = np.sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
        consecutive_failures = 0
        for r in range(rounds_played - 1, -1, -1):
            total_coop = np.sum(history.opponent_actions[r, :]) + (1 if history.my_actions[r] else 0)
            if total_coop < self.m:
                consecutive_failures += 1
            else:
                break
        if consecutive_failures >= 2:
            return Action.C
        if last_round_coop >= self.m and (not history.my_actions[-1]):
            return Action.D
        my_consecutive_coops = 0
        for r in range(rounds_played - 1, -1, -1):
            if history.my_actions[r]:
                my_consecutive_coops += 1
            else:
                break
        if expected_coop >= self.m:
            return Action.D
        elif expected_coop <= self.m - 2:
            return Action.D
        else:
            base_prob = (self.k - 1) / self.k if self.k > 1 else 0.5
            if last_round_coop == self.m and history.my_actions[-1]:
                base_prob = 0.7
            if my_consecutive_coops >= 2:
                base_prob -= 0.3
            base_prob = max(0.0, min(1.0, base_prob))
            return Action.C if random.random() < base_prob else Action.D

class Strategy_EXPLOITATIVE_3(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that aims to free-ride on cooperative
    players while maintaining just enough cooperation to prevent collective collapse.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if history is None:
            if self.m >= self.n - 1:
                return Action.C
            if self.m <= self.n / 2:
                return Action.D
            else:
                return Action.C
        n_opponents = self.n - 1
        n_completed_rounds = history.round_number
        opponent_coop_rates = []
        for i in range(n_opponents):
            coop_count = np.sum(history.opponent_actions[:, i])
            rate = coop_count / n_completed_rounds
            opponent_coop_rates.append(rate)
        reliable_cooperators = sum((1 for rate in opponent_coop_rates if rate > 0.7))
        predicted_coop = sum(opponent_coop_rates)
        recent_failures = 0
        lookback = min(3, n_completed_rounds)
        for t in range(n_completed_rounds - lookback, n_completed_rounds):
            others_coop = np.sum(history.opponent_actions[t, :])
            my_coop = 1 if history.my_actions[t] else 0
            total_coop = others_coop + my_coop
            if total_coop < self.m:
                recent_failures += 1
        all_defectors = all((rate < 0.3 for rate in opponent_coop_rates))
        if all_defectors:
            return Action.D
        if self.m >= self.n - 1:
            return Action.C
        if predicted_coop >= self.m:
            return Action.D
        if reliable_cooperators >= self.m:
            return Action.D
        if predicted_coop >= self.m - 1:
            if reliable_cooperators >= self.m - 1:
                return Action.D
            else:
                return Action.C
        if recent_failures >= 3 and predicted_coop >= self.m - 2:
            return Action.C
        last_round_others_coop = np.sum(history.opponent_actions[-1, :])
        last_round_my_coop = 1 if history.my_actions[-1] else 0
        last_round_total = last_round_others_coop + last_round_my_coop
        last_round_met = last_round_total >= self.m
        if not last_round_met and predicted_coop >= self.m - 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_4(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that aims to free-ride when
    the cooperation threshold is likely to be met without contributing,
    while minimizing wasted contributions when the threshold is unreachable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        n_opponents = self.n - 1
        rounds_played = history.round_number
        if rounds_played == 0:
            return Action.D
        coop_rates = []
        for j in range(n_opponents):
            opponent_coop_count = np.sum(history.opponent_actions[:, j])
            coop_rate = opponent_coop_count / rounds_played
            coop_rates.append(coop_rate)
        expected_others = sum(coop_rates)
        if expected_others >= self.m + 0.5:
            return Action.D
        elif expected_others < self.m - 1:
            return Action.D
        else:
            reliable = sum((1 for rate in coop_rates if rate > 0.7))
            if reliable >= self.m:
                return Action.D
            elif reliable == self.m - 1:
                rounds_remaining_ratio = (self.r - current_round) / self.r
                cooperate_prob = 0.3 * rounds_remaining_ratio
                if random.random() < cooperate_prob:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D

class Strategy_EXPLOITATIVE_5(BaseStrategy):
    """
    Threshold Vulture: An exploitative strategy that aims to defect when
    others are likely to meet the cooperation threshold without me,
    maximizing the free-rider payoff of (1 + k).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if history is None or len(history.my_actions) == 0:
            p_cooperate = (self.m - 1) / (self.n - 1) if self.n > 1 else 0.5
            if random.random() < p_cooperate:
                return Action.C
            else:
                return Action.D
        rounds_played = len(history.my_actions)
        total_others_coops = np.sum(history.opponent_actions)
        others_rate = total_others_coops / (rounds_played * (self.n - 1)) if rounds_played > 0 and self.n > 1 else 0
        expected_other_cooperators = others_rate * (self.n - 1)
        if rounds_played >= 2:
            last_round_coop_rate = np.sum(history.opponent_actions[-1, :]) / (self.n - 1) if self.n > 1 else 0
            prev_round_coop_rate = np.sum(history.opponent_actions[-2, :]) / (self.n - 1) if self.n > 1 else 0
            if prev_round_coop_rate > 0 and (prev_round_coop_rate - last_round_coop_rate) / prev_round_coop_rate > 0.2:
                return Action.D
        if expected_other_cooperators >= self.m:
            return Action.D
        elif expected_other_cooperators >= self.m - 1:
            p_defect = expected_other_cooperators - (self.m - 1)
            if random.random() < p_defect:
                return Action.D
            else:
                return Action.C
        elif expected_other_cooperators >= self.m - 2:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            if last_round_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_6(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that free-rides when others 
    meet the threshold, but cooperates conditionally when pivotal to avoid 
    collective disaster.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        stats = self._calculate_statistics(history)
        if stats['threshold_met_without_me_rate'] >= 0.7:
            return Action.D
        expected_others = stats['recent_cooperation_rate'] * (self.n - 1)
        if expected_others < self.m - 0.5:
            return Action.D
        if expected_others >= self.m + 1:
            return Action.D
        shortfall = self.m - expected_others
        if shortfall > 0:
            p_coop = min(1.0, shortfall / 1.5)
        else:
            p_coop = max(0.0, 0.3 - abs(shortfall) * 0.15)
        p_coop = max(0.0, min(0.8, p_coop))
        if self.n - self.m <= 1:
            p_coop += 0.2
        if self.k > 3:
            p_coop += 0.1
        if self.k < 1.5:
            p_coop -= 0.15
        p_coop = max(0.0, min(1.0, p_coop))
        if random.random() < p_coop:
            return Action.C
        else:
            return Action.D

    def _calculate_statistics(self, history: PlayerHistory) -> dict:
        """Calculate relevant statistics from game history."""
        n_rounds_played = history.round_number
        n_opponents = self.n - 1
        total_other_coop = np.sum(history.opponent_actions)
        total_other_plays = n_rounds_played * n_opponents
        cooperation_rate = total_other_coop / total_other_plays if total_other_plays > 0 else 0.0
        lookback = min(3, n_rounds_played)
        recent_other_coop = np.sum(history.opponent_actions[-lookback:, :])
        recent_other_plays = lookback * n_opponents
        recent_cooperation_rate = recent_other_coop / recent_other_plays if recent_other_plays > 0 else 0.0
        threshold_met_count = 0
        threshold_met_without_me_count = 0
        for r in range(n_rounds_played):
            my_coop = 1 if history.my_actions[r] else 0
            other_coop = np.sum(history.opponent_actions[r, :])
            total_coop = my_coop + other_coop
            if total_coop >= self.m:
                threshold_met_count += 1
            if other_coop >= self.m:
                threshold_met_without_me_count += 1
        threshold_met_rate = threshold_met_count / n_rounds_played if n_rounds_played > 0 else 0.0
        threshold_met_without_me_rate = threshold_met_without_me_count / n_rounds_played if n_rounds_played > 0 else 0.0
        return {'cooperation_rate': cooperation_rate, 'recent_cooperation_rate': recent_cooperation_rate, 'threshold_met_rate': threshold_met_rate, 'threshold_met_without_me_rate': threshold_met_without_me_rate}

class Strategy_EXPLOITATIVE_7(BaseStrategy):
    """
    Threshold Vulture: An exploitative strategy that free-rides when possible
    while ensuring the threshold is met just often enough to collect rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            threshold_ratio = self.m / self.n
            if self.n == 2 and self.m == 2:
                return Action.C
            if self.m == self.n - 1:
                return Action.C
            if threshold_ratio <= 0.5:
                return Action.D
            else:
                coop_prob = threshold_ratio - 0.1
                if self.k > 2:
                    coop_prob += 0.1
                if random.random() < coop_prob:
                    return Action.C
                return Action.D
        current_round = state.round_number
        rounds_played = history.round_number
        total_cooperators_history = []
        for r_idx in range(rounds_played):
            my_coop = 1 if history.my_actions[r_idx] else 0
            opp_coops = np.sum(history.opponent_actions[r_idx, :])
            total_cooperators_history.append(my_coop + opp_coops)
        avg_coop_count = np.mean(total_cooperators_history) if total_cooperators_history else 0
        recent_coop_count = total_cooperators_history[-1] if total_cooperators_history else 0
        opp_coop_rates = np.mean(history.opponent_actions, axis=0) if rounds_played > 0 else np.zeros(self.n - 1)
        my_coop_rate = np.mean(history.my_actions) if rounds_played > 0 else 0
        if current_round == self.r - 1:
            expected_others_cooperating = np.sum(opp_coop_rates)
            if expected_others_cooperating >= self.m:
                return Action.D
            elif expected_others_cooperating >= self.m - 1:
                if self.k > 1.5:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        if self.n == 2 and self.m == 2:
            return Action.C
        if recent_coop_count <= (1 if history.my_actions[-1] else 0):
            return Action.D
        rounds_threshold_met = sum((1 for c in total_cooperators_history if c >= self.m))
        if rounds_threshold_met == rounds_played and rounds_played >= 2:
            return Action.D
        std_coop = np.std(total_cooperators_history) if len(total_cooperators_history) > 1 else 0
        if std_coop > 1.5:
            if recent_coop_count >= self.m:
                return Action.D
            else:
                if random.random() < 0.4:
                    return Action.C
                return Action.D
        if avg_coop_count >= self.m + 1:
            return Action.D
        if self.m - 0.5 <= avg_coop_count <= self.m + 0.5:
            all_coop_rates = list(opp_coop_rates) + [my_coop_rate]
            all_coop_rates_sorted = sorted(all_coop_rates, reverse=True)
            my_rank = all_coop_rates_sorted.index(my_coop_rate) + 1
            if my_rank <= self.m:
                return Action.C
            else:
                return Action.D
        if avg_coop_count < self.m - 0.5:
            if recent_coop_count >= self.m - 1:
                return Action.C
            elif self.r - current_round <= 3:
                return Action.D
            else:
                coop_prob = self.m / self.n
                if self.k > 2:
                    coop_prob += 0.1
                if random.random() < coop_prob:
                    return Action.C
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_8(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that aims to free-ride on cooperators
    while ensuring the threshold is met just often enough to collect rewards.
    Defects heavily in early and late game, cooperates only when pivotal.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None or current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        n_opponents = self.n - 1
        completed_rounds = history.round_number
        reliable_count = 0
        for player_idx in range(n_opponents):
            player_coop_count = np.sum(history.opponent_actions[:, player_idx])
            coop_rate = player_coop_count / completed_rounds
            if coop_rate >= 0.6:
                reliable_count += 1
        last_round_opponent_coops = np.sum(history.opponent_actions[-1, :])
        my_last_action = history.my_actions[-1]
        last_round_total_coops = last_round_opponent_coops + (1 if my_last_action else 0)
        last_threshold_met = last_round_total_coops >= self.m
        if current_round == self.r - 2:
            if reliable_count >= self.m:
                return Action.D
            elif reliable_count == self.m - 1:
                prob = 0.4
                if not last_threshold_met:
                    prob += 0.2
                return Action.C if random.random() < prob else Action.D
            else:
                return Action.D
        if reliable_count >= self.m:
            return Action.D
        if reliable_count == self.m - 1:
            rounds_remaining = self.r - current_round
            pivot_probability = min(0.7, rounds_remaining / self.r)
            if not last_threshold_met:
                pivot_probability += 0.2
            pivot_probability = min(1.0, pivot_probability)
            return Action.C if random.random() < pivot_probability else Action.D
        if current_round <= self.r / 3 and last_round_opponent_coops >= self.m - 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_9(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that free-rides on others' cooperation
    while ensuring the threshold is met just often enough to collect rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.collapse_prevention_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None or current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        n_completed_rounds = history.round_number
        opponent_coop_rates = np.mean(history.opponent_actions, axis=0)
        threshold_met_count = 0
        for t in range(n_completed_rounds):
            total_coop = int(history.my_actions[t]) + np.sum(history.opponent_actions[t, :])
            if total_coop >= self.m:
                threshold_met_count += 1
        threshold_met_rate = threshold_met_count / n_completed_rounds if n_completed_rounds > 0 else 0
        predicted_cooperators = 0.0
        for i in range(len(opponent_coop_rates)):
            rate = opponent_coop_rates[i]
            if rate > 0.7:
                predicted_cooperators += 0.9
            else:
                predicted_cooperators += rate
        rounds_remaining = self.r - current_round
        middle_start = self.r // 3
        middle_end = 2 * self.r // 3
        if middle_start <= current_round <= middle_end:
            if threshold_met_rate < 0.3 and self.collapse_prevention_rounds == 0:
                self.collapse_prevention_rounds = 2
        if self.collapse_prevention_rounds > 0:
            self.collapse_prevention_rounds -= 1
            if random.random() < 0.4:
                return Action.C
        defection_multiplier = 1.3 if current_round == self.r - 2 else 1.0
        if self.n == self.m:
            return Action.D
        last_round_coop = int(history.my_actions[-1]) + np.sum(history.opponent_actions[-1, :])
        if last_round_coop == 0:
            return Action.D
        if threshold_met_rate == 1.0 and n_completed_rounds >= 2:
            return Action.D
        if predicted_cooperators >= self.m:
            return Action.D
        elif predicted_cooperators >= self.m - 1 and predicted_cooperators < self.m:
            if threshold_met_rate < 0.5:
                return Action.C
            else:
                defect_prob = min(0.7 * defection_multiplier, 1.0)
                if random.random() < defect_prob:
                    return Action.D
                else:
                    return Action.C
        else:
            gap = self.m - 1 - predicted_cooperators
            if gap <= 2 and rounds_remaining > self.r / 3:
                if self.k > 3:
                    return Action.C
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_10(BaseStrategy):
    """
    Threshold Exploiter: An exploitative strategy that free-rides when possible,
    cooperates when pivotal, and defects when cooperation is hopeless.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.threshold_met_while_defecting = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        current_round = state.round_number
        if current_round == r - 1:
            return Action.D
        if history is None:
            if random.random() < (n - m) / n:
                return Action.D
            else:
                return Action.C
        rounds_played = history.round_number
        if rounds_played > 0:
            my_last_action = history.my_actions[-1]
            if not my_last_action:
                self.consecutive_defections += 1
                total_coop_last = int(my_last_action) + np.sum(history.opponent_actions[-1, :])
                if total_coop_last >= m:
                    self.threshold_met_while_defecting += 1
            else:
                self.consecutive_defections = 0
                self.threshold_met_while_defecting = 0
        window = min(3, rounds_played)
        n_opponents = history.opponent_actions.shape[1]
        expected_others_cooperating = 0.0
        for j in range(n_opponents):
            recent_actions = history.opponent_actions[-window:, j]
            coop_rate = np.mean(recent_actions)
            expected_others_cooperating += coop_rate
        if n == 2 and m == 2:
            if current_round < r - 1:
                return Action.C
            else:
                return Action.D
        if m == n - 1:
            for j in range(n_opponents):
                defection_rate = 1 - np.mean(history.opponent_actions[:, j])
                if defection_rate > 0.8:
                    return Action.D
        if rounds_played >= 3:
            threshold_met_count = 0
            for t in range(min(3, rounds_played)):
                total_coop = int(history.my_actions[t]) + np.sum(history.opponent_actions[t, :])
                if total_coop >= m:
                    threshold_met_count += 1
            if threshold_met_count == 0:
                return Action.D
        threshold_adjustment = 0.0
        if k > 3:
            threshold_adjustment = 0.5
        if self.consecutive_defections >= 3 and self.threshold_met_while_defecting >= 3:
            if random.random() < 0.3:
                self.consecutive_defections = 0
                self.threshold_met_while_defecting = 0
                return Action.C
        upper_threshold = m + 0.5 - threshold_adjustment
        lower_threshold = m - 1.5 - threshold_adjustment
        if expected_others_cooperating >= upper_threshold:
            return Action.D
        elif expected_others_cooperating >= lower_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_11(BaseStrategy):
    """
    Threshold Freerider: An exploitative strategy that aims to freeride on others' cooperation
    while contributing just enough to prevent collective failure when necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        rounds_remaining = self.r - current_round
        if current_round == self.r - 1:
            return self._last_round_decision(history)
        expected_cooperators = self._estimate_cooperators_without_me(history)
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators >= self.m - 1:
            return self._pivotal_decision(history, rounds_remaining)
        else:
            return self._unlikely_threshold_decision(expected_cooperators)

    def _calculate_weighted_rate(self, opponent_history: np.ndarray, decay: float=0.7) -> float:
        """Calculate weighted cooperation rate with more recent rounds weighted higher."""
        if len(opponent_history) == 0:
            return 0.5
        n_rounds = len(opponent_history)
        weights = np.array([decay ** (n_rounds - 1 - i) for i in range(n_rounds)])
        weight_sum = np.sum(weights)
        if weight_sum == 0:
            return 0.5
        weighted_coop = np.sum(opponent_history * weights) / weight_sum
        return weighted_coop

    def _estimate_cooperators_without_me(self, history: PlayerHistory) -> float:
        """Estimate how many opponents will cooperate this round."""
        n_opponents = self.n - 1
        expected = 0.0
        for i in range(n_opponents):
            opponent_history = history.opponent_actions[:, i]
            if len(opponent_history) > 0:
                weighted_rate = self._calculate_weighted_rate(opponent_history, decay=0.7)
                expected += weighted_rate
            else:
                expected += 0.5
        return expected

    def _get_recent_success_rate(self, history: PlayerHistory) -> float:
        """Calculate the rate at which threshold was met in the last 3 rounds."""
        n_rounds = len(history.my_actions)
        lookback = min(3, n_rounds)
        if lookback == 0:
            return 0.5
        successes = 0
        for i in range(n_rounds - lookback, n_rounds):
            my_coop = 1 if history.my_actions[i] else 0
            opponent_coops = np.sum(history.opponent_actions[i, :])
            total_coops = my_coop + opponent_coops
            if total_coops >= self.m:
                successes += 1
        return successes / lookback

    def _pivotal_decision(self, history: PlayerHistory, rounds_remaining: int) -> Action:
        """Decision when I might be the deciding vote."""
        recent_success_rate = self._get_recent_success_rate(history)
        if recent_success_rate >= 0.67:
            return Action.D
        elif rounds_remaining <= 2:
            return Action.C
        else:
            fair_share = self.m / self.n
            if random.random() < fair_share * 0.8:
                return Action.C
            else:
                return Action.D

    def _last_round_decision(self, history: PlayerHistory) -> Action:
        """Decision for the last round - pure exploitation."""
        expected_cooperators = self._estimate_cooperators_without_me(history)
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators >= self.m - 1:
            if expected_cooperators < self.m - 0.3:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

    def _unlikely_threshold_decision(self, expected: float) -> Action:
        """Decision when threshold is unlikely to be met."""
        gap = self.m - expected - 1
        if gap >= 2:
            return Action.D
        elif random.random() < 0.2:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_12(BaseStrategy):
    """
    Threshold Vulture: An exploitative strategy that free-rides on others' cooperation
    whenever possible while contributing just enough to ensure the threshold is met
    when it's at risk. Defects when safe to free-ride or when cooperation is futile.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.decay_factor = 0.8
        self.threshold_miss_count = 0
        self.threshold_met_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            expected_others = (self.n - 1) * 0.5
            if expected_others >= self.m:
                return Action.D
            elif expected_others < self.m - 1:
                return Action.D
            else:
                return Action.C
        rounds_played = history.round_number
        n_opponents = self.n - 1
        opponent_probs = []
        for i in range(n_opponents):
            weighted_coop = 0.0
            weight_sum = 0.0
            for t in range(rounds_played):
                weight = self.decay_factor ** (rounds_played - 1 - t)
                if history.opponent_actions[t, i]:
                    weighted_coop += weight
                weight_sum += weight
            if weight_sum > 0:
                p_i = weighted_coop / weight_sum
            else:
                p_i = 0.5
            opponent_probs.append(p_i)
        last_round_cooperators = sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
        if last_round_cooperators >= self.m:
            self.threshold_met_count += 1
        else:
            self.threshold_miss_count += 1
        expected_others = sum(opponent_probs)
        variance = sum((p * (1 - p) for p in opponent_probs))
        std_dev = math.sqrt(variance) if variance > 0 else 0
        base_margin = 0.5
        if self.threshold_miss_count > self.threshold_met_count:
            safety_margin = base_margin * 0.5
        elif self.threshold_met_count > 2 * self.threshold_miss_count:
            safety_margin = base_margin * 1.5
        else:
            safety_margin = base_margin
        is_last_round = state.round_number == self.r - 1
        if is_last_round:
            if expected_others >= self.m:
                return Action.D
            elif expected_others < self.m - 1:
                return Action.D
            else:
                return Action.C if self.k > 1 else Action.D
        if std_dev > 0:
            z_threshold = (self.m - expected_others) / std_dev
            z_pivotal = (self.m - 1 - expected_others) / std_dev

            def normal_cdf(z):
                return 0.5 * (1 + math.erf(z / math.sqrt(2)))
            prob_threshold_met = 1 - normal_cdf(z_threshold)
            prob_pivotal = normal_cdf(z_pivotal + 0.5 / std_dev) - normal_cdf(z_pivotal - 0.5 / std_dev) if std_dev > 0.1 else 0.0
        else:
            prob_threshold_met = 1.0 if expected_others >= self.m else 0.0
            prob_pivotal = 1.0 if abs(expected_others - (self.m - 1)) < 0.5 else 0.0
        ev_defect = 1 + self.k * prob_threshold_met
        ev_cooperate = 0 + self.k * (prob_threshold_met + prob_pivotal)
        if expected_others >= self.m + safety_margin * std_dev:
            return Action.D
        elif expected_others < self.m - 1 - safety_margin * std_dev:
            return Action.D
        elif ev_defect >= ev_cooperate:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_13(BaseStrategy):
    """
    Threshold Vulture: An exploitative strategy that free-rides whenever possible
    while ensuring the threshold is met just often enough to collect rewards.
    Defects by default, cooperates only when pivotal.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return self._first_round_decision()
        if current_round == self.r - 1:
            return Action.D
        reliable_cooperators, reliable_defectors, swing_players = self._classify_players(history)
        n_reliable_coop = len(reliable_cooperators)
        n_reliable_def = len(reliable_defectors)
        n_swing = len(swing_players)
        if n_reliable_coop >= self.m:
            return Action.D
        if n_reliable_coop + n_swing < self.m - 1:
            return Action.D
        shortfall = self.m - n_reliable_coop
        if shortfall == 1 and n_swing == 0:
            p_coop = min(0.6, self.k / (self.k + 2))
            if random.random() < p_coop:
                return Action.C
            return Action.D
        if n_swing >= shortfall:
            p_coop = max(0.1, (shortfall - 1) / n_swing) if n_swing > 0 else 0.1
            if random.random() < p_coop:
                return Action.C
            return Action.D
        if shortfall > n_swing / 2:
            return Action.C
        if current_round >= 0.8 * self.r:
            if random.random() < 0.7:
                return Action.D
        last_round_coop = np.sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
        if last_round_coop < self.m:
            return Action.D
        if last_round_coop == self.m:
            if random.random() < 0.3:
                return Action.C
            return Action.D
        return Action.D

    def _first_round_decision(self) -> Action:
        if self.m >= self.n - 1:
            return Action.C
        if self.k >= 3:
            if random.random() < 0.4:
                return Action.C
            return Action.D
        return Action.D

    def _classify_players(self, history: PlayerHistory):
        """
        Classify each opponent into reliable cooperator, reliable defector, or swing player.
        """
        n_rounds_played = history.round_number
        n_opponents = history.opponent_actions.shape[1]
        reliable_cooperators = []
        reliable_defectors = []
        swing_players = []
        for player_idx in range(n_opponents):
            player_actions = history.opponent_actions[:, player_idx]
            coop_rate = np.mean(player_actions)
            if coop_rate >= 0.7:
                reliable_cooperators.append(player_idx)
            elif coop_rate <= 0.3:
                reliable_defectors.append(player_idx)
            else:
                swing_players.append(player_idx)
        return (reliable_cooperators, reliable_defectors, swing_players)

class Strategy_EXPLOITATIVE_14(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that free-rides when possible,
    only cooperates when pivotal, and exploits reliable cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.defect_boost = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None or current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        n_opponents = self.n - 1
        rounds_played = history.round_number
        opponent_coop_rates = []
        for i in range(n_opponents):
            coop_count = np.sum(history.opponent_actions[:, i])
            rate = coop_count / rounds_played
            opponent_coop_rates.append(rate)
        predicted_cooperators = sum(opponent_coop_rates)
        sucker_count = sum((1 for rate in opponent_coop_rates if rate > 0.8))
        threshold_met_count = 0
        for r_idx in range(rounds_played):
            total_coop = np.sum(history.opponent_actions[r_idx, :])
            if history.my_actions[r_idx]:
                total_coop += 1
            if total_coop >= self.m:
                threshold_met_count += 1
        threshold_met_rate = threshold_met_count / rounds_played
        last_round_idx = rounds_played - 1
        if history.my_actions[last_round_idx]:
            last_round_total_coop = np.sum(history.opponent_actions[last_round_idx, :]) + 1
            if last_round_total_coop < self.m:
                self.defect_boost = min(self.defect_boost + 0.3, 0.9)
        else:
            self.defect_boost = max(0.0, self.defect_boost - 0.1)
        if self.n == self.m:
            return Action.C
        if self.m == 2 and self.n > 4:
            if predicted_cooperators >= 2:
                return Action.D
        if rounds_played >= 3 and threshold_met_rate == 0:
            return Action.D
        if sucker_count >= self.m:
            return Action.D
        if predicted_cooperators >= self.m:
            return Action.D
        elif predicted_cooperators >= self.m - 1:
            if threshold_met_rate > 0.5:
                if random.random() < 0.3 + self.defect_boost:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.C
        elif predicted_cooperators >= self.m - 1.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_15(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that free-rides whenever possible
    while ensuring the collective threshold is still met. Aims to be among defectors
    when threshold is just barely met to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        n_opponents = self.n - 1
        if current_round == self.r - 1:
            return Action.D
        rounds_played = history.round_number
        reliability = np.zeros(n_opponents)
        for i in range(n_opponents):
            coop_count = np.sum(history.opponent_actions[:, i])
            reliability[i] = coop_count / rounds_played
        expected_coop = np.sum(reliability)
        if rounds_played >= 3:
            sucker_count = np.sum(reliability > 0.8)
        else:
            sucker_count = 0
        if sucker_count >= self.m:
            return Action.D
        last_two_failed = False
        if rounds_played >= 2:
            for t in range(-2, 0):
                opponent_coops = np.sum(history.opponent_actions[t, :])
                my_coop = 1 if history.my_actions[t] else 0
                total_coops = opponent_coops + my_coop
                if total_coops < self.m:
                    if t == -2:
                        last_two_failed = True
                    elif last_two_failed:
                        last_two_failed = True
                    else:
                        last_two_failed = False
                else:
                    last_two_failed = False
        if rounds_played >= 2:
            failures = 0
            for t in range(max(0, rounds_played - 2), rounds_played):
                opponent_coops = np.sum(history.opponent_actions[t, :])
                my_coop = 1 if history.my_actions[t] else 0
                total_coops = opponent_coops + my_coop
                if total_coops < self.m:
                    failures += 1
            last_two_failed = failures >= 2
        if last_two_failed and current_round < self.r - 2:
            return Action.C
        if self.n == self.m:
            return Action.C
        if expected_coop >= self.m:
            return Action.D
        elif expected_coop >= self.m - 1:
            prob_cooperate = self.m - expected_coop
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            if expected_coop >= self.m - 1.5:
                return Action.C
            return Action.D

class Strategy_EXPLOITATIVE_16(BaseStrategy):
    """
    Threshold Stalker: An exploitative strategy that aims to free-ride on others'
    cooperation while only cooperating when pivotal to reaching the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None or current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        n_opponents = self.n - 1
        rounds_played = history.round_number
        coop_rates = []
        for i in range(n_opponents):
            opponent_history = history.opponent_actions[:, i]
            coop_rate = np.mean(opponent_history)
            coop_rates.append(coop_rate)
        expected_coop = sum(coop_rates)
        reliable_count = sum((1 for rate in coop_rates if rate > 0.7))
        if reliable_count >= self.m:
            return Action.D
        if expected_coop >= self.m:
            return Action.D
        if expected_coop < self.m - 1.5:
            return Action.D
        last_round_coop = np.sum(history.opponent_actions[-1, :])
        my_last_action = history.my_actions[-1]
        total_last_coop = last_round_coop + (1 if my_last_action else 0)
        if total_last_coop == 0:
            return Action.D
        if reliable_count == self.m - 1 and rounds_played >= 2:
            if not history.my_actions[-1] and (not history.my_actions[-2]):
                return Action.C
        if expected_coop >= self.m - 1:
            pivot_prob = self.m - expected_coop
            if current_round >= self.r - 2:
                pivot_prob *= 0.5
            pivot_prob = max(0, min(1, pivot_prob))
            if random.random() < pivot_prob:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_17(BaseStrategy):
    """
    Calculated Parasite: An exploitative strategy that free-rides when possible
    and cooperates only when pivotal to reaching the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            if self.m <= self.n / 2:
                return Action.D
            else:
                return Action.C
        current_round = state.round_number
        total_rounds = self.r
        n_opponents = self.n - 1
        n_completed_rounds = history.round_number
        coop_rates = np.mean(history.opponent_actions, axis=0) if n_completed_rounds > 0 else np.zeros(n_opponents)
        expected_coops = np.sum(coop_rates)
        reliable_cooperators = np.sum(coop_rates > 0.7)
        last_round_opponent_coops = np.sum(history.opponent_actions[-1, :])
        my_last_action = history.my_actions[-1]
        last_round_coops = last_round_opponent_coops + (1 if my_last_action else 0)
        total_coops_per_round = np.sum(history.opponent_actions, axis=1) + history.my_actions.astype(int)
        threshold_met_rate = np.mean(total_coops_per_round >= self.m)
        early_end = total_rounds / 3
        middle_end = 2 * total_rounds / 3
        if current_round == total_rounds - 1:
            if reliable_cooperators >= self.m:
                return Action.D
            elif reliable_cooperators == self.m - 1 and self.k > 2:
                return Action.C
            else:
                return Action.D
        if current_round < early_end:
            if last_round_coops >= self.m:
                return Action.D
            elif last_round_coops == self.m - 1:
                return Action.C if random.random() < 0.5 else Action.D
            else:
                return Action.C
        if current_round < middle_end:
            if expected_coops >= self.m + 0.5:
                return Action.D
            elif expected_coops >= self.m - 0.5:
                prob_coop = self.m - expected_coops + 0.5
                prob_coop = max(0, min(1, prob_coop))
                return Action.C if random.random() < prob_coop else Action.D
            elif reliable_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if expected_coops >= self.m:
            return Action.D
        elif expected_coops >= self.m - 1 and threshold_met_rate > 0.5:
            return Action.C if random.random() < 0.3 else Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_18(BaseStrategy):
    """
    Threshold Vulture: An exploitative strategy that free-rides whenever possible
    while contributing only when pivotal to secure the threshold bonus.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            expected_cooperators = (self.n - 1) * 0.5
            if expected_cooperators >= self.m:
                return Action.D
            elif expected_cooperators >= self.m - 1:
                return Action.C
            else:
                if self.m > (self.n - 1) * 0.6:
                    return Action.C
                return Action.D
        current_round = state.round_number
        rounds_remaining = self.r - current_round
        n_opponents = self.n - 1
        opponent_coop_rates = []
        for i in range(n_opponents):
            coop_count = np.sum(history.opponent_actions[:, i])
            total_rounds = len(history.opponent_actions)
            rate = coop_count / total_rounds if total_rounds > 0 else 0.5
            opponent_coop_rates.append(rate)
        expected_cooperators = sum(opponent_coop_rates)
        coop_counts_per_round = np.sum(history.opponent_actions, axis=1)
        if len(coop_counts_per_round) > 1:
            uncertainty = max(1.0, np.std(coop_counts_per_round))
        else:
            uncertainty = 1.0
        reliable_cooperators = sum((1 for rate in opponent_coop_rates if rate >= 0.7))
        conditional_cooperators = sum((1 for rate in opponent_coop_rates if 0.3 <= rate < 0.7))
        free_riders = sum((1 for rate in opponent_coop_rates if rate < 0.3))
        if self.r > 1:
            round_progress = current_round / self.r
            if round_progress >= 0.8:
                round_discount = 0.3
            else:
                round_discount = 1.0 - 0.7 * (round_progress / 0.8) * 0.3
        else:
            round_discount = 0.3
        if rounds_remaining == 1:
            if expected_cooperators >= self.m:
                return Action.D
            elif expected_cooperators >= self.m - 1 and self.k > 1:
                return Action.C
            else:
                return Action.D
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators >= self.m - 1:
            if self.k > 1:
                if random.random() < round_discount:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        else:
            deficit = self.m - 1 - expected_cooperators
            potential_cooperators = reliable_cooperators + conditional_cooperators
            if potential_cooperators >= self.m - 1:
                prob_cooperate = max(0, min(1, 1 - deficit / uncertainty)) * round_discount * (self.k / (1 + self.k))
                if random.random() < prob_cooperate:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D

class Strategy_EXPLOITATIVE_19(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that aims to free-ride on cooperators
    while only cooperating when absolutely necessary to maintain the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        rounds_played = history.round_number
        last_round_opponent_coops = np.sum(history.opponent_actions[-1, :])
        my_last_action = history.my_actions[-1]
        last_round_total_coops = last_round_opponent_coops + (1 if my_last_action else 0)
        opponent_coop_rates = np.mean(history.opponent_actions, axis=0)
        reliable_opponent_coops = np.sum(opponent_coop_rates >= 0.5)
        total_actions = rounds_played * self.n
        total_coops = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        cooperation_rate = total_coops / total_actions if total_actions > 0 else 0
        consecutive_defections = 0
        for i in range(rounds_played - 1, -1, -1):
            if not history.my_actions[i]:
                consecutive_defections += 1
            else:
                break
        rounds_remaining = self.r - current_round
        i_defected_last = not my_last_action
        if self.n == self.m:
            return Action.D
        suckers = np.sum(opponent_coop_rates > 0.7)
        conditionals = np.sum((opponent_coop_rates >= 0.3) & (opponent_coop_rates <= 0.7))
        predicted_cooperators = suckers + 0.5 * conditionals
        if reliable_opponent_coops >= self.m:
            return Action.D
        if predicted_cooperators >= self.m:
            return Action.D
        if last_round_total_coops >= self.m:
            if i_defected_last:
                return Action.D
            else:
                return Action.D
        if last_round_total_coops == self.m - 1:
            if i_defected_last:
                if reliable_opponent_coops >= self.m - 1:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.D
        if last_round_total_coops < self.m - 1:
            threshold_rate = (self.m - 1) / self.n
            if cooperation_rate < threshold_rate:
                return Action.D
            elif rounds_remaining > self.r / 3 and consecutive_defections >= 2:
                return Action.C
            else:
                return Action.D
        if self.k > 3 and rounds_remaining > 2 and (predicted_cooperators >= self.m - 1):
            if consecutive_defections >= 3:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_20(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that aims to free-ride on others'
    cooperation while ensuring the threshold is met. Defects when others are likely
    to meet the threshold, cooperates only when pivotal and profitable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        n_opponents = self.n - 1
        rounds_played = history.round_number
        cooperation_rates = []
        for i in range(n_opponents):
            coop_count = np.sum(history.opponent_actions[:, i])
            cooperation_rates.append(coop_count / rounds_played)
        expected_coop_without_me = sum(cooperation_rates)
        recent_cooperators = np.sum(history.opponent_actions[-1, :])
        reliable_cooperators = sum((1 for rate in cooperation_rates if rate > 0.7))
        consistent_defectors = sum((1 for rate in cooperation_rates if rate < 0.3))
        if consistent_defectors >= n_opponents - self.m + 2:
            return Action.D
        if rounds_played >= 2:
            last_two_rounds_coop = [np.sum(history.opponent_actions[-1, :]), np.sum(history.opponent_actions[-2, :])]
            last_two_rounds_coop[0] += int(history.my_actions[-1])
            last_two_rounds_coop[1] += int(history.my_actions[-2])
            if last_two_rounds_coop[0] < self.m and last_two_rounds_coop[1] < self.m:
                return Action.C
        if current_round == self.r - 2:
            if expected_coop_without_me >= self.m - 0.5:
                return Action.D
            else:
                return Action.C
        if expected_coop_without_me >= self.m:
            return Action.D
        elif expected_coop_without_me >= self.m - 1:
            total_recent = recent_cooperators + int(history.my_actions[-1])
            if total_recent >= self.m:
                return Action.D
            else:
                prob_cooperate = (self.k - 1) / self.k
                if random.random() < prob_cooperate:
                    return Action.C
                else:
                    return Action.D
        else:
            potential_cooperators = n_opponents - consistent_defectors
            needed_beyond_expected = self.m - expected_coop_without_me - 1
            if potential_cooperators < needed_beyond_expected:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_21(BaseStrategy):
    """
    Exploitative Threshold Manipulator Strategy for Collective Risk Dilemma.
    
    Cooperates only when pivotal, exploits reliable cooperators, and defects
    aggressively in endgame scenarios.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if self.n == self.m:
            return Action.D
        if history is None or len(history.my_actions) == 0:
            p_coop = self.m / self.n
            return Action.C if random.random() < p_coop else Action.D
        n_opponents = self.n - 1
        num_completed_rounds = len(history.my_actions)
        recent_start = max(0, num_completed_rounds - 3)
        recent_opponent_actions = history.opponent_actions[recent_start:, :]
        if recent_opponent_actions.size > 0:
            coop_per_round = np.sum(recent_opponent_actions, axis=1)
            expected_others = np.mean(coop_per_round)
        else:
            expected_others = (self.m - 1) * n_opponents / self.n
        if expected_others >= self.m:
            p_coop = 0.1
        elif expected_others >= self.m - 1 and expected_others < self.m:
            p_coop = 0.7
        elif expected_others >= self.m - 2:
            p_coop = 0.4
        else:
            p_coop = 0.1
        if num_completed_rounds > 0:
            opponent_coop_rates = np.mean(history.opponent_actions, axis=0)
            reliable_count = np.sum(opponent_coop_rates > 0.7)
            reduction_factor = max(0.5, 1 - 0.1 * reliable_count)
            p_coop *= reduction_factor
        rounds_remaining = self.r - current_round - 1
        if rounds_remaining <= 2:
            p_coop *= 0.7
        k_adjustment = min(1.5, self.k / 2)
        p_coop *= k_adjustment
        if num_completed_rounds > 0:
            last_round_coops = np.sum(history.opponent_actions[-1, :])
            if last_round_coops == 0:
                p_coop = 0.05
            elif last_round_coops == self.m - 1:
                p_coop = max(p_coop, 0.8)
        if self.k <= 1.2:
            p_coop *= 0.5
        if self.k > self.n:
            p_coop = min(1.0, p_coop * 1.3)
        if self.m == 2 and self.n > 5:
            if num_completed_rounds > 0:
                last_round_coops = np.sum(history.opponent_actions[-1, :])
                if last_round_coops >= 2:
                    p_coop = 0.05
        p_coop = max(0.0, min(1.0, p_coop))
        return Action.C if random.random() < p_coop else Action.D

class Strategy_EXPLOITATIVE_23(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that free-rides on others' cooperation
    while ensuring the threshold is barely met, maximizing personal payoff through
    strategic defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        rounds_remaining = self.r - current_round - 1
        if current_round == self.r - 1:
            return Action.D
        end_game_threshold = max(1, self.r // 5)
        if rounds_remaining < end_game_threshold:
            return Action.D
        completed_rounds = history.round_number

        def get_total_coop(round_idx):
            my_coop = 1 if history.my_actions[round_idx] else 0
            others_coop = int(np.sum(history.opponent_actions[round_idx, :]))
            return my_coop + others_coop
        lookback = min(3, completed_rounds)
        recent_coop_values = [get_total_coop(completed_rounds - 1 - i) for i in range(lookback)]
        recent_coop = np.mean(recent_coop_values) if recent_coop_values else 0
        last_round = completed_rounds - 1
        my_last_action_was_coop = history.my_actions[last_round]
        others_cooperating_last = int(np.sum(history.opponent_actions[last_round, :]))
        lookback_others = min(3, completed_rounds)
        others_coop_history = [int(np.sum(history.opponent_actions[completed_rounds - 1 - i, :])) for i in range(lookback_others)]
        estimated_others_coop = np.mean(others_coop_history) if others_coop_history else 0
        if estimated_others_coop >= self.m:
            return Action.D
        if estimated_others_coop >= self.m - 1 and estimated_others_coop < self.m:
            if self.k > 1.5 and rounds_remaining > self.r // 4:
                return Action.C
            else:
                return Action.D
        if estimated_others_coop < self.m - 1:
            if completed_rounds >= 3:
                trend = int(np.sum(history.opponent_actions[last_round, :])) - int(np.sum(history.opponent_actions[last_round - 1, :]))
                if trend > 0 and estimated_others_coop >= self.m - 2:
                    return Action.C
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_24(BaseStrategy):
    """
    Threshold Freeloader: An exploitative strategy that estimates opponent cooperation
    rates and cooperates only when pivotal, while freeloading when others are likely
    to meet the threshold without us.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.freeloader_threshold = 0.6
        self.recent_successful_defections = 0

    def _binomial_pmf(self, k: int, n: int, p: float) -> float:
        """Calculate binomial probability mass function P(X = k)"""
        if p <= 0:
            return 1.0 if k == 0 else 0.0
        if p >= 1:
            return 1.0 if k == n else 0.0
        if k < 0 or k > n:
            return 0.0
        coeff = math.comb(n, k)
        return coeff * p ** k * (1 - p) ** (n - k)

    def _binomial_cdf_complement(self, k: int, n: int, p: float) -> float:
        """Calculate P(X >= k) for binomial distribution"""
        if p <= 0:
            return 1.0 if k <= 0 else 0.0
        if p >= 1:
            return 1.0 if k <= n else 0.0
        prob = 0.0
        for i in range(k, n + 1):
            prob += self._binomial_pmf(i, n, p)
        return prob

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == r - 1:
            return Action.D
        total_opponent_actions = history.opponent_actions.size
        total_cooperations = np.sum(history.opponent_actions)
        if total_opponent_actions > 0:
            p_coop = total_cooperations / total_opponent_actions
        else:
            p_coop = 0.5
        n_opponents = n - 1
        p_threshold_without_me = self._binomial_cdf_complement(m, n_opponents, p_coop)
        p_pivotal = self._binomial_pmf(m - 1, n_opponents, p_coop)
        if current_round >= 3:
            recent_rounds = min(3, current_round)
            successful_defections = 0
            for i in range(1, recent_rounds + 1):
                round_idx = current_round - i
                if round_idx >= 0:
                    my_action = history.my_actions[round_idx]
                    my_payoff = history.my_payoffs[round_idx]
                    if not my_action and my_payoff > 1.5:
                        successful_defections += 1
            if successful_defections >= 2:
                self.freeloader_threshold = 0.5
        collapse_adjustment = 0.0
        if current_round >= 2:
            for i in range(1, 3):
                round_idx = current_round - i
                if round_idx >= 0:
                    total_cooperators = np.sum(history.opponent_actions[round_idx]) + (1 if history.my_actions[round_idx] else 0)
                    if total_cooperators < m:
                        collapse_adjustment = 0.15
                        break
        if current_round >= 3:
            reliable_cooperators = 0
            for opp_idx in range(n_opponents):
                opp_coop_rate = np.mean(history.opponent_actions[:, opp_idx])
                if opp_coop_rate > 0.7:
                    reliable_cooperators += 1
            if reliable_cooperators >= m:
                return Action.D
        if p_threshold_without_me > self.freeloader_threshold:
            return Action.D
        elif p_pivotal > 0.3:
            return Action.C
        elif p_threshold_without_me < 0.2 and p_coop < m / n_opponents:
            return Action.D
        else:
            coop_prob = (m - 1) / n_opponents + collapse_adjustment
            coop_prob = min(1.0, max(0.0, coop_prob))
            if random.random() < coop_prob:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_25(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that identifies reliable cooperators
    and free-rides when safe, while cooperating just enough to maintain the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            if self.m <= self.n / 2:
                return Action.D
            else:
                return Action.C
        rounds_remaining = self.r - current_round - 1
        if current_round == self.r - 1:
            return Action.D
        n_opponents = self.n - 1
        completed_rounds = history.round_number
        coop_rates = []
        for i in range(n_opponents):
            opponent_coop_count = np.sum(history.opponent_actions[:, i])
            coop_rate = opponent_coop_count / completed_rounds
            coop_rates.append(coop_rate)
        reliable_count = sum((1 for rate in coop_rates if rate >= 0.7))
        expected_coops = sum(coop_rates)
        last_round_coops = np.sum(history.opponent_actions[-1, :])
        my_last_action = history.my_actions[-1]
        total_last_coops = last_round_coops + (1 if my_last_action else 0)
        threshold_met_last = total_last_coops >= self.m
        consecutive_failures = 0
        for t in range(completed_rounds - 1, -1, -1):
            round_coops = np.sum(history.opponent_actions[t, :]) + (1 if history.my_actions[t] else 0)
            if round_coops < self.m:
                consecutive_failures += 1
            else:
                break
        if expected_coops >= self.m + 0.5:
            return Action.D
        if self.m - 1 <= expected_coops < self.m + 0.5:
            pivot_probability = (self.m - expected_coops + 1) / 2
            time_discount = (rounds_remaining + 1) / self.r
            if random.random() < pivot_probability * time_discount:
                return Action.C
            else:
                return Action.D
        if not threshold_met_last:
            if consecutive_failures >= 2:
                return Action.D
            elif rounds_remaining > self.r / 3:
                return Action.C
            else:
                return Action.D
        if self.m == 2:
            check_rounds = min(3, completed_rounds)
            low_coop_rounds = 0
            for t in range(completed_rounds - check_rounds, completed_rounds):
                round_coops = np.sum(history.opponent_actions[t, :]) + (1 if history.my_actions[t] else 0)
                if round_coops < 2:
                    low_coop_rounds += 1
            if low_coop_rounds >= check_rounds:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_26(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that free-rides when others 
    will meet the threshold, cooperates only when pivotal, and manipulates 
    others into becoming reliable cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if len(history.my_actions) > 0:
            self.consecutive_defections = 0
            for i in range(len(history.my_actions) - 1, -1, -1):
                if not history.my_actions[i]:
                    self.consecutive_defections += 1
                else:
                    break
        n_opponents = history.opponent_actions.shape[1]
        player_coop_rates = []
        for i in range(n_opponents):
            coop_rate = np.mean(history.opponent_actions[:, i])
            player_coop_rates.append(coop_rate)
        predicted_cooperators = 0.0
        for rate in player_coop_rates:
            if rate >= 0.6:
                predicted_cooperators += 1.0
            elif rate >= 0.3:
                predicted_cooperators += 0.5
        semi_cooperators = sum((1 for rate in player_coop_rates if rate >= 0.2))
        rounds_played = len(history.my_actions)
        threshold_met_count = 0
        for t in range(rounds_played):
            total_coop = int(history.my_actions[t]) + sum(history.opponent_actions[t, :])
            if total_coop >= self.m:
                threshold_met_count += 1
        threshold_met_rate = threshold_met_count / rounds_played if rounds_played > 0 else 0
        coop_prob_modifier = 0.0
        if self.m >= self.n - 1:
            coop_prob_modifier += 0.2
        if self.k <= 1.5:
            coop_prob_modifier -= 0.3
        if self.k >= 3:
            coop_prob_modifier += 0.1
        if threshold_met_rate >= 0.7 and rounds_played >= 2:
            if predicted_cooperators >= self.m:
                return Action.D
        if threshold_met_rate <= 0.3 and rounds_played >= 2:
            if current_round >= self.r / 2:
                return Action.D
        if predicted_cooperators >= self.m:
            return Action.D
        if predicted_cooperators >= self.m - 1:
            pivot_probability = 0.7 * (self.r - current_round) / self.r + coop_prob_modifier
            pivot_probability = max(0, min(1, pivot_probability))
            if random.random() < pivot_probability:
                return Action.C
            else:
                return Action.D
        if predicted_cooperators + semi_cooperators >= self.m:
            return Action.C
        if self.consecutive_defections >= 2 and current_round < self.r - 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_27(BaseStrategy):
    """
    Threshold Vulture: An exploitative strategy that free-rides on others' cooperation
    while ensuring the threshold is met just often enough to collect rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        n_opponents = self.n - 1
        rounds_played = history.round_number
        cooperation_rates = np.zeros(n_opponents)
        for i in range(n_opponents):
            cooperation_rates[i] = np.mean(history.opponent_actions[:, i])
        predicted_cooperators = np.sum(cooperation_rates)

        def count_cooperators_in_round(round_idx):
            """Count total cooperators (including myself) in a given round."""
            my_coop = 1 if history.my_actions[round_idx] else 0
            opp_coop = np.sum(history.opponent_actions[round_idx, :])
            return my_coop + opp_coop
        collapse_detected = False
        if rounds_played >= 2:
            last_round_coop = count_cooperators_in_round(-1)
            second_last_coop = count_cooperators_in_round(-2)
            if last_round_coop < self.m and second_last_coop < self.m:
                collapse_detected = True
        if collapse_detected:
            if random.random() < 0.4:
                return Action.C
        if rounds_played >= 3:
            reliable_cooperators = np.sum(cooperation_rates > 0.7)
            if reliable_cooperators >= self.m:
                return Action.D
        if predicted_cooperators >= self.m:
            return Action.D
        elif predicted_cooperators >= self.m - 1:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_28(BaseStrategy):
    """
    Calculated Free-Rider: An exploitative strategy that defaults to defection
    and only cooperates when mathematically necessary to meet the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.n_opponents = self.n_players - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        rounds_played = history.round_number
        coop_counts = np.sum(history.opponent_actions, axis=0)
        coop_rates = coop_counts / rounds_played
        expected_other_coops = np.sum(coop_rates)
        variance = np.sum(coop_rates * (1 - coop_rates))
        sucker_count = np.sum(coop_rates > 0.8)
        if current_round == self.n_rounds - 1:
            if expected_other_coops >= self.m:
                return Action.D
            elif expected_other_coops >= self.m - 1 and self.k > 1:
                return Action.C
            else:
                return Action.D
        prob_threshold_without_me = self._calc_prob_at_least_m(coop_rates, self.m)
        if sucker_count >= self.m:
            return Action.D
        if expected_other_coops >= self.m + 0.5:
            return Action.D
        elif expected_other_coops >= self.m - 0.3:
            if rounds_played >= 2:
                last_round_coops = np.sum(history.opponent_actions[-1, :])
                prev_round_coops = np.sum(history.opponent_actions[-2, :])
                if last_round_coops < self.m and prev_round_coops < self.m:
                    return Action.C
            return Action.D
        elif expected_other_coops >= self.m - 1:
            if prob_threshold_without_me > 0.6:
                return Action.D
            else:
                return Action.C
        else:
            last_round_coops = np.sum(history.opponent_actions[-1, :])
            if last_round_coops == 0:
                return Action.D
            if self.m >= self.n_opponents:
                if prob_threshold_without_me > 0.3:
                    return Action.D
                else:
                    return Action.C
            return Action.D

    def _calc_prob_at_least_m(self, coop_rates: np.ndarray, m: int) -> float:
        """
        Calculate probability that at least m opponents cooperate.
        Uses normal approximation for large n, exact calculation for small n.
        """
        n = len(coop_rates)
        if n == 0:
            return 0.0 if m > 0 else 1.0
        expected = np.sum(coop_rates)
        variance = np.sum(coop_rates * (1 - coop_rates))
        if m > n:
            return 0.0
        if m <= 0:
            return 1.0
        if n > 10 and variance > 0:
            std = math.sqrt(variance)
            if std > 0:
                z = (m - 0.5 - expected) / std
                prob = 1.0 - self._normal_cdf(z)
                return max(0.0, min(1.0, prob))
        if n <= 10:
            return self._exact_prob_at_least_m(coop_rates, m)
        if expected >= m:
            return min(0.9, 0.5 + (expected - m) * 0.2)
        else:
            return max(0.1, 0.5 - (m - expected) * 0.2)

    def _exact_prob_at_least_m(self, coop_rates: np.ndarray, m: int) -> float:
        """Exact calculation using dynamic programming."""
        n = len(coop_rates)
        dp = np.zeros(n + 1)
        dp[0] = 1.0
        for i in range(n):
            new_dp = np.zeros(n + 1)
            p = coop_rates[i]
            for j in range(i + 2):
                if j > 0:
                    new_dp[j] += dp[j - 1] * p
                if j <= i:
                    new_dp[j] += dp[j] * (1 - p)
            dp = new_dp
        return np.sum(dp[m:])

    def _normal_cdf(self, z: float) -> float:
        """Approximation of standard normal CDF."""
        return 0.5 * (1 + math.erf(z / math.sqrt(2)))

class Strategy_EXPLOITATIVE_29(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that free-rides when the threshold
    is likely to be met without contribution, and cooperates only when pivotal.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round >= self.r - 1:
            return Action.D
        n_opponents = self.n - 1
        rounds_played = history.round_number
        if self.m >= self.n - 1:
            return Action.D
        if self.n == 2 and self.m == 2:
            return Action.D
        coop_probs = []
        for j in range(n_opponents):
            opponent_history = history.opponent_actions[:, j]
            total_coops = np.sum(opponent_history)
            overall_rate = total_coops / rounds_played
            recent_rounds = min(3, rounds_played)
            recent_coops = np.sum(opponent_history[-recent_rounds:])
            recent_rate = recent_coops / recent_rounds
            p_j = 0.4 * overall_rate + 0.6 * recent_rate
            coop_probs.append(p_j)
        expected_coop = sum(coop_probs)
        sucker_count = sum((1 for p in coop_probs if p > 0.8))
        if sucker_count >= self.m:
            return Action.D
        if rounds_played >= 3:
            threshold_met_streak = True
            my_defections = 0
            for t in range(-3, 0):
                round_coops = np.sum(history.opponent_actions[t, :])
                if history.my_actions[t]:
                    round_coops += 1
                else:
                    my_defections += 1
                if round_coops < self.m:
                    threshold_met_streak = False
                    break
            if threshold_met_streak and my_defections >= 2:
                return Action.D
        if np.sum(history.opponent_actions[-1, :]) == 0:
            return Action.D
        if expected_coop >= self.m + 0.5:
            return Action.D
        elif expected_coop >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_30(BaseStrategy):
    """
    Threshold Lurker: An exploitative strategy for the Collective Risk Dilemma.
    
    Core principles:
    1. Never be the sucker - avoid cooperating when enough others already will
    2. Avoid mutual destruction - cooperate only when pivotal
    3. Exploit predictable cooperators - free-ride on reliable contributors
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        n_opponents = self.n - 1
        rounds_played = history.round_number
        if self.n == 2 and self.m == 2:
            return Action.D
        if self.m >= self.n - 1:
            return Action.D
        opponent_coop_rates = []
        for i in range(n_opponents):
            opponent_history = history.opponent_actions[:, i]
            coop_rate = np.mean(opponent_history)
            opponent_coop_rates.append(coop_rate)
        reliable_cooperators = 0
        reliable_defectors = 0
        unpredictable_sum = 0.0
        for rate in opponent_coop_rates:
            if rate >= 0.7:
                reliable_cooperators += 1
            elif rate <= 0.3:
                reliable_defectors += 1
            else:
                unpredictable_sum += rate
        expected_C = reliable_cooperators * 0.85 + unpredictable_sum + reliable_defectors * 0.15

        def count_recent_failures(hist, lookback=3):
            failures = 0
            start = max(0, rounds_played - lookback)
            for r in range(start, rounds_played):
                my_coop = 1 if hist.my_actions[r] else 0
                opponent_coops = np.sum(hist.opponent_actions[r, :])
                total_coops = my_coop + opponent_coops
                if total_coops < self.m:
                    failures += 1
            return failures
        recent_failures = count_recent_failures(history)
        last_round_my_coop = history.my_actions[-1]
        last_round_opponent_coops = np.sum(history.opponent_actions[-1, :])
        last_round_total_coops = (1 if last_round_my_coop else 0) + last_round_opponent_coops
        last_round_success = last_round_total_coops >= self.m
        if expected_C >= self.m:
            return Action.D
        elif expected_C >= self.m - 1:
            if recent_failures >= 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_31(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that defects by default and only
    cooperates when strictly necessary to meet the threshold, maximizing free-riding
    opportunities while avoiding collective disaster when pivotal.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            threshold_ratio = self.m / self.n
            if threshold_ratio > 0.6:
                return Action.D
            else:
                if random.random() < 0.3:
                    return Action.C
                return Action.D
        n_opponents = self.n - 1
        rounds_played = history.round_number
        opponent_coop_rates = []
        for i in range(n_opponents):
            coop_count = np.sum(history.opponent_actions[:, i])
            opponent_coop_rates.append(coop_count / rounds_played)
        expected_others_coop = sum(opponent_coop_rates)
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        my_coop_count = np.sum(history.my_actions)
        my_coop_rate = my_coop_count / rounds_played
        avg_others_rate = np.mean(opponent_coop_rates) if opponent_coop_rates else 0.5
        if current_round == self.r - 1:
            if expected_others_coop >= self.m:
                return Action.D
            elif expected_others_coop >= self.m - 1 and expected_others_coop < self.m:
                return Action.C
            else:
                return Action.D
        if expected_others_coop >= self.m + 0.5:
            return Action.D
        if expected_others_coop < self.m - 1 - 0.3:
            return Action.D
        if self.m - 1 - 0.3 <= expected_others_coop < self.m + 0.5:
            if my_coop_rate > avg_others_rate + 0.15:
                return Action.D
            shortfall = self.m - expected_others_coop
            if shortfall <= 0:
                return Action.D
            elif shortfall <= 1:
                coop_probability = min(0.4, shortfall * 0.5)
                k_adjustment = min(1.5, self.k / 2)
                coop_probability = min(0.5, coop_probability * k_adjustment)
                if self.m > self.n / 2:
                    coop_probability = min(0.5, coop_probability * 1.2)
                if random.random() < coop_probability:
                    return Action.C
                return Action.D
            else:
                if last_round_cooperators >= self.m - 1:
                    if random.random() < 0.3:
                        return Action.C
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_32(BaseStrategy):
    """
    Exploitative "Threshold Parasite" strategy that maximizes free-riding
    by cooperating only when pivotal to meeting the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def _calculate_cooperation_probabilities(self, history, current_round, is_last_round):
        """Calculate cooperation probability for each opponent."""
        n_opponents = self.n - 1
        probs = []
        if history is None or current_round == 0:
            return [0.5] * n_opponents
        for j in range(n_opponents):
            opponent_history = history.opponent_actions[:, j]
            cooperations = np.sum(opponent_history)
            games_played = len(opponent_history)
            if is_last_round:
                raw_rate = cooperations / games_played
                p_j = max(0.0, raw_rate - 0.3)
            else:
                p_j = (cooperations + 1) / (games_played + 2)
            probs.append(p_j)
        return probs

    def _calculate_distribution(self, probs):
        """
        Calculate probability distribution of number of cooperating opponents
        using dynamic programming convolution.
        """
        n_opponents = len(probs)
        dp = [0.0] * (n_opponents + 1)
        dp[0] = 1.0
        for p in probs:
            new_dp = [0.0] * (n_opponents + 1)
            for i in range(n_opponents + 1):
                if dp[i] > 0:
                    new_dp[i] += dp[i] * (1 - p)
                    if i + 1 <= n_opponents:
                        new_dp[i + 1] += dp[i] * p
            dp = new_dp
        return dp

    def _count_reliable_cooperators(self, history):
        """Count opponents with cooperation rate > 80%."""
        if history is None:
            return 0
        n_opponents = self.n - 1
        reliable = 0
        games_played = history.round_number
        if games_played < 3:
            return 0
        for j in range(n_opponents):
            opponent_history = history.opponent_actions[:, j]
            coop_rate = np.mean(opponent_history)
            if coop_rate > 0.8:
                reliable += 1
        return reliable

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        is_last_round = current_round == self.r - 1
        if history is not None and history.round_number > 3:
            reliable_cooperators = self._count_reliable_cooperators(history)
            if reliable_cooperators >= self.m:
                return Action.D
        probs = self._calculate_cooperation_probabilities(history, current_round, is_last_round)
        dist = self._calculate_distribution(probs)
        n_opponents = self.n - 1
        P_meet_without_me = sum(dist[self.m:]) if self.m <= n_opponents else 0.0
        P_pivotal = dist[self.m - 1] if self.m - 1 <= n_opponents else 0.0
        E_defect = P_meet_without_me * (1 + self.k) + (1 - P_meet_without_me) * 1
        E_cooperate = (P_meet_without_me + P_pivotal) * self.k
        collapse_bonus = 0.0
        if history is not None and history.round_number > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            my_last_action = history.my_actions[-1]
            total_last_cooperators = last_round_cooperators + (1 if my_last_action else 0)
            if total_last_cooperators < self.m:
                collapse_bonus = 0.2 * self.k
        if E_cooperate + collapse_bonus > E_defect * 1.05:
            return Action.C
        else:
            return Action.D
